{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tianocore Edk2 PyTool Library (edk2toollib) This is a Tianocore maintained project consisting of a python library supporting UEFI firmware development. This package\u2019s intent is to provide an easy way to organize and share python code to facilitate reuse across environments, tools, and scripts. Inclusion of this package and dependency management is best managed using Pip/Pypi. This is a supplemental package and is not required to be used for edk2 builds. Current Status Host Type Toolchain Branch Build Status Test Status Code Coverage Linux Ubuntu 1804 Python 3.8.x master Windows Server 2019 Python 3.8.x master Current Release All release information is now tracked with Github tags , releases and milestones . Content The package contains classes and modules that can be used as the building blocks of tools that are relevant to UEFI firmware developers. These modules should attempt to provide generic support and avoid tightly coupling with specific use cases. It is expected these modules do not provide direct interaction with the user (through command line interfaces) but instead are intended to be wrapped in other scripts/tools which contains the specific usage and interface. Examples: File parsers for edk2 specific file types. These parse the file and provide an object for interacting with the content. UEFI specific services for encoding/decoding binary structures. UEFI defined values and interfaces for usage in python Python wrappers for other system cli tools ( signtool, catalog file generation, inf file generation, etc) Python utilities to provide consistent logging, command invocation, path resolution, etc License All content in this repository is licensed under BSD-2-Clause Plus Patent License . Usage NOTE: It is strongly recommended that you use python virtual environments. Virtual environments avoid changing the global python workspace and causing conflicting dependencies. Virtual environments are lightweight and easy to use. Learn more To install run pip install --upgrade edk2-pytool-library To use in your python code python from edk2toollib. < module > import < class > History This library and functionality was ported from Project Mu. For history and documentation prior to this see the original Project Mu project https://github.com/microsoft/mu_pip_python_library Contribution Process This project welcomes all types of contributions. For issues, bugs, and questions it is best to open a github issue . Code Contributions For code contributions this project leverages github pull requests. See github tutorials, help, and documentation for complete descriptions. For best success please follow the below process. Contributor opens an issue describing problem or new desired functionality Contributor forks repository in github Contributor creates branch for work in their fork Contributor makes code changes, writes relevant unit tests, authors documentation and release notes as necessary. Contributor runs tests locally Contributor submits PR to master branch of tianocore/edk2-pytool-library PR reviewers will provide feedback on change. If any modifications are required, contributor will make changes and push updates. PR automation will run and validate tests pass If all comments resolved, maintainers approved, and tests pass the PR will be squash merged and closed by the maintainers. Maintainers See the github team for more details. Documentation See the github repo docs folder","title":"Home"},{"location":"#tianocore-edk2-pytool-library-edk2toollib","text":"This is a Tianocore maintained project consisting of a python library supporting UEFI firmware development. This package\u2019s intent is to provide an easy way to organize and share python code to facilitate reuse across environments, tools, and scripts. Inclusion of this package and dependency management is best managed using Pip/Pypi. This is a supplemental package and is not required to be used for edk2 builds.","title":"Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"#current-status","text":"Host Type Toolchain Branch Build Status Test Status Code Coverage Linux Ubuntu 1804 Python 3.8.x master Windows Server 2019 Python 3.8.x master","title":"Current Status"},{"location":"#current-release","text":"All release information is now tracked with Github tags , releases and milestones .","title":"Current Release"},{"location":"#content","text":"The package contains classes and modules that can be used as the building blocks of tools that are relevant to UEFI firmware developers. These modules should attempt to provide generic support and avoid tightly coupling with specific use cases. It is expected these modules do not provide direct interaction with the user (through command line interfaces) but instead are intended to be wrapped in other scripts/tools which contains the specific usage and interface. Examples: File parsers for edk2 specific file types. These parse the file and provide an object for interacting with the content. UEFI specific services for encoding/decoding binary structures. UEFI defined values and interfaces for usage in python Python wrappers for other system cli tools ( signtool, catalog file generation, inf file generation, etc) Python utilities to provide consistent logging, command invocation, path resolution, etc","title":"Content"},{"location":"#license","text":"All content in this repository is licensed under BSD-2-Clause Plus Patent License .","title":"License"},{"location":"#usage","text":"NOTE: It is strongly recommended that you use python virtual environments. Virtual environments avoid changing the global python workspace and causing conflicting dependencies. Virtual environments are lightweight and easy to use. Learn more To install run pip install --upgrade edk2-pytool-library To use in your python code python from edk2toollib. < module > import < class >","title":"Usage"},{"location":"#history","text":"This library and functionality was ported from Project Mu. For history and documentation prior to this see the original Project Mu project https://github.com/microsoft/mu_pip_python_library","title":"History"},{"location":"#contribution-process","text":"This project welcomes all types of contributions. For issues, bugs, and questions it is best to open a github issue .","title":"Contribution Process"},{"location":"#code-contributions","text":"For code contributions this project leverages github pull requests. See github tutorials, help, and documentation for complete descriptions. For best success please follow the below process. Contributor opens an issue describing problem or new desired functionality Contributor forks repository in github Contributor creates branch for work in their fork Contributor makes code changes, writes relevant unit tests, authors documentation and release notes as necessary. Contributor runs tests locally Contributor submits PR to master branch of tianocore/edk2-pytool-library PR reviewers will provide feedback on change. If any modifications are required, contributor will make changes and push updates. PR automation will run and validate tests pass If all comments resolved, maintainers approved, and tests pass the PR will be squash merged and closed by the maintainers.","title":"Code Contributions"},{"location":"#maintainers","text":"See the github team for more details.","title":"Maintainers"},{"location":"#documentation","text":"See the github repo docs folder","title":"Documentation"},{"location":"developing/","text":"Developing Tianocore Edk2 PyTool Library (edk2toollib) Pre-Requisites Get the code cmd git clone https://github.com/tianocore/edk2-pytool-library.git Install development dependencies cmd pip install --upgrade -r requirements.txt Uninstall any copy of edk2-pytool-library cmd pip uninstall edk2-pytool-library Install from local source (run command from root of repo) cmd pip install -e . Testing Run a Basic Syntax/Lint Check (using flake8) and resolve any issues cmd flake8 edk2toollib INFO: Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run the BasicDevTests.py script to check file encoding, file naming, etc cmd BasicDevTests.py Run pytest with coverage data collected cmd pytest -v --junitxml=test.junit.xml --html=pytest_report.html --self-contained-html --cov=edk2toollib --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_report.html cov_html/index.html Conventions Shortlist File and folder names Use python defined Pep conventions. For example package, module, and class naming should follow PEP8 ( https://www.python.org/dev/peps/pep-0008/ ) Comments Docstring style comments should be added to each public function and class. *Existing code should be updated to be compliant as it is modified. New Module or Class When creating a new module or class it should be clearly defined for a single purpose and provide general purpose support. The module should be added to the package in which the interface is defined. For example for modules supporting interfaces defined in the UEFI specification it would be in the uefi package. If it is defined by EDK2 then it should be in the uefi.edk2 package. Documentation of the feature should be added to the docs/features folder in markdown format. The filename should be the package import path. For example for edk2toollib.logging.ansi_handler.py module the filename for documentation would be logging.ansi_handler.md . The content of this documentation should be focused on why. Docstrings within the module should describe functional parameters and usage info. Unit tests should be written in python unittest or pytest format. A test module should be added in the same folder or package as the module and the filename should be same as the module plus \u201c_test\u201d.","title":"Developing"},{"location":"developing/#developing-tianocore-edk2-pytool-library-edk2toollib","text":"","title":"Developing Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"developing/#pre-requisites","text":"Get the code cmd git clone https://github.com/tianocore/edk2-pytool-library.git Install development dependencies cmd pip install --upgrade -r requirements.txt Uninstall any copy of edk2-pytool-library cmd pip uninstall edk2-pytool-library Install from local source (run command from root of repo) cmd pip install -e .","title":"Pre-Requisites"},{"location":"developing/#testing","text":"Run a Basic Syntax/Lint Check (using flake8) and resolve any issues cmd flake8 edk2toollib INFO: Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run the BasicDevTests.py script to check file encoding, file naming, etc cmd BasicDevTests.py Run pytest with coverage data collected cmd pytest -v --junitxml=test.junit.xml --html=pytest_report.html --self-contained-html --cov=edk2toollib --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_report.html cov_html/index.html","title":"Testing"},{"location":"developing/#conventions-shortlist","text":"","title":"Conventions Shortlist"},{"location":"developing/#file-and-folder-names","text":"Use python defined Pep conventions. For example package, module, and class naming should follow PEP8 ( https://www.python.org/dev/peps/pep-0008/ )","title":"File and folder names"},{"location":"developing/#comments","text":"Docstring style comments should be added to each public function and class. *Existing code should be updated to be compliant as it is modified.","title":"Comments"},{"location":"developing/#new-module-or-class","text":"When creating a new module or class it should be clearly defined for a single purpose and provide general purpose support. The module should be added to the package in which the interface is defined. For example for modules supporting interfaces defined in the UEFI specification it would be in the uefi package. If it is defined by EDK2 then it should be in the uefi.edk2 package. Documentation of the feature should be added to the docs/features folder in markdown format. The filename should be the package import path. For example for edk2toollib.logging.ansi_handler.py module the filename for documentation would be logging.ansi_handler.md . The content of this documentation should be focused on why. Docstrings within the module should describe functional parameters and usage info. Unit tests should be written in python unittest or pytest format. A test module should be added in the same folder or package as the module and the filename should be same as the module plus \u201c_test\u201d.","title":"New Module or Class"},{"location":"publishing/","text":"Publishing Tianocore Edk2 PyTool Library (edk2toollib) The edk2toollib is published as a pypi (pip) module. The pip module is named edk2-pytool-library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here. Version Scheme Versioning follows: aa.bb.cc and is based on tags in git aa == Major version. Changes don\u2019t need to be backward compatible bb == Minor version. Significant new features. Backward compatibility generally maintained except when new feature is used. cc == Patch version. Bug fix or small optional feature. Backward compatibility maintained. Publishing Process NOTE: These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and checks. Update the readme.md Release Version History section with info on all important changes for this version. Remove the \u201c-dev\u201d tag from the version about to be released. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released and push tag. Tag format is v\\ .\\ .\\ Do the release process Install tools cmd pip install --upgrade -r requirements.publisher.txt Build a wheel cmd python setup.py sdist bdist_wheel Confirm wheel version is aligned with git tag cmd ConfirmVersionAndTag.py Publish the wheel/distribution to pypi cmd twine upload dist/*","title":"Publishing"},{"location":"publishing/#publishing-tianocore-edk2-pytool-library-edk2toollib","text":"The edk2toollib is published as a pypi (pip) module. The pip module is named edk2-pytool-library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here.","title":"Publishing Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"publishing/#version-scheme","text":"Versioning follows: aa.bb.cc and is based on tags in git aa == Major version. Changes don\u2019t need to be backward compatible bb == Minor version. Significant new features. Backward compatibility generally maintained except when new feature is used. cc == Patch version. Bug fix or small optional feature. Backward compatibility maintained.","title":"Version Scheme"},{"location":"publishing/#publishing-process","text":"NOTE: These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and checks. Update the readme.md Release Version History section with info on all important changes for this version. Remove the \u201c-dev\u201d tag from the version about to be released. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released and push tag. Tag format is v\\ .\\ .\\ Do the release process Install tools cmd pip install --upgrade -r requirements.publisher.txt Build a wheel cmd python setup.py sdist bdist_wheel Confirm wheel version is aligned with git tag cmd ConfirmVersionAndTag.py Publish the wheel/distribution to pypi cmd twine upload dist/*","title":"Publishing Process"},{"location":"using/","text":"Using Tianocore edk2 pytool library (edk2toollib) Installing NOTE: It is suggested to use python virtual environments to avoid dependency pollution and conflicts. Read More Install from pip pip install --upgrade edk2-pytool-library Using in python code from edk2toollib. < module > import < class >","title":"Using"},{"location":"using/#using-tianocore-edk2-pytool-library-edk2toollib","text":"","title":"Using Tianocore edk2 pytool library (edk2toollib)"},{"location":"using/#installing","text":"NOTE: It is suggested to use python virtual environments to avoid dependency pollution and conflicts. Read More Install from pip pip install --upgrade edk2-pytool-library","title":"Installing"},{"location":"using/#using-in-python-code","text":"from edk2toollib. < module > import < class >","title":"Using in python code"},{"location":"edk2toollib/","text":"Module edk2toollib View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.acpi edk2toollib.bin edk2toollib.gitignore_parser edk2toollib.log edk2toollib.tpm edk2toollib.uefi edk2toollib.utility_functions edk2toollib.utility_functions_test edk2toollib.windows","title":"Index"},{"location":"edk2toollib/#module-edk2toollib","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib"},{"location":"edk2toollib/#sub-modules","text":"edk2toollib.acpi edk2toollib.bin edk2toollib.gitignore_parser edk2toollib.log edk2toollib.tpm edk2toollib.uefi edk2toollib.utility_functions edk2toollib.utility_functions_test edk2toollib.windows","title":"Sub-modules"},{"location":"edk2toollib/bin/","text":"Module edk2toollib.bin View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Bin"},{"location":"edk2toollib/bin/#module-edk2toollibbin","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.bin"},{"location":"edk2toollib/gitignore_parser/","text":"Module edk2toollib.gitignore_parser View Source from pathlib import Path from os . path import dirname , abspath import re import os import collections \"\"\" gitignore parser configured to work for edk2-pytool-library \"\"\" # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ''' Original file is from https://github.com/mherrmann/gitignore_parser/blob/master/gitignore_parser.py sha hash: 31407327e4a10d122632c5f03c7a705b010e5fbd Original License: MIT License Copyright (c) 2018 Michael Herrmann Copyright (c) 2015 Steve Cook Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ''' def parse_gitignore_file ( full_path , base_dir = None ) : \"\"\" parse a gitignore file \"\"\" if base_dir is None : base_dir = dirname ( full_path ) with open ( full_path ) as ignore_file: lines = ignore_file . readlines () return parse_gitignore_lines ( lines , full_path , base_dir ) def parse_gitignore_lines ( lines : list , full_path: str , base_dir: str ) : \"\"\" parse a list of lines matching gitignore syntax \"\"\" counter = 0 rules = [] for line in lines : counter += 1 line = line . rstrip ( '\\n' ) rule = rule_from_pattern ( line , abspath ( base_dir ), source= ( full_path , counter )) if rule : rules . append ( rule ) return lambda file_path: any ( r . match ( file_path ) for r in rules ) def rule_from_pattern ( pattern , base_path = None , source = None ) : \"\"\" Take a .gitignore match pattern, such as \" *.py [ cod ] \" or \" **/*.bak \", and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. \"\"\" if base_path and base_path ! = abspath ( base_path ) : raise ValueError ( 'base_path must be absolute' ) # Store the exact pattern for our repr and string functions orig_pattern = pattern # Early returns follow # Discard comments and seperators if pattern . strip () == '' or pattern [ 0 ] == '#': return # Discard anything with more than two consecutive asterisks if pattern . find ( '***' ) > - 1 : return # Strip leading bang before examining double asterisks if pattern [ 0 ] == '!': negation = True pattern = pattern [ 1 : ] else : negation = False # Discard anything with invalid double - asterisks -- they can appear # at the start or the end , or be surrounded by slashes for m in re . finditer ( r'\\*\\*' , pattern ) : start_index = m . start () if ( start_index ! = 0 and start_index ! = len ( pattern ) - 2 and ( pattern [ start_index - 1 ] ! = '/' or pattern [ start_index + 2 ] ! = '/' )) : # noqa return # Special - casing '/' , which doesn't match any files or directories if pattern.rstrip() == '/': return directory_only = pattern[-1] == '/' # A slash is a sign that we're tied to the base_path of our rule # set . anchored = '/' in pattern [:- 1 ] if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ 0 ] == '*' and pattern [ 1 ] == '*': pattern = pattern [ 2 : ] anchored = False if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ - 1 ] == '/': pattern = pattern [:- 1 ] regex = fnmatch_pathname_to_regex ( pattern ) if anchored : regex = '' . join ([ '^' , regex ]) return IgnoreRule ( pattern = orig_pattern , regex = regex , negation = negation , directory_only = directory_only , anchored = anchored , base_path = Path ( base_path ) if base_path else None , source = source ) whitespace_re = re . compile ( r'(\\\\ )+$' ) IGNORE_RULE_FIELDS = [ 'pattern' , 'regex' , # Basic values 'negation' , 'directory_only' , 'anchored' , # Behavior flags 'base_path' , # Meaningful for gitignore - style behavior 'source' # ( file , line ) tuple for reporting ] class IgnoreRule ( collections . namedtuple ( 'IgnoreRule_' , IGNORE_RULE_FIELDS )) : def __ str__ ( self ) : return self . pattern def __ repr__ ( self ) : return '' . join ([ 'IgnoreRule(\\'', self.pattern, '\\')' ]) def match ( self , abs_path ) : matched = False if self . base_path: rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else : rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ) : rel_path = rel_path [ 2 : ] if re . search ( self . regex , rel_path ) : matched = True return matched # Frustratingly , python's fnmatch doesn't provide the FNM_PATHNAME # option that . gitignore's behavior depends on. def fnmatch_pathname_to_regex(pattern): \"\"\" Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style '*' and ' . ' wildcards. \"\"\" i, n = 0, len(pattern) seps = [re.escape(os.sep)] if os.altsep is not None: seps.append(re.escape(os.altsep)) seps_group = ' [ ' + ' | '.join(seps) + ' ] ' nonsep = r' [ ^ {}] '.format(' | '.join(seps)) res = [] while i < n: c = pattern[i] i += 1 if c == '*': try: if pattern[i] == '*': i += 1 res.append(' . *') if pattern[i] == '/': i += 1 res.append(''.join([seps_group, '?'])) else: res.append(''.join([nonsep, '*'])) except IndexError: res.append(''.join([nonsep, '*'])) elif c == '?': res.append(nonsep) elif c == '/': res.append(seps_group) elif c == ' [ ': j = i if j < n and pattern[j] == ' ! ': j += 1 if j < n and pattern[j] == ' ] ': j += 1 while j < n and pattern[j] != ' ] ': j += 1 if j >= n: res.append('\\\\ [ ') else: stuff = pattern[i:j].replace('\\\\', '\\\\\\\\') i = j + 1 if stuff[0] == ' ! ': stuff = ''.join(['^', stuff[1:]]) elif stuff[0] == '^': stuff = ''.join('\\\\' + stuff) res.append(' [{}] '.format(stuff)) else: res.append(re.escape(c)) res.insert(0, ' ( ?ms ) ') res.append(' $ ') return ' ' . join ( res ) Variables IGNORE_RULE_FIELDS whitespace_re Functions fnmatch_pathname_to_regex def fnmatch_pathname_to_regex ( pattern ) Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style \u2018*\u2019 and \u2018.\u2019 wildcards. View Source def fnmatch_pathname_to_regex ( pattern ) : \"\"\" Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style '*' and '.' wildcards. \"\"\" i , n = 0 , len ( pattern ) seps = [ re.escape(os.sep) ] if os . altsep is not None : seps . append ( re . escape ( os . altsep )) seps_group = '[' + '|' . join ( seps ) + ']' nonsep = r '[^{}]' . format ( '|' . join ( seps )) res = [] while i < n : c = pattern [ i ] i += 1 if c == '*' : try : if pattern [ i ] == '*' : i += 1 res . append ( '.*' ) if pattern [ i ] == '/' : i += 1 res . append ( '' . join ( [ seps_group, '?' ] )) else : res . append ( '' . join ( [ nonsep, '*' ] )) except IndexError : res . append ( '' . join ( [ nonsep, '*' ] )) elif c == '?' : res . append ( nonsep ) elif c == '/' : res . append ( seps_group ) elif c == '[' : j = i if j < n and pattern [ j ] == '!' : j += 1 if j < n and pattern [ j ] == ']' : j += 1 while j < n and pattern [ j ] != ']' : j += 1 if j >= n : res . append ( '\\\\[' ) else : stuff = pattern [ i:j ] . replace ( '\\\\' , '\\\\\\\\' ) i = j + 1 if stuff [ 0 ] == '!' : stuff = '' . join ( [ '^', stuff[1: ] ] ) elif stuff [ 0 ] == '^' : stuff = '' . join ( '\\\\' + stuff ) res . append ( '[{}]' . format ( stuff )) else : res . append ( re . escape ( c )) res . insert ( 0 , '(?ms)' ) res . append ( '$' ) return '' . join ( res ) parse_gitignore_file def parse_gitignore_file ( full_path , base_dir = None ) parse a gitignore file View Source def parse_gitignore_file ( full_path , base_dir = None ): \"\"\" parse a gitignore file \"\"\" if base_dir is None : base_dir = dirname ( full_path ) with open ( full_path ) as ignore_file : lines = ignore_file . readlines () return parse_gitignore_lines ( lines , full_path , base_dir ) parse_gitignore_lines def parse_gitignore_lines ( lines : list , full_path : str , base_dir : str ) parse a list of lines matching gitignore syntax View Source def parse_gitignore_lines ( lines : list , full_path : str , base_dir : str ): \"\"\" parse a list of lines matching gitignore syntax \"\"\" counter = 0 rules = [] for line in lines : counter += 1 line = line . rstrip ( '\\n' ) rule = rule_from_pattern ( line , abspath ( base_dir ), source = ( full_path , counter )) if rule : rules . append ( rule ) return lambda file_path : any ( r . match ( file_path ) for r in rules ) rule_from_pattern def rule_from_pattern ( pattern , base_path = None , source = None ) Take a .gitignore match pattern, such as \u201c .py[cod]\u201d or \u201c* /*.bak\u201d, and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. View Source def rule_from_pattern ( pattern , base_path = None , source = None ) : \"\"\" Take a .gitignore match pattern, such as \" *.py [ cod ] \" or \" **/*.bak \", and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. \"\"\" if base_path and base_path ! = abspath ( base_path ) : raise ValueError ( 'base_path must be absolute' ) # Store the exact pattern for our repr and string functions orig_pattern = pattern # Early returns follow # Discard comments and seperators if pattern . strip () == '' or pattern [ 0 ] == '#': return # Discard anything with more than two consecutive asterisks if pattern . find ( '***' ) > - 1 : return # Strip leading bang before examining double asterisks if pattern [ 0 ] == '!': negation = True pattern = pattern [ 1 : ] else : negation = False # Discard anything with invalid double - asterisks -- they can appear # at the start or the end , or be surrounded by slashes for m in re . finditer ( r'\\*\\*' , pattern ) : start_index = m . start () if ( start_index ! = 0 and start_index ! = len ( pattern ) - 2 and ( pattern [ start_index - 1 ] ! = '/' or pattern [ start_index + 2 ] ! = '/' )) : # noqa return # Special - casing '/' , which doesn't match any files or directories if pattern.rstrip() == '/': return directory_only = pattern[-1] == '/' # A slash is a sign that we're tied to the base_path of our rule # set . anchored = '/' in pattern [:- 1 ] if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ 0 ] == '*' and pattern [ 1 ] == '*': pattern = pattern [ 2 : ] anchored = False if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ - 1 ] == '/': pattern = pattern [:- 1 ] regex = fnmatch_pathname_to_regex ( pattern ) if anchored : regex = '' . join ([ '^' , regex ]) return IgnoreRule ( pattern = orig_pattern , regex = regex , negation = negation , directory_only = directory_only , anchored = anchored , base_path = Path ( base_path ) if base_path else None , source = source ) Classes IgnoreRule class IgnoreRule ( / , * args , ** kwargs ) IgnoreRule_(pattern, regex, negation, directory_only, anchored, base_path, source) View Source class IgnoreRule ( collections . namedtuple ( 'IgnoreRule_' , IGNORE_RULE_FIELDS )): def __str__ ( self ): return self . pattern def __repr__ ( self ): return '' . join ([ 'IgnoreRule(\\'' , self . pattern , '\\')' ]) def match ( self , abs_path ): matched = False if self . base_path: rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else: rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ): rel_path = rel_path [ 2 :] if re . search ( self . regex , rel_path ): matched = True return matched Ancestors (in MRO) edk2toollib.gitignore_parser.IgnoreRule_ builtins.tuple Instance variables anchored Alias for field number 4 base_path Alias for field number 5 directory_only Alias for field number 3 negation Alias for field number 2 pattern Alias for field number 0 regex Alias for field number 1 source Alias for field number 6 Methods count def count ( self , value , / ) Return number of occurrences of value. index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. match def match ( self , abs_path ) View Source def match ( self , abs_path ): matched = False if self . base_path : rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else : rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ): rel_path = rel_path [ 2 :] if re . search ( self . regex , rel_path ): matched = True return matched","title":"Gitignore parser"},{"location":"edk2toollib/gitignore_parser/#module-edk2toollibgitignore_parser","text":"View Source from pathlib import Path from os . path import dirname , abspath import re import os import collections \"\"\" gitignore parser configured to work for edk2-pytool-library \"\"\" # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ''' Original file is from https://github.com/mherrmann/gitignore_parser/blob/master/gitignore_parser.py sha hash: 31407327e4a10d122632c5f03c7a705b010e5fbd Original License: MIT License Copyright (c) 2018 Michael Herrmann Copyright (c) 2015 Steve Cook Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ''' def parse_gitignore_file ( full_path , base_dir = None ) : \"\"\" parse a gitignore file \"\"\" if base_dir is None : base_dir = dirname ( full_path ) with open ( full_path ) as ignore_file: lines = ignore_file . readlines () return parse_gitignore_lines ( lines , full_path , base_dir ) def parse_gitignore_lines ( lines : list , full_path: str , base_dir: str ) : \"\"\" parse a list of lines matching gitignore syntax \"\"\" counter = 0 rules = [] for line in lines : counter += 1 line = line . rstrip ( '\\n' ) rule = rule_from_pattern ( line , abspath ( base_dir ), source= ( full_path , counter )) if rule : rules . append ( rule ) return lambda file_path: any ( r . match ( file_path ) for r in rules ) def rule_from_pattern ( pattern , base_path = None , source = None ) : \"\"\" Take a .gitignore match pattern, such as \" *.py [ cod ] \" or \" **/*.bak \", and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. \"\"\" if base_path and base_path ! = abspath ( base_path ) : raise ValueError ( 'base_path must be absolute' ) # Store the exact pattern for our repr and string functions orig_pattern = pattern # Early returns follow # Discard comments and seperators if pattern . strip () == '' or pattern [ 0 ] == '#': return # Discard anything with more than two consecutive asterisks if pattern . find ( '***' ) > - 1 : return # Strip leading bang before examining double asterisks if pattern [ 0 ] == '!': negation = True pattern = pattern [ 1 : ] else : negation = False # Discard anything with invalid double - asterisks -- they can appear # at the start or the end , or be surrounded by slashes for m in re . finditer ( r'\\*\\*' , pattern ) : start_index = m . start () if ( start_index ! = 0 and start_index ! = len ( pattern ) - 2 and ( pattern [ start_index - 1 ] ! = '/' or pattern [ start_index + 2 ] ! = '/' )) : # noqa return # Special - casing '/' , which doesn't match any files or directories if pattern.rstrip() == '/': return directory_only = pattern[-1] == '/' # A slash is a sign that we're tied to the base_path of our rule # set . anchored = '/' in pattern [:- 1 ] if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ 0 ] == '*' and pattern [ 1 ] == '*': pattern = pattern [ 2 : ] anchored = False if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ - 1 ] == '/': pattern = pattern [:- 1 ] regex = fnmatch_pathname_to_regex ( pattern ) if anchored : regex = '' . join ([ '^' , regex ]) return IgnoreRule ( pattern = orig_pattern , regex = regex , negation = negation , directory_only = directory_only , anchored = anchored , base_path = Path ( base_path ) if base_path else None , source = source ) whitespace_re = re . compile ( r'(\\\\ )+$' ) IGNORE_RULE_FIELDS = [ 'pattern' , 'regex' , # Basic values 'negation' , 'directory_only' , 'anchored' , # Behavior flags 'base_path' , # Meaningful for gitignore - style behavior 'source' # ( file , line ) tuple for reporting ] class IgnoreRule ( collections . namedtuple ( 'IgnoreRule_' , IGNORE_RULE_FIELDS )) : def __ str__ ( self ) : return self . pattern def __ repr__ ( self ) : return '' . join ([ 'IgnoreRule(\\'', self.pattern, '\\')' ]) def match ( self , abs_path ) : matched = False if self . base_path: rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else : rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ) : rel_path = rel_path [ 2 : ] if re . search ( self . regex , rel_path ) : matched = True return matched # Frustratingly , python's fnmatch doesn't provide the FNM_PATHNAME # option that . gitignore's behavior depends on. def fnmatch_pathname_to_regex(pattern): \"\"\" Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style '*' and ' . ' wildcards. \"\"\" i, n = 0, len(pattern) seps = [re.escape(os.sep)] if os.altsep is not None: seps.append(re.escape(os.altsep)) seps_group = ' [ ' + ' | '.join(seps) + ' ] ' nonsep = r' [ ^ {}] '.format(' | '.join(seps)) res = [] while i < n: c = pattern[i] i += 1 if c == '*': try: if pattern[i] == '*': i += 1 res.append(' . *') if pattern[i] == '/': i += 1 res.append(''.join([seps_group, '?'])) else: res.append(''.join([nonsep, '*'])) except IndexError: res.append(''.join([nonsep, '*'])) elif c == '?': res.append(nonsep) elif c == '/': res.append(seps_group) elif c == ' [ ': j = i if j < n and pattern[j] == ' ! ': j += 1 if j < n and pattern[j] == ' ] ': j += 1 while j < n and pattern[j] != ' ] ': j += 1 if j >= n: res.append('\\\\ [ ') else: stuff = pattern[i:j].replace('\\\\', '\\\\\\\\') i = j + 1 if stuff[0] == ' ! ': stuff = ''.join(['^', stuff[1:]]) elif stuff[0] == '^': stuff = ''.join('\\\\' + stuff) res.append(' [{}] '.format(stuff)) else: res.append(re.escape(c)) res.insert(0, ' ( ?ms ) ') res.append(' $ ') return ' ' . join ( res )","title":"Module edk2toollib.gitignore_parser"},{"location":"edk2toollib/gitignore_parser/#variables","text":"IGNORE_RULE_FIELDS whitespace_re","title":"Variables"},{"location":"edk2toollib/gitignore_parser/#functions","text":"","title":"Functions"},{"location":"edk2toollib/gitignore_parser/#fnmatch_pathname_to_regex","text":"def fnmatch_pathname_to_regex ( pattern ) Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style \u2018*\u2019 and \u2018.\u2019 wildcards. View Source def fnmatch_pathname_to_regex ( pattern ) : \"\"\" Implements fnmatch style-behavior, as though with FNM_PATHNAME flagged; the path seperator will not match shell-style '*' and '.' wildcards. \"\"\" i , n = 0 , len ( pattern ) seps = [ re.escape(os.sep) ] if os . altsep is not None : seps . append ( re . escape ( os . altsep )) seps_group = '[' + '|' . join ( seps ) + ']' nonsep = r '[^{}]' . format ( '|' . join ( seps )) res = [] while i < n : c = pattern [ i ] i += 1 if c == '*' : try : if pattern [ i ] == '*' : i += 1 res . append ( '.*' ) if pattern [ i ] == '/' : i += 1 res . append ( '' . join ( [ seps_group, '?' ] )) else : res . append ( '' . join ( [ nonsep, '*' ] )) except IndexError : res . append ( '' . join ( [ nonsep, '*' ] )) elif c == '?' : res . append ( nonsep ) elif c == '/' : res . append ( seps_group ) elif c == '[' : j = i if j < n and pattern [ j ] == '!' : j += 1 if j < n and pattern [ j ] == ']' : j += 1 while j < n and pattern [ j ] != ']' : j += 1 if j >= n : res . append ( '\\\\[' ) else : stuff = pattern [ i:j ] . replace ( '\\\\' , '\\\\\\\\' ) i = j + 1 if stuff [ 0 ] == '!' : stuff = '' . join ( [ '^', stuff[1: ] ] ) elif stuff [ 0 ] == '^' : stuff = '' . join ( '\\\\' + stuff ) res . append ( '[{}]' . format ( stuff )) else : res . append ( re . escape ( c )) res . insert ( 0 , '(?ms)' ) res . append ( '$' ) return '' . join ( res )","title":"fnmatch_pathname_to_regex"},{"location":"edk2toollib/gitignore_parser/#parse_gitignore_file","text":"def parse_gitignore_file ( full_path , base_dir = None ) parse a gitignore file View Source def parse_gitignore_file ( full_path , base_dir = None ): \"\"\" parse a gitignore file \"\"\" if base_dir is None : base_dir = dirname ( full_path ) with open ( full_path ) as ignore_file : lines = ignore_file . readlines () return parse_gitignore_lines ( lines , full_path , base_dir )","title":"parse_gitignore_file"},{"location":"edk2toollib/gitignore_parser/#parse_gitignore_lines","text":"def parse_gitignore_lines ( lines : list , full_path : str , base_dir : str ) parse a list of lines matching gitignore syntax View Source def parse_gitignore_lines ( lines : list , full_path : str , base_dir : str ): \"\"\" parse a list of lines matching gitignore syntax \"\"\" counter = 0 rules = [] for line in lines : counter += 1 line = line . rstrip ( '\\n' ) rule = rule_from_pattern ( line , abspath ( base_dir ), source = ( full_path , counter )) if rule : rules . append ( rule ) return lambda file_path : any ( r . match ( file_path ) for r in rules )","title":"parse_gitignore_lines"},{"location":"edk2toollib/gitignore_parser/#rule_from_pattern","text":"def rule_from_pattern ( pattern , base_path = None , source = None ) Take a .gitignore match pattern, such as \u201c .py[cod]\u201d or \u201c* /*.bak\u201d, and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. View Source def rule_from_pattern ( pattern , base_path = None , source = None ) : \"\"\" Take a .gitignore match pattern, such as \" *.py [ cod ] \" or \" **/*.bak \", and return an IgnoreRule suitable for matching against files and directories. Patterns which do not match files, such as comments and blank lines, will return None. Because git allows for nested .gitignore files, a base_path value is required for correct behavior. The base path should be absolute. \"\"\" if base_path and base_path ! = abspath ( base_path ) : raise ValueError ( 'base_path must be absolute' ) # Store the exact pattern for our repr and string functions orig_pattern = pattern # Early returns follow # Discard comments and seperators if pattern . strip () == '' or pattern [ 0 ] == '#': return # Discard anything with more than two consecutive asterisks if pattern . find ( '***' ) > - 1 : return # Strip leading bang before examining double asterisks if pattern [ 0 ] == '!': negation = True pattern = pattern [ 1 : ] else : negation = False # Discard anything with invalid double - asterisks -- they can appear # at the start or the end , or be surrounded by slashes for m in re . finditer ( r'\\*\\*' , pattern ) : start_index = m . start () if ( start_index ! = 0 and start_index ! = len ( pattern ) - 2 and ( pattern [ start_index - 1 ] ! = '/' or pattern [ start_index + 2 ] ! = '/' )) : # noqa return # Special - casing '/' , which doesn't match any files or directories if pattern.rstrip() == '/': return directory_only = pattern[-1] == '/' # A slash is a sign that we're tied to the base_path of our rule # set . anchored = '/' in pattern [:- 1 ] if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ 0 ] == '*' and pattern [ 1 ] == '*': pattern = pattern [ 2 : ] anchored = False if pattern [ 0 ] == '/': pattern = pattern [ 1 : ] if pattern [ - 1 ] == '/': pattern = pattern [:- 1 ] regex = fnmatch_pathname_to_regex ( pattern ) if anchored : regex = '' . join ([ '^' , regex ]) return IgnoreRule ( pattern = orig_pattern , regex = regex , negation = negation , directory_only = directory_only , anchored = anchored , base_path = Path ( base_path ) if base_path else None , source = source )","title":"rule_from_pattern"},{"location":"edk2toollib/gitignore_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/gitignore_parser/#ignorerule","text":"class IgnoreRule ( / , * args , ** kwargs ) IgnoreRule_(pattern, regex, negation, directory_only, anchored, base_path, source) View Source class IgnoreRule ( collections . namedtuple ( 'IgnoreRule_' , IGNORE_RULE_FIELDS )): def __str__ ( self ): return self . pattern def __repr__ ( self ): return '' . join ([ 'IgnoreRule(\\'' , self . pattern , '\\')' ]) def match ( self , abs_path ): matched = False if self . base_path: rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else: rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ): rel_path = rel_path [ 2 :] if re . search ( self . regex , rel_path ): matched = True return matched","title":"IgnoreRule"},{"location":"edk2toollib/gitignore_parser/#ancestors-in-mro","text":"edk2toollib.gitignore_parser.IgnoreRule_ builtins.tuple","title":"Ancestors (in MRO)"},{"location":"edk2toollib/gitignore_parser/#instance-variables","text":"anchored Alias for field number 4 base_path Alias for field number 5 directory_only Alias for field number 3 negation Alias for field number 2 pattern Alias for field number 0 regex Alias for field number 1 source Alias for field number 6","title":"Instance variables"},{"location":"edk2toollib/gitignore_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/gitignore_parser/#count","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"edk2toollib/gitignore_parser/#index","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"edk2toollib/gitignore_parser/#match","text":"def match ( self , abs_path ) View Source def match ( self , abs_path ): matched = False if self . base_path : rel_path = str ( Path ( abs_path ). relative_to ( self . base_path )) else : rel_path = str ( Path ( abs_path )) if rel_path . startswith ( './' ): rel_path = rel_path [ 2 :] if re . search ( self . regex , rel_path ): matched = True return matched","title":"match"},{"location":"edk2toollib/utility_functions/","text":"Module edk2toollib.utility_functions View Source ## # Utility Functions to support re-use in python scripts. # Includes functions for running external commands, etc # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import re import os import logging import datetime import time import shutil import threading import subprocess import sys import inspect import platform import importlib from collections import namedtuple from enum import Enum as StdEnum def Enum ( * args ): items = [] if len ( args ) == 1 : item = args [ 0 ] if isinstance ( item , list ): items = item elif isinstance ( item , tuple ): items = list ( item ) else : items . append ( item ) else : items = args calling_frame = inspect . stack ()[ 1 ] calling_mod = inspect . getmodule ( calling_frame [ 0 ]) calling_func = calling_frame . function calling_line = calling_frame . lineno enum_name = calling_func + \":\" + str ( calling_line ) logging . warning ( f \"Enum is deprecated! Please fix it in {calling_mod}:{calling_func}\" ) return StdEnum ( enum_name , items , module = calling_mod ) #### # Class to support running commands from the shell in a python environment. # Don't use directly. # # PropagatingThread copied from sample here: # https://stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python #### class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ) . join () if self . exc : raise self . exc return self . ret #### # Helper functions for running commands from the shell in python environment # Don't use directly # # process output stream and write to log. # part of the threading pattern. # # http://stackoverflow.com/questions/19423008/logged-subprocess-communicate #### def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline () . decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () #### # Returns a namedtuple containing information about host machine. # # @return namedtuple Host(os=OS Type, arch=System Architecture, bit=Highest Order Bit) #### def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine arch = None bit = None if ( \"x86\" in processor_info . lower ()) or ( \"AMD\" in processor_info . upper ()) or ( \"INTEL\" in processor_info . upper ()): arch = \"x86\" elif ( \"ARM\" in processor_info . upper ()) or ( \"AARCH\" in processor_info . upper ()): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) #### # This is a mixing to do timing on a function. Use it like this: # # @timing # def function_i_want_to_time(): # ... #### def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000.0 )) return ret return wrap #### # Run a shell command and print the output to the log file # This is the public function that should be used to run commands from the shell in python environment # @param cmd - command being run, either quoted or not quoted # @param parameters - parameters string taken as is # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # @param logging_level - log level to log output at. Default is INFO # @param raise_exception_on_nonzero - Setting to true causes exception to be raised if the cmd # return code is not zero. # # @return returncode of called cmd #### def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\" \\' ' ) if \" \" in cmd : cmd = '\"' + cmd + '\"' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): thread = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) thread . start () c . wait () thread . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) returncode_str = \"{0:#010x}\" . format ( c . returncode ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"----------- Return Code: \" + returncode_str + \" ------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with Return Code: {1}\" . format ( cmd , returncode_str )) return c . returncode #### # Run a python script and print the output to the log file # This is the public function that should be used to execute python scripts from the shell in python environment. # The python script will be located using the path as if it was an executable. # # @param cmd - cmd string to run including parameters # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # # @return returncode of called cmd #### def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): # locate python file on path pythonfile . strip ( '\" \\' ' ) if \" \" in pythonfile : pythonfile = '\"' + pythonfile + '\"' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s \" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s \" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ) . split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s \" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ , logging_level = logging_level , raise_exception_on_nonzero = raise_exception_on_nonzero ) #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow stronger # security practices (HSM / smart cards / etc) # # Signing is in format specified by UEFI authentacted variables #### def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # Signtool parameters from # https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/secure-boot-key-generation-and-signing-using-hsm--example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't exist %s \" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow # stronger security practices (HSM / smart cards / etc) # # Signing is catalog format which is an attached signature #### def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # todo: link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret ### # Function to print a byte list as hex and optionally output ascii as well as # offset within the buffer ### def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ): Ascii = \"\" for index in range ( len ( ByteList )): # Start of New Line if ( index % 16 == 0 ): if ( IncludeOffset ): print ( \"0x %04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ): if ( IncludeHexSep ): print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x %02X \" % ByteList [ index ], end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ): Ascii += \".\" else : Ascii += ( \" %c \" % ByteList [ index ]) # End of Line if ( index % 16 == 15 ): if ( IncludeAscii ): print ( \" %s \" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ): # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ): # Pad out to the correct spot while ( index % 16 != 15 ): print ( \" \" , end = '' ) if ( index % 16 == 7 ): # account for the - symbol in the hex dump if ( IncludeOffset ): print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s \" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) # Simplified Comparison Function borrowed from StackOverflow... # https://stackoverflow.com/questions/1714027/version-number-comparison # With Python 3.0 help from: # https://docs.python.org/3.0/whatsnew/3.0.html#ordering-comparisons def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ) . split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! # if multiple instances are found in the same class hierarchy, pick the # most specific one. If multiple instances are found belonging to different # class hierarchies, raise an error. if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if ( DesiredClassInstance is None ) or issubclass ( _class , DesiredClassInstance ): DesiredClassInstance = _class elif not issubclass ( DesiredClassInstance , _class ): raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) return DesiredClassInstance if __name__ == '__main__' : pass # Test code for printing a byte buffer # a = [0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3a, 0x3b, 0x3c, 0x3d] # index = 0x55 # while(index < 0x65): # a.append(index) # PrintByteList(a) # index += 1 Functions CatalogSignWithSignTool def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ) View Source def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # todo : link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret DetachedSignWithSignTool def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = '1.2.840.113549.1.7.2' , Eku = None ) View Source def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # Signtool parameters from # https : // docs . microsoft . com / en - us / windows - hardware / manufacture / desktop / secure - boot - key - generation - and - signing - using - hsm --example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't exist %s\" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret Enum def Enum ( * args ) View Source def Enum ( * args ): items = [] if len ( args ) == 1 : item = args [ 0 ] if isinstance ( item , list ): items = item elif isinstance ( item , tuple ): items = list ( item ) else : items . append ( item ) else : items = args calling_frame = inspect . stack ()[ 1 ] calling_mod = inspect . getmodule ( calling_frame [ 0 ]) calling_func = calling_frame . function calling_line = calling_frame . lineno enum_name = calling_func + \":\" + str ( calling_line ) logging . warning ( f \"Enum is deprecated! Please fix it in {calling_mod}:{calling_func}\" ) return StdEnum ( enum_name , items , module = calling_mod ) GetHostInfo def GetHostInfo ( ) View Source def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine arch = None bit = None if ( \"x86\" in processor_info . lower ()) or ( \"AMD\" in processor_info . upper ()) or ( \"INTEL\" in processor_info . upper ()): arch = \"x86\" elif ( \"ARM\" in processor_info . upper ()) or ( \"AARCH\" in processor_info . upper ()): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) PrintByteList def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) View Source def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) : Ascii = \"\" for index in range ( len ( ByteList )) : # Start of New Line if ( index % 16 == 0 ) : if ( IncludeOffset ) : print ( \"0x%04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ) : if ( IncludeHexSep ) : print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x%02X\" % ByteList [ index ] , end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ) : Ascii += \".\" else : Ascii += ( \"%c\" % ByteList [ index ] ) # End of Line if ( index % 16 == 15 ) : if ( IncludeAscii ) : print ( \" %s\" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ) : # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ) : # Pad out to the correct spot while ( index % 16 != 15 ) : print ( \" \" , end = '' ) if ( index % 16 == 7 ) : # account for the - symbol in the hex dump if ( IncludeOffset ) : print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s\" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) RunCmd def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\"\\'') if \" \" in cmd: cmd = ' \"' + cmd + '\" ' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): thread = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) thread . start () c . wait () thread . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) returncode_str = \"{0:#010x}\" . format ( c . returncode ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"----------- Return Code: \" + returncode_str + \" ------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with Return Code: {1}\" . format ( cmd , returncode_str )) return c . returncode RunPythonScript def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): # locate python file on path pythonfile . strip ( '\"\\'') if \" \" in pythonfile: pythonfile = ' \"' + pythonfile + '\" ' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s\" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s\" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ). split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s\" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ , logging_level = logging_level , raise_exception_on_nonzero = raise_exception_on_nonzero ) import_module_by_file_name def import_module_by_file_name ( module_file_path ) Standard method of importing a Python file. Expecting absolute path. View Source def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule locate_class_in_module def locate_class_in_module ( Module , DesiredClass ) Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- View Source def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! # if multiple instances are found in the same class hierarchy, pick the # most specific one. If multiple instances are found belonging to different # class hierarchies, raise an error. if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if ( DesiredClassInstance is None ) or issubclass ( _class , DesiredClassInstance ): DesiredClassInstance = _class elif not issubclass ( DesiredClassInstance , _class ): raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) return DesiredClassInstance reader def reader ( filepath , outstream , stream , logging_level = 20 ) View Source def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline (). decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () timing def timing ( f ) View Source def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000 . 0 )) return ret return wrap version_compare def version_compare ( version1 , version2 ) View Source def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ). split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) Classes PropagatingThread class PropagatingThread ( group = None , target = None , name = None , args = (), kwargs = None , * , daemon = None ) A class that represents a thread of control. This class can be safely subclassed in a limited fashion. There are two ways to specify the activity: by passing a callable object to the constructor, or by overriding the run() method in a subclass. View Source class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try: if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target (* self . _Thread__args , ** self . _Thread__kwargs ) else: self . ret = self . _target (* self . _args , ** self . _kwargs ) except BaseException as e: self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc: raise self . exc return self . ret Ancestors (in MRO) threading.Thread Instance variables daemon A boolean value indicating whether this thread is a daemon thread. This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. The entire Python program exits when only daemon threads are left. ident Thread identifier of this thread or None if it has not been started. This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. name A string used for identification purposes only. It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor. Methods getName def getName ( self ) View Source def getName ( self ): return self . name isAlive def isAlive ( self ) Return whether the thread is alive. This method is deprecated, use is_alive() instead. View Source def isAlive ( self ): \"\"\"Return whether the thread is alive. This method is deprecated, use is_alive() instead. \"\"\" import warnings warnings . warn ( 'isAlive() is deprecated, use is_alive() instead' , PendingDeprecationWarning , stacklevel = 2 ) return self . is_alive () isDaemon def isDaemon ( self ) View Source def isDaemon ( self ): return self . daemon is_alive def is_alive ( self ) Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. View Source def is_alive ( self ): \"\"\"Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. \"\"\" assert self . _initialized , \"Thread.__init__() not called\" if self . _is_stopped or not self . _started . is_set (): return False self . _wait_for_tstate_lock ( False ) return not self . _is_stopped join def join ( self , timeout = None ) Wait until the thread terminates. This blocks the calling thread until the thread whose join() method is called terminates \u2013 either normally or through an unhandled exception or until the optional timeout occurs. When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened \u2013 if the thread is still alive, the join() call timed out. When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception. View Source def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc : raise self . exc return self . ret run def run ( self ) Method representing the thread\u2019s activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object\u2019s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. View Source def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3 . self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e setDaemon def setDaemon ( self , daemonic ) View Source def setDaemon ( self , daemonic ): self . daemon = daemonic setName def setName ( self , name ) View Source def setName ( self , name ): self . name = name start def start ( self ) Start the thread\u2019s activity. It must be called at most once per thread object. It arranges for the object\u2019s run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. View Source def start ( self ) : \"\"\"Start the thread's activity. It must be called at most once per thread object. It arranges for the object's run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. \"\"\" if not self . _initialized : raise RuntimeError ( \"thread.__init__() not called\" ) if self . _started . is_set () : raise RuntimeError ( \"threads can only be started once\" ) with _active_limbo_lock : _limbo [ self ] = self try : _start_new_thread ( self . _bootstrap , ()) except Exception : with _active_limbo_lock : del _limbo [ self ] raise self . _started . wait ()","title":"Utility functions"},{"location":"edk2toollib/utility_functions/#module-edk2toollibutility_functions","text":"View Source ## # Utility Functions to support re-use in python scripts. # Includes functions for running external commands, etc # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import re import os import logging import datetime import time import shutil import threading import subprocess import sys import inspect import platform import importlib from collections import namedtuple from enum import Enum as StdEnum def Enum ( * args ): items = [] if len ( args ) == 1 : item = args [ 0 ] if isinstance ( item , list ): items = item elif isinstance ( item , tuple ): items = list ( item ) else : items . append ( item ) else : items = args calling_frame = inspect . stack ()[ 1 ] calling_mod = inspect . getmodule ( calling_frame [ 0 ]) calling_func = calling_frame . function calling_line = calling_frame . lineno enum_name = calling_func + \":\" + str ( calling_line ) logging . warning ( f \"Enum is deprecated! Please fix it in {calling_mod}:{calling_func}\" ) return StdEnum ( enum_name , items , module = calling_mod ) #### # Class to support running commands from the shell in a python environment. # Don't use directly. # # PropagatingThread copied from sample here: # https://stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python #### class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ) . join () if self . exc : raise self . exc return self . ret #### # Helper functions for running commands from the shell in python environment # Don't use directly # # process output stream and write to log. # part of the threading pattern. # # http://stackoverflow.com/questions/19423008/logged-subprocess-communicate #### def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline () . decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () #### # Returns a namedtuple containing information about host machine. # # @return namedtuple Host(os=OS Type, arch=System Architecture, bit=Highest Order Bit) #### def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine arch = None bit = None if ( \"x86\" in processor_info . lower ()) or ( \"AMD\" in processor_info . upper ()) or ( \"INTEL\" in processor_info . upper ()): arch = \"x86\" elif ( \"ARM\" in processor_info . upper ()) or ( \"AARCH\" in processor_info . upper ()): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) #### # This is a mixing to do timing on a function. Use it like this: # # @timing # def function_i_want_to_time(): # ... #### def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000.0 )) return ret return wrap #### # Run a shell command and print the output to the log file # This is the public function that should be used to run commands from the shell in python environment # @param cmd - command being run, either quoted or not quoted # @param parameters - parameters string taken as is # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # @param logging_level - log level to log output at. Default is INFO # @param raise_exception_on_nonzero - Setting to true causes exception to be raised if the cmd # return code is not zero. # # @return returncode of called cmd #### def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\" \\' ' ) if \" \" in cmd : cmd = '\"' + cmd + '\"' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): thread = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) thread . start () c . wait () thread . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) returncode_str = \"{0:#010x}\" . format ( c . returncode ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"----------- Return Code: \" + returncode_str + \" ------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with Return Code: {1}\" . format ( cmd , returncode_str )) return c . returncode #### # Run a python script and print the output to the log file # This is the public function that should be used to execute python scripts from the shell in python environment. # The python script will be located using the path as if it was an executable. # # @param cmd - cmd string to run including parameters # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # # @return returncode of called cmd #### def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): # locate python file on path pythonfile . strip ( '\" \\' ' ) if \" \" in pythonfile : pythonfile = '\"' + pythonfile + '\"' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s \" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s \" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ) . split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s \" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ , logging_level = logging_level , raise_exception_on_nonzero = raise_exception_on_nonzero ) #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow stronger # security practices (HSM / smart cards / etc) # # Signing is in format specified by UEFI authentacted variables #### def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # Signtool parameters from # https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/secure-boot-key-generation-and-signing-using-hsm--example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't exist %s \" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow # stronger security practices (HSM / smart cards / etc) # # Signing is catalog format which is an attached signature #### def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # todo: link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret ### # Function to print a byte list as hex and optionally output ascii as well as # offset within the buffer ### def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ): Ascii = \"\" for index in range ( len ( ByteList )): # Start of New Line if ( index % 16 == 0 ): if ( IncludeOffset ): print ( \"0x %04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ): if ( IncludeHexSep ): print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x %02X \" % ByteList [ index ], end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ): Ascii += \".\" else : Ascii += ( \" %c \" % ByteList [ index ]) # End of Line if ( index % 16 == 15 ): if ( IncludeAscii ): print ( \" %s \" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ): # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ): # Pad out to the correct spot while ( index % 16 != 15 ): print ( \" \" , end = '' ) if ( index % 16 == 7 ): # account for the - symbol in the hex dump if ( IncludeOffset ): print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s \" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) # Simplified Comparison Function borrowed from StackOverflow... # https://stackoverflow.com/questions/1714027/version-number-comparison # With Python 3.0 help from: # https://docs.python.org/3.0/whatsnew/3.0.html#ordering-comparisons def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ) . split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! # if multiple instances are found in the same class hierarchy, pick the # most specific one. If multiple instances are found belonging to different # class hierarchies, raise an error. if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if ( DesiredClassInstance is None ) or issubclass ( _class , DesiredClassInstance ): DesiredClassInstance = _class elif not issubclass ( DesiredClassInstance , _class ): raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) return DesiredClassInstance if __name__ == '__main__' : pass # Test code for printing a byte buffer # a = [0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3a, 0x3b, 0x3c, 0x3d] # index = 0x55 # while(index < 0x65): # a.append(index) # PrintByteList(a) # index += 1","title":"Module edk2toollib.utility_functions"},{"location":"edk2toollib/utility_functions/#functions","text":"","title":"Functions"},{"location":"edk2toollib/utility_functions/#catalogsignwithsigntool","text":"def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ) View Source def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # todo : link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret","title":"CatalogSignWithSignTool"},{"location":"edk2toollib/utility_functions/#detachedsignwithsigntool","text":"def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = '1.2.840.113549.1.7.2' , Eku = None ) View Source def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # Signtool parameters from # https : // docs . microsoft . com / en - us / windows - hardware / manufacture / desktop / secure - boot - key - generation - and - signing - using - hsm --example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't exist %s\" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret","title":"DetachedSignWithSignTool"},{"location":"edk2toollib/utility_functions/#enum","text":"def Enum ( * args ) View Source def Enum ( * args ): items = [] if len ( args ) == 1 : item = args [ 0 ] if isinstance ( item , list ): items = item elif isinstance ( item , tuple ): items = list ( item ) else : items . append ( item ) else : items = args calling_frame = inspect . stack ()[ 1 ] calling_mod = inspect . getmodule ( calling_frame [ 0 ]) calling_func = calling_frame . function calling_line = calling_frame . lineno enum_name = calling_func + \":\" + str ( calling_line ) logging . warning ( f \"Enum is deprecated! Please fix it in {calling_mod}:{calling_func}\" ) return StdEnum ( enum_name , items , module = calling_mod )","title":"Enum"},{"location":"edk2toollib/utility_functions/#gethostinfo","text":"def GetHostInfo ( ) View Source def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine arch = None bit = None if ( \"x86\" in processor_info . lower ()) or ( \"AMD\" in processor_info . upper ()) or ( \"INTEL\" in processor_info . upper ()): arch = \"x86\" elif ( \"ARM\" in processor_info . upper ()) or ( \"AARCH\" in processor_info . upper ()): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit )","title":"GetHostInfo"},{"location":"edk2toollib/utility_functions/#printbytelist","text":"def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) View Source def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) : Ascii = \"\" for index in range ( len ( ByteList )) : # Start of New Line if ( index % 16 == 0 ) : if ( IncludeOffset ) : print ( \"0x%04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ) : if ( IncludeHexSep ) : print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x%02X\" % ByteList [ index ] , end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ) : Ascii += \".\" else : Ascii += ( \"%c\" % ByteList [ index ] ) # End of Line if ( index % 16 == 15 ) : if ( IncludeAscii ) : print ( \" %s\" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ) : # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ) : # Pad out to the correct spot while ( index % 16 != 15 ) : print ( \" \" , end = '' ) if ( index % 16 == 7 ) : # account for the - symbol in the hex dump if ( IncludeOffset ) : print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s\" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" )","title":"PrintByteList"},{"location":"edk2toollib/utility_functions/#runcmd","text":"def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\"\\'') if \" \" in cmd: cmd = ' \"' + cmd + '\" ' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): thread = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) thread . start () c . wait () thread . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) returncode_str = \"{0:#010x}\" . format ( c . returncode ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"----------- Return Code: \" + returncode_str + \" ------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with Return Code: {1}\" . format ( cmd , returncode_str )) return c . returncode","title":"RunCmd"},{"location":"edk2toollib/utility_functions/#runpythonscript","text":"def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): # locate python file on path pythonfile . strip ( '\"\\'') if \" \" in pythonfile: pythonfile = ' \"' + pythonfile + '\" ' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s\" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s\" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ). split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s\" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ , logging_level = logging_level , raise_exception_on_nonzero = raise_exception_on_nonzero )","title":"RunPythonScript"},{"location":"edk2toollib/utility_functions/#import_module_by_file_name","text":"def import_module_by_file_name ( module_file_path ) Standard method of importing a Python file. Expecting absolute path. View Source def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule","title":"import_module_by_file_name"},{"location":"edk2toollib/utility_functions/#locate_class_in_module","text":"def locate_class_in_module ( Module , DesiredClass ) Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- View Source def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass found in Module. It gives preference to classes that are defined in the module itself. This means that if you have an import that subclasses DesiredClass, it will be picked unless there is a class defined in the module that subclasses DesiredClass. In this hypothetical class hierarchy, GrandChildClass would be picked -------------- ------------ ----------------- |DesiredClass| -> |ChildClass| -> |GrandChildClass| -------------- ------------ ----------------- ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! # if multiple instances are found in the same class hierarchy, pick the # most specific one. If multiple instances are found belonging to different # class hierarchies, raise an error. if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if ( DesiredClassInstance is None ) or issubclass ( _class , DesiredClassInstance ): DesiredClassInstance = _class elif not issubclass ( DesiredClassInstance , _class ): raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) return DesiredClassInstance","title":"locate_class_in_module"},{"location":"edk2toollib/utility_functions/#reader","text":"def reader ( filepath , outstream , stream , logging_level = 20 ) View Source def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline (). decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close ()","title":"reader"},{"location":"edk2toollib/utility_functions/#timing","text":"def timing ( f ) View Source def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000 . 0 )) return ret return wrap","title":"timing"},{"location":"edk2toollib/utility_functions/#version_compare","text":"def version_compare ( version1 , version2 ) View Source def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ). split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b )","title":"version_compare"},{"location":"edk2toollib/utility_functions/#classes","text":"","title":"Classes"},{"location":"edk2toollib/utility_functions/#propagatingthread","text":"class PropagatingThread ( group = None , target = None , name = None , args = (), kwargs = None , * , daemon = None ) A class that represents a thread of control. This class can be safely subclassed in a limited fashion. There are two ways to specify the activity: by passing a callable object to the constructor, or by overriding the run() method in a subclass. View Source class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try: if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target (* self . _Thread__args , ** self . _Thread__kwargs ) else: self . ret = self . _target (* self . _args , ** self . _kwargs ) except BaseException as e: self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc: raise self . exc return self . ret","title":"PropagatingThread"},{"location":"edk2toollib/utility_functions/#ancestors-in-mro","text":"threading.Thread","title":"Ancestors (in MRO)"},{"location":"edk2toollib/utility_functions/#instance-variables","text":"daemon A boolean value indicating whether this thread is a daemon thread. This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. The entire Python program exits when only daemon threads are left. ident Thread identifier of this thread or None if it has not been started. This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. name A string used for identification purposes only. It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor.","title":"Instance variables"},{"location":"edk2toollib/utility_functions/#methods","text":"","title":"Methods"},{"location":"edk2toollib/utility_functions/#getname","text":"def getName ( self ) View Source def getName ( self ): return self . name","title":"getName"},{"location":"edk2toollib/utility_functions/#isalive","text":"def isAlive ( self ) Return whether the thread is alive. This method is deprecated, use is_alive() instead. View Source def isAlive ( self ): \"\"\"Return whether the thread is alive. This method is deprecated, use is_alive() instead. \"\"\" import warnings warnings . warn ( 'isAlive() is deprecated, use is_alive() instead' , PendingDeprecationWarning , stacklevel = 2 ) return self . is_alive ()","title":"isAlive"},{"location":"edk2toollib/utility_functions/#isdaemon","text":"def isDaemon ( self ) View Source def isDaemon ( self ): return self . daemon","title":"isDaemon"},{"location":"edk2toollib/utility_functions/#is_alive","text":"def is_alive ( self ) Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. View Source def is_alive ( self ): \"\"\"Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. \"\"\" assert self . _initialized , \"Thread.__init__() not called\" if self . _is_stopped or not self . _started . is_set (): return False self . _wait_for_tstate_lock ( False ) return not self . _is_stopped","title":"is_alive"},{"location":"edk2toollib/utility_functions/#join","text":"def join ( self , timeout = None ) Wait until the thread terminates. This blocks the calling thread until the thread whose join() method is called terminates \u2013 either normally or through an unhandled exception or until the optional timeout occurs. When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened \u2013 if the thread is still alive, the join() call timed out. When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception. View Source def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc : raise self . exc return self . ret","title":"join"},{"location":"edk2toollib/utility_functions/#run","text":"def run ( self ) Method representing the thread\u2019s activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object\u2019s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. View Source def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3 . self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e","title":"run"},{"location":"edk2toollib/utility_functions/#setdaemon","text":"def setDaemon ( self , daemonic ) View Source def setDaemon ( self , daemonic ): self . daemon = daemonic","title":"setDaemon"},{"location":"edk2toollib/utility_functions/#setname","text":"def setName ( self , name ) View Source def setName ( self , name ): self . name = name","title":"setName"},{"location":"edk2toollib/utility_functions/#start","text":"def start ( self ) Start the thread\u2019s activity. It must be called at most once per thread object. It arranges for the object\u2019s run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. View Source def start ( self ) : \"\"\"Start the thread's activity. It must be called at most once per thread object. It arranges for the object's run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. \"\"\" if not self . _initialized : raise RuntimeError ( \"thread.__init__() not called\" ) if self . _started . is_set () : raise RuntimeError ( \"threads can only be started once\" ) with _active_limbo_lock : _limbo [ self ] = self try : _start_new_thread ( self . _bootstrap , ()) except Exception : with _active_limbo_lock : del _limbo [ self ] raise self . _started . wait ()","title":"start"},{"location":"edk2toollib/acpi/","text":"Module edk2toollib.acpi View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.acpi.dmar_parser edk2toollib.acpi.ivrs_parser edk2toollib.acpi.ivrs_parser_test","title":"Index"},{"location":"edk2toollib/acpi/#module-edk2toollibacpi","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.acpi"},{"location":"edk2toollib/acpi/#sub-modules","text":"edk2toollib.acpi.dmar_parser edk2toollib.acpi.ivrs_parser edk2toollib.acpi.ivrs_parser_test","title":"Sub-modules"},{"location":"edk2toollib/acpi/dmar_parser/","text":"Module edk2toollib.acpi.dmar_parser View Source ## # Python script that converts a raw DMAR table into a struct # More details see https://software.intel.com/sites/default/files/managed/c5/15/vt-directed-io-spec.pdf # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import sys import struct import xml.etree.ElementTree as ET DMARParserVersion = '1.01' class DMARTable ( object ): # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ): self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable . DMARHeaderLength :] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header . Length :] self . xml = self . toXml () def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ): retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ): return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ) . text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ): STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ): return \"\"\" \\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x %08X Revision : 0x %02X Checksum : 0x %02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x %08X Creator ID : %s Creator Revision : 0x %08X Host Address Width : 0x %02X Flags : 0x %02X \\n \"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x %X ' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) return xml_repr class RemappingStructHeader ( object ): STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ): ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ): return \"\"\" \\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBHQ' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . DRDHHeaderLength :] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n DRHD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x Register Base Address : 0x %016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHHHQQ' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . RMRRHeaderLength :] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ): retString = \"\" for index , item in enumerate ( self . DeviceScope ): retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ): xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x %X ' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x %X ' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n RMRR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %04X Segment Number : 0x %04x Reserved Memory Base Address : 0x %016x Reserved Memory Region Limit Address : 0x %016x \\n \"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBH' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . ASTRHeaderLength :] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n ASTR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHIQI' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x %X ' % self . ProximityDomain ) return xml_repr def __str__ ( self ): return \"\"\" \\n RHSA ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %08X Register Base Address : 0x %016X Proximity Domain : 0x %08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ): header_format = '=HH' def __init__ ( self , header_byte_array , length ): self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ): self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i : i + 1 ])[ 0 ] header_byte_array = header_byte_array [ 7 :] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x %X ' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , ' %s ' % self . ACPIObjectName ) return xml_repr def __str__ ( self ): return \"\"\" \\n ANDD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %06X ACPI Device Number : 0x %02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ): STRUCT_FORMAT = '=BBHBB' # spell-checker: disable-line def __init__ ( self , header_byte_array ): ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset : offset + 1 ]), struct . unpack ( \"<B\" , header_byte_array [ offset + 1 : offset + 2 ]))) offset += 2 number_path_entries -= 1 def getPath ( self ): retstring = \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ): retstring = \"\"\" \\n\\t\\t %s \\t\\t -------------------------------------------------- \\t\\t Type : 0x %02X \\t\\t Length : 0x %02X \\t\\t Reserved : 0x %04X \\t\\t Enumeration ID : 0x %02x \\t\\t Start Bus Number : 0x %02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \" \\n \" return retstring Variables DMARParserVersion Classes DMARTable class DMARTable ( data ) View Source class DMARTable ( object ) : # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ) : self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable.DMARHeaderLength: ] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header.Length: ] self . xml = self . toXml () def toXml ( self ) : root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ) : retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ) : return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ) : return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ) : goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ) : print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ) : STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ) : return \"\"\"\\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x%08X Revision : 0x%02X Checksum : 0x%02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x%08X Creator ID : %s Creator Revision : 0x%08X Host Address Width : 0x%02X Flags : 0x%02X\\n\"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x%X' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) return xml_repr class RemappingStructHeader ( object ) : STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ) : return \"\"\"\\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBHQ' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.DRDHHeaderLength: ] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n DRHD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x Register Base Address : 0x%016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHHHQQ' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.RMRRHeaderLength: ] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ) : retString = \"\" for index , item in enumerate ( self . DeviceScope ) : retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ) : xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x%X' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x%X' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n RMRR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%04X Segment Number : 0x%04x Reserved Memory Base Address : 0x%016x Reserved Memory Region Limit Address : 0x%016x\\n\"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBH' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.ASTRHeaderLength: ] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n ASTR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHIQI' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x%X' % self . ProximityDomain ) return xml_repr def __str__ ( self ) : return \"\"\"\\n RHSA ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%08X Register Base Address : 0x%016X Proximity Domain : 0x%08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ) : header_format = '=HH' def __init__ ( self , header_byte_array , length ) : self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ) : self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i:i + 1 ] ) [ 0 ] header_byte_array = header_byte_array [ 7: ] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x%X' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , '%s' % self . ACPIObjectName ) return xml_repr def __str__ ( self ) : return \"\"\"\\n ANDD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%06X ACPI Device Number : 0x%02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ) : STRUCT_FORMAT = '=BBHBB' # spell - checker : disable - line def __init__ ( self , header_byte_array ) : ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset:offset + 1 ] ), struct . unpack ( \"<B\" , header_byte_array [ offset + 1:offset + 2 ] ))) offset += 2 number_path_entries -= 1 def getPath ( self ) : retstring = \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ) : retstring = \"\"\"\\n\\t\\t %s \\t\\t-------------------------------------------------- \\t\\t Type : 0x%02X \\t\\t Length : 0x%02X \\t\\t Reserved : 0x%04X \\t\\t Enumeration ID : 0x%02x \\t\\t Start Bus Number : 0x%02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \"\\n\" return retstring Class variables ANDDHeaderLength ANDDStruct ASTRHeaderLength ATSRStruct AcpiTableHeader DMARHeaderLength DRDHHeaderLength DRHDStruct DeviceScopeHeaderLength DeviceScopeStruct RHSAStruct RMRRHeaderLength RMRRStruct RemappingStructHeader Methods ANDDCount def ANDDCount ( self ) View Source def ANDDCount ( self ): return self . dmar_table . ANDDCount CheckRMRRCount def CheckRMRRCount ( self , goldenxml = None ) View Source def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True DMARBitEnabled def DMARBitEnabled ( self ) View Source def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) toXml def toXml ( self ) View Source def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root","title":"Dmar parser"},{"location":"edk2toollib/acpi/dmar_parser/#module-edk2toollibacpidmar_parser","text":"View Source ## # Python script that converts a raw DMAR table into a struct # More details see https://software.intel.com/sites/default/files/managed/c5/15/vt-directed-io-spec.pdf # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import sys import struct import xml.etree.ElementTree as ET DMARParserVersion = '1.01' class DMARTable ( object ): # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ): self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable . DMARHeaderLength :] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header . Length :] self . xml = self . toXml () def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ): retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ): return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ) . text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ): STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ): return \"\"\" \\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x %08X Revision : 0x %02X Checksum : 0x %02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x %08X Creator ID : %s Creator Revision : 0x %08X Host Address Width : 0x %02X Flags : 0x %02X \\n \"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x %X ' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) return xml_repr class RemappingStructHeader ( object ): STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ): ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ): return \"\"\" \\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBHQ' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . DRDHHeaderLength :] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n DRHD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x Register Base Address : 0x %016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHHHQQ' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . RMRRHeaderLength :] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ): retString = \"\" for index , item in enumerate ( self . DeviceScope ): retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ): xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x %X ' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x %X ' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n RMRR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %04X Segment Number : 0x %04x Reserved Memory Base Address : 0x %016x Reserved Memory Region Limit Address : 0x %016x \\n \"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBH' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . ASTRHeaderLength :] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n ASTR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHIQI' # spell-checker: disable-line def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x %X ' % self . ProximityDomain ) return xml_repr def __str__ ( self ): return \"\"\" \\n RHSA ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %08X Register Base Address : 0x %016X Proximity Domain : 0x %08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ): header_format = '=HH' def __init__ ( self , header_byte_array , length ): self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ): self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i : i + 1 ])[ 0 ] header_byte_array = header_byte_array [ 7 :] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x %X ' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , ' %s ' % self . ACPIObjectName ) return xml_repr def __str__ ( self ): return \"\"\" \\n ANDD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %06X ACPI Device Number : 0x %02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ): STRUCT_FORMAT = '=BBHBB' # spell-checker: disable-line def __init__ ( self , header_byte_array ): ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset : offset + 1 ]), struct . unpack ( \"<B\" , header_byte_array [ offset + 1 : offset + 2 ]))) offset += 2 number_path_entries -= 1 def getPath ( self ): retstring = \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ): retstring = \"\"\" \\n\\t\\t %s \\t\\t -------------------------------------------------- \\t\\t Type : 0x %02X \\t\\t Length : 0x %02X \\t\\t Reserved : 0x %04X \\t\\t Enumeration ID : 0x %02x \\t\\t Start Bus Number : 0x %02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \" \\n \" return retstring","title":"Module edk2toollib.acpi.dmar_parser"},{"location":"edk2toollib/acpi/dmar_parser/#variables","text":"DMARParserVersion","title":"Variables"},{"location":"edk2toollib/acpi/dmar_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/acpi/dmar_parser/#dmartable","text":"class DMARTable ( data ) View Source class DMARTable ( object ) : # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ) : self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable.DMARHeaderLength: ] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header.Length: ] self . xml = self . toXml () def toXml ( self ) : root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ) : retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ) : return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ) : return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ) : goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ) : print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ) : STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ) : return \"\"\"\\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x%08X Revision : 0x%02X Checksum : 0x%02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x%08X Creator ID : %s Creator Revision : 0x%08X Host Address Width : 0x%02X Flags : 0x%02X\\n\"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x%X' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) return xml_repr class RemappingStructHeader ( object ) : STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ) : return \"\"\"\\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBHQ' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.DRDHHeaderLength: ] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n DRHD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x Register Base Address : 0x%016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHHHQQ' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.RMRRHeaderLength: ] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ) : retString = \"\" for index , item in enumerate ( self . DeviceScope ) : retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ) : xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x%X' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x%X' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n RMRR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%04X Segment Number : 0x%04x Reserved Memory Base Address : 0x%016x Reserved Memory Region Limit Address : 0x%016x\\n\"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBH' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.ASTRHeaderLength: ] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n ASTR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHIQI' # spell - checker : disable - line def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x%X' % self . ProximityDomain ) return xml_repr def __str__ ( self ) : return \"\"\"\\n RHSA ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%08X Register Base Address : 0x%016X Proximity Domain : 0x%08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ) : header_format = '=HH' def __init__ ( self , header_byte_array , length ) : self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ) : self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i:i + 1 ] ) [ 0 ] header_byte_array = header_byte_array [ 7: ] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x%X' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , '%s' % self . ACPIObjectName ) return xml_repr def __str__ ( self ) : return \"\"\"\\n ANDD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%06X ACPI Device Number : 0x%02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ) : STRUCT_FORMAT = '=BBHBB' # spell - checker : disable - line def __init__ ( self , header_byte_array ) : ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset:offset + 1 ] ), struct . unpack ( \"<B\" , header_byte_array [ offset + 1:offset + 2 ] ))) offset += 2 number_path_entries -= 1 def getPath ( self ) : retstring = \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ) : retstring = \"\"\"\\n\\t\\t %s \\t\\t-------------------------------------------------- \\t\\t Type : 0x%02X \\t\\t Length : 0x%02X \\t\\t Reserved : 0x%04X \\t\\t Enumeration ID : 0x%02x \\t\\t Start Bus Number : 0x%02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \"\\n\" return retstring","title":"DMARTable"},{"location":"edk2toollib/acpi/dmar_parser/#class-variables","text":"ANDDHeaderLength ANDDStruct ASTRHeaderLength ATSRStruct AcpiTableHeader DMARHeaderLength DRDHHeaderLength DRHDStruct DeviceScopeHeaderLength DeviceScopeStruct RHSAStruct RMRRHeaderLength RMRRStruct RemappingStructHeader","title":"Class variables"},{"location":"edk2toollib/acpi/dmar_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/acpi/dmar_parser/#anddcount","text":"def ANDDCount ( self ) View Source def ANDDCount ( self ): return self . dmar_table . ANDDCount","title":"ANDDCount"},{"location":"edk2toollib/acpi/dmar_parser/#checkrmrrcount","text":"def CheckRMRRCount ( self , goldenxml = None ) View Source def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True","title":"CheckRMRRCount"},{"location":"edk2toollib/acpi/dmar_parser/#dmarbitenabled","text":"def DMARBitEnabled ( self ) View Source def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit )","title":"DMARBitEnabled"},{"location":"edk2toollib/acpi/dmar_parser/#toxml","text":"def toXml ( self ) View Source def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root","title":"toXml"},{"location":"edk2toollib/acpi/ivrs_parser/","text":"Module edk2toollib.acpi.ivrs_parser View Source ## # Copyright (C) Microsoft Corporation. All rights reserved. # SPDX-License-Identifier: BSD-2-Clause-Patent # # Python script that converts a raw IVRS table into a struct, the spec version is based on # https://www.amd.com/system/files/TechDocs/48882_IOMMU.pdf ## import sys import struct import xml.etree.ElementTree as ET from enum import IntEnum IVRSParserVersion = '1.00' # spell-checker:ignore IVMD, IOMMUEFR class IVRS_TABLE ( object ): def __init__ ( self , data = None ): self . acpi_header = None self . SubStructs = list () self . IVMD_list = list () if data is not None : self . Decode ( data ) def Decode ( self , data ): self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [: IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size ]) # Start from the end of ACPI header, but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size :] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ): raise Exception ( 'Incoming data checksum does not add up: checksum field %x , calculated is %x ' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): remapping_header = self . IVMD_STRUCT ( t_data [: IVRS_TABLE . IVMD_STRUCT . struct_format_size ]) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ): self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d ' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header . Length :] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ): raise Exception ( \"IVRS length does not add up. Parsed len: %d , reported len: %d \" % ( t_length , self . acpi_header . Length )) def Encode ( self ): bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD/IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str def ToXmlElementTree ( self ): root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root def DumpInfo ( self ): self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo () @staticmethod def validateChecksum8 ( data ): return sum ( data ) & 0xFF def updateACPISum ( self ): temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0x100 - ( temp_sum & 0xFF )) & 0xFF def addIVHDEntry ( self , ivhd ): # append entry to the list, update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum () def addIVMDEntry ( self , ivmd ): # append entry to the list, update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD, thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum () def IVRSBitEnabled ( self ): return bool ( self . acpi_header . IVRSBit ) class ACPI_TABLE_HEADER ( object ): struct_format = '=4sIBB6s8sI4sIIQ' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , data = None ): self . Signature = None self . Length = 0 self . Revision = 0 self . Checksum = 0 self . OEMID = 0 self . OEMTableID = 0 self . OEMRevision = 0 self . CreatorID = 0 self . CreatorRevision = 0 self . IVinfo = None self . Reserved = 0 self . IVRSBit = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) = struct . unpack ( IVRS_TABLE . ACPI_TABLE_HEADER . struct_format , header_byte_array ) self . IVRSBit = self . IVinfo & 0x02 if ( self . IVinfo & 0x1E ) == 0 : sys . exit ( - 1 ) def Encode ( self ): return struct . pack ( self . struct_format , self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) def DumpInfo ( self ): print ( ' ACPI Table Header' ) print ( '------------------------------------------------------------------' ) print ( 'Signature : {Signature:s}' . format ( Signature = self . Signature . decode ())) print ( 'Length : 0x{Length:08X}' . format ( Length = self . Length )) print ( 'Revision : 0x{Revision:02X}' . format ( Revision = self . Revision )) print ( 'Checksum : 0x{Checksum:02X}' . format ( Checksum = self . Checksum )) print ( 'OEM ID : {OEMID:s}' . format ( OEMID = self . OEMID . decode ())) print ( 'OEM Table ID : {OEMTableID:s}' . format ( OEMTableID = self . OEMTableID . decode ())) print ( 'OEM Revision : 0x{OEMRevision:08X}' . format ( OEMRevision = self . OEMRevision )) print ( 'Creator ID : {CreatorID:s}' . format ( CreatorID = self . CreatorID . decode ())) print ( 'Creator Revision : 0x{CreatorRevision:08X}' . format ( CreatorRevision = self . CreatorRevision )) print ( 'IVinfo : 0x{IVinfo:08X}' . format ( IVinfo = self . IVinfo )) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'IVinfo' , '0x %X ' % self . IVinfo ) return xml_repr class REMAPPING_STRUCT_HEADER ( object ): struct_format = '=B' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , header_byte_array ): ( self . Type , ) = struct . unpack ( IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format , header_byte_array [: IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format_size ]) class IVHD_STRUCT ( REMAPPING_STRUCT_HEADER ): # cspell:disable-next disable the spell checker from thinking this a word struct_format = '=BBHHHQHHI' struct_format_size = struct . calcsize ( struct_format ) ex_format = \"=QQ\" ex_format_size = struct . calcsize ( ex_format ) class IVHD_TYPE ( IntEnum ): TYPE_10H = 0x10 TYPE_11H = 0x11 TYPE_40H = 0x40 def __init__ ( self , data = None ): self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . CapabilityOffset = 0 self . IOMMUBaseAddress = 0 self . SegmentGroup = 0 self . IOMMUInfo = None self . IOMMUFeatureInfo = None self . IOMMUEFRImage = None self . Reserved = 0 self . DeviceTableEntries = list () if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . Flags , t_Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) = struct . unpack ( IVRS_TABLE . IVHD_STRUCT . struct_format , header_byte_array [: IVRS_TABLE . IVHD_STRUCT . struct_format_size ]) self . Length = 0 if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): ivhd_hdr_size = ( IVRS_TABLE . IVHD_STRUCT . struct_format_size + IVRS_TABLE . IVHD_STRUCT . ex_format_size ) ( self . IOMMUEFRImage , self . Reserved ) = \\ struct . unpack ( IVRS_TABLE . IVHD_STRUCT . ex_format , header_byte_array [ IVRS_TABLE . IVHD_STRUCT . struct_format_size : ivhd_hdr_size ]) else : ivhd_hdr_size = IVRS_TABLE . IVHD_STRUCT . struct_format_size header_byte_array = header_byte_array [ ivhd_hdr_size :] bytes_left = t_Length - ivhd_hdr_size self . Length += ivhd_hdr_size # Get Sub Structs while bytes_left > 0 : device_scope = IVRS_TABLE . DEVICE_TABLE_ENTRY . Factory ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length if ( device_scope . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END ): self . addDTEEntry ( device_scope ) if ( t_Length != self . Length ) or ( bytes_left != 0 ): raise Exception ( \"IVHD length does not add up. Parsed len: %d , reported len: %d \" % ( self . Length , t_Length )) def Encode ( self ): byte_str = b '' byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) if self . IOMMUEFRImage is not None : byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . ex_format , self . IOMMUEFRImage , self . Reserved ) for dte in self . DeviceTableEntries : byte_str += dte . Encode () return byte_str def addDTEEntry ( self , dte ): # append raw data, update length. checksum will be left untouched self . Length += len ( dte . Encode ()) self . DeviceTableEntries . append ( dte ) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'IVHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'IOMMUDeviceID' , '0x %X ' % self . DeviceID ) xml_repr . set ( 'CapabilityOffset' , '0x %X ' % self . CapabilityOffset ) xml_repr . set ( 'IOMMUBaseAddress' , '0x %X ' % self . IOMMUBaseAddress ) xml_repr . set ( 'SegmentGroup' , '0x %X ' % self . SegmentGroup ) xml_repr . set ( 'IOMMUInfo' , '0x %X ' % self . IOMMUInfo ) xml_repr . set ( 'IOMMUFeatureInfo' , '0x %X ' % self . IOMMUFeatureInfo ) if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): xml_repr . set ( 'IOMMUEFRImage' , '0x %X ' % self . IOMMUEFRImage ) # Add SubStructs for item in self . DeviceTableEntries : xml_repr . append ( item . ToXmlElementTree ()) return xml_repr def DumpInfo ( self ): print ( \" \\t IVHD\" ) print ( \" \\t ----------------------------------------------------------------\" ) print ( ' \\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t Flags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( ' \\t Length : 0x{Length:04X}' . format ( Length = self . Length )) print ( ' \\t IOMMU Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t Capability Offset : 0x{CapabilityOffset:04X}' . format ( CapabilityOffset = self . CapabilityOffset )) print ( ' \\t IOMMU Base Address : 0x{IOMMUBaseAddress:016X}' . format ( IOMMUBaseAddress = self . IOMMUBaseAddress )) print ( ' \\t Segment Group : 0x{SegmentGroup:04X}' . format ( SegmentGroup = self . SegmentGroup )) print ( ' \\t IOMMU Info : 0x{IOMMUInfo:04X}' . format ( IOMMUInfo = self . IOMMUInfo )) print ( ' \\t IOMMU Feature Info : 0x{IOMMUFeatureInfo:08X}' . format ( IOMMUFeatureInfo = self . IOMMUFeatureInfo )) for item in self . DeviceTableEntries : item . DumpInfo () class IVMD_STRUCT ( REMAPPING_STRUCT_HEADER ): # cspell:disable-next disable spell checker from thinking this is a word struct_format = '=BBHHHQQQ' struct_format_size = struct . calcsize ( struct_format ) class IVMD_TYPE ( IntEnum ): TYPE_20H = 0x20 # All peripherals TYPE_21H = 0x21 # Specified peripheral TYPE_22H = 0x22 # Peripheral range def __init__ ( self , data = None ): self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . AuxiliaryData = None self . Reserved = 0 self . IVMDStartAddress = 0 self . IVMDMemoryBlockLength = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) = struct . unpack ( IVRS_TABLE . IVMD_STRUCT . struct_format , header_byte_array ) # IVMD is simple, the length is fixed, so assert if not if ( self . Length != len ( header_byte_array )): raise Exception ( \"Bad IVMD entry size %d , expecting %d \" % ( self . Length , len ( header_byte_array ))) def Encode ( self ): return struct . pack ( IVRS_TABLE . IVMD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'IVMD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'DeviceID' , '0x %X ' % self . DeviceID ) if ( self . Type != IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): xml_repr . set ( 'AuxiliaryData' , '0x %X ' % self . AuxiliaryData ) else : xml_repr . set ( 'EndofRange' , '0x %X ' % self . AuxiliaryData ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'IVMDStartAddress' , '0x %X ' % self . IVMDStartAddress ) xml_repr . set ( 'IVMDMemoryBlockLength' , '0x %X ' % self . IVMDMemoryBlockLength ) return xml_repr def DumpInfo ( self ): print ( \" \\t IVMD\" ) print ( \" \\t ----------------------------------------------------------------\" ) print ( ' \\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t Flags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( ' \\t Length : 0x{Length:04X}' . format ( Length = self . Length )) print ( ' \\t DeviceID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t AuxiliaryData : 0x{AuxiliaryData:04X}' . format ( AuxiliaryData = self . AuxiliaryData )) print ( ' \\t Reserved : 0x{Reserved:016X}' . format ( Reserved = self . Reserved )) print ( ' \\t IVMD Start Address : 0x{IVMDStartAddress:016X}' . format ( IVMDStartAddress = self . IVMDStartAddress )) print ( ' \\t IVMD Memory Block Length : 0x{IVMDMemoryBlockLength:016X}' . format ( IVMDMemoryBlockLength = self . Type )) class DEVICE_TABLE_ENTRY ( object ): struct_format = '=BHB' struct_format_size = struct . calcsize ( struct_format ) dte_var_ext_format = \"=8s8sBB\" dte_var_len = struct_format_size + struct . calcsize ( dte_var_ext_format ) class DTE_TYPE ( IntEnum ): RESERVED = 0 ALL = 1 SELECT = 2 RANGE_START = 3 RANGE_END = 4 ALIAS_SELECT = 66 ALIAS_RANGE_START = 67 EX_SELECT = 70 EX_RANGE_START = 71 SPECIAL = 72 ACPI = 240 # # this method is a factory # @staticmethod def Factory ( data ): if ( data is None ): raise Exception ( \"Invalid File stream\" ) RemapHeader = IVRS_TABLE . REMAPPING_STRUCT_HEADER ( data ) Type = RemapHeader . Type if ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_RESERVED ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_SPECIAL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ACPI ( data ) else : return None class DEVICE_TABLE_ENTRY_RESERVED ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALL ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL , self . Type ) self . TypeString = \"All\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START , self . Type ) self . TypeString = \"Range\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALIAS_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT , self . Type ) self . TypeString = \"Alias Select\" # Two DevID, one for alias, one for source self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . EndDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START , self . Type ) self . TypeString = \"Alias Range\" # Two DevID, one for alias start, one for source start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_EX_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT , self . Type ) self . TypeString = \"Extended Select\" # Two DTE setting, one for standard setting, one for extended setting (AtsDisabled, etc.) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting, one for standard setting, one for extended setting (AtsDisabled, etc.) byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( ' \\t\\t Extended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_EX_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START , self . Type ) self . TypeString = \"Extended Range\" # Two DTE setting, one for standard setting start, one for extended setting start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting, one for standard setting start, one for extended setting start byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 4 , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( ' \\t\\t Extended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_SPECIAL ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL , self . Type ) self . TypeString = \"Special Device\" # First half for standard DTE setting, second half for special DevID and its variety (APIC, HPET, etc.) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . Handle , self . SourceDeviceID , self . Variety ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # First half for standard DTE setting, second half for special DevID and its variety (APIC, HPET, etc.) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Handle , self . SourceDeviceID , self . Variety ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) xml_item . set ( 'Handle' , '0x %X ' % ( self . Handle )) if self . Variety == 1 : xml_item . set ( 'Variety' , 'IOAPIC' ) elif self . Variety == 2 : xml_item . set ( 'Variety' , 'HPET' ) else : xml_item . set ( 'Variety' , 'Reserved %X ' % ( self . Variety )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) if self . Variety == 1 : var_str = \"IOAPIC\" elif self . Variety == 2 : var_str = \"HPET\" else : var_str = \"Reserved 0x %02X \" % ( self . Variety ) print ( ' \\t\\t Handle : 0x{Handle:02X}' . format ( Handle = self . Handle )) print ( ' \\t\\t Variety : {Variety:s}' . format ( Variety = var_str )) class DEVICE_TABLE_ENTRY_ACPI ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI , self . Type ) self . TypeString = \"Variable Length ACPI HID Device\" ( self . HID , self . CID , self . UIDFormat , self . UIDLength ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len ]) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len + self . UIDLength if self . UIDFormat == 0 : self . UID = None elif self . UIDFormat == 1 : ( self . UID ,) = struct . unpack ( \"=Q\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len : self . Length ]) elif self . UIDFormat == 2 : ( self . UID ,) = \\ struct . unpack ( \"= %s s\" % self . UIDLength , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Variable Length ACPI HID Device byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , self . HID , self . CID , self . UIDFormat , self . UIDLength ) if self . UIDFormat == 1 : byte_str += struct . pack ( \"=Q\" , self . UID ) elif self . UIDFormat == 2 : byte_str += struct . pack ( \"= %s s\" % self . UIDLength , self . UID ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'HardwareID' , ' %s ' % ( self . HID )) xml_item . set ( 'ExtendedDTE Setting' , ' %s ' % ( self . CID )) xml_item . set ( 'UniqueIDFormat' , ' %d ' % ( self . UIDFormat )) xml_item . set ( 'UniqueIDLength' , ' %d ' % ( self . UIDLength )) if self . UIDFormat == 0 : xml_item . set ( 'UniqueID' , 'None' ) elif self . UIDFormat == 1 : xml_item . set ( 'UniqueID' , '0x %X ' % ( self . UID )) elif self . UIDFormat == 2 : xml_item . set ( 'UniqueID' , ' %s ' % ( self . UID )) else : print ( \"Unrecognized UID format detected\" ) sys . exit ( - 1 ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Hardware ID : {HID:s}' . format ( HID = self . HID . decode ())) print ( ' \\t\\t Extended DTE Setting : {CID:s}' . format ( CID = self . CID . decode ())) print ( ' \\t\\t Unique ID Format : {UIDFormat:d}' . format ( UIDFormat = self . UIDFormat )) print ( ' \\t\\t Unique ID Length : {UIDLength:d}' . format ( UIDLength = self . UIDLength )) if self . UIDFormat == 0 : print ( ' \\t\\t Unique ID : None' ) elif self . UIDFormat == 1 : print ( ' \\t\\t Unique ID : 0x{UID:X}' . format ( UID = self . UID )) elif self . UIDFormat == 2 : print ( ' \\t\\t Unique ID : {UID:s}' . format ( UID = self . UID . decode ())) else : raise Exception ( \"Unrecognized UID format detected %d \" % self . UIDFormat ) Variables IVRSParserVersion Classes IVRS_TABLE class IVRS_TABLE ( data = None ) View Source class IVRS_TABLE ( object ) : def __init__ ( self , data = None ) : self . acpi_header = None self . SubStructs = list () self . IVMD_list = list () if data is not None : self . Decode ( data ) def Decode ( self , data ) : self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [ :IVRS_TABLE.ACPI_TABLE_HEADER.struct_format_size ] ) # Start from the end of ACPI header , but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE.ACPI_TABLE_HEADER.struct_format_size: ] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ) : raise Exception ( 'Incoming data checksum does not add up: checksum field %x, calculated is %x' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ) : remapping_header = self . IVMD_STRUCT ( t_data [ :IVRS_TABLE.IVMD_STRUCT.struct_format_size ] ) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) : self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header.Length: ] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ) : raise Exception ( \"IVRS length does not add up. Parsed len: %d, reported len: %d\" % ( t_length , self . acpi_header . Length )) def Encode ( self ) : bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD / IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str def ToXmlElementTree ( self ) : root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root def DumpInfo ( self ) : self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo () @staticmethod def validateChecksum8 ( data ) : return sum ( data ) & 0xFF def updateACPISum ( self ) : temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0x100 - ( temp_sum & 0xFF )) & 0xFF def addIVHDEntry ( self , ivhd ) : # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum () def addIVMDEntry ( self , ivmd ) : # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD , thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum () def IVRSBitEnabled ( self ) : return bool ( self . acpi_header . IVRSBit ) class ACPI_TABLE_HEADER ( object ) : struct_format = '=4sIBB6s8sI4sIIQ' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , data = None ) : self . Signature = None self . Length = 0 self . Revision = 0 self . Checksum = 0 self . OEMID = 0 self . OEMTableID = 0 self . OEMRevision = 0 self . CreatorID = 0 self . CreatorRevision = 0 self . IVinfo = None self . Reserved = 0 self . IVRSBit = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) = struct . unpack ( IVRS_TABLE . ACPI_TABLE_HEADER . struct_format , header_byte_array ) self . IVRSBit = self . IVinfo & 0x02 if ( self . IVinfo & 0x1E ) == 0 : sys . exit ( - 1 ) def Encode ( self ) : return struct . pack ( self . struct_format , self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) def DumpInfo ( self ) : print ( ' ACPI Table Header' ) print ( '------------------------------------------------------------------' ) print ( 'Signature : {Signature:s}' . format ( Signature = self . Signature . decode ())) print ( 'Length : 0x{Length:08X}' . format ( Length = self . Length )) print ( 'Revision : 0x{Revision:02X}' . format ( Revision = self . Revision )) print ( 'Checksum : 0x{Checksum:02X}' . format ( Checksum = self . Checksum )) print ( 'OEM ID : {OEMID:s}' . format ( OEMID = self . OEMID . decode ())) print ( 'OEM Table ID : {OEMTableID:s}' . format ( OEMTableID = self . OEMTableID . decode ())) print ( 'OEM Revision : 0x{OEMRevision:08X}' . format ( OEMRevision = self . OEMRevision )) print ( 'Creator ID : {CreatorID:s}' . format ( CreatorID = self . CreatorID . decode ())) print ( 'Creator Revision : 0x{CreatorRevision:08X}' . format ( CreatorRevision = self . CreatorRevision )) print ( 'IVinfo : 0x{IVinfo:08X}' . format ( IVinfo = self . IVinfo )) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'IVinfo' , '0x%X' % self . IVinfo ) return xml_repr class REMAPPING_STRUCT_HEADER ( object ) : struct_format = '=B' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , header_byte_array ) : ( self . Type , ) = struct . unpack ( IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format , header_byte_array [ :IVRS_TABLE.REMAPPING_STRUCT_HEADER.struct_format_size ] ) class IVHD_STRUCT ( REMAPPING_STRUCT_HEADER ) : # cspell : disable - next disable the spell checker from thinking this a word struct_format = '=BBHHHQHHI' struct_format_size = struct . calcsize ( struct_format ) ex_format = \"=QQ\" ex_format_size = struct . calcsize ( ex_format ) class IVHD_TYPE ( IntEnum ) : TYPE_10H = 0x10 TYPE_11H = 0x11 TYPE_40H = 0x40 def __init__ ( self , data = None ) : self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . CapabilityOffset = 0 self . IOMMUBaseAddress = 0 self . SegmentGroup = 0 self . IOMMUInfo = None self . IOMMUFeatureInfo = None self . IOMMUEFRImage = None self . Reserved = 0 self . DeviceTableEntries = list () if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . Flags , t_Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) = struct . unpack ( IVRS_TABLE . IVHD_STRUCT . struct_format , header_byte_array [ :IVRS_TABLE.IVHD_STRUCT.struct_format_size ] ) self . Length = 0 if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : ivhd_hdr_size = ( IVRS_TABLE . IVHD_STRUCT . struct_format_size + IVRS_TABLE . IVHD_STRUCT . ex_format_size ) ( self . IOMMUEFRImage , self . Reserved ) = \\ struct . unpack ( IVRS_TABLE . IVHD_STRUCT . ex_format , header_byte_array [ IVRS_TABLE.IVHD_STRUCT.struct_format_size:ivhd_hdr_size ] ) else : ivhd_hdr_size = IVRS_TABLE . IVHD_STRUCT . struct_format_size header_byte_array = header_byte_array [ ivhd_hdr_size: ] bytes_left = t_Length - ivhd_hdr_size self . Length += ivhd_hdr_size # Get Sub Structs while bytes_left > 0 : device_scope = IVRS_TABLE . DEVICE_TABLE_ENTRY . Factory ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length if ( device_scope . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END ) : self . addDTEEntry ( device_scope ) if ( t_Length != self . Length ) or ( bytes_left != 0 ) : raise Exception ( \"IVHD length does not add up. Parsed len: %d, reported len: %d\" % ( self . Length , t_Length )) def Encode ( self ) : byte_str = b '' byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) if self . IOMMUEFRImage is not None : byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . ex_format , self . IOMMUEFRImage , self . Reserved ) for dte in self . DeviceTableEntries : byte_str += dte . Encode () return byte_str def addDTEEntry ( self , dte ) : # append raw data , update length . checksum will be left untouched self . Length += len ( dte . Encode ()) self . DeviceTableEntries . append ( dte ) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'IVHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'IOMMUDeviceID' , '0x%X' % self . DeviceID ) xml_repr . set ( 'CapabilityOffset' , '0x%X' % self . CapabilityOffset ) xml_repr . set ( 'IOMMUBaseAddress' , '0x%X' % self . IOMMUBaseAddress ) xml_repr . set ( 'SegmentGroup' , '0x%X' % self . SegmentGroup ) xml_repr . set ( 'IOMMUInfo' , '0x%X' % self . IOMMUInfo ) xml_repr . set ( 'IOMMUFeatureInfo' , '0x%X' % self . IOMMUFeatureInfo ) if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : xml_repr . set ( 'IOMMUEFRImage' , '0x%X' % self . IOMMUEFRImage ) # Add SubStructs for item in self . DeviceTableEntries : xml_repr . append ( item . ToXmlElementTree ()) return xml_repr def DumpInfo ( self ) : print ( \"\\t IVHD\" ) print ( \"\\t----------------------------------------------------------------\" ) print ( '\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\tFlags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( '\\tLength : 0x{Length:04X}' . format ( Length = self . Length )) print ( '\\tIOMMU Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\tCapability Offset : 0x{CapabilityOffset:04X}' . format ( CapabilityOffset = self . CapabilityOffset )) print ( '\\tIOMMU Base Address : 0x{IOMMUBaseAddress:016X}' . format ( IOMMUBaseAddress = self . IOMMUBaseAddress )) print ( '\\tSegment Group : 0x{SegmentGroup:04X}' . format ( SegmentGroup = self . SegmentGroup )) print ( '\\tIOMMU Info : 0x{IOMMUInfo:04X}' . format ( IOMMUInfo = self . IOMMUInfo )) print ( '\\tIOMMU Feature Info : 0x{IOMMUFeatureInfo:08X}' . format ( IOMMUFeatureInfo = self . IOMMUFeatureInfo )) for item in self . DeviceTableEntries : item . DumpInfo () class IVMD_STRUCT ( REMAPPING_STRUCT_HEADER ) : # cspell : disable - next disable spell checker from thinking this is a word struct_format = '=BBHHHQQQ' struct_format_size = struct . calcsize ( struct_format ) class IVMD_TYPE ( IntEnum ) : TYPE_20H = 0x20 # All peripherals TYPE_21H = 0x21 # Specified peripheral TYPE_22H = 0x22 # Peripheral range def __init__ ( self , data = None ) : self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . AuxiliaryData = None self . Reserved = 0 self . IVMDStartAddress = 0 self . IVMDMemoryBlockLength = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) = struct . unpack ( IVRS_TABLE . IVMD_STRUCT . struct_format , header_byte_array ) # IVMD is simple , the length is fixed , so assert if not if ( self . Length != len ( header_byte_array )) : raise Exception ( \"Bad IVMD entry size %d, expecting %d\" % ( self . Length , len ( header_byte_array ))) def Encode ( self ) : return struct . pack ( IVRS_TABLE . IVMD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'IVMD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'DeviceID' , '0x%X' % self . DeviceID ) if ( self . Type != IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ) : xml_repr . set ( 'AuxiliaryData' , '0x%X' % self . AuxiliaryData ) else : xml_repr . set ( 'EndofRange' , '0x%X' % self . AuxiliaryData ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'IVMDStartAddress' , '0x%X' % self . IVMDStartAddress ) xml_repr . set ( 'IVMDMemoryBlockLength' , '0x%X' % self . IVMDMemoryBlockLength ) return xml_repr def DumpInfo ( self ) : print ( \"\\t IVMD\" ) print ( \"\\t----------------------------------------------------------------\" ) print ( '\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\tFlags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( '\\tLength : 0x{Length:04X}' . format ( Length = self . Length )) print ( '\\tDeviceID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\tAuxiliaryData : 0x{AuxiliaryData:04X}' . format ( AuxiliaryData = self . AuxiliaryData )) print ( '\\tReserved : 0x{Reserved:016X}' . format ( Reserved = self . Reserved )) print ( '\\tIVMD Start Address : 0x{IVMDStartAddress:016X}' . format ( IVMDStartAddress = self . IVMDStartAddress )) print ( '\\tIVMD Memory Block Length : 0x{IVMDMemoryBlockLength:016X}' . format ( IVMDMemoryBlockLength = self . Type )) class DEVICE_TABLE_ENTRY ( object ) : struct_format = '=BHB' struct_format_size = struct . calcsize ( struct_format ) dte_var_ext_format = \"=8s8sBB\" dte_var_len = struct_format_size + struct . calcsize ( dte_var_ext_format ) class DTE_TYPE ( IntEnum ) : RESERVED = 0 ALL = 1 SELECT = 2 RANGE_START = 3 RANGE_END = 4 ALIAS_SELECT = 66 ALIAS_RANGE_START = 67 EX_SELECT = 70 EX_RANGE_START = 71 SPECIAL = 72 ACPI = 240 # # this method is a factory # @staticmethod def Factory ( data ) : if ( data is None ) : raise Exception ( \"Invalid File stream\" ) RemapHeader = IVRS_TABLE . REMAPPING_STRUCT_HEADER ( data ) Type = RemapHeader . Type if ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_RESERVED ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_SPECIAL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ACPI ( data ) else : return None class DEVICE_TABLE_ENTRY_RESERVED ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'Type' , '0x%X' % self . Type ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALL ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL , self . Type ) self . TypeString = \"All\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START , self . Type ) self . TypeString = \"Range\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALIAS_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT , self . Type ) self . TypeString = \"Alias Select\" # Two DevID , one for alias , one for source self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . EndDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START , self . Type ) self . TypeString = \"Alias Range\" # Two DevID , one for alias start , one for source start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_EX_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT , self . Type ) self . TypeString = \"Extended Select\" # Two DTE setting , one for standard setting , one for extended setting ( AtsDisabled , etc .) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting , one for standard setting , one for extended setting ( AtsDisabled , etc .) byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( '\\t\\tExtended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_EX_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START , self . Type ) self . TypeString = \"Extended Range\" # Two DTE setting , one for standard setting start , one for extended setting start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting , one for standard setting start , one for extended setting start byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 4 , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( '\\t\\tExtended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_SPECIAL ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL , self . Type ) self . TypeString = \"Special Device\" # First half for standard DTE setting , second half for special DevID and its variety ( APIC , HPET , etc .) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . Handle , self . SourceDeviceID , self . Variety ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # First half for standard DTE setting , second half for special DevID and its variety ( APIC , HPET , etc .) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Handle , self . SourceDeviceID , self . Variety ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) xml_item . set ( 'Handle' , '0x%X' % ( self . Handle )) if self . Variety == 1 : xml_item . set ( 'Variety' , 'IOAPIC' ) elif self . Variety == 2 : xml_item . set ( 'Variety' , 'HPET' ) else : xml_item . set ( 'Variety' , 'Reserved %X' % ( self . Variety )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) if self . Variety == 1 : var_str = \"IOAPIC\" elif self . Variety == 2 : var_str = \"HPET\" else : var_str = \"Reserved 0x%02X\" % ( self . Variety ) print ( '\\t\\tHandle : 0x{Handle:02X}' . format ( Handle = self . Handle )) print ( '\\t\\tVariety : {Variety:s}' . format ( Variety = var_str )) class DEVICE_TABLE_ENTRY_ACPI ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI , self . Type ) self . TypeString = \"Variable Length ACPI HID Device\" ( self . HID , self . CID , self . UIDFormat , self . UIDLength ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size: IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len ] ) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len + self . UIDLength if self . UIDFormat == 0 : self . UID = None elif self . UIDFormat == 1 : ( self . UID ,) = struct . unpack ( \"=Q\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len: self.Length ] ) elif self . UIDFormat == 2 : ( self . UID ,) = \\ struct . unpack ( \"=%ss\" % self . UIDLength , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Variable Length ACPI HID Device byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , self . HID , self . CID , self . UIDFormat , self . UIDLength ) if self . UIDFormat == 1 : byte_str += struct . pack ( \"=Q\" , self . UID ) elif self . UIDFormat == 2 : byte_str += struct . pack ( \"=%ss\" % self . UIDLength , self . UID ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'HardwareID' , '%s' % ( self . HID )) xml_item . set ( 'ExtendedDTE Setting' , '%s' % ( self . CID )) xml_item . set ( 'UniqueIDFormat' , '%d' % ( self . UIDFormat )) xml_item . set ( 'UniqueIDLength' , '%d' % ( self . UIDLength )) if self . UIDFormat == 0 : xml_item . set ( 'UniqueID' , 'None' ) elif self . UIDFormat == 1 : xml_item . set ( 'UniqueID' , '0x%X' % ( self . UID )) elif self . UIDFormat == 2 : xml_item . set ( 'UniqueID' , '%s' % ( self . UID )) else : print ( \"Unrecognized UID format detected\" ) sys . exit ( - 1 ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tHardware ID : {HID:s}' . format ( HID = self . HID . decode ())) print ( '\\t\\tExtended DTE Setting : {CID:s}' . format ( CID = self . CID . decode ())) print ( '\\t\\tUnique ID Format : {UIDFormat:d}' . format ( UIDFormat = self . UIDFormat )) print ( '\\t\\tUnique ID Length : {UIDLength:d}' . format ( UIDLength = self . UIDLength )) if self . UIDFormat == 0 : print ( '\\t\\tUnique ID : None' ) elif self . UIDFormat == 1 : print ( '\\t\\tUnique ID : 0x{UID:X}' . format ( UID = self . UID )) elif self . UIDFormat == 2 : print ( '\\t\\tUnique ID : {UID:s}' . format ( UID = self . UID . decode ())) else : raise Exception ( \"Unrecognized UID format detected %d\" % self . UIDFormat ) Class variables ACPI_TABLE_HEADER DEVICE_TABLE_ENTRY DEVICE_TABLE_ENTRY_ACPI DEVICE_TABLE_ENTRY_ALIAS_RANGE_START DEVICE_TABLE_ENTRY_ALIAS_SELECT DEVICE_TABLE_ENTRY_ALL DEVICE_TABLE_ENTRY_EX_RANGE_START DEVICE_TABLE_ENTRY_EX_SELECT DEVICE_TABLE_ENTRY_RANGE_START DEVICE_TABLE_ENTRY_RESERVED DEVICE_TABLE_ENTRY_SELECT DEVICE_TABLE_ENTRY_SPECIAL IVHD_STRUCT IVMD_STRUCT REMAPPING_STRUCT_HEADER Static methods validateChecksum8 def validateChecksum8 ( data ) View Source @staticmethod def validateChecksum8 ( data ) : return sum ( data ) & 0xFF Methods Decode def Decode ( self , data ) View Source def Decode ( self , data ): self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [: IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size ]) # Start from the end of ACPI header , but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size :] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ): raise Exception ( 'Incoming data checksum does not add up: checksum field %x, calculated is %x' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): remapping_header = self . IVMD_STRUCT ( t_data [: IVRS_TABLE . IVMD_STRUCT . struct_format_size ]) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ): self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header . Length :] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ): raise Exception ( \"IVRS length does not add up. Parsed len: %d, reported len: %d\" % ( t_length , self . acpi_header . Length )) DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo () Encode def Encode ( self ) View Source def Encode ( self ): bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD / IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str IVRSBitEnabled def IVRSBitEnabled ( self ) View Source def IVRSBitEnabled ( self ): return bool ( self . acpi_header . IVRSBit ) ToXmlElementTree def ToXmlElementTree ( self ) View Source def ToXmlElementTree ( self ): root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root addIVHDEntry def addIVHDEntry ( self , ivhd ) View Source def addIVHDEntry ( self , ivhd ): # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum () addIVMDEntry def addIVMDEntry ( self , ivmd ) View Source def addIVMDEntry ( self , ivmd ): # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD , thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum () updateACPISum def updateACPISum ( self ) View Source def updateACPISum ( self ): temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0 x100 - ( temp_sum & 0 xFF )) & 0 xFF","title":"Ivrs parser"},{"location":"edk2toollib/acpi/ivrs_parser/#module-edk2toollibacpiivrs_parser","text":"View Source ## # Copyright (C) Microsoft Corporation. All rights reserved. # SPDX-License-Identifier: BSD-2-Clause-Patent # # Python script that converts a raw IVRS table into a struct, the spec version is based on # https://www.amd.com/system/files/TechDocs/48882_IOMMU.pdf ## import sys import struct import xml.etree.ElementTree as ET from enum import IntEnum IVRSParserVersion = '1.00' # spell-checker:ignore IVMD, IOMMUEFR class IVRS_TABLE ( object ): def __init__ ( self , data = None ): self . acpi_header = None self . SubStructs = list () self . IVMD_list = list () if data is not None : self . Decode ( data ) def Decode ( self , data ): self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [: IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size ]) # Start from the end of ACPI header, but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size :] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ): raise Exception ( 'Incoming data checksum does not add up: checksum field %x , calculated is %x ' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): remapping_header = self . IVMD_STRUCT ( t_data [: IVRS_TABLE . IVMD_STRUCT . struct_format_size ]) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ): self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d ' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header . Length :] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ): raise Exception ( \"IVRS length does not add up. Parsed len: %d , reported len: %d \" % ( t_length , self . acpi_header . Length )) def Encode ( self ): bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD/IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str def ToXmlElementTree ( self ): root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root def DumpInfo ( self ): self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo () @staticmethod def validateChecksum8 ( data ): return sum ( data ) & 0xFF def updateACPISum ( self ): temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0x100 - ( temp_sum & 0xFF )) & 0xFF def addIVHDEntry ( self , ivhd ): # append entry to the list, update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum () def addIVMDEntry ( self , ivmd ): # append entry to the list, update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD, thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum () def IVRSBitEnabled ( self ): return bool ( self . acpi_header . IVRSBit ) class ACPI_TABLE_HEADER ( object ): struct_format = '=4sIBB6s8sI4sIIQ' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , data = None ): self . Signature = None self . Length = 0 self . Revision = 0 self . Checksum = 0 self . OEMID = 0 self . OEMTableID = 0 self . OEMRevision = 0 self . CreatorID = 0 self . CreatorRevision = 0 self . IVinfo = None self . Reserved = 0 self . IVRSBit = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) = struct . unpack ( IVRS_TABLE . ACPI_TABLE_HEADER . struct_format , header_byte_array ) self . IVRSBit = self . IVinfo & 0x02 if ( self . IVinfo & 0x1E ) == 0 : sys . exit ( - 1 ) def Encode ( self ): return struct . pack ( self . struct_format , self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) def DumpInfo ( self ): print ( ' ACPI Table Header' ) print ( '------------------------------------------------------------------' ) print ( 'Signature : {Signature:s}' . format ( Signature = self . Signature . decode ())) print ( 'Length : 0x{Length:08X}' . format ( Length = self . Length )) print ( 'Revision : 0x{Revision:02X}' . format ( Revision = self . Revision )) print ( 'Checksum : 0x{Checksum:02X}' . format ( Checksum = self . Checksum )) print ( 'OEM ID : {OEMID:s}' . format ( OEMID = self . OEMID . decode ())) print ( 'OEM Table ID : {OEMTableID:s}' . format ( OEMTableID = self . OEMTableID . decode ())) print ( 'OEM Revision : 0x{OEMRevision:08X}' . format ( OEMRevision = self . OEMRevision )) print ( 'Creator ID : {CreatorID:s}' . format ( CreatorID = self . CreatorID . decode ())) print ( 'Creator Revision : 0x{CreatorRevision:08X}' . format ( CreatorRevision = self . CreatorRevision )) print ( 'IVinfo : 0x{IVinfo:08X}' . format ( IVinfo = self . IVinfo )) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'IVinfo' , '0x %X ' % self . IVinfo ) return xml_repr class REMAPPING_STRUCT_HEADER ( object ): struct_format = '=B' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , header_byte_array ): ( self . Type , ) = struct . unpack ( IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format , header_byte_array [: IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format_size ]) class IVHD_STRUCT ( REMAPPING_STRUCT_HEADER ): # cspell:disable-next disable the spell checker from thinking this a word struct_format = '=BBHHHQHHI' struct_format_size = struct . calcsize ( struct_format ) ex_format = \"=QQ\" ex_format_size = struct . calcsize ( ex_format ) class IVHD_TYPE ( IntEnum ): TYPE_10H = 0x10 TYPE_11H = 0x11 TYPE_40H = 0x40 def __init__ ( self , data = None ): self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . CapabilityOffset = 0 self . IOMMUBaseAddress = 0 self . SegmentGroup = 0 self . IOMMUInfo = None self . IOMMUFeatureInfo = None self . IOMMUEFRImage = None self . Reserved = 0 self . DeviceTableEntries = list () if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . Flags , t_Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) = struct . unpack ( IVRS_TABLE . IVHD_STRUCT . struct_format , header_byte_array [: IVRS_TABLE . IVHD_STRUCT . struct_format_size ]) self . Length = 0 if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): ivhd_hdr_size = ( IVRS_TABLE . IVHD_STRUCT . struct_format_size + IVRS_TABLE . IVHD_STRUCT . ex_format_size ) ( self . IOMMUEFRImage , self . Reserved ) = \\ struct . unpack ( IVRS_TABLE . IVHD_STRUCT . ex_format , header_byte_array [ IVRS_TABLE . IVHD_STRUCT . struct_format_size : ivhd_hdr_size ]) else : ivhd_hdr_size = IVRS_TABLE . IVHD_STRUCT . struct_format_size header_byte_array = header_byte_array [ ivhd_hdr_size :] bytes_left = t_Length - ivhd_hdr_size self . Length += ivhd_hdr_size # Get Sub Structs while bytes_left > 0 : device_scope = IVRS_TABLE . DEVICE_TABLE_ENTRY . Factory ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length if ( device_scope . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END ): self . addDTEEntry ( device_scope ) if ( t_Length != self . Length ) or ( bytes_left != 0 ): raise Exception ( \"IVHD length does not add up. Parsed len: %d , reported len: %d \" % ( self . Length , t_Length )) def Encode ( self ): byte_str = b '' byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) if self . IOMMUEFRImage is not None : byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . ex_format , self . IOMMUEFRImage , self . Reserved ) for dte in self . DeviceTableEntries : byte_str += dte . Encode () return byte_str def addDTEEntry ( self , dte ): # append raw data, update length. checksum will be left untouched self . Length += len ( dte . Encode ()) self . DeviceTableEntries . append ( dte ) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'IVHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'IOMMUDeviceID' , '0x %X ' % self . DeviceID ) xml_repr . set ( 'CapabilityOffset' , '0x %X ' % self . CapabilityOffset ) xml_repr . set ( 'IOMMUBaseAddress' , '0x %X ' % self . IOMMUBaseAddress ) xml_repr . set ( 'SegmentGroup' , '0x %X ' % self . SegmentGroup ) xml_repr . set ( 'IOMMUInfo' , '0x %X ' % self . IOMMUInfo ) xml_repr . set ( 'IOMMUFeatureInfo' , '0x %X ' % self . IOMMUFeatureInfo ) if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): xml_repr . set ( 'IOMMUEFRImage' , '0x %X ' % self . IOMMUEFRImage ) # Add SubStructs for item in self . DeviceTableEntries : xml_repr . append ( item . ToXmlElementTree ()) return xml_repr def DumpInfo ( self ): print ( \" \\t IVHD\" ) print ( \" \\t ----------------------------------------------------------------\" ) print ( ' \\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t Flags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( ' \\t Length : 0x{Length:04X}' . format ( Length = self . Length )) print ( ' \\t IOMMU Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t Capability Offset : 0x{CapabilityOffset:04X}' . format ( CapabilityOffset = self . CapabilityOffset )) print ( ' \\t IOMMU Base Address : 0x{IOMMUBaseAddress:016X}' . format ( IOMMUBaseAddress = self . IOMMUBaseAddress )) print ( ' \\t Segment Group : 0x{SegmentGroup:04X}' . format ( SegmentGroup = self . SegmentGroup )) print ( ' \\t IOMMU Info : 0x{IOMMUInfo:04X}' . format ( IOMMUInfo = self . IOMMUInfo )) print ( ' \\t IOMMU Feature Info : 0x{IOMMUFeatureInfo:08X}' . format ( IOMMUFeatureInfo = self . IOMMUFeatureInfo )) for item in self . DeviceTableEntries : item . DumpInfo () class IVMD_STRUCT ( REMAPPING_STRUCT_HEADER ): # cspell:disable-next disable spell checker from thinking this is a word struct_format = '=BBHHHQQQ' struct_format_size = struct . calcsize ( struct_format ) class IVMD_TYPE ( IntEnum ): TYPE_20H = 0x20 # All peripherals TYPE_21H = 0x21 # Specified peripheral TYPE_22H = 0x22 # Peripheral range def __init__ ( self , data = None ): self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . AuxiliaryData = None self . Reserved = 0 self . IVMDStartAddress = 0 self . IVMDMemoryBlockLength = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) = struct . unpack ( IVRS_TABLE . IVMD_STRUCT . struct_format , header_byte_array ) # IVMD is simple, the length is fixed, so assert if not if ( self . Length != len ( header_byte_array )): raise Exception ( \"Bad IVMD entry size %d , expecting %d \" % ( self . Length , len ( header_byte_array ))) def Encode ( self ): return struct . pack ( IVRS_TABLE . IVMD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) def ToXmlElementTree ( self ): xml_repr = ET . Element ( 'IVMD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'DeviceID' , '0x %X ' % self . DeviceID ) if ( self . Type != IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): xml_repr . set ( 'AuxiliaryData' , '0x %X ' % self . AuxiliaryData ) else : xml_repr . set ( 'EndofRange' , '0x %X ' % self . AuxiliaryData ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'IVMDStartAddress' , '0x %X ' % self . IVMDStartAddress ) xml_repr . set ( 'IVMDMemoryBlockLength' , '0x %X ' % self . IVMDMemoryBlockLength ) return xml_repr def DumpInfo ( self ): print ( \" \\t IVMD\" ) print ( \" \\t ----------------------------------------------------------------\" ) print ( ' \\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t Flags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( ' \\t Length : 0x{Length:04X}' . format ( Length = self . Length )) print ( ' \\t DeviceID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t AuxiliaryData : 0x{AuxiliaryData:04X}' . format ( AuxiliaryData = self . AuxiliaryData )) print ( ' \\t Reserved : 0x{Reserved:016X}' . format ( Reserved = self . Reserved )) print ( ' \\t IVMD Start Address : 0x{IVMDStartAddress:016X}' . format ( IVMDStartAddress = self . IVMDStartAddress )) print ( ' \\t IVMD Memory Block Length : 0x{IVMDMemoryBlockLength:016X}' . format ( IVMDMemoryBlockLength = self . Type )) class DEVICE_TABLE_ENTRY ( object ): struct_format = '=BHB' struct_format_size = struct . calcsize ( struct_format ) dte_var_ext_format = \"=8s8sBB\" dte_var_len = struct_format_size + struct . calcsize ( dte_var_ext_format ) class DTE_TYPE ( IntEnum ): RESERVED = 0 ALL = 1 SELECT = 2 RANGE_START = 3 RANGE_END = 4 ALIAS_SELECT = 66 ALIAS_RANGE_START = 67 EX_SELECT = 70 EX_RANGE_START = 71 SPECIAL = 72 ACPI = 240 # # this method is a factory # @staticmethod def Factory ( data ): if ( data is None ): raise Exception ( \"Invalid File stream\" ) RemapHeader = IVRS_TABLE . REMAPPING_STRUCT_HEADER ( data ) Type = RemapHeader . Type if ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_RESERVED ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_SPECIAL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ): return IVRS_TABLE . DEVICE_TABLE_ENTRY_ACPI ( data ) else : return None class DEVICE_TABLE_ENTRY_RESERVED ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALL ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL , self . Type ) self . TypeString = \"All\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START , self . Type ) self . TypeString = \"Range\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALIAS_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT , self . Type ) self . TypeString = \"Alias Select\" # Two DevID, one for alias, one for source self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . EndDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START , self . Type ) self . TypeString = \"Alias Range\" # Two DevID, one for alias start, one for source start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_EX_SELECT ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT , self . Type ) self . TypeString = \"Extended Select\" # Two DTE setting, one for standard setting, one for extended setting (AtsDisabled, etc.) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting, one for standard setting, one for extended setting (AtsDisabled, etc.) byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( ' \\t\\t Extended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_EX_RANGE_START ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START , self . Type ) self . TypeString = \"Extended Range\" # Two DTE setting, one for standard setting start, one for extended setting start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self . Length : ( self . Length + IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size )]) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting, one for standard setting start, one for extended setting start byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 4 , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'StartofRange' , '0x %X ' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x %X ' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Start of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t End of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( ' \\t\\t Extended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_SPECIAL ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL , self . Type ) self . TypeString = \"Special Device\" # First half for standard DTE setting, second half for special DevID and its variety (APIC, HPET, etc.) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . Handle , self . SourceDeviceID , self . Variety ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # First half for standard DTE setting, second half for special DevID and its variety (APIC, HPET, etc.) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Handle , self . SourceDeviceID , self . Variety ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x %X ' % ( self . SourceDeviceID )) xml_item . set ( 'Handle' , '0x %X ' % ( self . Handle )) if self . Variety == 1 : xml_item . set ( 'Variety' , 'IOAPIC' ) elif self . Variety == 2 : xml_item . set ( 'Variety' , 'HPET' ) else : xml_item . set ( 'Variety' , 'Reserved %X ' % ( self . Variety )) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Source Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) if self . Variety == 1 : var_str = \"IOAPIC\" elif self . Variety == 2 : var_str = \"HPET\" else : var_str = \"Reserved 0x %02X \" % ( self . Variety ) print ( ' \\t\\t Handle : 0x{Handle:02X}' . format ( Handle = self . Handle )) print ( ' \\t\\t Variety : {Variety:s}' . format ( Variety = var_str )) class DEVICE_TABLE_ENTRY_ACPI ( object ): def __init__ ( self , data = None ): self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ): ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [: IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ]) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ): raise Exception ( \"Input device type ( %d ) does not match expectation ( %d )\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI , self . Type ) self . TypeString = \"Variable Length ACPI HID Device\" ( self . HID , self . CID , self . UIDFormat , self . UIDLength ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size : IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len ]) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len + self . UIDLength if self . UIDFormat == 0 : self . UID = None elif self . UIDFormat == 1 : ( self . UID ,) = struct . unpack ( \"=Q\" , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len : self . Length ]) elif self . UIDFormat == 2 : ( self . UID ,) = \\ struct . unpack ( \"= %s s\" % self . UIDLength , header_byte_array [ IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len : self . Length ]) def Encode ( self ): byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Variable Length ACPI HID Device byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , self . HID , self . CID , self . UIDFormat , self . UIDLength ) if self . UIDFormat == 1 : byte_str += struct . pack ( \"=Q\" , self . UID ) elif self . UIDFormat == 2 : byte_str += struct . pack ( \"= %s s\" % self . UIDLength , self . UID ) return byte_str def ToXmlElementTree ( self ): xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x %X ' % self . Type ) xml_item . set ( 'DeviceID' , '0x %X ' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x %X ' % ( self . DTESetting )) xml_item . set ( 'HardwareID' , ' %s ' % ( self . HID )) xml_item . set ( 'ExtendedDTE Setting' , ' %s ' % ( self . CID )) xml_item . set ( 'UniqueIDFormat' , ' %d ' % ( self . UIDFormat )) xml_item . set ( 'UniqueIDLength' , ' %d ' % ( self . UIDLength )) if self . UIDFormat == 0 : xml_item . set ( 'UniqueID' , 'None' ) elif self . UIDFormat == 1 : xml_item . set ( 'UniqueID' , '0x %X ' % ( self . UID )) elif self . UIDFormat == 2 : xml_item . set ( 'UniqueID' , ' %s ' % ( self . UID )) else : print ( \"Unrecognized UID format detected\" ) sys . exit ( - 1 ) return xml_item def DumpInfo ( self ): print ( ' \\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( ' \\t\\t --------------------------------------------------' ) print ( ' \\t\\t Type : 0x{Type:02X}' . format ( Type = self . Type )) print ( ' \\t\\t Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( ' \\t\\t DTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( ' \\t\\t Hardware ID : {HID:s}' . format ( HID = self . HID . decode ())) print ( ' \\t\\t Extended DTE Setting : {CID:s}' . format ( CID = self . CID . decode ())) print ( ' \\t\\t Unique ID Format : {UIDFormat:d}' . format ( UIDFormat = self . UIDFormat )) print ( ' \\t\\t Unique ID Length : {UIDLength:d}' . format ( UIDLength = self . UIDLength )) if self . UIDFormat == 0 : print ( ' \\t\\t Unique ID : None' ) elif self . UIDFormat == 1 : print ( ' \\t\\t Unique ID : 0x{UID:X}' . format ( UID = self . UID )) elif self . UIDFormat == 2 : print ( ' \\t\\t Unique ID : {UID:s}' . format ( UID = self . UID . decode ())) else : raise Exception ( \"Unrecognized UID format detected %d \" % self . UIDFormat )","title":"Module edk2toollib.acpi.ivrs_parser"},{"location":"edk2toollib/acpi/ivrs_parser/#variables","text":"IVRSParserVersion","title":"Variables"},{"location":"edk2toollib/acpi/ivrs_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/acpi/ivrs_parser/#ivrs_table","text":"class IVRS_TABLE ( data = None ) View Source class IVRS_TABLE ( object ) : def __init__ ( self , data = None ) : self . acpi_header = None self . SubStructs = list () self . IVMD_list = list () if data is not None : self . Decode ( data ) def Decode ( self , data ) : self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [ :IVRS_TABLE.ACPI_TABLE_HEADER.struct_format_size ] ) # Start from the end of ACPI header , but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE.ACPI_TABLE_HEADER.struct_format_size: ] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ) : raise Exception ( 'Incoming data checksum does not add up: checksum field %x, calculated is %x' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ) : remapping_header = self . IVMD_STRUCT ( t_data [ :IVRS_TABLE.IVMD_STRUCT.struct_format_size ] ) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) : self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header.Length: ] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ) : raise Exception ( \"IVRS length does not add up. Parsed len: %d, reported len: %d\" % ( t_length , self . acpi_header . Length )) def Encode ( self ) : bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD / IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str def ToXmlElementTree ( self ) : root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root def DumpInfo ( self ) : self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo () @staticmethod def validateChecksum8 ( data ) : return sum ( data ) & 0xFF def updateACPISum ( self ) : temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0x100 - ( temp_sum & 0xFF )) & 0xFF def addIVHDEntry ( self , ivhd ) : # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum () def addIVMDEntry ( self , ivmd ) : # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD , thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum () def IVRSBitEnabled ( self ) : return bool ( self . acpi_header . IVRSBit ) class ACPI_TABLE_HEADER ( object ) : struct_format = '=4sIBB6s8sI4sIIQ' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , data = None ) : self . Signature = None self . Length = 0 self . Revision = 0 self . Checksum = 0 self . OEMID = 0 self . OEMTableID = 0 self . OEMRevision = 0 self . CreatorID = 0 self . CreatorRevision = 0 self . IVinfo = None self . Reserved = 0 self . IVRSBit = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) = struct . unpack ( IVRS_TABLE . ACPI_TABLE_HEADER . struct_format , header_byte_array ) self . IVRSBit = self . IVinfo & 0x02 if ( self . IVinfo & 0x1E ) == 0 : sys . exit ( - 1 ) def Encode ( self ) : return struct . pack ( self . struct_format , self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . IVinfo , self . Reserved ) def DumpInfo ( self ) : print ( ' ACPI Table Header' ) print ( '------------------------------------------------------------------' ) print ( 'Signature : {Signature:s}' . format ( Signature = self . Signature . decode ())) print ( 'Length : 0x{Length:08X}' . format ( Length = self . Length )) print ( 'Revision : 0x{Revision:02X}' . format ( Revision = self . Revision )) print ( 'Checksum : 0x{Checksum:02X}' . format ( Checksum = self . Checksum )) print ( 'OEM ID : {OEMID:s}' . format ( OEMID = self . OEMID . decode ())) print ( 'OEM Table ID : {OEMTableID:s}' . format ( OEMTableID = self . OEMTableID . decode ())) print ( 'OEM Revision : 0x{OEMRevision:08X}' . format ( OEMRevision = self . OEMRevision )) print ( 'Creator ID : {CreatorID:s}' . format ( CreatorID = self . CreatorID . decode ())) print ( 'Creator Revision : 0x{CreatorRevision:08X}' . format ( CreatorRevision = self . CreatorRevision )) print ( 'IVinfo : 0x{IVinfo:08X}' . format ( IVinfo = self . IVinfo )) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'IVinfo' , '0x%X' % self . IVinfo ) return xml_repr class REMAPPING_STRUCT_HEADER ( object ) : struct_format = '=B' struct_format_size = struct . calcsize ( struct_format ) def __init__ ( self , header_byte_array ) : ( self . Type , ) = struct . unpack ( IVRS_TABLE . REMAPPING_STRUCT_HEADER . struct_format , header_byte_array [ :IVRS_TABLE.REMAPPING_STRUCT_HEADER.struct_format_size ] ) class IVHD_STRUCT ( REMAPPING_STRUCT_HEADER ) : # cspell : disable - next disable the spell checker from thinking this a word struct_format = '=BBHHHQHHI' struct_format_size = struct . calcsize ( struct_format ) ex_format = \"=QQ\" ex_format_size = struct . calcsize ( ex_format ) class IVHD_TYPE ( IntEnum ) : TYPE_10H = 0x10 TYPE_11H = 0x11 TYPE_40H = 0x40 def __init__ ( self , data = None ) : self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . CapabilityOffset = 0 self . IOMMUBaseAddress = 0 self . SegmentGroup = 0 self . IOMMUInfo = None self . IOMMUFeatureInfo = None self . IOMMUEFRImage = None self . Reserved = 0 self . DeviceTableEntries = list () if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . Flags , t_Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) = struct . unpack ( IVRS_TABLE . IVHD_STRUCT . struct_format , header_byte_array [ :IVRS_TABLE.IVHD_STRUCT.struct_format_size ] ) self . Length = 0 if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : ivhd_hdr_size = ( IVRS_TABLE . IVHD_STRUCT . struct_format_size + IVRS_TABLE . IVHD_STRUCT . ex_format_size ) ( self . IOMMUEFRImage , self . Reserved ) = \\ struct . unpack ( IVRS_TABLE . IVHD_STRUCT . ex_format , header_byte_array [ IVRS_TABLE.IVHD_STRUCT.struct_format_size:ivhd_hdr_size ] ) else : ivhd_hdr_size = IVRS_TABLE . IVHD_STRUCT . struct_format_size header_byte_array = header_byte_array [ ivhd_hdr_size: ] bytes_left = t_Length - ivhd_hdr_size self . Length += ivhd_hdr_size # Get Sub Structs while bytes_left > 0 : device_scope = IVRS_TABLE . DEVICE_TABLE_ENTRY . Factory ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length if ( device_scope . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END ) : self . addDTEEntry ( device_scope ) if ( t_Length != self . Length ) or ( bytes_left != 0 ) : raise Exception ( \"IVHD length does not add up. Parsed len: %d, reported len: %d\" % ( self . Length , t_Length )) def Encode ( self ) : byte_str = b '' byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . CapabilityOffset , self . IOMMUBaseAddress , self . SegmentGroup , self . IOMMUInfo , self . IOMMUFeatureInfo ) if self . IOMMUEFRImage is not None : byte_str += struct . pack ( IVRS_TABLE . IVHD_STRUCT . ex_format , self . IOMMUEFRImage , self . Reserved ) for dte in self . DeviceTableEntries : byte_str += dte . Encode () return byte_str def addDTEEntry ( self , dte ) : # append raw data , update length . checksum will be left untouched self . Length += len ( dte . Encode ()) self . DeviceTableEntries . append ( dte ) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'IVHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'IOMMUDeviceID' , '0x%X' % self . DeviceID ) xml_repr . set ( 'CapabilityOffset' , '0x%X' % self . CapabilityOffset ) xml_repr . set ( 'IOMMUBaseAddress' , '0x%X' % self . IOMMUBaseAddress ) xml_repr . set ( 'SegmentGroup' , '0x%X' % self . SegmentGroup ) xml_repr . set ( 'IOMMUInfo' , '0x%X' % self . IOMMUInfo ) xml_repr . set ( 'IOMMUFeatureInfo' , '0x%X' % self . IOMMUFeatureInfo ) if ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( self . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ) : xml_repr . set ( 'IOMMUEFRImage' , '0x%X' % self . IOMMUEFRImage ) # Add SubStructs for item in self . DeviceTableEntries : xml_repr . append ( item . ToXmlElementTree ()) return xml_repr def DumpInfo ( self ) : print ( \"\\t IVHD\" ) print ( \"\\t----------------------------------------------------------------\" ) print ( '\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\tFlags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( '\\tLength : 0x{Length:04X}' . format ( Length = self . Length )) print ( '\\tIOMMU Device ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\tCapability Offset : 0x{CapabilityOffset:04X}' . format ( CapabilityOffset = self . CapabilityOffset )) print ( '\\tIOMMU Base Address : 0x{IOMMUBaseAddress:016X}' . format ( IOMMUBaseAddress = self . IOMMUBaseAddress )) print ( '\\tSegment Group : 0x{SegmentGroup:04X}' . format ( SegmentGroup = self . SegmentGroup )) print ( '\\tIOMMU Info : 0x{IOMMUInfo:04X}' . format ( IOMMUInfo = self . IOMMUInfo )) print ( '\\tIOMMU Feature Info : 0x{IOMMUFeatureInfo:08X}' . format ( IOMMUFeatureInfo = self . IOMMUFeatureInfo )) for item in self . DeviceTableEntries : item . DumpInfo () class IVMD_STRUCT ( REMAPPING_STRUCT_HEADER ) : # cspell : disable - next disable spell checker from thinking this is a word struct_format = '=BBHHHQQQ' struct_format_size = struct . calcsize ( struct_format ) class IVMD_TYPE ( IntEnum ) : TYPE_20H = 0x20 # All peripherals TYPE_21H = 0x21 # Specified peripheral TYPE_22H = 0x22 # Peripheral range def __init__ ( self , data = None ) : self . Type = None self . Flags = None self . Length = 0 self . DeviceID = 0 self . AuxiliaryData = None self . Reserved = 0 self . IVMDStartAddress = 0 self . IVMDMemoryBlockLength = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) = struct . unpack ( IVRS_TABLE . IVMD_STRUCT . struct_format , header_byte_array ) # IVMD is simple , the length is fixed , so assert if not if ( self . Length != len ( header_byte_array )) : raise Exception ( \"Bad IVMD entry size %d, expecting %d\" % ( self . Length , len ( header_byte_array ))) def Encode ( self ) : return struct . pack ( IVRS_TABLE . IVMD_STRUCT . struct_format , self . Type , self . Flags , self . Length , self . DeviceID , self . AuxiliaryData , self . Reserved , self . IVMDStartAddress , self . IVMDMemoryBlockLength ) def ToXmlElementTree ( self ) : xml_repr = ET . Element ( 'IVMD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'DeviceID' , '0x%X' % self . DeviceID ) if ( self . Type != IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ) : xml_repr . set ( 'AuxiliaryData' , '0x%X' % self . AuxiliaryData ) else : xml_repr . set ( 'EndofRange' , '0x%X' % self . AuxiliaryData ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'IVMDStartAddress' , '0x%X' % self . IVMDStartAddress ) xml_repr . set ( 'IVMDMemoryBlockLength' , '0x%X' % self . IVMDMemoryBlockLength ) return xml_repr def DumpInfo ( self ) : print ( \"\\t IVMD\" ) print ( \"\\t----------------------------------------------------------------\" ) print ( '\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\tFlags : 0x{Flags:02X}' . format ( Flags = self . Flags )) print ( '\\tLength : 0x{Length:04X}' . format ( Length = self . Length )) print ( '\\tDeviceID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\tAuxiliaryData : 0x{AuxiliaryData:04X}' . format ( AuxiliaryData = self . AuxiliaryData )) print ( '\\tReserved : 0x{Reserved:016X}' . format ( Reserved = self . Reserved )) print ( '\\tIVMD Start Address : 0x{IVMDStartAddress:016X}' . format ( IVMDStartAddress = self . IVMDStartAddress )) print ( '\\tIVMD Memory Block Length : 0x{IVMDMemoryBlockLength:016X}' . format ( IVMDMemoryBlockLength = self . Type )) class DEVICE_TABLE_ENTRY ( object ) : struct_format = '=BHB' struct_format_size = struct . calcsize ( struct_format ) dte_var_ext_format = \"=8s8sBB\" dte_var_len = struct_format_size + struct . calcsize ( dte_var_ext_format ) class DTE_TYPE ( IntEnum ) : RESERVED = 0 ALL = 1 SELECT = 2 RANGE_START = 3 RANGE_END = 4 ALIAS_SELECT = 66 ALIAS_RANGE_START = 67 EX_SELECT = 70 EX_RANGE_START = 71 SPECIAL = 72 ACPI = 240 # # this method is a factory # @staticmethod def Factory ( data ) : if ( data is None ) : raise Exception ( \"Invalid File stream\" ) RemapHeader = IVRS_TABLE . REMAPPING_STRUCT_HEADER ( data ) Type = RemapHeader . Type if ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_RESERVED ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_SELECT ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_EX_RANGE_START ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_SPECIAL ( data ) elif ( Type == IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ) : return IVRS_TABLE . DEVICE_TABLE_ENTRY_ACPI ( data ) else : return None class DEVICE_TABLE_ENTRY_RESERVED ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RESERVED , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'Type' , '0x%X' % self . Type ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALL ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALL , self . Type ) self . TypeString = \"All\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SELECT , self . Type ) self . TypeString = \"Reserved\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : return struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_START , self . Type ) self . TypeString = \"Range\" self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) class DEVICE_TABLE_ENTRY_ALIAS_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_SELECT , self . Type ) self . TypeString = \"Alias Select\" # Two DevID , one for alias , one for source self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_ALIAS_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . SourceDeviceID = 0 self . EndDeviceID = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ALIAS_RANGE_START , self . Type ) self . TypeString = \"Alias Range\" # Two DevID , one for alias start , one for source start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( _ , self . SourceDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 0 , self . SourceDeviceID , 0 ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) class DEVICE_TABLE_ENTRY_EX_SELECT ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_SELECT , self . Type ) self . TypeString = \"Extended Select\" # Two DTE setting , one for standard setting , one for extended setting ( AtsDisabled , etc .) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting , one for standard setting , one for extended setting ( AtsDisabled , etc .) byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( '\\t\\tExtended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_EX_RANGE_START ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . EX_RANGE_START , self . Type ) self . TypeString = \"Extended Range\" # Two DTE setting , one for standard setting start , one for extended setting start self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . ExtendedDTESetting ,) = \\ struct . unpack ( \"=I\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) ( Type , self . EndDeviceID , _ ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ self.Length: (self.Length + IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size) ] ) if Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . RANGE_END : print ( \"Start of range does not follow end of range\" ) sys . exit ( - 1 ) self . Length += IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Two DTE setting , one for standard setting start , one for extended setting start byte_str += struct . pack ( \"=I\" , self . ExtendedDTESetting ) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , 4 , self . EndDeviceID , 0 ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'StartofRange' , '0x%X' % self . DeviceID ) xml_item . set ( 'EndofRange' , '0x%X' % ( self . EndDeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : xml_item . set ( 'ExtendedDTESetting' , 'ATS requests blocked' ) else : xml_item . set ( 'ExtendedDTESetting' , 'ATS allowed' ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tStart of Range : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tEnd of Range : 0x{EndDeviceID:04X}' . format ( EndDeviceID = self . EndDeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) if ( self . ExtendedDTESetting & 0x80000000 ) != 0 : ats_str = \"ATS requests blocked\" else : ats_str = \"ATS allowed\" print ( '\\t\\tExtended DTE Setting : {ExtendedDTESetting:s}' . format ( ExtendedDTESetting = ats_str )) class DEVICE_TABLE_ENTRY_SPECIAL ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . SPECIAL , self . Type ) self . TypeString = \"Special Device\" # First half for standard DTE setting , second half for special DevID and its variety ( APIC , HPET , etc .) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size + \\ IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format_size ( self . Handle , self . SourceDeviceID , self . Variety ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # First half for standard DTE setting , second half for special DevID and its variety ( APIC , HPET , etc .) byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Handle , self . SourceDeviceID , self . Variety ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'SourceDeviceID' , '0x%X' % ( self . SourceDeviceID )) xml_item . set ( 'Handle' , '0x%X' % ( self . Handle )) if self . Variety == 1 : xml_item . set ( 'Variety' , 'IOAPIC' ) elif self . Variety == 2 : xml_item . set ( 'Variety' , 'HPET' ) else : xml_item . set ( 'Variety' , 'Reserved %X' % ( self . Variety )) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tSource Device ID : 0x{SourceDeviceID:04X}' . format ( SourceDeviceID = self . SourceDeviceID )) if self . Variety == 1 : var_str = \"IOAPIC\" elif self . Variety == 2 : var_str = \"HPET\" else : var_str = \"Reserved 0x%02X\" % ( self . Variety ) print ( '\\t\\tHandle : 0x{Handle:02X}' . format ( Handle = self . Handle )) print ( '\\t\\tVariety : {Variety:s}' . format ( Variety = var_str )) class DEVICE_TABLE_ENTRY_ACPI ( object ) : def __init__ ( self , data = None ) : self . Type = 0 self . DeviceID = 0 self . DTESetting = 0 self . ExtendedDTESetting = 0 self . TypeString = None self . Length = 0 if data is not None : self . Decode ( data ) def Decode ( self , header_byte_array ) : ( self . Type , self . DeviceID , self . DTESetting ) = struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , header_byte_array [ :IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size ] ) if ( self . Type != IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI ) : raise Exception ( \"Input device type (%d) does not match expectation (%d)\" , IVRS_TABLE . DEVICE_TABLE_ENTRY . DTE_TYPE . ACPI , self . Type ) self . TypeString = \"Variable Length ACPI HID Device\" ( self . HID , self . CID , self . UIDFormat , self . UIDLength ) = \\ struct . unpack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.struct_format_size: IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len ] ) self . Length = IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_len + self . UIDLength if self . UIDFormat == 0 : self . UID = None elif self . UIDFormat == 1 : ( self . UID ,) = struct . unpack ( \"=Q\" , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len: self.Length ] ) elif self . UIDFormat == 2 : ( self . UID ,) = \\ struct . unpack ( \"=%ss\" % self . UIDLength , header_byte_array [ IVRS_TABLE.DEVICE_TABLE_ENTRY.dte_var_len:self.Length ] ) def Encode ( self ) : byte_str = struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . struct_format , self . Type , self . DeviceID , self . DTESetting ) # Variable Length ACPI HID Device byte_str += struct . pack ( IVRS_TABLE . DEVICE_TABLE_ENTRY . dte_var_ext_format , self . HID , self . CID , self . UIDFormat , self . UIDLength ) if self . UIDFormat == 1 : byte_str += struct . pack ( \"=Q\" , self . UID ) elif self . UIDFormat == 2 : byte_str += struct . pack ( \"=%ss\" % self . UIDLength , self . UID ) return byte_str def ToXmlElementTree ( self ) : xml_item = ET . Element ( self . TypeString . replace ( \" \" , \"\" )) xml_item . set ( 'Type' , '0x%X' % self . Type ) xml_item . set ( 'DeviceID' , '0x%X' % ( self . DeviceID )) xml_item . set ( 'DTESetting' , '0x%X' % ( self . DTESetting )) xml_item . set ( 'HardwareID' , '%s' % ( self . HID )) xml_item . set ( 'ExtendedDTE Setting' , '%s' % ( self . CID )) xml_item . set ( 'UniqueIDFormat' , '%d' % ( self . UIDFormat )) xml_item . set ( 'UniqueIDLength' , '%d' % ( self . UIDLength )) if self . UIDFormat == 0 : xml_item . set ( 'UniqueID' , 'None' ) elif self . UIDFormat == 1 : xml_item . set ( 'UniqueID' , '0x%X' % ( self . UID )) elif self . UIDFormat == 2 : xml_item . set ( 'UniqueID' , '%s' % ( self . UID )) else : print ( \"Unrecognized UID format detected\" ) sys . exit ( - 1 ) return xml_item def DumpInfo ( self ) : print ( '\\t\\t {TypeString:s}' . format ( TypeString = self . TypeString )) print ( '\\t\\t--------------------------------------------------' ) print ( '\\t\\tType : 0x{Type:02X}' . format ( Type = self . Type )) print ( '\\t\\tDevice ID : 0x{DeviceID:04X}' . format ( DeviceID = self . DeviceID )) print ( '\\t\\tDTE Setting : 0x{DTESetting:02X}' . format ( DTESetting = self . DTESetting )) print ( '\\t\\tHardware ID : {HID:s}' . format ( HID = self . HID . decode ())) print ( '\\t\\tExtended DTE Setting : {CID:s}' . format ( CID = self . CID . decode ())) print ( '\\t\\tUnique ID Format : {UIDFormat:d}' . format ( UIDFormat = self . UIDFormat )) print ( '\\t\\tUnique ID Length : {UIDLength:d}' . format ( UIDLength = self . UIDLength )) if self . UIDFormat == 0 : print ( '\\t\\tUnique ID : None' ) elif self . UIDFormat == 1 : print ( '\\t\\tUnique ID : 0x{UID:X}' . format ( UID = self . UID )) elif self . UIDFormat == 2 : print ( '\\t\\tUnique ID : {UID:s}' . format ( UID = self . UID . decode ())) else : raise Exception ( \"Unrecognized UID format detected %d\" % self . UIDFormat )","title":"IVRS_TABLE"},{"location":"edk2toollib/acpi/ivrs_parser/#class-variables","text":"ACPI_TABLE_HEADER DEVICE_TABLE_ENTRY DEVICE_TABLE_ENTRY_ACPI DEVICE_TABLE_ENTRY_ALIAS_RANGE_START DEVICE_TABLE_ENTRY_ALIAS_SELECT DEVICE_TABLE_ENTRY_ALL DEVICE_TABLE_ENTRY_EX_RANGE_START DEVICE_TABLE_ENTRY_EX_SELECT DEVICE_TABLE_ENTRY_RANGE_START DEVICE_TABLE_ENTRY_RESERVED DEVICE_TABLE_ENTRY_SELECT DEVICE_TABLE_ENTRY_SPECIAL IVHD_STRUCT IVMD_STRUCT REMAPPING_STRUCT_HEADER","title":"Class variables"},{"location":"edk2toollib/acpi/ivrs_parser/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/acpi/ivrs_parser/#validatechecksum8","text":"def validateChecksum8 ( data ) View Source @staticmethod def validateChecksum8 ( data ) : return sum ( data ) & 0xFF","title":"validateChecksum8"},{"location":"edk2toollib/acpi/ivrs_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/acpi/ivrs_parser/#decode","text":"def Decode ( self , data ) View Source def Decode ( self , data ): self . acpi_header = IVRS_TABLE . ACPI_TABLE_HEADER ( data [: IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size ]) # Start from the end of ACPI header , but store the parsed length for verification t_length = self . acpi_header . Length self . acpi_header . Length = IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size t_data = data [ IVRS_TABLE . ACPI_TABLE_HEADER . struct_format_size :] # sanity check on incoming data Checksum8 = IVRS_TABLE . validateChecksum8 ( data ) if ( Checksum8 != 0 ): raise Exception ( 'Incoming data checksum does not add up: checksum field %x, calculated is %x' % ( self . acpi_header . Checksum , Checksum8 )) while len ( t_data ) > 0 : # Get type and length of remapping struct remapping_header = self . REMAPPING_STRUCT_HEADER ( t_data ) # Parse remapping struct if ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_10H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_11H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVHD_STRUCT . IVHD_TYPE . TYPE_40H ): remapping_header = self . IVHD_STRUCT ( t_data ) self . addIVHDEntry ( remapping_header ) elif ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_21H ) or \\ ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_22H ): remapping_header = self . IVMD_STRUCT ( t_data [: IVRS_TABLE . IVMD_STRUCT . struct_format_size ]) self . addIVMDEntry ( remapping_header ) if ( remapping_header . Type == IVRS_TABLE . IVMD_STRUCT . IVMD_TYPE . TYPE_20H ): self . IVRSBit = 0 else : print ( 'Reserved remapping struct found in IVRS table %d' % remapping_header . Type ) sys . exit ( - 1 ) # Update data position t_data = t_data [ remapping_header . Length :] if ( self . acpi_header . Length != t_length ) or ( len ( t_data ) != 0 ): raise Exception ( \"IVRS length does not add up. Parsed len: %d, reported len: %d\" % ( t_length , self . acpi_header . Length ))","title":"Decode"},{"location":"edk2toollib/acpi/ivrs_parser/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): self . acpi_header . DumpInfo () for sub in self . SubStructs : sub . DumpInfo ()","title":"DumpInfo"},{"location":"edk2toollib/acpi/ivrs_parser/#encode","text":"def Encode ( self ) View Source def Encode ( self ): bytes_str = b '' # Append ACPI header bytes_str += self . acpi_header . Encode () # All IVHD / IVMD entries for ivxd in self . SubStructs : bytes_str += ivxd . Encode () return bytes_str","title":"Encode"},{"location":"edk2toollib/acpi/ivrs_parser/#ivrsbitenabled","text":"def IVRSBitEnabled ( self ) View Source def IVRSBitEnabled ( self ): return bool ( self . acpi_header . IVRSBit )","title":"IVRSBitEnabled"},{"location":"edk2toollib/acpi/ivrs_parser/#toxmlelementtree","text":"def ToXmlElementTree ( self ) View Source def ToXmlElementTree ( self ): root = ET . Element ( 'IVRSTable' ) root . append ( self . acpi_header . ToXmlElementTree ()) for sub in self . SubStructs : root . append ( sub . ToXmlElementTree ()) return root","title":"ToXmlElementTree"},{"location":"edk2toollib/acpi/ivrs_parser/#addivhdentry","text":"def addIVHDEntry ( self , ivhd ) View Source def addIVHDEntry ( self , ivhd ): # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivhd . Encode ()) self . SubStructs . append ( ivhd ) self . updateACPISum ()","title":"addIVHDEntry"},{"location":"edk2toollib/acpi/ivrs_parser/#addivmdentry","text":"def addIVMDEntry ( self , ivmd ) View Source def addIVMDEntry ( self , ivmd ): # append entry to the list , update length and checksum self . acpi_header . Length += len ( ivmd . Encode ()) # IVMD has to follow the corresponding IVHD , thus the list records all entries to maintain order self . SubStructs . append ( ivmd ) self . IVMD_list . append ( ivmd ) self . updateACPISum ()","title":"addIVMDEntry"},{"location":"edk2toollib/acpi/ivrs_parser/#updateacpisum","text":"def updateACPISum ( self ) View Source def updateACPISum ( self ): temp_sum = 0 # Clear the checksum before calculating sum self . acpi_header . Checksum = 0 temp_str = self . Encode () temp_sum = sum ( temp_str ) self . acpi_header . Checksum = ( 0 x100 - ( temp_sum & 0 xFF )) & 0 xFF","title":"updateACPISum"},{"location":"edk2toollib/log/","text":"Module edk2toollib.log View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.log.ansi_handler edk2toollib.log.ansi_handler_test edk2toollib.log.file_handler edk2toollib.log.junit_report_format edk2toollib.log.junit_report_format_test edk2toollib.log.markdown_handler edk2toollib.log.string_handler edk2toollib.log.string_handler_test","title":"Index"},{"location":"edk2toollib/log/#module-edk2toolliblog","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.log"},{"location":"edk2toollib/log/#sub-modules","text":"edk2toollib.log.ansi_handler edk2toollib.log.ansi_handler_test edk2toollib.log.file_handler edk2toollib.log.junit_report_format edk2toollib.log.junit_report_format_test edk2toollib.log.markdown_handler edk2toollib.log.string_handler edk2toollib.log.string_handler_test","title":"Sub-modules"},{"location":"edk2toollib/log/ansi_handler/","text":"Module edk2toollib.log.ansi_handler View Source ## # Handle basic logging with color via ANSI commands # Will call into win32 commands as needed when needed # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import re from edk2toollib.utility_functions import GetHostInfo try : # try to import windows types from winDLL import ctypes from ctypes import LibraryLoader windll = LibraryLoader ( ctypes . WinDLL ) from ctypes import wintypes except ( AttributeError , ImportError ): # if we run into an exception (ie on unix or linux) windll = None # create blank lambda def SetConsoleTextAttribute (): None # create blank lambda def winapi_test (): None else : # if we don't raise an exception when we import windows types # then execute this but don't catch an exception if raised from ctypes import byref , Structure # inspired by https://github.com/tartley/colorama/ class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '( %d , %d , %d , %d , %d , %d , %d , %d , %d , %d , %d )' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) # a simple wrapper around the few methods calls to windows class Win32Console ( object ): _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes . HANDLE , wintypes . WORD , ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes . DWORD , ] _GetStdHandle . restype = wintypes . HANDLE # from winbase.h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ): csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test (): return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ): handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ): handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) # from wincon.h class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background # defines the different codes for the ansi colors class AnsiColor ( object ): BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported, but not part of the standard. BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ): if type ( item ) is str and hasattr ( self , item ): return True # check if we contain the color number for attr_name in dir ( self ): if getattr ( self , attr_name ) is item : return True return False # the formatter that outputs ANSI codes as needed class ColoredFormatter ( logging . Formatter ): AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ): logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ): levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result # returns the string formatted ANSI command for the specific color def get_ansi_string ( color = AnsiColor . RESET ): CSI = ' \\033 [' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' class ColoredStreamHandler ( logging . StreamHandler ): # Control Sequence Introducer ANSI_CSI_RE = re . compile ( ' \\001 ? \\033\\\\ [((?: \\\\ d|;)*)([a-zA-Z]) \\002 ?' ) def __init__ ( self , stream = None , strip = None , convert = None ): logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo () . os == \"Windows\" # We test if the WinAPI works, because even if we are on Windows # we may be using a terminal that doesn't support the WinAPI # (e.g. Cygwin Terminal). In this case it's up to the terminal # to support the ANSI codes. self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ) . wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream, stripping ANSI if specified def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ): if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1 :] kwargs = dict () func ( * args , ** kwargs ) # logging.handler method we are overriding to emit a record def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) Functions get_ansi_string def get_ansi_string ( color = 39 ) View Source def get_ansi_string ( color = AnsiColor . RESET ): CSI = '\\033[' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' Classes AnsiColor class AnsiColor ( / , * args , ** kwargs ) View Source class AnsiColor ( object ) : BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported , but not part of the standard . BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ) : if type ( item ) is str and hasattr ( self , item ) : return True # check if we contain the color number for attr_name in dir ( self ) : if getattr ( self , attr_name ) is item : return True return False Class variables BG_BLACK BG_BLUE BG_CYAN BG_GREEN BG_LIGHTBLACK_EX BG_LIGHTBLUE_EX BG_LIGHTCYAN_EX BG_LIGHTGREEN_EX BG_LIGHTMAGENTA_EX BG_LIGHTRED_EX BG_LIGHTWHITE_EX BG_LIGHTYELLOW_EX BG_MAGENTA BG_RED BG_RESET BG_WHITE BG_YELLOW BLACK BLUE CYAN GREEN LIGHTBLACK_EX LIGHTBLUE_EX LIGHTCYAN_EX LIGHTGREEN_EX LIGHTMAGENTA_EX LIGHTRED_EX LIGHTWHITE_EX LIGHTYELLOW_EX MAGENTA RED RESET WHITE YELLOW CONSOLE_SCREEN_BUFFER_INFO class CONSOLE_SCREEN_BUFFER_INFO ( / , * args , ** kwargs ) Structure base class View Source class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) Ancestors (in MRO) _ctypes.Structure _ctypes._CData Class variables COORD dwCursorPosition dwMaximumWindowSize dwSize srWindow wAttributes ColoredFormatter class ColoredFormatter ( msg = '' , use_azure = False ) Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the the style-dependent default value, \u201c%(message)s\u201d, \u201c{message}\u201d, or \u201c${message}\u201d, is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user\u2019s message and arguments are pre- formatted into a LogRecord\u2019s message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\u201cDEBUG\u201d, \u201cINFO\u201d, \u201cWARNING\u201d, \u201cERROR\u201d, \u201cCRITICAL\u201d) %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted View Source class ColoredFormatter ( logging . Formatter ) : AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ) : logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result Ancestors (in MRO) logging.Formatter Class variables AZURE_COLORS COLORS default_msec_format default_time_format Methods converter def converter ( ... ) localtime([seconds]) -> (tm_year,tm_mon,tm_mday,tm_hour,tm_min, tm_sec,tm_wday,tm_yday,tm_isdst) Convert seconds since the Epoch to a time tuple expressing local time. When \u2018seconds\u2019 is not passed in, convert the current time instead. format def format ( self , record ) Format the specified record as text. The record\u2019s attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. View Source def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result formatException def formatException ( self , ei ) Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() View Source def formatException ( self , ei ) : \"\"\" Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() \"\"\" sio = io . StringIO () tb = ei [ 2 ] # See issues # 9427 , # 1553375. Commented out for now . #if getattr ( self , 'fullstack' , False ) : # traceback . print_stack ( tb . tb_frame . f_back , file = sio ) traceback . print_exception ( ei [ 0 ], ei [ 1 ], tb , None , sio ) s = sio . getvalue () sio . close () if s [ - 1 : ] == \"\\n\" : s = s [:- 1 ] return s formatMessage def formatMessage ( self , record ) View Source def formatMessage ( self , record ): return self . _style . format ( record ) formatStack def formatStack ( self , stack_info ) This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func: traceback.print_stack , but with the last trailing newline removed. The base implementation just returns the value passed in. View Source def formatStack ( self , stack_info ): \"\"\" This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func:`traceback.print_stack`, but with the last trailing newline removed. The base implementation just returns the value passed in. \"\"\" return stack_info formatTime def formatTime ( self , record , datefmt = None ) Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the \u2018converter\u2019 attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the \u2018converter\u2019 attribute in the Formatter class. View Source def formatTime ( self , record , datefmt = None ): \"\"\" Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the 'converter' attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the 'converter' attribute in the Formatter class. \"\"\" ct = self . converter ( record . created ) if datefmt : s = time . strftime ( datefmt , ct ) else : t = time . strftime ( self . default_time_format , ct ) s = self . default_msec_format % ( t , record . msecs ) return s usesTime def usesTime ( self ) Check if the format uses the creation time of the record. View Source def usesTime ( self ): \"\"\" Check if the format uses the creation time of the record. \"\"\" return self . _style . usesTime () ColoredStreamHandler class ColoredStreamHandler ( stream = None , strip = None , convert = None ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class ColoredStreamHandler ( logging . StreamHandler ) : # Control Sequence Introducer ANSI_CSI_RE = re . compile ( '\\001?\\033\\\\[((?:\\\\d|;)*)([a-zA-Z])\\002?' ) def __init__ ( self , stream = None , strip = None , convert = None ) : logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo (). os == \"Windows\" # We test if the WinAPI works , because even if we are on Windows # we may be using a terminal that doesn 't support the WinAPI # (e.g. Cygwin Terminal). In this case it' s up to the terminal # to support the ANSI codes . self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output ? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls ? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ). wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ) : if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) : if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ) : if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ) : if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ) : return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ) : self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream , stripping ANSI if specified def write ( self , text ) : if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ) : cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ) : start , end = match . span () if ( cursor < start ) : self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ) : if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start:end ] ) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ) : if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ) : params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) # logging . handler method we are overriding to emit a record def emit ( self , record ) : try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) Ancestors (in MRO) logging.StreamHandler logging.Handler logging.Filterer Class variables ANSI_CSI_RE terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) call_win32 def call_win32 ( self , command , params ) View Source def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) close def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock () convert_ansi def convert_ansi ( self , paramstring , command ) View Source def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) extract_params def extract_params ( self , command , paramstring ) View Source def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_attrs def get_attrs ( self ) View Source def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name get_win32_calls def get_win32_calls ( self ) View Source def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_attrs def set_attrs ( self , value ) View Source def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) set_background def set_background ( self , back = None , light = False , on_stderr = False ) View Source def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) set_console def set_console ( self , attrs = None , on_stderr = False ) View Source def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) set_foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) View Source def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock () write def write ( self , text ) View Source def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) write_and_convert def write_and_convert ( self , text ) View Source def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) write_plain_text def write_plain_text ( self , text , start = None , end = None ) View Source def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () Win32Console class Win32Console ( / , * args , ** kwargs ) View Source class Win32Console ( object ) : _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes.HANDLE, wintypes.WORD, ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes.DWORD, ] _GetStdHandle . restype = wintypes . HANDLE # from winbase . h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ) : csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) Class variables STDERR STDOUT Static methods GetConsoleScreenBufferInfo def GetConsoleScreenBufferInfo ( stream_id =- 11 ) View Source @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi SetConsoleTextAttribute def SetConsoleTextAttribute ( stream_id , attrs ) View Source @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) winapi_test def winapi_test ( ) View Source @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) WinColor class WinColor ( / , * args , ** kwargs ) View Source class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background Class variables BLACK BLUE BRIGHT BRIGHT_BACKGROUND CYAN GREEN GREY MAGENTA NORMAL RED YELLOW","title":"Ansi handler"},{"location":"edk2toollib/log/ansi_handler/#module-edk2toolliblogansi_handler","text":"View Source ## # Handle basic logging with color via ANSI commands # Will call into win32 commands as needed when needed # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import re from edk2toollib.utility_functions import GetHostInfo try : # try to import windows types from winDLL import ctypes from ctypes import LibraryLoader windll = LibraryLoader ( ctypes . WinDLL ) from ctypes import wintypes except ( AttributeError , ImportError ): # if we run into an exception (ie on unix or linux) windll = None # create blank lambda def SetConsoleTextAttribute (): None # create blank lambda def winapi_test (): None else : # if we don't raise an exception when we import windows types # then execute this but don't catch an exception if raised from ctypes import byref , Structure # inspired by https://github.com/tartley/colorama/ class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '( %d , %d , %d , %d , %d , %d , %d , %d , %d , %d , %d )' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) # a simple wrapper around the few methods calls to windows class Win32Console ( object ): _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes . HANDLE , wintypes . WORD , ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes . DWORD , ] _GetStdHandle . restype = wintypes . HANDLE # from winbase.h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ): csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test (): return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ): handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ): handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) # from wincon.h class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background # defines the different codes for the ansi colors class AnsiColor ( object ): BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported, but not part of the standard. BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ): if type ( item ) is str and hasattr ( self , item ): return True # check if we contain the color number for attr_name in dir ( self ): if getattr ( self , attr_name ) is item : return True return False # the formatter that outputs ANSI codes as needed class ColoredFormatter ( logging . Formatter ): AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ): logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ): levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result # returns the string formatted ANSI command for the specific color def get_ansi_string ( color = AnsiColor . RESET ): CSI = ' \\033 [' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' class ColoredStreamHandler ( logging . StreamHandler ): # Control Sequence Introducer ANSI_CSI_RE = re . compile ( ' \\001 ? \\033\\\\ [((?: \\\\ d|;)*)([a-zA-Z]) \\002 ?' ) def __init__ ( self , stream = None , strip = None , convert = None ): logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo () . os == \"Windows\" # We test if the WinAPI works, because even if we are on Windows # we may be using a terminal that doesn't support the WinAPI # (e.g. Cygwin Terminal). In this case it's up to the terminal # to support the ANSI codes. self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ) . wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream, stripping ANSI if specified def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ): if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1 :] kwargs = dict () func ( * args , ** kwargs ) # logging.handler method we are overriding to emit a record def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"Module edk2toollib.log.ansi_handler"},{"location":"edk2toollib/log/ansi_handler/#functions","text":"","title":"Functions"},{"location":"edk2toollib/log/ansi_handler/#get_ansi_string","text":"def get_ansi_string ( color = 39 ) View Source def get_ansi_string ( color = AnsiColor . RESET ): CSI = '\\033[' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm'","title":"get_ansi_string"},{"location":"edk2toollib/log/ansi_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/ansi_handler/#ansicolor","text":"class AnsiColor ( / , * args , ** kwargs ) View Source class AnsiColor ( object ) : BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported , but not part of the standard . BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ) : if type ( item ) is str and hasattr ( self , item ) : return True # check if we contain the color number for attr_name in dir ( self ) : if getattr ( self , attr_name ) is item : return True return False","title":"AnsiColor"},{"location":"edk2toollib/log/ansi_handler/#class-variables","text":"BG_BLACK BG_BLUE BG_CYAN BG_GREEN BG_LIGHTBLACK_EX BG_LIGHTBLUE_EX BG_LIGHTCYAN_EX BG_LIGHTGREEN_EX BG_LIGHTMAGENTA_EX BG_LIGHTRED_EX BG_LIGHTWHITE_EX BG_LIGHTYELLOW_EX BG_MAGENTA BG_RED BG_RESET BG_WHITE BG_YELLOW BLACK BLUE CYAN GREEN LIGHTBLACK_EX LIGHTBLUE_EX LIGHTCYAN_EX LIGHTGREEN_EX LIGHTMAGENTA_EX LIGHTRED_EX LIGHTWHITE_EX LIGHTYELLOW_EX MAGENTA RED RESET WHITE YELLOW","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#console_screen_buffer_info","text":"class CONSOLE_SCREEN_BUFFER_INFO ( / , * args , ** kwargs ) Structure base class View Source class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X )","title":"CONSOLE_SCREEN_BUFFER_INFO"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro","text":"_ctypes.Structure _ctypes._CData","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_1","text":"COORD dwCursorPosition dwMaximumWindowSize dwSize srWindow wAttributes","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#coloredformatter","text":"class ColoredFormatter ( msg = '' , use_azure = False ) Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the the style-dependent default value, \u201c%(message)s\u201d, \u201c{message}\u201d, or \u201c${message}\u201d, is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user\u2019s message and arguments are pre- formatted into a LogRecord\u2019s message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\u201cDEBUG\u201d, \u201cINFO\u201d, \u201cWARNING\u201d, \u201cERROR\u201d, \u201cCRITICAL\u201d) %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted View Source class ColoredFormatter ( logging . Formatter ) : AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ) : logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result","title":"ColoredFormatter"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro_1","text":"logging.Formatter","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_2","text":"AZURE_COLORS COLORS default_msec_format default_time_format","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/ansi_handler/#converter","text":"def converter ( ... ) localtime([seconds]) -> (tm_year,tm_mon,tm_mday,tm_hour,tm_min, tm_sec,tm_wday,tm_yday,tm_isdst) Convert seconds since the Epoch to a time tuple expressing local time. When \u2018seconds\u2019 is not passed in, convert the current time instead.","title":"converter"},{"location":"edk2toollib/log/ansi_handler/#format","text":"def format ( self , record ) Format the specified record as text. The record\u2019s attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. View Source def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result","title":"format"},{"location":"edk2toollib/log/ansi_handler/#formatexception","text":"def formatException ( self , ei ) Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() View Source def formatException ( self , ei ) : \"\"\" Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() \"\"\" sio = io . StringIO () tb = ei [ 2 ] # See issues # 9427 , # 1553375. Commented out for now . #if getattr ( self , 'fullstack' , False ) : # traceback . print_stack ( tb . tb_frame . f_back , file = sio ) traceback . print_exception ( ei [ 0 ], ei [ 1 ], tb , None , sio ) s = sio . getvalue () sio . close () if s [ - 1 : ] == \"\\n\" : s = s [:- 1 ] return s","title":"formatException"},{"location":"edk2toollib/log/ansi_handler/#formatmessage","text":"def formatMessage ( self , record ) View Source def formatMessage ( self , record ): return self . _style . format ( record )","title":"formatMessage"},{"location":"edk2toollib/log/ansi_handler/#formatstack","text":"def formatStack ( self , stack_info ) This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func: traceback.print_stack , but with the last trailing newline removed. The base implementation just returns the value passed in. View Source def formatStack ( self , stack_info ): \"\"\" This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func:`traceback.print_stack`, but with the last trailing newline removed. The base implementation just returns the value passed in. \"\"\" return stack_info","title":"formatStack"},{"location":"edk2toollib/log/ansi_handler/#formattime","text":"def formatTime ( self , record , datefmt = None ) Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the \u2018converter\u2019 attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the \u2018converter\u2019 attribute in the Formatter class. View Source def formatTime ( self , record , datefmt = None ): \"\"\" Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the 'converter' attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the 'converter' attribute in the Formatter class. \"\"\" ct = self . converter ( record . created ) if datefmt : s = time . strftime ( datefmt , ct ) else : t = time . strftime ( self . default_time_format , ct ) s = self . default_msec_format % ( t , record . msecs ) return s","title":"formatTime"},{"location":"edk2toollib/log/ansi_handler/#usestime","text":"def usesTime ( self ) Check if the format uses the creation time of the record. View Source def usesTime ( self ): \"\"\" Check if the format uses the creation time of the record. \"\"\" return self . _style . usesTime ()","title":"usesTime"},{"location":"edk2toollib/log/ansi_handler/#coloredstreamhandler","text":"class ColoredStreamHandler ( stream = None , strip = None , convert = None ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class ColoredStreamHandler ( logging . StreamHandler ) : # Control Sequence Introducer ANSI_CSI_RE = re . compile ( '\\001?\\033\\\\[((?:\\\\d|;)*)([a-zA-Z])\\002?' ) def __init__ ( self , stream = None , strip = None , convert = None ) : logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo (). os == \"Windows\" # We test if the WinAPI works , because even if we are on Windows # we may be using a terminal that doesn 't support the WinAPI # (e.g. Cygwin Terminal). In this case it' s up to the terminal # to support the ANSI codes . self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output ? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls ? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ). wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ) : if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) : if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ) : if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ) : if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ) : return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ) : self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream , stripping ANSI if specified def write ( self , text ) : if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ) : cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ) : start , end = match . span () if ( cursor < start ) : self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ) : if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start:end ] ) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ) : if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ) : params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) # logging . handler method we are overriding to emit a record def emit ( self , record ) : try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"ColoredStreamHandler"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro_2","text":"logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_3","text":"ANSI_CSI_RE terminator","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/ansi_handler/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/log/ansi_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/ansi_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/ansi_handler/#call_win32","text":"def call_win32 ( self , command , params ) View Source def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs )","title":"call_win32"},{"location":"edk2toollib/log/ansi_handler/#close","text":"def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock ()","title":"close"},{"location":"edk2toollib/log/ansi_handler/#convert_ansi","text":"def convert_ansi ( self , paramstring , command ) View Source def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params )","title":"convert_ansi"},{"location":"edk2toollib/log/ansi_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/ansi_handler/#emit","text":"def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"emit"},{"location":"edk2toollib/log/ansi_handler/#extract_params","text":"def extract_params ( self , command , paramstring ) View Source def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params","title":"extract_params"},{"location":"edk2toollib/log/ansi_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/ansi_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/ansi_handler/#format_1","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/ansi_handler/#get_attrs","text":"def get_attrs ( self ) View Source def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light )","title":"get_attrs"},{"location":"edk2toollib/log/ansi_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/ansi_handler/#get_win32_calls","text":"def get_win32_calls ( self ) View Source def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict ()","title":"get_win32_calls"},{"location":"edk2toollib/log/ansi_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/ansi_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/ansi_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/ansi_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/ansi_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/ansi_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/ansi_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/ansi_handler/#set_attrs","text":"def set_attrs ( self , value ) View Source def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND )","title":"set_attrs"},{"location":"edk2toollib/log/ansi_handler/#set_background","text":"def set_background ( self , back = None , light = False , on_stderr = False ) View Source def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr )","title":"set_background"},{"location":"edk2toollib/log/ansi_handler/#set_console","text":"def set_console ( self , attrs = None , on_stderr = False ) View Source def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs )","title":"set_console"},{"location":"edk2toollib/log/ansi_handler/#set_foreground","text":"def set_foreground ( self , fore = None , light = False , on_stderr = False ) View Source def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr )","title":"set_foreground"},{"location":"edk2toollib/log/ansi_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/ansi_handler/#write","text":"def write ( self , text ) View Source def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text )","title":"write"},{"location":"edk2toollib/log/ansi_handler/#write_and_convert","text":"def write_and_convert ( self , text ) View Source def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text ))","title":"write_and_convert"},{"location":"edk2toollib/log/ansi_handler/#write_plain_text","text":"def write_plain_text ( self , text , start = None , end = None ) View Source def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush ()","title":"write_plain_text"},{"location":"edk2toollib/log/ansi_handler/#win32console","text":"class Win32Console ( / , * args , ** kwargs ) View Source class Win32Console ( object ) : _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes.HANDLE, wintypes.WORD, ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes.DWORD, ] _GetStdHandle . restype = wintypes . HANDLE # from winbase . h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ) : csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs )","title":"Win32Console"},{"location":"edk2toollib/log/ansi_handler/#class-variables_4","text":"STDERR STDOUT","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/log/ansi_handler/#getconsolescreenbufferinfo","text":"def GetConsoleScreenBufferInfo ( stream_id =- 11 ) View Source @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi","title":"GetConsoleScreenBufferInfo"},{"location":"edk2toollib/log/ansi_handler/#setconsoletextattribute","text":"def SetConsoleTextAttribute ( stream_id , attrs ) View Source @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs )","title":"SetConsoleTextAttribute"},{"location":"edk2toollib/log/ansi_handler/#winapi_test","text":"def winapi_test ( ) View Source @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR )))","title":"winapi_test"},{"location":"edk2toollib/log/ansi_handler/#wincolor","text":"class WinColor ( / , * args , ** kwargs ) View Source class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background","title":"WinColor"},{"location":"edk2toollib/log/ansi_handler/#class-variables_5","text":"BLACK BLUE BRIGHT BRIGHT_BACKGROUND CYAN GREEN GREY MAGENTA NORMAL RED YELLOW","title":"Class variables"},{"location":"edk2toollib/log/file_handler/","text":"Module edk2toollib.log.file_handler View Source ## # Handle basic logging outputting to files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv Classes FileHandler class FileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv Ancestors (in MRO) logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Closes the stream. View Source def close ( self ): \"\"\" Closes the stream. \"\"\" self . acquire () try : try : if self . stream : try : self . flush () finally : stream = self . stream self . stream = None if hasattr ( stream , \"close\" ): stream . close () finally : # Issue # 19523 : call unconditionally to # prevent a handler leak when delay is set StreamHandler . close ( self ) finally : self . release () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ): \"\"\" Emit a record. If the stream was not opened because 'delay' was specified in the constructor, open it before calling the superclass's emit. \"\"\" if self . stream is None : self . stream = self . _open () StreamHandler . emit ( self , record ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"File handler"},{"location":"edk2toollib/log/file_handler/#module-edk2toolliblogfile_handler","text":"View Source ## # Handle basic logging outputting to files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"Module edk2toollib.log.file_handler"},{"location":"edk2toollib/log/file_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/file_handler/#filehandler","text":"class FileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv","title":"FileHandler"},{"location":"edk2toollib/log/file_handler/#ancestors-in-mro","text":"logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/file_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/file_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/file_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/file_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/file_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/file_handler/#close","text":"def close ( self ) Closes the stream. View Source def close ( self ): \"\"\" Closes the stream. \"\"\" self . acquire () try : try : if self . stream : try : self . flush () finally : stream = self . stream self . stream = None if hasattr ( stream , \"close\" ): stream . close () finally : # Issue # 19523 : call unconditionally to # prevent a handler leak when delay is set StreamHandler . close ( self ) finally : self . release ()","title":"close"},{"location":"edk2toollib/log/file_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/file_handler/#emit","text":"def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ): \"\"\" Emit a record. If the stream was not opened because 'delay' was specified in the constructor, open it before calling the superclass's emit. \"\"\" if self . stream is None : self . stream = self . _open () StreamHandler . emit ( self , record )","title":"emit"},{"location":"edk2toollib/log/file_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/file_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/file_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/file_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/file_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/file_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/file_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/file_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/file_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/file_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/file_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/file_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/junit_report_format/","text":"Module edk2toollib.log.junit_report_format View Source ## # junit_report_format # This module contains support for Outputting Junit test results xml. # # Used to support CI/CD and exporting test results for other tools. # This does test report generation without being a test runner. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import time from xml.sax.saxutils import escape class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) ## # Test Case class # ## class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . ClassName = escape ( ClassName . strip (), { '\"' : \"&quot;\" }) self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \" \\n \" def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \" \\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped type=\"skipped\">' ) outstream . write ( self . StdOut ) outstream . write ( '</skipped>' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) ## # Test Suite class. Create new suites by using the JunitTestReport Object # # ## class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . Package = escape ( Package . strip (), { '\"' : \"&quot;\" }) self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases : if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases : a . Output ( outstream ) outstream . write ( '</testsuite>' ) ## # Test Report. Top level object test reporting. # # ## class JunitTestReport ( object ): def __init__ ( self ): self . TestSuites = [] def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts def Output ( self , filepath ): f = open ( filepath , \"w\" ) f . write ( '' ) f . write ( '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' ) f . write ( '<testsuites>' ) for a in self . TestSuites : a . Output ( f ) f . write ( '</testsuites>' ) f . close () Classes JunitReportError class JunitReportError ( type , msg ) View Source class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) JunitReportFailure class JunitReportFailure ( type , msg ) View Source class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) JunitReportTestCase class JunitReportTestCase ( Name , ClassName ) View Source class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . ClassName = escape ( ClassName . strip (), { '\"' : \"&quot;\" }) self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \"\\n \" def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \"\\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED: outstream . write ( '<skipped type=\"skipped\">' ) outstream . write ( self . StdOut ) outstream . write ( '</skipped>' ) elif self . Status == JunitReportTestCase . FAILED: outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR: outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS: raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) Class variables ERROR FAILED NEW SKIPPED SUCCESS Methods LogStdError def LogStdError ( self , msg ) View Source def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \"\\n \" LogStdOut def LogStdOut ( self , msg ) View Source def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \"\\n \" Output def Output ( self , outstream ) View Source def Output(self, outstream): outstream.write(' <testcase classname= \"{0}\" name= \"{1}\" time= \"{2}\" > '.format(self.ClassName, self.Name, self.Time)) if self.Status == JunitReportTestCase.SKIPPED: outstream.write(' <skipped type= \"skipped\" > ') outstream.write(self.StdOut) outstream.write(' </skipped> ') elif self.Status == JunitReportTestCase.FAILED: outstream.write(' <failure message= \"{0}\" type= \"{1}\" /> '.format(self.FailureMsg.Message, self.FailureMsg.Type)) elif self.Status == JunitReportTestCase.ERROR: outstream.write(' <error message= \"{0}\" type= \"{1}\" /> '.format(self.ErrorMsg.Message, self.ErrorMsg.Type)) elif self.Status != JunitReportTestCase.SUCCESS: raise Exception(\"Can't output a testcase {0}.{1} in invalid state {2}\".format(self.ClassName, self.Name, self.Status)) outstream.write(' <system-out> ' + self.StdOut + ' </system-out> ') outstream.write(' <system-err> ' + self.StdErr + ' </system-err> ') outstream.write(' </testcase> ') SetError def SetError ( self , Msg , Type ) View Source def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) SetFailed def SetFailed ( self , Msg , Type ) View Source def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) SetSkipped def SetSkipped ( self ) View Source def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime SetSuccess def SetSuccess ( self ) View Source def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime JunitReportTestSuite class JunitReportTestSuite ( Name , Package , Id ) View Source class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . Package = escape ( Package . strip (), { '\"' : \"&quot;\" }) self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases: if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases: a . Output ( outstream ) outstream . write ( '</testsuite>' ) Methods Output def Output ( self , outstream ) View Source def Output(self, outstream): Errors = 0 Failures = 0 Skipped = 0 Tests = len(self.TestCases) for a in self.TestCases: if(a.Status == JunitReportTestCase.FAILED): Failures += 1 elif(a.Status == JunitReportTestCase.ERROR): Errors += 1 elif(a.Status == JunitReportTestCase.SKIPPED): Skipped += 1 outstream.write(' <testsuite id= \"{0}\" name= \"{1}\" package= \"{2}\" errors= \"{3}\" tests= \"{4}\" ' ' failures= \"{5}\" skipped= \"{6}\" > '.format(self.TestId, self.Name, self.Package, Errors, Tests, Failures, Skipped)) for a in self.TestCases: a.Output(outstream) outstream.write(' </testsuite> ') create_new_testcase def create_new_testcase ( self , name , classname ) View Source def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc JunitTestReport class JunitTestReport ( ) View Source class JunitTestReport(object): def __init__(self): self.TestSuites = [] def create_new_testsuite(self, name, package): id = len(self.TestSuites) ts = JunitReportTestSuite(name, package, id) self.TestSuites.append(ts) return ts def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close() Methods Output def Output ( self , filepath ) View Source def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close() create_new_testsuite def create_new_testsuite ( self , name , package ) View Source def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts","title":"Junit report format"},{"location":"edk2toollib/log/junit_report_format/#module-edk2toolliblogjunit_report_format","text":"View Source ## # junit_report_format # This module contains support for Outputting Junit test results xml. # # Used to support CI/CD and exporting test results for other tools. # This does test report generation without being a test runner. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import time from xml.sax.saxutils import escape class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" }) ## # Test Case class # ## class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . ClassName = escape ( ClassName . strip (), { '\"' : \"&quot;\" }) self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \" \\n \" def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \" \\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped type=\"skipped\">' ) outstream . write ( self . StdOut ) outstream . write ( '</skipped>' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) ## # Test Suite class. Create new suites by using the JunitTestReport Object # # ## class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . Package = escape ( Package . strip (), { '\"' : \"&quot;\" }) self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases : if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases : a . Output ( outstream ) outstream . write ( '</testsuite>' ) ## # Test Report. Top level object test reporting. # # ## class JunitTestReport ( object ): def __init__ ( self ): self . TestSuites = [] def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts def Output ( self , filepath ): f = open ( filepath , \"w\" ) f . write ( '' ) f . write ( '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' ) f . write ( '<testsuites>' ) for a in self . TestSuites : a . Output ( f ) f . write ( '</testsuites>' ) f . close ()","title":"Module edk2toollib.log.junit_report_format"},{"location":"edk2toollib/log/junit_report_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/junit_report_format/#junitreporterror","text":"class JunitReportError ( type , msg ) View Source class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" })","title":"JunitReportError"},{"location":"edk2toollib/log/junit_report_format/#junitreportfailure","text":"class JunitReportFailure ( type , msg ) View Source class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = escape ( msg . strip (), { '\"' : \"&quot;\" }) self . Type = escape ( type . strip (), { '\"' : \"&quot;\" })","title":"JunitReportFailure"},{"location":"edk2toollib/log/junit_report_format/#junitreporttestcase","text":"class JunitReportTestCase ( Name , ClassName ) View Source class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . ClassName = escape ( ClassName . strip (), { '\"' : \"&quot;\" }) self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \"\\n \" def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \"\\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED: outstream . write ( '<skipped type=\"skipped\">' ) outstream . write ( self . StdOut ) outstream . write ( '</skipped>' ) elif self . Status == JunitReportTestCase . FAILED: outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR: outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS: raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' )","title":"JunitReportTestCase"},{"location":"edk2toollib/log/junit_report_format/#class-variables","text":"ERROR FAILED NEW SKIPPED SUCCESS","title":"Class variables"},{"location":"edk2toollib/log/junit_report_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#logstderror","text":"def LogStdError ( self , msg ) View Source def LogStdError ( self , msg ): self . StdErr += escape ( msg . strip ()) + \"\\n \"","title":"LogStdError"},{"location":"edk2toollib/log/junit_report_format/#logstdout","text":"def LogStdOut ( self , msg ) View Source def LogStdOut ( self , msg ): self . StdOut += escape ( msg . strip ()) + \"\\n \"","title":"LogStdOut"},{"location":"edk2toollib/log/junit_report_format/#output","text":"def Output ( self , outstream ) View Source def Output(self, outstream): outstream.write(' <testcase classname= \"{0}\" name= \"{1}\" time= \"{2}\" > '.format(self.ClassName, self.Name, self.Time)) if self.Status == JunitReportTestCase.SKIPPED: outstream.write(' <skipped type= \"skipped\" > ') outstream.write(self.StdOut) outstream.write(' </skipped> ') elif self.Status == JunitReportTestCase.FAILED: outstream.write(' <failure message= \"{0}\" type= \"{1}\" /> '.format(self.FailureMsg.Message, self.FailureMsg.Type)) elif self.Status == JunitReportTestCase.ERROR: outstream.write(' <error message= \"{0}\" type= \"{1}\" /> '.format(self.ErrorMsg.Message, self.ErrorMsg.Type)) elif self.Status != JunitReportTestCase.SUCCESS: raise Exception(\"Can't output a testcase {0}.{1} in invalid state {2}\".format(self.ClassName, self.Name, self.Status)) outstream.write(' <system-out> ' + self.StdOut + ' </system-out> ') outstream.write(' <system-err> ' + self.StdErr + ' </system-err> ') outstream.write(' </testcase> ')","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#seterror","text":"def SetError ( self , Msg , Type ) View Source def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg )","title":"SetError"},{"location":"edk2toollib/log/junit_report_format/#setfailed","text":"def SetFailed ( self , Msg , Type ) View Source def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg )","title":"SetFailed"},{"location":"edk2toollib/log/junit_report_format/#setskipped","text":"def SetSkipped ( self ) View Source def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime","title":"SetSkipped"},{"location":"edk2toollib/log/junit_report_format/#setsuccess","text":"def SetSuccess ( self ) View Source def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime","title":"SetSuccess"},{"location":"edk2toollib/log/junit_report_format/#junitreporttestsuite","text":"class JunitReportTestSuite ( Name , Package , Id ) View Source class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = escape ( Name . strip (), { '\"' : \"&quot;\" }) self . Package = escape ( Package . strip (), { '\"' : \"&quot;\" }) self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases: if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases: a . Output ( outstream ) outstream . write ( '</testsuite>' )","title":"JunitReportTestSuite"},{"location":"edk2toollib/log/junit_report_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#output_1","text":"def Output ( self , outstream ) View Source def Output(self, outstream): Errors = 0 Failures = 0 Skipped = 0 Tests = len(self.TestCases) for a in self.TestCases: if(a.Status == JunitReportTestCase.FAILED): Failures += 1 elif(a.Status == JunitReportTestCase.ERROR): Errors += 1 elif(a.Status == JunitReportTestCase.SKIPPED): Skipped += 1 outstream.write(' <testsuite id= \"{0}\" name= \"{1}\" package= \"{2}\" errors= \"{3}\" tests= \"{4}\" ' ' failures= \"{5}\" skipped= \"{6}\" > '.format(self.TestId, self.Name, self.Package, Errors, Tests, Failures, Skipped)) for a in self.TestCases: a.Output(outstream) outstream.write(' </testsuite> ')","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#create_new_testcase","text":"def create_new_testcase ( self , name , classname ) View Source def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc","title":"create_new_testcase"},{"location":"edk2toollib/log/junit_report_format/#junittestreport","text":"class JunitTestReport ( ) View Source class JunitTestReport(object): def __init__(self): self.TestSuites = [] def create_new_testsuite(self, name, package): id = len(self.TestSuites) ts = JunitReportTestSuite(name, package, id) self.TestSuites.append(ts) return ts def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close()","title":"JunitTestReport"},{"location":"edk2toollib/log/junit_report_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#output_2","text":"def Output ( self , filepath ) View Source def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close()","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#create_new_testsuite","text":"def create_new_testsuite ( self , name , package ) View Source def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts","title":"create_new_testsuite"},{"location":"edk2toollib/log/markdown_handler/","text":"Module edk2toollib.log.markdown_handler View Source ## # Handle basic logging outputting to markdown # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class MarkdownFileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report \\n \" ) self . stream . write ( \"[Go to table of contents](#table-of-contents) \\n \" ) self . stream . write ( \"===== \\n \" ) self . stream . write ( \" [Go to Error List](#error-list) \\n \" ) self . stream . write ( \"===== \\n \" ) self . contents = [] self . error_records = [] def emit ( self , record ): if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [])) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046: merged two stream.writes into one. stream . write ( msg + self . terminator ) # self.flush() def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ): # Using info from here https://stackoverflow.com/a/38507669 # get rid of uppercase characters text = text . lower () . strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ) . replace ( \",\" , \"\" ) . replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ): output = \" + \\\" {0} \\\" from {1}:{2} \\n \" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ): self . stream . write ( \"## Table of Contents \\n \" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1}) \\n \" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1}) \\n \" . format ( section , section_link )) self . stream . write ( \"## Error List \\n \" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () Classes MarkdownFileHandler class MarkdownFileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class MarkdownFileHandler ( logging . FileHandler ) : def __init__ ( self , filename , mode = 'w+' ) : logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report\\n\" ) self . stream . write ( \"[Go to table of contents](#table-of-contents)\\n\" ) self . stream . write ( \"=====\\n\" ) self . stream . write ( \" [Go to Error List](#error-list)\\n\" ) self . stream . write ( \"=====\\n\" ) self . contents = [] self . error_records = [] def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) # self . flush () def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ) : # Using info from here https : // stackoverflow . com / a / 38507669 # get rid of uppercase characters text = text . lower (). strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ). replace ( \",\" , \"\" ). replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ) : output = \" + \\\" { 0 }\\ \" from {1}:{2}\\n\" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ) : self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () Ancestors (in MRO) logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Closes the stream. View Source def close ( self ): self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"Markdown handler"},{"location":"edk2toollib/log/markdown_handler/#module-edk2toolliblogmarkdown_handler","text":"View Source ## # Handle basic logging outputting to markdown # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class MarkdownFileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report \\n \" ) self . stream . write ( \"[Go to table of contents](#table-of-contents) \\n \" ) self . stream . write ( \"===== \\n \" ) self . stream . write ( \" [Go to Error List](#error-list) \\n \" ) self . stream . write ( \"===== \\n \" ) self . contents = [] self . error_records = [] def emit ( self , record ): if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [])) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046: merged two stream.writes into one. stream . write ( msg + self . terminator ) # self.flush() def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ): # Using info from here https://stackoverflow.com/a/38507669 # get rid of uppercase characters text = text . lower () . strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ) . replace ( \",\" , \"\" ) . replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ): output = \" + \\\" {0} \\\" from {1}:{2} \\n \" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ): self . stream . write ( \"## Table of Contents \\n \" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1}) \\n \" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1}) \\n \" . format ( section , section_link )) self . stream . write ( \"## Error List \\n \" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"Module edk2toollib.log.markdown_handler"},{"location":"edk2toollib/log/markdown_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/markdown_handler/#markdownfilehandler","text":"class MarkdownFileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class MarkdownFileHandler ( logging . FileHandler ) : def __init__ ( self , filename , mode = 'w+' ) : logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report\\n\" ) self . stream . write ( \"[Go to table of contents](#table-of-contents)\\n\" ) self . stream . write ( \"=====\\n\" ) self . stream . write ( \" [Go to Error List](#error-list)\\n\" ) self . stream . write ( \"=====\\n\" ) self . contents = [] self . error_records = [] def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) # self . flush () def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ) : # Using info from here https : // stackoverflow . com / a / 38507669 # get rid of uppercase characters text = text . lower (). strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ). replace ( \",\" , \"\" ). replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ) : output = \" + \\\" { 0 }\\ \" from {1}:{2}\\n\" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ) : self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"MarkdownFileHandler"},{"location":"edk2toollib/log/markdown_handler/#ancestors-in-mro","text":"logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/markdown_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/markdown_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/markdown_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/markdown_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/markdown_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/markdown_handler/#close","text":"def close ( self ) Closes the stream. View Source def close ( self ): self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"close"},{"location":"edk2toollib/log/markdown_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/markdown_handler/#emit","text":"def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator )","title":"emit"},{"location":"edk2toollib/log/markdown_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/markdown_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/markdown_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/markdown_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/markdown_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) except Exception : # silently fail pass finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/markdown_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/markdown_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/markdown_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/markdown_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/markdown_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/markdown_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/markdown_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/string_handler/","text":"Module edk2toollib.log.string_handler View Source ## # Handle basic logging by streaming into stringIO # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import io class StringStreamHandler ( logging . StreamHandler ): terminator = ' \\n ' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = io . StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) Classes StringStreamHandler class StringStreamHandler ( ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class StringStreamHandler ( logging . StreamHandler ): terminator = '\\n' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = io . StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) Ancestors (in MRO) logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): \"\"\" Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an 'encoding' attribute, it is used to determine how to do the output to the stream. \"\"\" try : msg = self . format ( record ) stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) self . flush () except RecursionError : # See issue 36272 raise except Exception : self . handleError ( record ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb readlines def readlines ( self , hint =- 1 ) View Source def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) seek def seek ( self , offset , whence ) View Source def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) seek_end def seek_end ( self ) View Source def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END ) seek_start def seek_start ( self ) View Source def seek_start ( self ): self . stream . seek ( 0 , 0 ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"String handler"},{"location":"edk2toollib/log/string_handler/#module-edk2toolliblogstring_handler","text":"View Source ## # Handle basic logging by streaming into stringIO # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import io class StringStreamHandler ( logging . StreamHandler ): terminator = ' \\n ' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = io . StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"Module edk2toollib.log.string_handler"},{"location":"edk2toollib/log/string_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/string_handler/#stringstreamhandler","text":"class StringStreamHandler ( ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class StringStreamHandler ( logging . StreamHandler ): terminator = '\\n' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = io . StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"StringStreamHandler"},{"location":"edk2toollib/log/string_handler/#ancestors-in-mro","text":"logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/string_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/string_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/string_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/string_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/string_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/string_handler/#close","text":"def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock ()","title":"close"},{"location":"edk2toollib/log/string_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/string_handler/#emit","text":"def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): \"\"\" Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an 'encoding' attribute, it is used to determine how to do the output to the stream. \"\"\" try : msg = self . format ( record ) stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) self . flush () except RecursionError : # See issue 36272 raise except Exception : self . handleError ( record )","title":"emit"},{"location":"edk2toollib/log/string_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/string_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/string_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/string_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/string_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/string_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/string_handler/#readlines","text":"def readlines ( self , hint =- 1 ) View Source def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint )","title":"readlines"},{"location":"edk2toollib/log/string_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/string_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/string_handler/#seek","text":"def seek ( self , offset , whence ) View Source def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"seek"},{"location":"edk2toollib/log/string_handler/#seek_end","text":"def seek_end ( self ) View Source def seek_end ( self ): self . stream . seek ( 0 , io . SEEK_END )","title":"seek_end"},{"location":"edk2toollib/log/string_handler/#seek_start","text":"def seek_start ( self ) View Source def seek_start ( self ): self . stream . seek ( 0 , 0 )","title":"seek_start"},{"location":"edk2toollib/log/string_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/string_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/string_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/string_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/tpm/","text":"Module edk2toollib.tpm View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.tpm.tpm2_defs edk2toollib.tpm.tpm2_defs_test edk2toollib.tpm.tpm2_policy_calc edk2toollib.tpm.tpm2_policy_calc_test edk2toollib.tpm.tpm2_simulator edk2toollib.tpm.tpm2_stream edk2toollib.tpm.tpm2_stream_test","title":"Index"},{"location":"edk2toollib/tpm/#module-edk2toollibtpm","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.tpm"},{"location":"edk2toollib/tpm/#sub-modules","text":"edk2toollib.tpm.tpm2_defs edk2toollib.tpm.tpm2_defs_test edk2toollib.tpm.tpm2_policy_calc edk2toollib.tpm.tpm2_policy_calc_test edk2toollib.tpm.tpm2_simulator edk2toollib.tpm.tpm2_stream edk2toollib.tpm.tpm2_stream_test","title":"Sub-modules"},{"location":"edk2toollib/tpm/tpm2_defs/","text":"Module edk2toollib.tpm.tpm2_defs View Source # @file tpm2_defs . py # This file contains utility classes to help interpret definitions from the # Tpm20 . h header file in TianoCore . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## ## # INCLUDES CONTENTS FROM TianoCore Tpm20 . h HEADER FILE !! # # TPM2 .0 Specification data structures # ( Trusted Platform Module Library Specification , Family \"2.0\" , Level 00 , Revision 00.96 , # @http : // www . trustedcomputinggroup . org / resources / tpm_library_specification ) # # Check http : // trustedcomputinggroup . org for latest specification updates . # # Copyright ( c ) 2013 - 2015 , Intel Corporation . All rights reserved . < BR > ## # spell - checker : disable # Table 7 - TPM_ALG_ID Constants TPM_ALG_Size = 2 TPM_ALG_Pack = \"H\" TPM_ALG_ERROR = 0x0000 TPM_ALG_FIRST = 0x0001 TPM_ALG_RSA = 0x0001 TPM_ALG_SHA = 0x0004 TPM_ALG_SHA1 = 0x0004 TPM_ALG_HMAC = 0x0005 TPM_ALG_AES = 0x0006 TPM_ALG_MGF1 = 0x0007 TPM_ALG_KEYEDHASH = 0x0008 TPM_ALG_XOR = 0x000A TPM_ALG_SHA256 = 0x000B TPM_ALG_SHA384 = 0x000C TPM_ALG_SHA512 = 0x000D TPM_ALG_NULL = 0x0010 TPM_ALG_SM3_256 = 0x0012 TPM_ALG_SM4 = 0x0013 TPM_ALG_RSASSA = 0x0014 TPM_ALG_RSAES = 0x0015 TPM_ALG_RSAPSS = 0x0016 TPM_ALG_OAEP = 0x0017 TPM_ALG_ECDSA = 0x0018 TPM_ALG_ECDH = 0x0019 TPM_ALG_ECDAA = 0x001A TPM_ALG_SM2 = 0x001B TPM_ALG_ECSCHNORR = 0x001C TPM_ALG_ECMQV = 0x001D TPM_ALG_KDF1_SP800_56a = 0x0020 TPM_ALG_KDF2 = 0x0021 TPM_ALG_KDF1_SP800_108 = 0x0022 TPM_ALG_ECC = 0x0023 TPM_ALG_SYMCIPHER = 0x0025 TPM_ALG_CTR = 0x0040 TPM_ALG_OFB = 0x0041 TPM_ALG_CBC = 0x0042 TPM_ALG_CFB = 0x0043 TPM_ALG_ECB = 0x0044 TPM_ALG_LAST = 0x0044 # Table 11 - TPM_CC Constants ( Numeric Order ) TPM_CC_Size = 4 TPM_CC_Pack = \"L\" TPM_CC_FIRST = 0x0000011F TPM_CC_PP_FIRST = 0x0000011F TPM_CC_NV_UndefineSpaceSpecial = 0x0000011F TPM_CC_EvictControl = 0x00000120 TPM_CC_HierarchyControl = 0x00000121 TPM_CC_NV_UndefineSpace = 0x00000122 TPM_CC_ChangeEPS = 0x00000124 TPM_CC_ChangePPS = 0x00000125 TPM_CC_Clear = 0x00000126 TPM_CC_ClearControl = 0x00000127 TPM_CC_ClockSet = 0x00000128 TPM_CC_HierarchyChangeAuth = 0x00000129 TPM_CC_NV_DefineSpace = 0x0000012A TPM_CC_PCR_Allocate = 0x0000012B TPM_CC_PCR_SetAuthPolicy = 0x0000012C TPM_CC_PP_Commands = 0x0000012D TPM_CC_SetPrimaryPolicy = 0x0000012E TPM_CC_FieldUpgradeStart = 0x0000012F TPM_CC_ClockRateAdjust = 0x00000130 TPM_CC_CreatePrimary = 0x00000131 TPM_CC_NV_GlobalWriteLock = 0x00000132 TPM_CC_PP_LAST = 0x00000132 TPM_CC_GetCommandAuditDigest = 0x00000133 TPM_CC_NV_Increment = 0x00000134 TPM_CC_NV_SetBits = 0x00000135 TPM_CC_NV_Extend = 0x00000136 TPM_CC_NV_Write = 0x00000137 TPM_CC_NV_WriteLock = 0x00000138 TPM_CC_DictionaryAttackLockReset = 0x00000139 TPM_CC_DictionaryAttackParameters = 0x0000013A TPM_CC_NV_ChangeAuth = 0x0000013B TPM_CC_PCR_Event = 0x0000013C TPM_CC_PCR_Reset = 0x0000013D TPM_CC_SequenceComplete = 0x0000013E TPM_CC_SetAlgorithmSet = 0x0000013F TPM_CC_SetCommandCodeAuditStatus = 0x00000140 TPM_CC_FieldUpgradeData = 0x00000141 TPM_CC_IncrementalSelfTest = 0x00000142 TPM_CC_SelfTest = 0x00000143 TPM_CC_Startup = 0x00000144 TPM_CC_Shutdown = 0x00000145 TPM_CC_StirRandom = 0x00000146 TPM_CC_ActivateCredential = 0x00000147 TPM_CC_Certify = 0x00000148 TPM_CC_PolicyNV = 0x00000149 TPM_CC_CertifyCreation = 0x0000014A TPM_CC_Duplicate = 0x0000014B TPM_CC_GetTime = 0x0000014C TPM_CC_GetSessionAuditDigest = 0x0000014D TPM_CC_NV_Read = 0x0000014E TPM_CC_NV_ReadLock = 0x0000014F TPM_CC_ObjectChangeAuth = 0x00000150 TPM_CC_PolicySecret = 0x00000151 TPM_CC_Rewrap = 0x00000152 TPM_CC_Create = 0x00000153 TPM_CC_ECDH_ZGen = 0x00000154 TPM_CC_HMAC = 0x00000155 TPM_CC_Import = 0x00000156 TPM_CC_Load = 0x00000157 TPM_CC_Quote = 0x00000158 TPM_CC_RSA_Decrypt = 0x00000159 TPM_CC_HMAC_Start = 0x0000015B TPM_CC_SequenceUpdate = 0x0000015C TPM_CC_Sign = 0x0000015D TPM_CC_Unseal = 0x0000015E TPM_CC_PolicySigned = 0x00000160 TPM_CC_ContextLoad = 0x00000161 TPM_CC_ContextSave = 0x00000162 TPM_CC_ECDH_KeyGen = 0x00000163 TPM_CC_EncryptDecrypt = 0x00000164 TPM_CC_FlushContext = 0x00000165 TPM_CC_LoadExternal = 0x00000167 TPM_CC_MakeCredential = 0x00000168 TPM_CC_NV_ReadPublic = 0x00000169 TPM_CC_PolicyAuthorize = 0x0000016A TPM_CC_PolicyAuthValue = 0x0000016B TPM_CC_PolicyCommandCode = 0x0000016C TPM_CC_PolicyCounterTimer = 0x0000016D TPM_CC_PolicyCpHash = 0x0000016E TPM_CC_PolicyLocality = 0x0000016F TPM_CC_PolicyNameHash = 0x00000170 TPM_CC_PolicyOR = 0x00000171 TPM_CC_PolicyTicket = 0x00000172 TPM_CC_ReadPublic = 0x00000173 TPM_CC_RSA_Encrypt = 0x00000174 TPM_CC_StartAuthSession = 0x00000176 TPM_CC_VerifySignature = 0x00000177 TPM_CC_ECC_Parameters = 0x00000178 TPM_CC_FirmwareRead = 0x00000179 TPM_CC_GetCapability = 0x0000017A TPM_CC_GetRandom = 0x0000017B TPM_CC_GetTestResult = 0x0000017C TPM_CC_Hash = 0x0000017D TPM_CC_PCR_Read = 0x0000017E TPM_CC_PolicyPCR = 0x0000017F TPM_CC_PolicyRestart = 0x00000180 TPM_CC_ReadClock = 0x00000181 TPM_CC_PCR_Extend = 0x00000182 TPM_CC_PCR_SetAuthValue = 0x00000183 TPM_CC_NV_Certify = 0x00000184 TPM_CC_EventSequenceComplete = 0x00000185 TPM_CC_HashSequenceStart = 0x00000186 TPM_CC_PolicyPhysicalPresence = 0x00000187 TPM_CC_PolicyDuplicationSelect = 0x00000188 TPM_CC_PolicyGetDigest = 0x00000189 TPM_CC_TestParms = 0x0000018A TPM_CC_Commit = 0x0000018B TPM_CC_PolicyPassword = 0x0000018C TPM_CC_ZGen_2Phase = 0x0000018D TPM_CC_EC_Ephemeral = 0x0000018E TPM_CC_LAST = 0x0000018E # Table 18 - TPM_ST Constants TPM_ST_Size = 2 TPM_ST_Pack = \"H\" TPM_ST_RSP_COMMAND = 0x00C4 TPM_ST_NULL = 0X8000 TPM_ST_NO_SESSIONS = 0x8001 TPM_ST_SESSIONS = 0x8002 TPM_ST_ATTEST_NV = 0x8014 TPM_ST_ATTEST_COMMAND_AUDIT = 0x8015 TPM_ST_ATTEST_SESSION_AUDIT = 0x8016 TPM_ST_ATTEST_CERTIFY = 0x8017 TPM_ST_ATTEST_QUOTE = 0x8018 TPM_ST_ATTEST_TIME = 0x8019 TPM_ST_ATTEST_CREATION = 0x801A TPM_ST_CREATION = 0x8021 TPM_ST_VERIFIED = 0x8022 TPM_ST_AUTH_SECRET = 0x8023 TPM_ST_HASHCHECK = 0x8024 TPM_ST_AUTH_SIGNED = 0x8025 TPM_ST_FU_MANIFEST = 0x8029 # Table 19 - TPM_SU Constants TPM_SU_Size = 2 TPM_SU_Pack = \"H\" TPM_SU_CLEAR = 0x0000 TPM_SU_STATE = 0x0001 # Table 20 - TPM_SE Constants TPM_SE_Size = 1 TPM_SE_Pack = \"B\" TPM_SE_HMAC = 0x00 TPM_SE_POLICY = 0x01 TPM_SE_TRIAL = 0x03 # Table 27 - TPM_RH Constants TPM_RH_Size = 4 TPM_RH_Pack = \"L\" TPM_RH_FIRST = 0x40000000 TPM_RH_SRK = 0x40000000 TPM_RH_OWNER = 0x40000001 TPM_RH_REVOKE = 0x40000002 TPM_RH_TRANSPORT = 0x40000003 TPM_RH_OPERATOR = 0x40000004 TPM_RH_ADMIN = 0x40000005 TPM_RH_EK = 0x40000006 TPM_RH_NULL = 0x40000007 TPM_RH_UNASSIGNED = 0x40000008 TPM_RS_PW = 0x40000009 TPM_RH_LOCKOUT = 0x4000000A TPM_RH_ENDORSEMENT = 0x4000000B TPM_RH_PLATFORM = 0x4000000C TPM_RH_PLATFORM_NV = 0x4000000D TPM_RH_AUTH_00 = 0x40000010 TPM_RH_AUTH_FF = 0x4000010F TPM_RH_LAST = 0x4000010F class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None Variables TPM_ALG_AES TPM_ALG_CBC TPM_ALG_CFB TPM_ALG_CTR TPM_ALG_ECB TPM_ALG_ECC TPM_ALG_ECDAA TPM_ALG_ECDH TPM_ALG_ECDSA TPM_ALG_ECMQV TPM_ALG_ECSCHNORR TPM_ALG_ERROR TPM_ALG_FIRST TPM_ALG_HMAC TPM_ALG_KDF1_SP800_108 TPM_ALG_KDF1_SP800_56a TPM_ALG_KDF2 TPM_ALG_KEYEDHASH TPM_ALG_LAST TPM_ALG_MGF1 TPM_ALG_NULL TPM_ALG_OAEP TPM_ALG_OFB TPM_ALG_Pack TPM_ALG_RSA TPM_ALG_RSAES TPM_ALG_RSAPSS TPM_ALG_RSASSA TPM_ALG_SHA TPM_ALG_SHA1 TPM_ALG_SHA256 TPM_ALG_SHA384 TPM_ALG_SHA512 TPM_ALG_SM2 TPM_ALG_SM3_256 TPM_ALG_SM4 TPM_ALG_SYMCIPHER TPM_ALG_Size TPM_ALG_XOR TPM_CC_ActivateCredential TPM_CC_Certify TPM_CC_CertifyCreation TPM_CC_ChangeEPS TPM_CC_ChangePPS TPM_CC_Clear TPM_CC_ClearControl TPM_CC_ClockRateAdjust TPM_CC_ClockSet TPM_CC_Commit TPM_CC_ContextLoad TPM_CC_ContextSave TPM_CC_Create TPM_CC_CreatePrimary TPM_CC_DictionaryAttackLockReset TPM_CC_DictionaryAttackParameters TPM_CC_Duplicate TPM_CC_ECC_Parameters TPM_CC_ECDH_KeyGen TPM_CC_ECDH_ZGen TPM_CC_EC_Ephemeral TPM_CC_EncryptDecrypt TPM_CC_EventSequenceComplete TPM_CC_EvictControl TPM_CC_FIRST TPM_CC_FieldUpgradeData TPM_CC_FieldUpgradeStart TPM_CC_FirmwareRead TPM_CC_FlushContext TPM_CC_GetCapability TPM_CC_GetCommandAuditDigest TPM_CC_GetRandom TPM_CC_GetSessionAuditDigest TPM_CC_GetTestResult TPM_CC_GetTime TPM_CC_HMAC TPM_CC_HMAC_Start TPM_CC_Hash TPM_CC_HashSequenceStart TPM_CC_HierarchyChangeAuth TPM_CC_HierarchyControl TPM_CC_Import TPM_CC_IncrementalSelfTest TPM_CC_LAST TPM_CC_Load TPM_CC_LoadExternal TPM_CC_MakeCredential TPM_CC_NV_Certify TPM_CC_NV_ChangeAuth TPM_CC_NV_DefineSpace TPM_CC_NV_Extend TPM_CC_NV_GlobalWriteLock TPM_CC_NV_Increment TPM_CC_NV_Read TPM_CC_NV_ReadLock TPM_CC_NV_ReadPublic TPM_CC_NV_SetBits TPM_CC_NV_UndefineSpace TPM_CC_NV_UndefineSpaceSpecial TPM_CC_NV_Write TPM_CC_NV_WriteLock TPM_CC_ObjectChangeAuth TPM_CC_PCR_Allocate TPM_CC_PCR_Event TPM_CC_PCR_Extend TPM_CC_PCR_Read TPM_CC_PCR_Reset TPM_CC_PCR_SetAuthPolicy TPM_CC_PCR_SetAuthValue TPM_CC_PP_Commands TPM_CC_PP_FIRST TPM_CC_PP_LAST TPM_CC_Pack TPM_CC_PolicyAuthValue TPM_CC_PolicyAuthorize TPM_CC_PolicyCommandCode TPM_CC_PolicyCounterTimer TPM_CC_PolicyCpHash TPM_CC_PolicyDuplicationSelect TPM_CC_PolicyGetDigest TPM_CC_PolicyLocality TPM_CC_PolicyNV TPM_CC_PolicyNameHash TPM_CC_PolicyOR TPM_CC_PolicyPCR TPM_CC_PolicyPassword TPM_CC_PolicyPhysicalPresence TPM_CC_PolicyRestart TPM_CC_PolicySecret TPM_CC_PolicySigned TPM_CC_PolicyTicket TPM_CC_Quote TPM_CC_RSA_Decrypt TPM_CC_RSA_Encrypt TPM_CC_ReadClock TPM_CC_ReadPublic TPM_CC_Rewrap TPM_CC_SelfTest TPM_CC_SequenceComplete TPM_CC_SequenceUpdate TPM_CC_SetAlgorithmSet TPM_CC_SetCommandCodeAuditStatus TPM_CC_SetPrimaryPolicy TPM_CC_Shutdown TPM_CC_Sign TPM_CC_Size TPM_CC_StartAuthSession TPM_CC_Startup TPM_CC_StirRandom TPM_CC_TestParms TPM_CC_Unseal TPM_CC_VerifySignature TPM_CC_ZGen_2Phase TPM_RH_ADMIN TPM_RH_AUTH_00 TPM_RH_AUTH_FF TPM_RH_EK TPM_RH_ENDORSEMENT TPM_RH_FIRST TPM_RH_LAST TPM_RH_LOCKOUT TPM_RH_NULL TPM_RH_OPERATOR TPM_RH_OWNER TPM_RH_PLATFORM TPM_RH_PLATFORM_NV TPM_RH_Pack TPM_RH_REVOKE TPM_RH_SRK TPM_RH_Size TPM_RH_TRANSPORT TPM_RH_UNASSIGNED TPM_RS_PW TPM_SE_HMAC TPM_SE_POLICY TPM_SE_Pack TPM_SE_Size TPM_SE_TRIAL TPM_ST_ATTEST_CERTIFY TPM_ST_ATTEST_COMMAND_AUDIT TPM_ST_ATTEST_CREATION TPM_ST_ATTEST_NV TPM_ST_ATTEST_QUOTE TPM_ST_ATTEST_SESSION_AUDIT TPM_ST_ATTEST_TIME TPM_ST_AUTH_SECRET TPM_ST_AUTH_SIGNED TPM_ST_CREATION TPM_ST_FU_MANIFEST TPM_ST_HASHCHECK TPM_ST_NO_SESSIONS TPM_ST_NULL TPM_ST_Pack TPM_ST_RSP_COMMAND TPM_ST_SESSIONS TPM_ST_Size TPM_ST_VERIFIED TPM_SU_CLEAR TPM_SU_Pack TPM_SU_STATE TPM_SU_Size Classes CommandCode class CommandCode ( / , * args , ** kwargs ) View Source class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) Static methods get_code def get_code ( cc_string ) View Source @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) get_string def get_string ( cc_code ) View Source @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) ResponseCode class ResponseCode ( / , * args , ** kwargs ) View Source class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None Static methods get_simple_string def get_simple_string ( rc_code ) View Source @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) parse_code def parse_code ( rc_code ) View Source @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"Tpm2 defs"},{"location":"edk2toollib/tpm/tpm2_defs/#module-edk2toollibtpmtpm2_defs","text":"View Source # @file tpm2_defs . py # This file contains utility classes to help interpret definitions from the # Tpm20 . h header file in TianoCore . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## ## # INCLUDES CONTENTS FROM TianoCore Tpm20 . h HEADER FILE !! # # TPM2 .0 Specification data structures # ( Trusted Platform Module Library Specification , Family \"2.0\" , Level 00 , Revision 00.96 , # @http : // www . trustedcomputinggroup . org / resources / tpm_library_specification ) # # Check http : // trustedcomputinggroup . org for latest specification updates . # # Copyright ( c ) 2013 - 2015 , Intel Corporation . All rights reserved . < BR > ## # spell - checker : disable # Table 7 - TPM_ALG_ID Constants TPM_ALG_Size = 2 TPM_ALG_Pack = \"H\" TPM_ALG_ERROR = 0x0000 TPM_ALG_FIRST = 0x0001 TPM_ALG_RSA = 0x0001 TPM_ALG_SHA = 0x0004 TPM_ALG_SHA1 = 0x0004 TPM_ALG_HMAC = 0x0005 TPM_ALG_AES = 0x0006 TPM_ALG_MGF1 = 0x0007 TPM_ALG_KEYEDHASH = 0x0008 TPM_ALG_XOR = 0x000A TPM_ALG_SHA256 = 0x000B TPM_ALG_SHA384 = 0x000C TPM_ALG_SHA512 = 0x000D TPM_ALG_NULL = 0x0010 TPM_ALG_SM3_256 = 0x0012 TPM_ALG_SM4 = 0x0013 TPM_ALG_RSASSA = 0x0014 TPM_ALG_RSAES = 0x0015 TPM_ALG_RSAPSS = 0x0016 TPM_ALG_OAEP = 0x0017 TPM_ALG_ECDSA = 0x0018 TPM_ALG_ECDH = 0x0019 TPM_ALG_ECDAA = 0x001A TPM_ALG_SM2 = 0x001B TPM_ALG_ECSCHNORR = 0x001C TPM_ALG_ECMQV = 0x001D TPM_ALG_KDF1_SP800_56a = 0x0020 TPM_ALG_KDF2 = 0x0021 TPM_ALG_KDF1_SP800_108 = 0x0022 TPM_ALG_ECC = 0x0023 TPM_ALG_SYMCIPHER = 0x0025 TPM_ALG_CTR = 0x0040 TPM_ALG_OFB = 0x0041 TPM_ALG_CBC = 0x0042 TPM_ALG_CFB = 0x0043 TPM_ALG_ECB = 0x0044 TPM_ALG_LAST = 0x0044 # Table 11 - TPM_CC Constants ( Numeric Order ) TPM_CC_Size = 4 TPM_CC_Pack = \"L\" TPM_CC_FIRST = 0x0000011F TPM_CC_PP_FIRST = 0x0000011F TPM_CC_NV_UndefineSpaceSpecial = 0x0000011F TPM_CC_EvictControl = 0x00000120 TPM_CC_HierarchyControl = 0x00000121 TPM_CC_NV_UndefineSpace = 0x00000122 TPM_CC_ChangeEPS = 0x00000124 TPM_CC_ChangePPS = 0x00000125 TPM_CC_Clear = 0x00000126 TPM_CC_ClearControl = 0x00000127 TPM_CC_ClockSet = 0x00000128 TPM_CC_HierarchyChangeAuth = 0x00000129 TPM_CC_NV_DefineSpace = 0x0000012A TPM_CC_PCR_Allocate = 0x0000012B TPM_CC_PCR_SetAuthPolicy = 0x0000012C TPM_CC_PP_Commands = 0x0000012D TPM_CC_SetPrimaryPolicy = 0x0000012E TPM_CC_FieldUpgradeStart = 0x0000012F TPM_CC_ClockRateAdjust = 0x00000130 TPM_CC_CreatePrimary = 0x00000131 TPM_CC_NV_GlobalWriteLock = 0x00000132 TPM_CC_PP_LAST = 0x00000132 TPM_CC_GetCommandAuditDigest = 0x00000133 TPM_CC_NV_Increment = 0x00000134 TPM_CC_NV_SetBits = 0x00000135 TPM_CC_NV_Extend = 0x00000136 TPM_CC_NV_Write = 0x00000137 TPM_CC_NV_WriteLock = 0x00000138 TPM_CC_DictionaryAttackLockReset = 0x00000139 TPM_CC_DictionaryAttackParameters = 0x0000013A TPM_CC_NV_ChangeAuth = 0x0000013B TPM_CC_PCR_Event = 0x0000013C TPM_CC_PCR_Reset = 0x0000013D TPM_CC_SequenceComplete = 0x0000013E TPM_CC_SetAlgorithmSet = 0x0000013F TPM_CC_SetCommandCodeAuditStatus = 0x00000140 TPM_CC_FieldUpgradeData = 0x00000141 TPM_CC_IncrementalSelfTest = 0x00000142 TPM_CC_SelfTest = 0x00000143 TPM_CC_Startup = 0x00000144 TPM_CC_Shutdown = 0x00000145 TPM_CC_StirRandom = 0x00000146 TPM_CC_ActivateCredential = 0x00000147 TPM_CC_Certify = 0x00000148 TPM_CC_PolicyNV = 0x00000149 TPM_CC_CertifyCreation = 0x0000014A TPM_CC_Duplicate = 0x0000014B TPM_CC_GetTime = 0x0000014C TPM_CC_GetSessionAuditDigest = 0x0000014D TPM_CC_NV_Read = 0x0000014E TPM_CC_NV_ReadLock = 0x0000014F TPM_CC_ObjectChangeAuth = 0x00000150 TPM_CC_PolicySecret = 0x00000151 TPM_CC_Rewrap = 0x00000152 TPM_CC_Create = 0x00000153 TPM_CC_ECDH_ZGen = 0x00000154 TPM_CC_HMAC = 0x00000155 TPM_CC_Import = 0x00000156 TPM_CC_Load = 0x00000157 TPM_CC_Quote = 0x00000158 TPM_CC_RSA_Decrypt = 0x00000159 TPM_CC_HMAC_Start = 0x0000015B TPM_CC_SequenceUpdate = 0x0000015C TPM_CC_Sign = 0x0000015D TPM_CC_Unseal = 0x0000015E TPM_CC_PolicySigned = 0x00000160 TPM_CC_ContextLoad = 0x00000161 TPM_CC_ContextSave = 0x00000162 TPM_CC_ECDH_KeyGen = 0x00000163 TPM_CC_EncryptDecrypt = 0x00000164 TPM_CC_FlushContext = 0x00000165 TPM_CC_LoadExternal = 0x00000167 TPM_CC_MakeCredential = 0x00000168 TPM_CC_NV_ReadPublic = 0x00000169 TPM_CC_PolicyAuthorize = 0x0000016A TPM_CC_PolicyAuthValue = 0x0000016B TPM_CC_PolicyCommandCode = 0x0000016C TPM_CC_PolicyCounterTimer = 0x0000016D TPM_CC_PolicyCpHash = 0x0000016E TPM_CC_PolicyLocality = 0x0000016F TPM_CC_PolicyNameHash = 0x00000170 TPM_CC_PolicyOR = 0x00000171 TPM_CC_PolicyTicket = 0x00000172 TPM_CC_ReadPublic = 0x00000173 TPM_CC_RSA_Encrypt = 0x00000174 TPM_CC_StartAuthSession = 0x00000176 TPM_CC_VerifySignature = 0x00000177 TPM_CC_ECC_Parameters = 0x00000178 TPM_CC_FirmwareRead = 0x00000179 TPM_CC_GetCapability = 0x0000017A TPM_CC_GetRandom = 0x0000017B TPM_CC_GetTestResult = 0x0000017C TPM_CC_Hash = 0x0000017D TPM_CC_PCR_Read = 0x0000017E TPM_CC_PolicyPCR = 0x0000017F TPM_CC_PolicyRestart = 0x00000180 TPM_CC_ReadClock = 0x00000181 TPM_CC_PCR_Extend = 0x00000182 TPM_CC_PCR_SetAuthValue = 0x00000183 TPM_CC_NV_Certify = 0x00000184 TPM_CC_EventSequenceComplete = 0x00000185 TPM_CC_HashSequenceStart = 0x00000186 TPM_CC_PolicyPhysicalPresence = 0x00000187 TPM_CC_PolicyDuplicationSelect = 0x00000188 TPM_CC_PolicyGetDigest = 0x00000189 TPM_CC_TestParms = 0x0000018A TPM_CC_Commit = 0x0000018B TPM_CC_PolicyPassword = 0x0000018C TPM_CC_ZGen_2Phase = 0x0000018D TPM_CC_EC_Ephemeral = 0x0000018E TPM_CC_LAST = 0x0000018E # Table 18 - TPM_ST Constants TPM_ST_Size = 2 TPM_ST_Pack = \"H\" TPM_ST_RSP_COMMAND = 0x00C4 TPM_ST_NULL = 0X8000 TPM_ST_NO_SESSIONS = 0x8001 TPM_ST_SESSIONS = 0x8002 TPM_ST_ATTEST_NV = 0x8014 TPM_ST_ATTEST_COMMAND_AUDIT = 0x8015 TPM_ST_ATTEST_SESSION_AUDIT = 0x8016 TPM_ST_ATTEST_CERTIFY = 0x8017 TPM_ST_ATTEST_QUOTE = 0x8018 TPM_ST_ATTEST_TIME = 0x8019 TPM_ST_ATTEST_CREATION = 0x801A TPM_ST_CREATION = 0x8021 TPM_ST_VERIFIED = 0x8022 TPM_ST_AUTH_SECRET = 0x8023 TPM_ST_HASHCHECK = 0x8024 TPM_ST_AUTH_SIGNED = 0x8025 TPM_ST_FU_MANIFEST = 0x8029 # Table 19 - TPM_SU Constants TPM_SU_Size = 2 TPM_SU_Pack = \"H\" TPM_SU_CLEAR = 0x0000 TPM_SU_STATE = 0x0001 # Table 20 - TPM_SE Constants TPM_SE_Size = 1 TPM_SE_Pack = \"B\" TPM_SE_HMAC = 0x00 TPM_SE_POLICY = 0x01 TPM_SE_TRIAL = 0x03 # Table 27 - TPM_RH Constants TPM_RH_Size = 4 TPM_RH_Pack = \"L\" TPM_RH_FIRST = 0x40000000 TPM_RH_SRK = 0x40000000 TPM_RH_OWNER = 0x40000001 TPM_RH_REVOKE = 0x40000002 TPM_RH_TRANSPORT = 0x40000003 TPM_RH_OPERATOR = 0x40000004 TPM_RH_ADMIN = 0x40000005 TPM_RH_EK = 0x40000006 TPM_RH_NULL = 0x40000007 TPM_RH_UNASSIGNED = 0x40000008 TPM_RS_PW = 0x40000009 TPM_RH_LOCKOUT = 0x4000000A TPM_RH_ENDORSEMENT = 0x4000000B TPM_RH_PLATFORM = 0x4000000C TPM_RH_PLATFORM_NV = 0x4000000D TPM_RH_AUTH_00 = 0x40000010 TPM_RH_AUTH_FF = 0x4000010F TPM_RH_LAST = 0x4000010F class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"Module edk2toollib.tpm.tpm2_defs"},{"location":"edk2toollib/tpm/tpm2_defs/#variables","text":"TPM_ALG_AES TPM_ALG_CBC TPM_ALG_CFB TPM_ALG_CTR TPM_ALG_ECB TPM_ALG_ECC TPM_ALG_ECDAA TPM_ALG_ECDH TPM_ALG_ECDSA TPM_ALG_ECMQV TPM_ALG_ECSCHNORR TPM_ALG_ERROR TPM_ALG_FIRST TPM_ALG_HMAC TPM_ALG_KDF1_SP800_108 TPM_ALG_KDF1_SP800_56a TPM_ALG_KDF2 TPM_ALG_KEYEDHASH TPM_ALG_LAST TPM_ALG_MGF1 TPM_ALG_NULL TPM_ALG_OAEP TPM_ALG_OFB TPM_ALG_Pack TPM_ALG_RSA TPM_ALG_RSAES TPM_ALG_RSAPSS TPM_ALG_RSASSA TPM_ALG_SHA TPM_ALG_SHA1 TPM_ALG_SHA256 TPM_ALG_SHA384 TPM_ALG_SHA512 TPM_ALG_SM2 TPM_ALG_SM3_256 TPM_ALG_SM4 TPM_ALG_SYMCIPHER TPM_ALG_Size TPM_ALG_XOR TPM_CC_ActivateCredential TPM_CC_Certify TPM_CC_CertifyCreation TPM_CC_ChangeEPS TPM_CC_ChangePPS TPM_CC_Clear TPM_CC_ClearControl TPM_CC_ClockRateAdjust TPM_CC_ClockSet TPM_CC_Commit TPM_CC_ContextLoad TPM_CC_ContextSave TPM_CC_Create TPM_CC_CreatePrimary TPM_CC_DictionaryAttackLockReset TPM_CC_DictionaryAttackParameters TPM_CC_Duplicate TPM_CC_ECC_Parameters TPM_CC_ECDH_KeyGen TPM_CC_ECDH_ZGen TPM_CC_EC_Ephemeral TPM_CC_EncryptDecrypt TPM_CC_EventSequenceComplete TPM_CC_EvictControl TPM_CC_FIRST TPM_CC_FieldUpgradeData TPM_CC_FieldUpgradeStart TPM_CC_FirmwareRead TPM_CC_FlushContext TPM_CC_GetCapability TPM_CC_GetCommandAuditDigest TPM_CC_GetRandom TPM_CC_GetSessionAuditDigest TPM_CC_GetTestResult TPM_CC_GetTime TPM_CC_HMAC TPM_CC_HMAC_Start TPM_CC_Hash TPM_CC_HashSequenceStart TPM_CC_HierarchyChangeAuth TPM_CC_HierarchyControl TPM_CC_Import TPM_CC_IncrementalSelfTest TPM_CC_LAST TPM_CC_Load TPM_CC_LoadExternal TPM_CC_MakeCredential TPM_CC_NV_Certify TPM_CC_NV_ChangeAuth TPM_CC_NV_DefineSpace TPM_CC_NV_Extend TPM_CC_NV_GlobalWriteLock TPM_CC_NV_Increment TPM_CC_NV_Read TPM_CC_NV_ReadLock TPM_CC_NV_ReadPublic TPM_CC_NV_SetBits TPM_CC_NV_UndefineSpace TPM_CC_NV_UndefineSpaceSpecial TPM_CC_NV_Write TPM_CC_NV_WriteLock TPM_CC_ObjectChangeAuth TPM_CC_PCR_Allocate TPM_CC_PCR_Event TPM_CC_PCR_Extend TPM_CC_PCR_Read TPM_CC_PCR_Reset TPM_CC_PCR_SetAuthPolicy TPM_CC_PCR_SetAuthValue TPM_CC_PP_Commands TPM_CC_PP_FIRST TPM_CC_PP_LAST TPM_CC_Pack TPM_CC_PolicyAuthValue TPM_CC_PolicyAuthorize TPM_CC_PolicyCommandCode TPM_CC_PolicyCounterTimer TPM_CC_PolicyCpHash TPM_CC_PolicyDuplicationSelect TPM_CC_PolicyGetDigest TPM_CC_PolicyLocality TPM_CC_PolicyNV TPM_CC_PolicyNameHash TPM_CC_PolicyOR TPM_CC_PolicyPCR TPM_CC_PolicyPassword TPM_CC_PolicyPhysicalPresence TPM_CC_PolicyRestart TPM_CC_PolicySecret TPM_CC_PolicySigned TPM_CC_PolicyTicket TPM_CC_Quote TPM_CC_RSA_Decrypt TPM_CC_RSA_Encrypt TPM_CC_ReadClock TPM_CC_ReadPublic TPM_CC_Rewrap TPM_CC_SelfTest TPM_CC_SequenceComplete TPM_CC_SequenceUpdate TPM_CC_SetAlgorithmSet TPM_CC_SetCommandCodeAuditStatus TPM_CC_SetPrimaryPolicy TPM_CC_Shutdown TPM_CC_Sign TPM_CC_Size TPM_CC_StartAuthSession TPM_CC_Startup TPM_CC_StirRandom TPM_CC_TestParms TPM_CC_Unseal TPM_CC_VerifySignature TPM_CC_ZGen_2Phase TPM_RH_ADMIN TPM_RH_AUTH_00 TPM_RH_AUTH_FF TPM_RH_EK TPM_RH_ENDORSEMENT TPM_RH_FIRST TPM_RH_LAST TPM_RH_LOCKOUT TPM_RH_NULL TPM_RH_OPERATOR TPM_RH_OWNER TPM_RH_PLATFORM TPM_RH_PLATFORM_NV TPM_RH_Pack TPM_RH_REVOKE TPM_RH_SRK TPM_RH_Size TPM_RH_TRANSPORT TPM_RH_UNASSIGNED TPM_RS_PW TPM_SE_HMAC TPM_SE_POLICY TPM_SE_Pack TPM_SE_Size TPM_SE_TRIAL TPM_ST_ATTEST_CERTIFY TPM_ST_ATTEST_COMMAND_AUDIT TPM_ST_ATTEST_CREATION TPM_ST_ATTEST_NV TPM_ST_ATTEST_QUOTE TPM_ST_ATTEST_SESSION_AUDIT TPM_ST_ATTEST_TIME TPM_ST_AUTH_SECRET TPM_ST_AUTH_SIGNED TPM_ST_CREATION TPM_ST_FU_MANIFEST TPM_ST_HASHCHECK TPM_ST_NO_SESSIONS TPM_ST_NULL TPM_ST_Pack TPM_ST_RSP_COMMAND TPM_ST_SESSIONS TPM_ST_Size TPM_ST_VERIFIED TPM_SU_CLEAR TPM_SU_Pack TPM_SU_STATE TPM_SU_Size","title":"Variables"},{"location":"edk2toollib/tpm/tpm2_defs/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_defs/#commandcode","text":"class CommandCode ( / , * args , ** kwargs ) View Source class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None )","title":"CommandCode"},{"location":"edk2toollib/tpm/tpm2_defs/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/tpm/tpm2_defs/#get_code","text":"def get_code ( cc_string ) View Source @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None )","title":"get_code"},{"location":"edk2toollib/tpm/tpm2_defs/#get_string","text":"def get_string ( cc_code ) View Source @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None )","title":"get_string"},{"location":"edk2toollib/tpm/tpm2_defs/#responsecode","text":"class ResponseCode ( / , * args , ** kwargs ) View Source class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"ResponseCode"},{"location":"edk2toollib/tpm/tpm2_defs/#static-methods_1","text":"","title":"Static methods"},{"location":"edk2toollib/tpm/tpm2_defs/#get_simple_string","text":"def get_simple_string ( rc_code ) View Source @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None )","title":"get_simple_string"},{"location":"edk2toollib/tpm/tpm2_defs/#parse_code","text":"def parse_code ( rc_code ) View Source @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"parse_code"},{"location":"edk2toollib/tpm/tpm2_policy_calc/","text":"Module edk2toollib.tpm.tpm2_policy_calc View Source # @file tpm2_policy_calc.py # This file contains classes used to calculate TPM 2.0 policies # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.tpm.tpm2_defs as t2d import hashlib import struct # ======================================================================================== ## # POLICY TREE CLASSES # These are used to describe a final policy structure. # You can construct nodes to form complex policies from the policy primitive classes. ## # PolicyTreeOr <--- Tree Node # / \\ # PolicyTreeSolo PolicyTreeAnd <--- Tree Nodes # / / \\ # PolicyCommandCode PolicyLocality PolicyCommandCode <--- Primitives ## # ======================================================================================== class PolicyHasher ( object ): def __init__ ( self , hash_type ): if hash_type not in [ 'sha256' , 'sha384' ]: raise ValueError ( \"Invalid hash type ' %s '!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 }[ hash_type ] def get_size ( self ): return self . hash_size def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b ' \\x00 ' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components : if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b ' \\x00 ' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b ' \\x00 ' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) # ======================================================================================== ## # POLICY PRIMITIVES # These classes are used to describe a single assertion (eg. PolicyLocality) and # can be used with the PolicyTree classes to construct complex policies. ## # ======================================================================================== class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None : self . bitfield = self . calc_bitfield_from_list ( localities ) else : self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities : # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality ' %d '!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality ' %d ' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else : for value in localities : bitfield |= 1 << value return bitfield def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None : raise ValueError ( \"Command code ' %s ' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) Classes PolicyCalculator class PolicyCalculator ( primitive_dict , policy_tree ) View Source class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass Methods generate_digest def generate_digest ( self , digest_type ) View Source def generate_digest ( self , digest_type ): pass PolicyCommandCode class PolicyCommandCode ( command_code_string = None ) View Source class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None: raise ValueError ( \"Command code '%s' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) Methods get_buffer_for_digest def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) get_code def get_code ( self ) View Source def get_code ( self ): return self . command_code_string PolicyHasher class PolicyHasher ( hash_type ) View Source class PolicyHasher ( object ) : def __init__ ( self , hash_type ) : if hash_type not in [ 'sha256', 'sha384' ] : raise ValueError ( \"Invalid hash type '%s'!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 } [ hash_type ] def get_size ( self ) : return self . hash_size def hash ( self , data ) : hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () Methods get_size def get_size ( self ) View Source def get_size ( self ): return self . hash_size hash def hash ( self , data ) View Source def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () PolicyLocality class PolicyLocality ( localities ) View Source class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None: self . bitfield = self . calc_bitfield_from_list ( localities ) else: self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities: # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality '%d'!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality '%d' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else: for value in localities: bitfield |= 1 << value return bitfield def get_buffer_for_digest(self): # NOTE: We force big-endian to match the marshalling in the TPM. return struct.pack(\"> LB \", t2d . TPM_CC_PolicyLocality , self . bitfield ) Methods calc_bitfield_from_list def calc_bitfield_from_list ( self , localities ) View Source def calc_bitfield_from_list ( self , localities ): bitfield = 0 b00000000 # First , we need to validate all of the localities in the list . for value in localities : # If the value is in a bad range , we 're done here. if not (0 <= value < 5) and not (32 <= value < 256): raise ValueError(\"Invalid locality ' % d '!\" % value) # An \"upper\" locality must be individual. Cannot combine with 0-4. if (32 <= value < 256) and len(localities) > 1: raise ValueError(\"Cannot combine locality ' % d ' with others!\" % value) # If the list is empty... well, we' re done . if len ( localities ) == 0 : pass # Now , if we 're an \"upper\" locality, that' s a simple value . elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities . else : for value in localities : bitfield |= 1 << value return bitfield get_bitfield def get_bitfield ( self ) View Source def get_bitfield ( self ): return self . bitfield get_buffer_for_digest def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) PolicyTreeAnd class PolicyTreeAnd ( components ) View Source class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components: if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b' \\ x00' * hash_obj . get_size () for component in self . components: current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): current_digest = b '\\x00' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest get_type def get_type ( self ) View Source def get_type ( self ): return 'and' validate def validate ( self ) View Source def validate ( self ): return True PolicyTreeOr class PolicyTreeOr ( components ) View Source class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components: # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b' \\ x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b'' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) get_policy_buffer def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b '\\x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer get_type def get_type ( self ) View Source def get_type ( self ): return 'or' validate def validate ( self ) View Source def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy . if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid . if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result PolicyTreeSolo class PolicyTreeSolo ( policy_obj ) This object should only be used to put a single policy claim under an OR View Source class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b' \\ x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) get_policy_buffer def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): return ( b '\\x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () get_type def get_type ( self ) View Source def get_type ( self ): return 'solo' validate def validate ( self ) View Source def validate ( self ): return True","title":"Tpm2 policy calc"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#module-edk2toollibtpmtpm2_policy_calc","text":"View Source # @file tpm2_policy_calc.py # This file contains classes used to calculate TPM 2.0 policies # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.tpm.tpm2_defs as t2d import hashlib import struct # ======================================================================================== ## # POLICY TREE CLASSES # These are used to describe a final policy structure. # You can construct nodes to form complex policies from the policy primitive classes. ## # PolicyTreeOr <--- Tree Node # / \\ # PolicyTreeSolo PolicyTreeAnd <--- Tree Nodes # / / \\ # PolicyCommandCode PolicyLocality PolicyCommandCode <--- Primitives ## # ======================================================================================== class PolicyHasher ( object ): def __init__ ( self , hash_type ): if hash_type not in [ 'sha256' , 'sha384' ]: raise ValueError ( \"Invalid hash type ' %s '!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 }[ hash_type ] def get_size ( self ): return self . hash_size def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b ' \\x00 ' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components : if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b ' \\x00 ' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b ' \\x00 ' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) # ======================================================================================== ## # POLICY PRIMITIVES # These classes are used to describe a single assertion (eg. PolicyLocality) and # can be used with the PolicyTree classes to construct complex policies. ## # ======================================================================================== class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None : self . bitfield = self . calc_bitfield_from_list ( localities ) else : self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities : # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality ' %d '!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality ' %d ' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else : for value in localities : bitfield |= 1 << value return bitfield def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None : raise ValueError ( \"Command code ' %s ' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"Module edk2toollib.tpm.tpm2_policy_calc"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policycalculator","text":"class PolicyCalculator ( primitive_dict , policy_tree ) View Source class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass","title":"PolicyCalculator"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#generate_digest","text":"def generate_digest ( self , digest_type ) View Source def generate_digest ( self , digest_type ): pass","title":"generate_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policycommandcode","text":"class PolicyCommandCode ( command_code_string = None ) View Source class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None: raise ValueError ( \"Command code '%s' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"PolicyCommandCode"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_buffer_for_digest","text":"def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"get_buffer_for_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_code","text":"def get_code ( self ) View Source def get_code ( self ): return self . command_code_string","title":"get_code"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policyhasher","text":"class PolicyHasher ( hash_type ) View Source class PolicyHasher ( object ) : def __init__ ( self , hash_type ) : if hash_type not in [ 'sha256', 'sha384' ] : raise ValueError ( \"Invalid hash type '%s'!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 } [ hash_type ] def get_size ( self ) : return self . hash_size def hash ( self , data ) : hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest ()","title":"PolicyHasher"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return self . hash_size","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#hash","text":"def hash ( self , data ) View Source def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest ()","title":"hash"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policylocality","text":"class PolicyLocality ( localities ) View Source class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None: self . bitfield = self . calc_bitfield_from_list ( localities ) else: self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities: # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality '%d'!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality '%d' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else: for value in localities: bitfield |= 1 << value return bitfield def get_buffer_for_digest(self): # NOTE: We force big-endian to match the marshalling in the TPM. return struct.pack(\"> LB \", t2d . TPM_CC_PolicyLocality , self . bitfield )","title":"PolicyLocality"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#calc_bitfield_from_list","text":"def calc_bitfield_from_list ( self , localities ) View Source def calc_bitfield_from_list ( self , localities ): bitfield = 0 b00000000 # First , we need to validate all of the localities in the list . for value in localities : # If the value is in a bad range , we 're done here. if not (0 <= value < 5) and not (32 <= value < 256): raise ValueError(\"Invalid locality ' % d '!\" % value) # An \"upper\" locality must be individual. Cannot combine with 0-4. if (32 <= value < 256) and len(localities) > 1: raise ValueError(\"Cannot combine locality ' % d ' with others!\" % value) # If the list is empty... well, we' re done . if len ( localities ) == 0 : pass # Now , if we 're an \"upper\" locality, that' s a simple value . elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities . else : for value in localities : bitfield |= 1 << value return bitfield","title":"calc_bitfield_from_list"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_bitfield","text":"def get_bitfield ( self ) View Source def get_bitfield ( self ): return self . bitfield","title":"get_bitfield"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_buffer_for_digest_1","text":"def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield )","title":"get_buffer_for_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreeand","text":"class PolicyTreeAnd ( components ) View Source class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components: if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b' \\ x00' * hash_obj . get_size () for component in self . components: current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest","title":"PolicyTreeAnd"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): current_digest = b '\\x00' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type","text":"def get_type ( self ) View Source def get_type ( self ): return 'and'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate","text":"def validate ( self ) View Source def validate ( self ): return True","title":"validate"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreeor","text":"class PolicyTreeOr ( components ) View Source class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components: # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b' \\ x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b'' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"PolicyTreeOr"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_5","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_1","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_buffer","text":"def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b '\\x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer","title":"get_policy_buffer"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type_1","text":"def get_type ( self ) View Source def get_type ( self ): return 'or'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate_1","text":"def validate ( self ) View Source def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy . if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid . if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result","title":"validate"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreesolo","text":"class PolicyTreeSolo ( policy_obj ) This object should only be used to put a single policy claim under an OR View Source class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b' \\ x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"PolicyTreeSolo"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_6","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_2","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_buffer_1","text":"def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): return ( b '\\x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest ()","title":"get_policy_buffer"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type_2","text":"def get_type ( self ) View Source def get_type ( self ): return 'solo'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate_2","text":"def validate ( self ) View Source def validate ( self ): return True","title":"validate"},{"location":"edk2toollib/tpm/tpm2_simulator/","text":"Module edk2toollib.tpm.tpm2_simulator View Source # @file tpm2_simulator.py # This file contains transportation layer classes for interacting with the TPM 2.0 simulator. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import socket import struct import edk2toollib.tpm.tpm2_stream as t2s import edk2toollib.tpm.tpm2_defs as t2d PLAT_COMMANDS = { 'TPM_SIGNAL_POWER_ON' : 1 , 'TPM_SIGNAL_POWER_OFF' : 2 , 'TPM_SIGNAL_PHYS_PRES_ON' : 3 , 'TPM_SIGNAL_PHYS_PRES_OFF' : 4 , 'TPM_SIGNAL_HASH_START' : 5 , 'TPM_SIGNAL_HASH_DATA' : 6 , # {UINT32 BufferSize, BYTE[BufferSize] Buffer} 'TPM_SIGNAL_HASH_END' : 7 , 'TPM_SEND_COMMAND' : 8 , # {BYTE Locality, UINT32 InBufferSize, BYTE[InBufferSize] InBuffer} -> # {UINT32 OutBufferSize, BYTE[OutBufferSize] OutBuffer} 'TPM_SIGNAL_CANCEL_ON' : 9 , 'TPM_SIGNAL_CANCEL_OFF' : 10 , 'TPM_SIGNAL_NV_ON' : 11 , 'TPM_SIGNAL_NV_OFF' : 12 , 'TPM_SIGNAL_KEY_CACHE_ON' : 13 , 'TPM_SIGNAL_KEY_CACHE_OFF' : 14 , 'TPM_REMOTE_HANDSHAKE' : 15 , 'TPM_SET_ALTERNATIVE_RESULT' : 16 , 'TPM_SIGNAL_RESET' : 17 , 'TPM_SESSION_END' : 20 , 'TPM_STOP' : 21 , 'TPM_GET_COMMAND_RESPONSE_SIZES' : 25 , 'TPM_TEST_FAILURE_MODE' : 30 , } class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ) . __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ) . encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ) . encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ()) Variables PLAT_COMMANDS Classes TpmSimulator class TpmSimulator ( host = 'localhost' , port = 2321 ) View Source class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ). __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True: result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ()) Methods read_raw_data def read_raw_data ( self , count ) View Source def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data send_data def send_data ( self , data ) View Source def send_data ( self , data ): # Send the \"I'm about to send data\" command . self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data . self . send_raw_data ( struct . pack ( \">b\" , 0 x03 )) # Send the size of the data . self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now , send the data itself . self . send_raw_data ( data ) # Poll until a result is available . # NOTE : This shouldn ' t be necessary and denotes a lack of understanding ... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) send_raw_data def send_raw_data ( self , data ) View Source def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) startup def startup ( self , type ) View Source def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0 x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"Tpm2 simulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#module-edk2toollibtpmtpm2_simulator","text":"View Source # @file tpm2_simulator.py # This file contains transportation layer classes for interacting with the TPM 2.0 simulator. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import socket import struct import edk2toollib.tpm.tpm2_stream as t2s import edk2toollib.tpm.tpm2_defs as t2d PLAT_COMMANDS = { 'TPM_SIGNAL_POWER_ON' : 1 , 'TPM_SIGNAL_POWER_OFF' : 2 , 'TPM_SIGNAL_PHYS_PRES_ON' : 3 , 'TPM_SIGNAL_PHYS_PRES_OFF' : 4 , 'TPM_SIGNAL_HASH_START' : 5 , 'TPM_SIGNAL_HASH_DATA' : 6 , # {UINT32 BufferSize, BYTE[BufferSize] Buffer} 'TPM_SIGNAL_HASH_END' : 7 , 'TPM_SEND_COMMAND' : 8 , # {BYTE Locality, UINT32 InBufferSize, BYTE[InBufferSize] InBuffer} -> # {UINT32 OutBufferSize, BYTE[OutBufferSize] OutBuffer} 'TPM_SIGNAL_CANCEL_ON' : 9 , 'TPM_SIGNAL_CANCEL_OFF' : 10 , 'TPM_SIGNAL_NV_ON' : 11 , 'TPM_SIGNAL_NV_OFF' : 12 , 'TPM_SIGNAL_KEY_CACHE_ON' : 13 , 'TPM_SIGNAL_KEY_CACHE_OFF' : 14 , 'TPM_REMOTE_HANDSHAKE' : 15 , 'TPM_SET_ALTERNATIVE_RESULT' : 16 , 'TPM_SIGNAL_RESET' : 17 , 'TPM_SESSION_END' : 20 , 'TPM_STOP' : 21 , 'TPM_GET_COMMAND_RESPONSE_SIZES' : 25 , 'TPM_TEST_FAILURE_MODE' : 30 , } class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ) . __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ) . encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ) . encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"Module edk2toollib.tpm.tpm2_simulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#variables","text":"PLAT_COMMANDS","title":"Variables"},{"location":"edk2toollib/tpm/tpm2_simulator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_simulator/#tpmsimulator","text":"class TpmSimulator ( host = 'localhost' , port = 2321 ) View Source class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ). __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True: result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"TpmSimulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_simulator/#read_raw_data","text":"def read_raw_data ( self , count ) View Source def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data","title":"read_raw_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#send_data","text":"def send_data ( self , data ) View Source def send_data ( self , data ): # Send the \"I'm about to send data\" command . self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data . self . send_raw_data ( struct . pack ( \">b\" , 0 x03 )) # Send the size of the data . self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now , send the data itself . self . send_raw_data ( data ) # Poll until a result is available . # NOTE : This shouldn ' t be necessary and denotes a lack of understanding ... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size )","title":"send_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#send_raw_data","text":"def send_raw_data ( self , data ) View Source def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data )","title":"send_raw_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#startup","text":"def startup ( self , type ) View Source def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0 x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"startup"},{"location":"edk2toollib/tpm/tpm2_stream/","text":"Module edk2toollib.tpm.tpm2_stream View Source # @file tpm2_stream.py # This file contains utility classes to help marshal and un-marshal data to/from the TPM. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) class Tpm2StreamPrimitive ( Tpm2StreamElement ): def __init__ ( self , size , value ): super ( Tpm2StreamPrimitive , self ) . __init__ () if size not in ( 1 , 2 , 4 , 8 ): raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" }[ size ] self . value = value def marshal ( self ): return struct . pack ( self . pack_string , self . value ) class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ) . __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ) . __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ) . __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements ) Classes TPM2B class TPM2B ( data ) View Source class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ). __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) update_data def update_data ( self , data ) View Source def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size TPM2_COMMAND_HEADER class TPM2_COMMAND_HEADER ( tag , size , code ) View Source class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ). __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) update_size def update_size ( self , size ) View Source def update_size ( self , size ): self . size = size Tpm2CommandStream class Tpm2CommandStream ( tag , size , code ) View Source class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ). __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b'' . join ( element . marshal () for element in self . stream_elements ) Methods add_element def add_element ( self , element ) View Source def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) get_size def get_size ( self ) View Source def get_size ( self ): return self . stream_size get_stream def get_stream ( self ) View Source def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements ) Tpm2StreamElement class Tpm2StreamElement ( ) View Source class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) Descendants edk2toollib.tpm.tpm2_stream.Tpm2StreamPrimitive edk2toollib.tpm.tpm2_stream.TPM2_COMMAND_HEADER edk2toollib.tpm.tpm2_stream.TPM2B Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) Tpm2StreamPrimitive class Tpm2StreamPrimitive ( size , value ) View Source class Tpm2StreamPrimitive ( Tpm2StreamElement ) : def __init__ ( self , size , value ) : super ( Tpm2StreamPrimitive , self ). __init__ () if size not in ( 1 , 2 , 4 , 8 ) : raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" } [ size ] self . value = value def marshal ( self ) : return struct . pack ( self . pack_string , self . value ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . value )","title":"Tpm2 stream"},{"location":"edk2toollib/tpm/tpm2_stream/#module-edk2toollibtpmtpm2_stream","text":"View Source # @file tpm2_stream.py # This file contains utility classes to help marshal and un-marshal data to/from the TPM. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) class Tpm2StreamPrimitive ( Tpm2StreamElement ): def __init__ ( self , size , value ): super ( Tpm2StreamPrimitive , self ) . __init__ () if size not in ( 1 , 2 , 4 , 8 ): raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" }[ size ] self . value = value def marshal ( self ): return struct . pack ( self . pack_string , self . value ) class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ) . __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ) . __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ) . __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements )","title":"Module edk2toollib.tpm.tpm2_stream"},{"location":"edk2toollib/tpm/tpm2_stream/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2b","text":"class TPM2B ( data ) View Source class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ). __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data )","title":"TPM2B"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data )","title":"marshal"},{"location":"edk2toollib/tpm/tpm2_stream/#update_data","text":"def update_data ( self , data ) View Source def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size","title":"update_data"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2_command_header","text":"class TPM2_COMMAND_HEADER ( tag , size , code ) View Source class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ). __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code )","title":"TPM2_COMMAND_HEADER"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro_1","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_1","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal_1","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code )","title":"marshal"},{"location":"edk2toollib/tpm/tpm2_stream/#update_size","text":"def update_size ( self , size ) View Source def update_size ( self , size ): self . size = size","title":"update_size"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2commandstream","text":"class Tpm2CommandStream ( tag , size , code ) View Source class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ). __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b'' . join ( element . marshal () for element in self . stream_elements )","title":"Tpm2CommandStream"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#add_element","text":"def add_element ( self , element ) View Source def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size )","title":"add_element"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_2","text":"def get_size ( self ) View Source def get_size ( self ): return self . stream_size","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#get_stream","text":"def get_stream ( self ) View Source def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements )","title":"get_stream"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2streamelement","text":"class Tpm2StreamElement ( ) View Source class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"Tpm2StreamElement"},{"location":"edk2toollib/tpm/tpm2_stream/#descendants","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamPrimitive edk2toollib.tpm.tpm2_stream.TPM2_COMMAND_HEADER edk2toollib.tpm.tpm2_stream.TPM2B","title":"Descendants"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_3","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2streamprimitive","text":"class Tpm2StreamPrimitive ( size , value ) View Source class Tpm2StreamPrimitive ( Tpm2StreamElement ) : def __init__ ( self , size , value ) : super ( Tpm2StreamPrimitive , self ). __init__ () if size not in ( 1 , 2 , 4 , 8 ) : raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" } [ size ] self . value = value def marshal ( self ) : return struct . pack ( self . pack_string , self . value )","title":"Tpm2StreamPrimitive"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro_2","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_4","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal_2","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . value )","title":"marshal"},{"location":"edk2toollib/uefi/","text":"Module edk2toollib.uefi View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.authenticated_variables_structure_support edk2toollib.uefi.bmp_object edk2toollib.uefi.bmp_object_test edk2toollib.uefi.edk2 edk2toollib.uefi.fmp_auth_header edk2toollib.uefi.fmp_capsule_header edk2toollib.uefi.fmp_capsule_header_test edk2toollib.uefi.pi_firmware_file edk2toollib.uefi.pi_firmware_volume edk2toollib.uefi.status_codes edk2toollib.uefi.status_codes_test edk2toollib.uefi.uefi_capsule_header edk2toollib.uefi.uefi_multi_phase edk2toollib.uefi.wincert","title":"Index"},{"location":"edk2toollib/uefi/#module-edk2toollibuefi","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi"},{"location":"edk2toollib/uefi/#sub-modules","text":"edk2toollib.uefi.authenticated_variables_structure_support edk2toollib.uefi.bmp_object edk2toollib.uefi.bmp_object_test edk2toollib.uefi.edk2 edk2toollib.uefi.fmp_auth_header edk2toollib.uefi.fmp_capsule_header edk2toollib.uefi.fmp_capsule_header_test edk2toollib.uefi.pi_firmware_file edk2toollib.uefi.pi_firmware_volume edk2toollib.uefi.status_codes edk2toollib.uefi.status_codes_test edk2toollib.uefi.uefi_capsule_header edk2toollib.uefi.uefi_multi_phase edk2toollib.uefi.wincert","title":"Sub-modules"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/","text":"Module edk2toollib.uefi.authenticated_variables_structure_support View Source ## # UEFI Authenticated Variable Structure Support Library # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import datetime import struct import hashlib import uuid from edk2toollib.uefi.wincert import WinCert , WinCertUefiGuid from edk2toollib.utility_functions import PrintByteList # spell-checker: ignore decodefs, createfs ''' Structures definition based on UEFI specification (UEFI 2.7) Each object can be created and or populated from a file stream. Each object can be written to a filesteam as binary and printed to the console in text. ''' # UEFI global Variable Namespace EfiGlobalVarNamespaceUuid = uuid . UUID ( '8BE4DF61-93CA-11d2-AA0D-00E098032B8C' ) Sha256Oid = [ 0x60 , 0x86 , 0x48 , 0x01 , 0x65 , 0x03 , 0x04 , 0x02 , 0x01 ] # # EFI_SIGNATURE_DATA Structure for X509 Certs # class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize # # EFI_SIGNATURE_DATA Structure for Sha256 hash # class EfiSignatureDataEfiCertSha256 ( object ): STATIC_STRUCT_SIZE = 16 + hashlib . sha256 () . digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()) . digest ()) elif ( digest is not None ): self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 () . digest_size )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )): print ( \" %02X \" % sdl [ index ], end = '' ) print ( \"\" ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) class EfiSignatureDataFactory ( object ): EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid.UUID(\"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\") # EFI_CERT_RSA2048_SHA256_GUID = uuid.UUID(\"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\") # noqa: E501 # EFI_CERT_SHA1_GUID = uuid.UUID(\"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\") # EFI_CERT_RSA2048_SHA1_GUID = uuid.UUID(\"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\") # noqa: E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid.UUID(\"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\") # EFI_CERT_SHA384_GUID = uuid.UUID(\"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\") # EFI_CERT_SHA512_GUID = uuid.UUID(\"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\") EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid.UUID(\"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\") # noqa: E501 # EFI_CERT_X509_SHA512_GUID = uuid.UUID(\"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\") # noqa: E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid.UUID(\"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\") # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): raise Exception ( \"Invalid Size 0x %x \" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s \" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object. # Type will be baed on GUID # Value will be based on type and Content (content stream opened for reading) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ): if ( ContentFileStream is None ): raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) ## # EFI_SIGNATURE_LIST structure ## class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else : self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x %x \" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x %x \" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s \" % str ( self . SignatureType )) print ( \" Signature List Size: 0x %x \" % self . SignatureListSize ) print ( \" Signature Header Size: 0x %x \" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x %x \" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x %x \" % TimeZone ) logging . debug ( \"Daylight value is: 0x %X \" % Daylight ) def Print ( self ): print ( \"EfiTime: %s \" % datetime . datetime . strftime ( self . Time , \"%A, %B %d , %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n %s \" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) ''' THESE ARE NOT SUPPORTED IN THE TOOL typedef struct { /// /// The SHA256 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA256_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA256; typedef struct { /// /// The SHA384 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA384_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA384; typedef struct { /// /// The SHA512 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA512_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA512; ''' Variables EfiGlobalVarNamespaceUuid Sha256Oid Classes EFiVariableAuthentication2 class EFiVariableAuthentication2 ( Time = datetime . datetime ( 2020 , 5 , 29 , 14 , 56 , 40 , 284631 ), decodefs = None ) View Source class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try: self . SigListPayload = EfiSignatureList ( fs ) except Exception as e: logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) Print def Print ( self ) View Source def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) SetPayload def SetPayload ( self , fs ) View Source def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) EfiSignatureDataEfiCertSha256 class EfiSignatureDataEfiCertSha256 ( decodefs = None , createfs = None , digest = None , sigowner = None ) View Source class EfiSignatureDataEfiCertSha256 ( object ) : STATIC_STRUCT_SIZE = 16 + hashlib . sha256 (). digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ) : if ( decodefs is not None ) : self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ) : # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()). digest ()) elif ( digest is not None ) : self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) def Write ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ) : raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ) : return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE Class variables STATIC_STRUCT_SIZE Methods GetTotalSize def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) Print def Print ( self ) View Source def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) EfiSignatureDataEfiCertX509 class EfiSignatureDataEfiCertX509 ( decodefs = None , decodesize = 0 , createfs = None , sigowner = None ) View Source class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else: raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else: sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize Class variables STATIC_STRUCT_SIZE Methods GetTotalSize def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize PopulateFromFileStream def PopulateFromFileStream ( self , fs , decodesize ) View Source def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) EfiSignatureDataFactory class EfiSignatureDataFactory ( / , * args , ** kwargs ) View Source class EfiSignatureDataFactory ( object ) : EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid . UUID ( \"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\" ) # EFI_CERT_RSA2048_SHA256_GUID = uuid . UUID ( \"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\" ) # noqa : E501 # EFI_CERT_SHA1_GUID = uuid . UUID ( \"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\" ) # EFI_CERT_RSA2048_SHA1_GUID = uuid . UUID ( \"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\" ) # noqa : E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid . UUID ( \"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\" ) # EFI_CERT_SHA384_GUID = uuid . UUID ( \"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\" ) # EFI_CERT_SHA512_GUID = uuid . UUID ( \"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\" ) EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid . UUID ( \"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\" ) # noqa : E501 # EFI_CERT_X509_SHA512_GUID = uuid . UUID ( \"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\" ) # noqa : E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( \"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\" ) # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object . # Type will be baed on GUID # Value will be based on type and Content ( content stream opened for reading ) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) Class variables EFI_CERT_SHA256_GUID EFI_CERT_X509_GUID EFI_CERT_X509_SHA256_GUID Static methods Create def Create ( type , ContentFileStream , sigowner ) View Source @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) Factory def Factory ( fs , type , size ) View Source @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None EfiSignatureHeader class EfiSignatureHeader ( ) View Source class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) EfiSignatureList class EfiSignatureList ( filestream = None , typeguid = None ) View Source class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else: self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else: print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List: a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List: a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else: self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize Class variables STATIC_STRUCT_SIZE Methods AddSignatureData def AddSignatureData ( self , SigDataObject ) View Source def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize AddSignatureHeader def AddSignatureHeader ( self , SigHeader , SigSize = 0 ) View Source def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing ( size 0 ) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly . if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) EfiTime class EfiTime ( Time = datetime . datetime ( 2020 , 5 , 29 , 14 , 56 , 40 , 284631 ), decodefs = None ) View Source class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 Class variables STATIC_STRUCT_SIZE Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"Authenticated variables structure support"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#module-edk2toollibuefiauthenticated_variables_structure_support","text":"View Source ## # UEFI Authenticated Variable Structure Support Library # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import datetime import struct import hashlib import uuid from edk2toollib.uefi.wincert import WinCert , WinCertUefiGuid from edk2toollib.utility_functions import PrintByteList # spell-checker: ignore decodefs, createfs ''' Structures definition based on UEFI specification (UEFI 2.7) Each object can be created and or populated from a file stream. Each object can be written to a filesteam as binary and printed to the console in text. ''' # UEFI global Variable Namespace EfiGlobalVarNamespaceUuid = uuid . UUID ( '8BE4DF61-93CA-11d2-AA0D-00E098032B8C' ) Sha256Oid = [ 0x60 , 0x86 , 0x48 , 0x01 , 0x65 , 0x03 , 0x04 , 0x02 , 0x01 ] # # EFI_SIGNATURE_DATA Structure for X509 Certs # class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize # # EFI_SIGNATURE_DATA Structure for Sha256 hash # class EfiSignatureDataEfiCertSha256 ( object ): STATIC_STRUCT_SIZE = 16 + hashlib . sha256 () . digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()) . digest ()) elif ( digest is not None ): self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 () . digest_size )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )): print ( \" %02X \" % sdl [ index ], end = '' ) print ( \"\" ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) class EfiSignatureDataFactory ( object ): EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid.UUID(\"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\") # EFI_CERT_RSA2048_SHA256_GUID = uuid.UUID(\"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\") # noqa: E501 # EFI_CERT_SHA1_GUID = uuid.UUID(\"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\") # EFI_CERT_RSA2048_SHA1_GUID = uuid.UUID(\"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\") # noqa: E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid.UUID(\"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\") # EFI_CERT_SHA384_GUID = uuid.UUID(\"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\") # EFI_CERT_SHA512_GUID = uuid.UUID(\"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\") EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid.UUID(\"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\") # noqa: E501 # EFI_CERT_X509_SHA512_GUID = uuid.UUID(\"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\") # noqa: E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid.UUID(\"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\") # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): raise Exception ( \"Invalid Size 0x %x \" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s \" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object. # Type will be baed on GUID # Value will be based on type and Content (content stream opened for reading) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ): if ( ContentFileStream is None ): raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) ## # EFI_SIGNATURE_LIST structure ## class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else : self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x %x \" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x %x \" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s \" % str ( self . SignatureType )) print ( \" Signature List Size: 0x %x \" % self . SignatureListSize ) print ( \" Signature Header Size: 0x %x \" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x %x \" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x %x \" % TimeZone ) logging . debug ( \"Daylight value is: 0x %X \" % Daylight ) def Print ( self ): print ( \"EfiTime: %s \" % datetime . datetime . strftime ( self . Time , \"%A, %B %d , %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n %s \" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) ''' THESE ARE NOT SUPPORTED IN THE TOOL typedef struct { /// /// The SHA256 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA256_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA256; typedef struct { /// /// The SHA384 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA384_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA384; typedef struct { /// /// The SHA512 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA512_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA512; '''","title":"Module edk2toollib.uefi.authenticated_variables_structure_support"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#variables","text":"EfiGlobalVarNamespaceUuid Sha256Oid","title":"Variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efivariableauthentication2","text":"class EFiVariableAuthentication2 ( Time = datetime . datetime ( 2020 , 5 , 29 , 14 , 56 , 40 , 284631 ), decodefs = None ) View Source class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try: self . SigListPayload = EfiSignatureList ( fs ) except Exception as e: logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize ))","title":"EFiVariableAuthentication2"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print","text":"def Print ( self ) View Source def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#setpayload","text":"def SetPayload ( self , fs ) View Source def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize ))","title":"SetPayload"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedataeficertsha256","text":"class EfiSignatureDataEfiCertSha256 ( decodefs = None , createfs = None , digest = None , sigowner = None ) View Source class EfiSignatureDataEfiCertSha256 ( object ) : STATIC_STRUCT_SIZE = 16 + hashlib . sha256 (). digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ) : if ( decodefs is not None ) : self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ) : # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()). digest ()) elif ( digest is not None ) : self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) def Write ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ) : raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ) : return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE","title":"EfiSignatureDataEfiCertSha256"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#gettotalsize","text":"def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE","title":"GetTotalSize"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_1","text":"def Print ( self ) View Source def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedataeficertx509","text":"class EfiSignatureDataEfiCertX509 ( decodefs = None , decodesize = 0 , createfs = None , sigowner = None ) View Source class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else: raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else: sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize","title":"EfiSignatureDataEfiCertX509"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_1","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#gettotalsize_1","text":"def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize","title":"GetTotalSize"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_2","text":"def PopulateFromFileStream ( self , fs , decodesize ) View Source def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_2","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_2","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedatafactory","text":"class EfiSignatureDataFactory ( / , * args , ** kwargs ) View Source class EfiSignatureDataFactory ( object ) : EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid . UUID ( \"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\" ) # EFI_CERT_RSA2048_SHA256_GUID = uuid . UUID ( \"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\" ) # noqa : E501 # EFI_CERT_SHA1_GUID = uuid . UUID ( \"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\" ) # EFI_CERT_RSA2048_SHA1_GUID = uuid . UUID ( \"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\" ) # noqa : E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid . UUID ( \"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\" ) # EFI_CERT_SHA384_GUID = uuid . UUID ( \"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\" ) # EFI_CERT_SHA512_GUID = uuid . UUID ( \"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\" ) EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid . UUID ( \"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\" ) # noqa : E501 # EFI_CERT_X509_SHA512_GUID = uuid . UUID ( \"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\" ) # noqa : E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( \"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\" ) # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object . # Type will be baed on GUID # Value will be based on type and Content ( content stream opened for reading ) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" )","title":"EfiSignatureDataFactory"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_2","text":"EFI_CERT_SHA256_GUID EFI_CERT_X509_GUID EFI_CERT_X509_SHA256_GUID","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#create","text":"def Create ( type , ContentFileStream , sigowner ) View Source @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" )","title":"Create"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#factory","text":"def Factory ( fs , type , size ) View Source @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None","title":"Factory"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignatureheader","text":"class EfiSignatureHeader ( ) View Source class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" )","title":"EfiSignatureHeader"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturelist","text":"class EfiSignatureList ( filestream = None , typeguid = None ) View Source class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else: self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else: print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List: a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List: a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else: self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize","title":"EfiSignatureList"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_3","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#addsignaturedata","text":"def AddSignatureData ( self , SigDataObject ) View Source def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize","title":"AddSignatureData"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#addsignatureheader","text":"def AddSignatureHeader ( self , SigHeader , SigSize = 0 ) View Source def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize","title":"AddSignatureHeader"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_3","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing ( size 0 ) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly . if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_3","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print ()","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_3","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efitime","text":"class EfiTime ( Time = datetime . datetime ( 2020 , 5 , 29 , 14 , 56 , 40 , 284631 ), decodefs = None ) View Source class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"EfiTime"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_4","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_4","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_4","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" ))","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_4","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"Write"},{"location":"edk2toollib/uefi/bmp_object/","text":"Module edk2toollib.uefi.bmp_object View Source # @file # Helper lib to read and parse bitmap graphics files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import struct class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None : self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else : self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x %X \" % self . Blue ) logger . info ( \" Green: 0x %X \" % self . Green ) logger . info ( \" Red: 0x %X \" % self . Red ) logger . info ( \" Reserved: 0x %X \" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) class BmpObject ( object ): STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB; < -- Start of FileHeader # CHAR8 CharM; # UINT32 Size; # UINT16 Reserved[2]; # UINT32 ImageOffset; <-- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize; < -- Start of BmpHeader # UINT32 PixelWidth; # UINT32 PixelHeight; # UINT16 Planes; ///< Must be 1 # UINT16 BitPerPixel; ///< 1, 4, 8, or 24 # UINT32 CompressionType; # UINT32 ImageSize; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter; # UINT32 YPixelsPerMeter; # UINT32 NumberOfColors; # UINT32 ImportantColors; # } BMP_IMAGE_HEADER; def __init__ ( self , filestream = None ): self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x %X ( %d )\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x %X Less Than 0x %X \" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d \" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d \" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x %X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ): self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s \" % self . CharB ) self . logger . info ( \" CharM: %s \" % self . CharM ) self . logger . info ( \" Size: 0x %X ( %d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x %X \" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x %X \" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x %X ( %d )\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x %X \" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x %X ( %d )\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x %X ( %d )\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x %X \" % self . Planes ) self . logger . info ( \" BitPerPixel: %d \" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x %X \" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x %X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d \" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d \" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d \" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d \" % self . ImportantColors ) # print color maps if ( PrintColorMapData ): for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ): self . logger . info ( \" BMP Padding (0x %X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ): self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData ) Classes BmpColorMap class BmpColorMap ( filestream = None ) View Source class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None: self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else: self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None: raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE: # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) Class variables STATIC_SIZE Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] Print def Print ( self ) View Source def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) BmpObject class BmpObject ( filestream = None ) View Source class BmpObject ( object ) : STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB ; < -- Start of FileHeader # CHAR8 CharM ; # UINT32 Size ; # UINT16 Reserved [ 2 ] ; # UINT32 ImageOffset ; < -- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize ; < -- Start of BmpHeader # UINT32 PixelWidth ; # UINT32 PixelHeight ; # UINT16 Planes ; ///< Must be 1 # UINT16 BitPerPixel ; ///< 1 , 4 , 8 , or 24 # UINT32 CompressionType ; # UINT32 ImageSize ; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter ; # UINT32 YPixelsPerMeter ; # UINT32 NumberOfColors ; # UINT32 ImportantColors ; # } BMP_IMAGE_HEADER ; def __init__ ( self , filestream = None ) : self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ) : if ( self . BitPerPixel == 1 ) : return 2 elif ( self . BitPerPixel == 4 ) : return 16 elif ( self . BitPerPixel == 8 ) : return 256 else : return 0 # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ) : # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ) : raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if ( self . Size < self . HeaderSize ) : raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )) : raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ) : # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ) : ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ) : self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )) : raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ) : self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ) : raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ) : # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ) : fs . write ( self . Padding ) # Pixel data if ( self . ImageData ) : fs . write ( self . ImageData ) Class variables STATIC_FILE_HEADER_SIZE STATIC_IMAGE_HEADER_SIZE Methods ExpectedColorMapEntires def ExpectedColorMapEntires ( self ) View Source def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) Print def Print ( self , PrintImageData = False , PrintColorMapData = False ) View Source def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) Write def Write ( self , fs ) View Source def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Bmp object"},{"location":"edk2toollib/uefi/bmp_object/#module-edk2toollibuefibmp_object","text":"View Source # @file # Helper lib to read and parse bitmap graphics files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import struct class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None : self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else : self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x %X \" % self . Blue ) logger . info ( \" Green: 0x %X \" % self . Green ) logger . info ( \" Red: 0x %X \" % self . Red ) logger . info ( \" Reserved: 0x %X \" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) class BmpObject ( object ): STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB; < -- Start of FileHeader # CHAR8 CharM; # UINT32 Size; # UINT16 Reserved[2]; # UINT32 ImageOffset; <-- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize; < -- Start of BmpHeader # UINT32 PixelWidth; # UINT32 PixelHeight; # UINT16 Planes; ///< Must be 1 # UINT16 BitPerPixel; ///< 1, 4, 8, or 24 # UINT32 CompressionType; # UINT32 ImageSize; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter; # UINT32 YPixelsPerMeter; # UINT32 NumberOfColors; # UINT32 ImportantColors; # } BMP_IMAGE_HEADER; def __init__ ( self , filestream = None ): self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x %X ( %d )\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x %X Less Than 0x %X \" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d \" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d \" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x %X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ): self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s \" % self . CharB ) self . logger . info ( \" CharM: %s \" % self . CharM ) self . logger . info ( \" Size: 0x %X ( %d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x %X \" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x %X \" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x %X ( %d )\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x %X \" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x %X ( %d )\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x %X ( %d )\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x %X \" % self . Planes ) self . logger . info ( \" BitPerPixel: %d \" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x %X \" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x %X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d \" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d \" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d \" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d \" % self . ImportantColors ) # print color maps if ( PrintColorMapData ): for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ): self . logger . info ( \" BMP Padding (0x %X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ): self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Module edk2toollib.uefi.bmp_object"},{"location":"edk2toollib/uefi/bmp_object/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/bmp_object/#bmpcolormap","text":"class BmpColorMap ( filestream = None ) View Source class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None: self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else: self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None: raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE: # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved ))","title":"BmpColorMap"},{"location":"edk2toollib/uefi/bmp_object/#class-variables","text":"STATIC_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/bmp_object/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/bmp_object/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ]","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/bmp_object/#print","text":"def Print ( self ) View Source def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved )","title":"Print"},{"location":"edk2toollib/uefi/bmp_object/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved ))","title":"Write"},{"location":"edk2toollib/uefi/bmp_object/#bmpobject","text":"class BmpObject ( filestream = None ) View Source class BmpObject ( object ) : STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB ; < -- Start of FileHeader # CHAR8 CharM ; # UINT32 Size ; # UINT16 Reserved [ 2 ] ; # UINT32 ImageOffset ; < -- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize ; < -- Start of BmpHeader # UINT32 PixelWidth ; # UINT32 PixelHeight ; # UINT16 Planes ; ///< Must be 1 # UINT16 BitPerPixel ; ///< 1 , 4 , 8 , or 24 # UINT32 CompressionType ; # UINT32 ImageSize ; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter ; # UINT32 YPixelsPerMeter ; # UINT32 NumberOfColors ; # UINT32 ImportantColors ; # } BMP_IMAGE_HEADER ; def __init__ ( self , filestream = None ) : self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ) : if ( self . BitPerPixel == 1 ) : return 2 elif ( self . BitPerPixel == 4 ) : return 16 elif ( self . BitPerPixel == 8 ) : return 256 else : return 0 # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ) : # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ) : raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if ( self . Size < self . HeaderSize ) : raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )) : raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ) : # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ) : ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ) : self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )) : raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ) : self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ) : raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ) : # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ) : fs . write ( self . Padding ) # Pixel data if ( self . ImageData ) : fs . write ( self . ImageData )","title":"BmpObject"},{"location":"edk2toollib/uefi/bmp_object/#class-variables_1","text":"STATIC_FILE_HEADER_SIZE STATIC_IMAGE_HEADER_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/bmp_object/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/bmp_object/#expectedcolormapentires","text":"def ExpectedColorMapEntires ( self ) View Source def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0","title":"ExpectedColorMapEntires"},{"location":"edk2toollib/uefi/bmp_object/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ()))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/bmp_object/#print_1","text":"def Print ( self , PrintImageData = False , PrintColorMapData = False ) View Source def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" )","title":"Print"},{"location":"edk2toollib/uefi/bmp_object/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Write"},{"location":"edk2toollib/uefi/fmp_auth_header/","text":"Module edk2toollib.uefi.fmp_auth_header FmpAuthHeader View Source ## @file # Module that encodes and decodes a EFI_FIRMWARE_IMAGE_AUTHENTICATION with # certificate data and payload data. # # Copyright (c) 2018 - 2019, Intel Corporation. All rights reserved.<BR> # Copyright (c) Microsoft Corporation # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpAuthHeader ''' import struct from edk2toollib.uefi.wincert import WinCertUefiGuid from edk2toollib.uefi.edk2.fmp_payload_header import FmpPayloadHeaderClass class FmpAuthHeaderClass ( object ): # /// # /// Image Attribute -Authentication Required # /// # typedef struct { # /// # /// It is included in the signature of AuthInfo. It is used to ensure freshness/no replay. # /// It is incremented during each firmware image operation. # /// # UINT64 MonotonicCount; # /// # /// Provides the authorization for the firmware image operations. It is a signature across # /// the image data and the Monotonic Count value. Caller uses the private key that is # /// associated with a public key that has been provisioned via the key exchange. # /// Because this is defined as a signature, WIN_CERTIFICATE_UEFI_GUID.CertType must # /// be EFI_CERT_TYPE_PKCS7_GUID. # /// # WIN_CERTIFICATE_UEFI_GUID AuthInfo; # } EFI_FIRMWARE_IMAGE_AUTHENTICATION; _MonotonicCountFormat = '<Q' _MonotonicCountSize = struct . calcsize ( _MonotonicCountFormat ) def __init__ ( self ): self . MonotonicCount = 0 self . AuthInfo = WinCertUefiGuid () self . Payload = b '' self . FmpPayloadHeader = None def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None : return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else : return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize :]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize :]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : return False return True def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None : self . FmpPayloadHeader . DumpInfo () Classes FmpAuthHeaderClass class FmpAuthHeaderClass ( ) View Source class FmpAuthHeaderClass ( object ): # /// # /// Image Attribute -Authentication Required # /// # typedef struct { # /// # /// It is included in the signature of AuthInfo. It is used to ensure freshness/no replay. # /// It is incremented during each firmware image operation. # /// # UINT64 MonotonicCount; # /// # /// Provides the authorization for the firmware image operations. It is a signature across # /// the image data and the Monotonic Count value. Caller uses the private key that is # /// associated with a public key that has been provisioned via the key exchange. # /// Because this is defined as a signature, WIN_CERTIFICATE_UEFI_GUID.CertType must # /// be EFI_CERT_TYPE_PKCS7_GUID. # /// # WIN_CERTIFICATE_UEFI_GUID AuthInfo; # } EFI_FIRMWARE_IMAGE_AUTHENTICATION; _MonotonicCountFormat = '<Q' _MonotonicCountSize = struct . calcsize ( _MonotonicCountFormat ) def __init__ ( self ): self . MonotonicCount = 0 self . AuthInfo = WinCertUefiGuid () self . Payload = b'' self . FmpPayloadHeader = None def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None: return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else: return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize: raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize: ]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize: return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize: ]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le: return False return True def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None: self . FmpPayloadHeader . DumpInfo () Methods Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize :]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None : self . FmpPayloadHeader . DumpInfo () Encode def Encode ( self ) View Source def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None : return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else : return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload IsSigned def IsSigned ( self , Buffer ) View Source def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize :]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : return False return True","title":"Fmp auth header"},{"location":"edk2toollib/uefi/fmp_auth_header/#module-edk2toollibuefifmp_auth_header","text":"FmpAuthHeader View Source ## @file # Module that encodes and decodes a EFI_FIRMWARE_IMAGE_AUTHENTICATION with # certificate data and payload data. # # Copyright (c) 2018 - 2019, Intel Corporation. All rights reserved.<BR> # Copyright (c) Microsoft Corporation # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpAuthHeader ''' import struct from edk2toollib.uefi.wincert import WinCertUefiGuid from edk2toollib.uefi.edk2.fmp_payload_header import FmpPayloadHeaderClass class FmpAuthHeaderClass ( object ): # /// # /// Image Attribute -Authentication Required # /// # typedef struct { # /// # /// It is included in the signature of AuthInfo. It is used to ensure freshness/no replay. # /// It is incremented during each firmware image operation. # /// # UINT64 MonotonicCount; # /// # /// Provides the authorization for the firmware image operations. It is a signature across # /// the image data and the Monotonic Count value. Caller uses the private key that is # /// associated with a public key that has been provisioned via the key exchange. # /// Because this is defined as a signature, WIN_CERTIFICATE_UEFI_GUID.CertType must # /// be EFI_CERT_TYPE_PKCS7_GUID. # /// # WIN_CERTIFICATE_UEFI_GUID AuthInfo; # } EFI_FIRMWARE_IMAGE_AUTHENTICATION; _MonotonicCountFormat = '<Q' _MonotonicCountSize = struct . calcsize ( _MonotonicCountFormat ) def __init__ ( self ): self . MonotonicCount = 0 self . AuthInfo = WinCertUefiGuid () self . Payload = b '' self . FmpPayloadHeader = None def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None : return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else : return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize :]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize :]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : return False return True def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None : self . FmpPayloadHeader . DumpInfo ()","title":"Module edk2toollib.uefi.fmp_auth_header"},{"location":"edk2toollib/uefi/fmp_auth_header/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/fmp_auth_header/#fmpauthheaderclass","text":"class FmpAuthHeaderClass ( ) View Source class FmpAuthHeaderClass ( object ): # /// # /// Image Attribute -Authentication Required # /// # typedef struct { # /// # /// It is included in the signature of AuthInfo. It is used to ensure freshness/no replay. # /// It is incremented during each firmware image operation. # /// # UINT64 MonotonicCount; # /// # /// Provides the authorization for the firmware image operations. It is a signature across # /// the image data and the Monotonic Count value. Caller uses the private key that is # /// associated with a public key that has been provisioned via the key exchange. # /// Because this is defined as a signature, WIN_CERTIFICATE_UEFI_GUID.CertType must # /// be EFI_CERT_TYPE_PKCS7_GUID. # /// # WIN_CERTIFICATE_UEFI_GUID AuthInfo; # } EFI_FIRMWARE_IMAGE_AUTHENTICATION; _MonotonicCountFormat = '<Q' _MonotonicCountSize = struct . calcsize ( _MonotonicCountFormat ) def __init__ ( self ): self . MonotonicCount = 0 self . AuthInfo = WinCertUefiGuid () self . Payload = b'' self . FmpPayloadHeader = None def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None: return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else: return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize: raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize: ]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize: return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize: ]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le: return False return True def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None: self . FmpPayloadHeader . DumpInfo ()","title":"FmpAuthHeaderClass"},{"location":"edk2toollib/uefi/fmp_auth_header/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/fmp_auth_header/#decode","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : raise ValueError ( MonotonicCount ,) = struct . unpack ( self . _MonotonicCountFormat , Buffer [: self . _MonotonicCountSize ] ) self . MonotonicCount = MonotonicCount self . Payload = self . AuthInfo . Decode ( Buffer [ self . _MonotonicCountSize :]) if len ( self . Payload ) > 0 : self . FmpPayloadHeader = FmpPayloadHeaderClass () self . FmpPayloadHeader . Decode ( self . Payload ) return self . Payload","title":"Decode"},{"location":"edk2toollib/uefi/fmp_auth_header/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_IMAGE_AUTHENTICATION.MonotonicCount = {MonotonicCount:016X}' . format ( MonotonicCount = self . MonotonicCount )) self . AuthInfo . DumpInfo () print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpPayloadHeader is not None : self . FmpPayloadHeader . DumpInfo ()","title":"DumpInfo"},{"location":"edk2toollib/uefi/fmp_auth_header/#encode","text":"def Encode ( self ) View Source def Encode ( self ): FmpAuthHeader = struct . pack ( self . _MonotonicCountFormat , self . MonotonicCount ) if self . FmpPayloadHeader is not None : return FmpAuthHeader + self . AuthInfo . Encode () + self . FmpPayloadHeader . Encode () else : return FmpAuthHeader + self . AuthInfo . Encode () + self . Payload","title":"Encode"},{"location":"edk2toollib/uefi/fmp_auth_header/#issigned","text":"def IsSigned ( self , Buffer ) View Source def IsSigned ( self , Buffer ): if len ( Buffer ) < self . _MonotonicCountSize : return False auth_info = WinCertUefiGuid ( Buffer [ self . _MonotonicCountSize :]) if auth_info . CertType != WinCertUefiGuid . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : return False return True","title":"IsSigned"},{"location":"edk2toollib/uefi/fmp_capsule_header/","text":"Module edk2toollib.uefi.fmp_capsule_header FmpCapsuleHeader View Source ## @file # Module that encodes and decodes a EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER with # a payload. # # Copyright (c) 2018 - 2019, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpCapsuleHeader ''' import struct import uuid from edk2toollib.uefi.fmp_auth_header import FmpAuthHeaderClass class FmpCapsuleImageHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// Used to identify device firmware targeted by this update. This guid is matched by # /// system firmware against ImageTypeId field within a EFI_FIRMWARE_IMAGE_DESCRIPTOR # /// # EFI_GUID UpdateImageTypeId; # # /// # /// Passed as ImageIndex in call to EFI_FIRMWARE_MANAGEMENT_PROTOCOL.SetImage () # /// # UINT8 UpdateImageIndex; # UINT8 reserved_bytes[3]; # # /// # /// Size of the binary update image which immediately follows this structure # /// # UINT32 UpdateImageSize; # # /// # /// Size of the VendorCode bytes which optionally immediately follow binary update image in the capsule # /// # UINT32 UpdateVendorCodeSize; # # /// # /// The HardwareInstance to target with this update. If value is zero it means match all # /// HardwareInstances. This field allows update software to target only a single device in # /// cases where there are more than one device with the same ImageTypeId GUID. # /// This header is outside the signed data of the Authentication Info structure and # /// therefore can be modified without changing the Auth data. # /// # UINT64 UpdateHardwareInstance; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION 0x00000002 _StructFormat = '<I16sB3BIIQ' # spell-checker: disable-line _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION = 0x00000002 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION self . UpdateImageTypeId = uuid . UUID ( '00000000-0000-0000-0000-000000000000' ) self . UpdateImageIndex = 0 self . UpdateImageSize = 0 self . UpdateVendorCodeSize = 0 self . UpdateHardwareInstance = 0x0000000000000000 self . Payload = b '' self . VendorCodeBytes = b '' self . FmpAuthHeader = None def Encode ( self ): # If we have an FmpAuthHeader, let's collapse that now. if self . FmpAuthHeader is not None : self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION : raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize :]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize : self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize :] return Buffer [ self . _StructSize :] def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ) . upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None : self . FmpAuthHeader . DumpInfo () class FmpCapsuleHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// The number of drivers included in the capsule and the number of corresponding # /// offsets stored in ItemOffsetList array. # /// # UINT16 EmbeddedDriverCount; # # /// # /// The number of payload items included in the capsule and the number of # /// corresponding offsets stored in the ItemOffsetList array. # /// # UINT16 PayloadItemCount; # # /// # /// Variable length array of dimension [EmbeddedDriverCount + PayloadItemCount] # /// containing offsets of each of the drivers and payload items contained within the capsule # /// # // UINT64 ItemOffsetList[]; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION 0x00000001 _StructFormat = '<IHH' _StructSize = struct . calcsize ( _StructFormat ) _ItemOffsetFormat = '<Q' _ItemOffsetSize = struct . calcsize ( _ItemOffsetFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION = 0x00000001 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION self . EmbeddedDriverCount = 0 self . PayloadItemCount = 0 self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] def AddEmbeddedDriver ( self , EmbeddedDriver ): self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1 def GetEmbeddedDriver ( self , Index ): return self . _EmbeddedDriverList [ Index ] def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ): self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1 def GetFmpCapsuleImageHeader ( self , Index ): return self . _FmpCapsuleImageHeaderList [ Index ] def Encode ( self ): self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ): ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset : Offset + self . _ItemOffsetSize ])[ 0 ] if ItemOffset >= len ( Buffer ): raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset :] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ): Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ): Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset : Offset + Length ]) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ): Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ): Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset : Offset + Length ]) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo () Classes FmpCapsuleHeaderClass class FmpCapsuleHeaderClass ( ) View Source class FmpCapsuleHeaderClass ( object ) : # typedef struct { # UINT32 Version ; # # /// # /// The number of drivers included in the capsule and the number of corresponding # /// offsets stored in ItemOffsetList array . # /// # UINT16 EmbeddedDriverCount ; # # /// # /// The number of payload items included in the capsule and the number of # /// corresponding offsets stored in the ItemOffsetList array . # /// # UINT16 PayloadItemCount ; # # /// # /// Variable length array of dimension [ EmbeddedDriverCount + PayloadItemCount ] # /// containing offsets of each of the drivers and payload items contained within the capsule # /// # // UINT64 ItemOffsetList [] ; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER ; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION 0x00000001 _StructFormat = '<IHH' _StructSize = struct . calcsize ( _StructFormat ) _ItemOffsetFormat = '<Q' _ItemOffsetSize = struct . calcsize ( _ItemOffsetFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION = 0x00000001 def __init__ ( self ) : self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION self . EmbeddedDriverCount = 0 self . PayloadItemCount = 0 self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] def AddEmbeddedDriver ( self , EmbeddedDriver ) : self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1 def GetEmbeddedDriver ( self , Index ) : return self . _EmbeddedDriverList [ Index ] def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ) : self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1 def GetFmpCapsuleImageHeader ( self , Index ) : return self . _FmpCapsuleImageHeaderList [ Index ] def Encode ( self ) : self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ) : ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset:Offset + self._ItemOffsetSize ] ) [ 0 ] if ItemOffset >= len ( Buffer ) : raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset: ] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset:Offset + Length ] ) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset:Offset + Length ] ) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result def DumpInfo ( self ) : print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo () Class variables EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION Methods AddEmbeddedDriver def AddEmbeddedDriver ( self , EmbeddedDriver ) View Source def AddEmbeddedDriver ( self , EmbeddedDriver ): self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1 AddFmpCapsuleImageHeader def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ) View Source def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ): self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1 Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ) : ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset:Offset + self._ItemOffsetSize ] ) [ 0 ] if ItemOffset >= len ( Buffer ) : raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset: ] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset:Offset + Length ] ) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset:Offset + Length ] ) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo () Encode def Encode ( self ) View Source def Encode ( self ): self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData GetEmbeddedDriver def GetEmbeddedDriver ( self , Index ) View Source def GetEmbeddedDriver ( self , Index ) : return self . _EmbeddedDriverList [ Index ] GetFmpCapsuleImageHeader def GetFmpCapsuleImageHeader ( self , Index ) View Source def GetFmpCapsuleImageHeader ( self , Index ) : return self . _FmpCapsuleImageHeaderList [ Index ] FmpCapsuleImageHeaderClass class FmpCapsuleImageHeaderClass ( ) View Source class FmpCapsuleImageHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// Used to identify device firmware targeted by this update. This guid is matched by # /// system firmware against ImageTypeId field within a EFI_FIRMWARE_IMAGE_DESCRIPTOR # /// # EFI_GUID UpdateImageTypeId; # # /// # /// Passed as ImageIndex in call to EFI_FIRMWARE_MANAGEMENT_PROTOCOL.SetImage () # /// # UINT8 UpdateImageIndex; # UINT8 reserved_bytes[3]; # # /// # /// Size of the binary update image which immediately follows this structure # /// # UINT32 UpdateImageSize; # # /// # /// Size of the VendorCode bytes which optionally immediately follow binary update image in the capsule # /// # UINT32 UpdateVendorCodeSize; # # /// # /// The HardwareInstance to target with this update. If value is zero it means match all # /// HardwareInstances. This field allows update software to target only a single device in # /// cases where there are more than one device with the same ImageTypeId GUID. # /// This header is outside the signed data of the Authentication Info structure and # /// therefore can be modified without changing the Auth data. # /// # UINT64 UpdateHardwareInstance; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION 0x00000002 _StructFormat = '<I16sB3BIIQ' # spell-checker: disable-line _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION = 0x00000002 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION self . UpdateImageTypeId = uuid . UUID ( '00000000-0000-0000-0000-000000000000' ) self . UpdateImageIndex = 0 self . UpdateImageSize = 0 self . UpdateVendorCodeSize = 0 self . UpdateHardwareInstance = 0x0000000000000000 self . Payload = b'' self . VendorCodeBytes = b'' self . FmpAuthHeader = None def Encode ( self ): # If we have an FmpAuthHeader, let's collapse that now. if self . FmpAuthHeader is not None: self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION: raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize: ]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize:self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize: ] return Buffer [ self . _StructSize: ] def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ). upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None: self . FmpAuthHeader . DumpInfo () Class variables EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION Methods Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION : raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize :]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize : self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize :] return Buffer [ self . _StructSize :] DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ). upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None : self . FmpAuthHeader . DumpInfo () Encode def Encode ( self ) View Source def Encode ( self ): # If we have an FmpAuthHeader , let ' s collapse that now . if self . FmpAuthHeader is not None : self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes","title":"Fmp capsule header"},{"location":"edk2toollib/uefi/fmp_capsule_header/#module-edk2toollibuefifmp_capsule_header","text":"FmpCapsuleHeader View Source ## @file # Module that encodes and decodes a EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER with # a payload. # # Copyright (c) 2018 - 2019, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpCapsuleHeader ''' import struct import uuid from edk2toollib.uefi.fmp_auth_header import FmpAuthHeaderClass class FmpCapsuleImageHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// Used to identify device firmware targeted by this update. This guid is matched by # /// system firmware against ImageTypeId field within a EFI_FIRMWARE_IMAGE_DESCRIPTOR # /// # EFI_GUID UpdateImageTypeId; # # /// # /// Passed as ImageIndex in call to EFI_FIRMWARE_MANAGEMENT_PROTOCOL.SetImage () # /// # UINT8 UpdateImageIndex; # UINT8 reserved_bytes[3]; # # /// # /// Size of the binary update image which immediately follows this structure # /// # UINT32 UpdateImageSize; # # /// # /// Size of the VendorCode bytes which optionally immediately follow binary update image in the capsule # /// # UINT32 UpdateVendorCodeSize; # # /// # /// The HardwareInstance to target with this update. If value is zero it means match all # /// HardwareInstances. This field allows update software to target only a single device in # /// cases where there are more than one device with the same ImageTypeId GUID. # /// This header is outside the signed data of the Authentication Info structure and # /// therefore can be modified without changing the Auth data. # /// # UINT64 UpdateHardwareInstance; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION 0x00000002 _StructFormat = '<I16sB3BIIQ' # spell-checker: disable-line _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION = 0x00000002 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION self . UpdateImageTypeId = uuid . UUID ( '00000000-0000-0000-0000-000000000000' ) self . UpdateImageIndex = 0 self . UpdateImageSize = 0 self . UpdateVendorCodeSize = 0 self . UpdateHardwareInstance = 0x0000000000000000 self . Payload = b '' self . VendorCodeBytes = b '' self . FmpAuthHeader = None def Encode ( self ): # If we have an FmpAuthHeader, let's collapse that now. if self . FmpAuthHeader is not None : self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION : raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize :]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize : self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize :] return Buffer [ self . _StructSize :] def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ) . upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None : self . FmpAuthHeader . DumpInfo () class FmpCapsuleHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// The number of drivers included in the capsule and the number of corresponding # /// offsets stored in ItemOffsetList array. # /// # UINT16 EmbeddedDriverCount; # # /// # /// The number of payload items included in the capsule and the number of # /// corresponding offsets stored in the ItemOffsetList array. # /// # UINT16 PayloadItemCount; # # /// # /// Variable length array of dimension [EmbeddedDriverCount + PayloadItemCount] # /// containing offsets of each of the drivers and payload items contained within the capsule # /// # // UINT64 ItemOffsetList[]; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION 0x00000001 _StructFormat = '<IHH' _StructSize = struct . calcsize ( _StructFormat ) _ItemOffsetFormat = '<Q' _ItemOffsetSize = struct . calcsize ( _ItemOffsetFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION = 0x00000001 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION self . EmbeddedDriverCount = 0 self . PayloadItemCount = 0 self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] def AddEmbeddedDriver ( self , EmbeddedDriver ): self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1 def GetEmbeddedDriver ( self , Index ): return self . _EmbeddedDriverList [ Index ] def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ): self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1 def GetFmpCapsuleImageHeader ( self , Index ): return self . _FmpCapsuleImageHeaderList [ Index ] def Encode ( self ): self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ): ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset : Offset + self . _ItemOffsetSize ])[ 0 ] if ItemOffset >= len ( Buffer ): raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset :] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ): Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ): Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset : Offset + Length ]) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ): Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ): Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset : Offset + Length ]) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo ()","title":"Module edk2toollib.uefi.fmp_capsule_header"},{"location":"edk2toollib/uefi/fmp_capsule_header/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/fmp_capsule_header/#fmpcapsuleheaderclass","text":"class FmpCapsuleHeaderClass ( ) View Source class FmpCapsuleHeaderClass ( object ) : # typedef struct { # UINT32 Version ; # # /// # /// The number of drivers included in the capsule and the number of corresponding # /// offsets stored in ItemOffsetList array . # /// # UINT16 EmbeddedDriverCount ; # # /// # /// The number of payload items included in the capsule and the number of # /// corresponding offsets stored in the ItemOffsetList array . # /// # UINT16 PayloadItemCount ; # # /// # /// Variable length array of dimension [ EmbeddedDriverCount + PayloadItemCount ] # /// containing offsets of each of the drivers and payload items contained within the capsule # /// # // UINT64 ItemOffsetList [] ; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER ; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION 0x00000001 _StructFormat = '<IHH' _StructSize = struct . calcsize ( _StructFormat ) _ItemOffsetFormat = '<Q' _ItemOffsetSize = struct . calcsize ( _ItemOffsetFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION = 0x00000001 def __init__ ( self ) : self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION self . EmbeddedDriverCount = 0 self . PayloadItemCount = 0 self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] def AddEmbeddedDriver ( self , EmbeddedDriver ) : self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1 def GetEmbeddedDriver ( self , Index ) : return self . _EmbeddedDriverList [ Index ] def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ) : self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1 def GetFmpCapsuleImageHeader ( self , Index ) : return self . _FmpCapsuleImageHeaderList [ Index ] def Encode ( self ) : self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ) : ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset:Offset + self._ItemOffsetSize ] ) [ 0 ] if ItemOffset >= len ( Buffer ) : raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset: ] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset:Offset + Length ] ) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset:Offset + Length ] ) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result def DumpInfo ( self ) : print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo ()","title":"FmpCapsuleHeaderClass"},{"location":"edk2toollib/uefi/fmp_capsule_header/#class-variables","text":"EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION","title":"Class variables"},{"location":"edk2toollib/uefi/fmp_capsule_header/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/fmp_capsule_header/#addembeddeddriver","text":"def AddEmbeddedDriver ( self , EmbeddedDriver ) View Source def AddEmbeddedDriver ( self , EmbeddedDriver ): self . _EmbeddedDriverList . append ( EmbeddedDriver ) self . EmbeddedDriverCount += 1","title":"AddEmbeddedDriver"},{"location":"edk2toollib/uefi/fmp_capsule_header/#addfmpcapsuleimageheader","text":"def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ) View Source def AddFmpCapsuleImageHeader ( self , FmpCapsuleHeader ): self . _FmpCapsuleImageHeaderList . append ( FmpCapsuleHeader ) self . PayloadItemCount += 1","title":"AddFmpCapsuleImageHeader"},{"location":"edk2toollib/uefi/fmp_capsule_header/#decode","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , EmbeddedDriverCount , PayloadItemCount ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER_INIT_VERSION : raise ValueError self . Version = Version self . EmbeddedDriverCount = EmbeddedDriverCount self . PayloadItemCount = PayloadItemCount self . _EmbeddedDriverList = [] self . _FmpCapsuleImageHeaderList = [] offset_list = [] # # Parse the ItemOffsetList values # Offset = self . _StructSize for Index in range ( 0 , EmbeddedDriverCount + PayloadItemCount ) : ItemOffset = struct . unpack ( self . _ItemOffsetFormat , Buffer [ Offset:Offset + self._ItemOffsetSize ] ) [ 0 ] if ItemOffset >= len ( Buffer ) : raise ValueError offset_list . append ( ItemOffset ) Offset = Offset + self . _ItemOffsetSize Result = Buffer [ Offset: ] # # Parse the EmbeddedDrivers # for Index in range ( 0 , EmbeddedDriverCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset self . AddEmbeddedDriver ( Buffer [ Offset:Offset + Length ] ) # # Parse the Payloads that are FMP Capsule Images # for Index in range ( EmbeddedDriverCount , EmbeddedDriverCount + PayloadItemCount ) : Offset = offset_list [ Index ] if Index < ( len ( offset_list ) - 1 ) : Length = offset_list [ Index + 1 ] - Offset else : Length = len ( Buffer ) - Offset FmpCapsuleImageHeader = FmpCapsuleImageHeaderClass () FmpCapsuleImageHeader . Decode ( Buffer [ Offset:Offset + Length ] ) self . AddFmpCapsuleImageHeader ( FmpCapsuleImageHeader ) return Result","title":"Decode"},{"location":"edk2toollib/uefi/fmp_capsule_header/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.EmbeddedDriverCount = {EmbeddedDriverCount:08X}' . format ( EmbeddedDriverCount = self . EmbeddedDriverCount )) for EmbeddedDriver in self . _EmbeddedDriverList : print ( ' sizeof (EmbeddedDriver) = {Size:08X}' . format ( Size = len ( EmbeddedDriver ))) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.PayloadItemCount = {PayloadItemCount:08X}' . format ( PayloadItemCount = self . PayloadItemCount )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_HEADER.ItemOffsetList = ' ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImageHeader . DumpInfo ()","title":"DumpInfo"},{"location":"edk2toollib/uefi/fmp_capsule_header/#encode","text":"def Encode ( self ) View Source def Encode ( self ): self . EmbeddedDriverCount = len ( self . _EmbeddedDriverList ) self . PayloadItemCount = len ( self . _FmpCapsuleImageHeaderList ) FmpCapsuleHeader = struct . pack ( self . _StructFormat , self . Version , self . EmbeddedDriverCount , self . PayloadItemCount ) FmpCapsuleData = b '' offset_list = [] Offset = self . _StructSize + ( self . EmbeddedDriverCount + self . PayloadItemCount ) * self . _ItemOffsetSize for EmbeddedDriver in self . _EmbeddedDriverList : FmpCapsuleData = FmpCapsuleData + EmbeddedDriver offset_list . append ( Offset ) Offset = Offset + len ( EmbeddedDriver ) for FmpCapsuleImageHeader in self . _FmpCapsuleImageHeaderList : FmpCapsuleImage = FmpCapsuleImageHeader . Encode () FmpCapsuleData = FmpCapsuleData + FmpCapsuleImage offset_list . append ( Offset ) Offset = Offset + len ( FmpCapsuleImage ) for Offset in offset_list : FmpCapsuleHeader = FmpCapsuleHeader + struct . pack ( self . _ItemOffsetFormat , Offset ) return FmpCapsuleHeader + FmpCapsuleData","title":"Encode"},{"location":"edk2toollib/uefi/fmp_capsule_header/#getembeddeddriver","text":"def GetEmbeddedDriver ( self , Index ) View Source def GetEmbeddedDriver ( self , Index ) : return self . _EmbeddedDriverList [ Index ]","title":"GetEmbeddedDriver"},{"location":"edk2toollib/uefi/fmp_capsule_header/#getfmpcapsuleimageheader","text":"def GetFmpCapsuleImageHeader ( self , Index ) View Source def GetFmpCapsuleImageHeader ( self , Index ) : return self . _FmpCapsuleImageHeaderList [ Index ]","title":"GetFmpCapsuleImageHeader"},{"location":"edk2toollib/uefi/fmp_capsule_header/#fmpcapsuleimageheaderclass","text":"class FmpCapsuleImageHeaderClass ( ) View Source class FmpCapsuleImageHeaderClass ( object ): # typedef struct { # UINT32 Version; # # /// # /// Used to identify device firmware targeted by this update. This guid is matched by # /// system firmware against ImageTypeId field within a EFI_FIRMWARE_IMAGE_DESCRIPTOR # /// # EFI_GUID UpdateImageTypeId; # # /// # /// Passed as ImageIndex in call to EFI_FIRMWARE_MANAGEMENT_PROTOCOL.SetImage () # /// # UINT8 UpdateImageIndex; # UINT8 reserved_bytes[3]; # # /// # /// Size of the binary update image which immediately follows this structure # /// # UINT32 UpdateImageSize; # # /// # /// Size of the VendorCode bytes which optionally immediately follow binary update image in the capsule # /// # UINT32 UpdateVendorCodeSize; # # /// # /// The HardwareInstance to target with this update. If value is zero it means match all # /// HardwareInstances. This field allows update software to target only a single device in # /// cases where there are more than one device with the same ImageTypeId GUID. # /// This header is outside the signed data of the Authentication Info structure and # /// therefore can be modified without changing the Auth data. # /// # UINT64 UpdateHardwareInstance; # } EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER; # # #define EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION 0x00000002 _StructFormat = '<I16sB3BIIQ' # spell-checker: disable-line _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION = 0x00000002 def __init__ ( self ): self . Version = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION self . UpdateImageTypeId = uuid . UUID ( '00000000-0000-0000-0000-000000000000' ) self . UpdateImageIndex = 0 self . UpdateImageSize = 0 self . UpdateVendorCodeSize = 0 self . UpdateHardwareInstance = 0x0000000000000000 self . Payload = b'' self . VendorCodeBytes = b'' self . FmpAuthHeader = None def Encode ( self ): # If we have an FmpAuthHeader, let's collapse that now. if self . FmpAuthHeader is not None: self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION: raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize: ]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize:self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize: ] return Buffer [ self . _StructSize: ] def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ). upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None: self . FmpAuthHeader . DumpInfo ()","title":"FmpCapsuleImageHeaderClass"},{"location":"edk2toollib/uefi/fmp_capsule_header/#class-variables_1","text":"EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION","title":"Class variables"},{"location":"edk2toollib/uefi/fmp_capsule_header/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/fmp_capsule_header/#decode_1","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Version , UpdateImageTypeId , UpdateImageIndex , r0 , r1 , r2 , UpdateImageSize , UpdateVendorCodeSize , UpdateHardwareInstance ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Version < self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER_INIT_VERSION : raise ValueError if UpdateImageIndex < 1 : raise ValueError if UpdateImageSize + UpdateVendorCodeSize != len ( Buffer [ self . _StructSize :]): raise ValueError self . Version = Version self . UpdateImageTypeId = uuid . UUID ( bytes_le = UpdateImageTypeId ) self . UpdateImageIndex = UpdateImageIndex self . UpdateImageSize = UpdateImageSize self . UpdateVendorCodeSize = UpdateVendorCodeSize self . UpdateHardwareInstance = UpdateHardwareInstance self . Payload = Buffer [ self . _StructSize : self . _StructSize + UpdateImageSize ] if len ( self . Payload ) > 0 : self . FmpAuthHeader = FmpAuthHeaderClass () self . FmpAuthHeader . Decode ( self . Payload ) self . VendorCodeBytes = Buffer [ self . _StructSize + UpdateImageSize :] return Buffer [ self . _StructSize :]","title":"Decode"},{"location":"edk2toollib/uefi/fmp_capsule_header/#dumpinfo_1","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.Version = {Version:08X}' . format ( Version = self . Version )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageTypeId = {UpdateImageTypeId}' . format ( UpdateImageTypeId = str ( self . UpdateImageTypeId ). upper ())) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageIndex = {UpdateImageIndex:08X}' . format ( UpdateImageIndex = self . UpdateImageIndex )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateImageSize = {UpdateImageSize:08X}' . format ( UpdateImageSize = self . UpdateImageSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateVendorCodeSize = {UpdateVendorCodeSize:08X}' . format ( UpdateVendorCodeSize = self . UpdateVendorCodeSize )) print ( 'EFI_FIRMWARE_MANAGEMENT_CAPSULE_IMAGE_HEADER.UpdateHardwareInstance = {UpdateHardwareInstance:016X}' . format ( UpdateHardwareInstance = self . UpdateHardwareInstance )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) print ( 'sizeof (VendorCodeBytes) = {Size:08X}' . format ( Size = len ( self . VendorCodeBytes ))) if self . FmpAuthHeader is not None : self . FmpAuthHeader . DumpInfo ()","title":"DumpInfo"},{"location":"edk2toollib/uefi/fmp_capsule_header/#encode_1","text":"def Encode ( self ) View Source def Encode ( self ): # If we have an FmpAuthHeader , let ' s collapse that now . if self . FmpAuthHeader is not None : self . Payload = self . FmpAuthHeader . Encode () self . UpdateImageSize = len ( self . Payload ) self . UpdateVendorCodeSize = len ( self . VendorCodeBytes ) FmpCapsuleImageHeader = struct . pack ( self . _StructFormat , self . Version , self . UpdateImageTypeId . bytes_le , self . UpdateImageIndex , 0 , 0 , 0 , self . UpdateImageSize , self . UpdateVendorCodeSize , self . UpdateHardwareInstance ) return FmpCapsuleImageHeader + self . Payload + self . VendorCodeBytes","title":"Encode"},{"location":"edk2toollib/uefi/pi_firmware_file/","text":"Module edk2toollib.uefi.pi_firmware_file View Source # @file # Module contains helper classes and functions to work with UEFI FFs. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # EFI_FFS_FILE_HEADER # # typedef struct { # EFI_GUID Name; # EFI_FFS_INTEGRITY_CHECK IntegrityCheck; # EFI_FV_FILETYPE Type; # EFI_FFS_FILE_ATTRIBUTES Attributes; # UINT8 Size[3]; # EFI_FFS_FILE_STATE State; # } EFI_FFS_FILE_HEADER; class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" # spell-checker: disable-line self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) Classes EfiFirmwareFileSystemHeader class EfiFirmwareFileSystemHeader ( ) View Source class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" # spell-checker: disable-line self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) Methods get_size def get_size ( self ) View Source def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self serialize def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"Pi firmware file"},{"location":"edk2toollib/uefi/pi_firmware_file/#module-edk2toollibuefipi_firmware_file","text":"View Source # @file # Module contains helper classes and functions to work with UEFI FFs. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # EFI_FFS_FILE_HEADER # # typedef struct { # EFI_GUID Name; # EFI_FFS_INTEGRITY_CHECK IntegrityCheck; # EFI_FV_FILETYPE Type; # EFI_FFS_FILE_ATTRIBUTES Attributes; # UINT8 Size[3]; # EFI_FFS_FILE_STATE State; # } EFI_FFS_FILE_HEADER; class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" # spell-checker: disable-line self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"Module edk2toollib.uefi.pi_firmware_file"},{"location":"edk2toollib/uefi/pi_firmware_file/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/pi_firmware_file/#efifirmwarefilesystemheader","text":"class EfiFirmwareFileSystemHeader ( ) View Source class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" # spell-checker: disable-line self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"EfiFirmwareFileSystemHeader"},{"location":"edk2toollib/uefi/pi_firmware_file/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_file/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 )","title":"get_size"},{"location":"edk2toollib/uefi/pi_firmware_file/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_file/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"serialize"},{"location":"edk2toollib/uefi/pi_firmware_volume/","text":"Module edk2toollib.uefi.pi_firmware_volume View Source # @file # Module contains helper classes and functions to work with UEFI FVs. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # UEFI GUIDs # EfiSystemNvDataFvGuid = uuid . UUID ( fields = ( 0xFFF12B8D , 0x7696 , 0x4C8B , 0xA9 , 0x85 , 0x2747075B4F50 )) # # UEFI #Defines # EFI_FVH_SIGNATURE = b \"_FVH\" # # EFI_FIRMWARE_VOLUME_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_HEADER structure/byte buffer. # # typedef struct { # UINT8 ZeroVector[16]; # EFI_GUID FileSystemGuid; # UINT64 FvLength; # UINT32 Signature; # EFI_FVB_ATTRIBUTES_2 Attributes; # UINT16 HeaderLength; # UINT16 Checksum; # UINT16 ExtHeaderOffset; # UINT8 Reserved[1]; # UINT8 Revision; # EFI_FV_BLOCK_MAP_ENTRY BlockMap[1]; # } EFI_FIRMWARE_VOLUME_HEADER; class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" # spell-checker: disable-line self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) # # EFI_FIRMWARE_VOLUME_EXT_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_EXT_HEADER structure/byte buffer. # # typedef struct { # EFI_GUID FileSystemGuid; # UINT32 ExtHeaderSize; # } EFI_FIRMWARE_VOLUME_EXT_HEADER; class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self Variables EFI_FVH_SIGNATURE EfiSystemNvDataFvGuid Classes EfiFirmwareVolumeExtHeader class EfiFirmwareVolumeExtHeader ( ) View Source class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self EfiFirmwareVolumeHeader class EfiFirmwareVolumeHeader ( ) View Source class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" # spell-checker: disable-line self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE: raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is . if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self serialize def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"Pi firmware volume"},{"location":"edk2toollib/uefi/pi_firmware_volume/#module-edk2toollibuefipi_firmware_volume","text":"View Source # @file # Module contains helper classes and functions to work with UEFI FVs. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # UEFI GUIDs # EfiSystemNvDataFvGuid = uuid . UUID ( fields = ( 0xFFF12B8D , 0x7696 , 0x4C8B , 0xA9 , 0x85 , 0x2747075B4F50 )) # # UEFI #Defines # EFI_FVH_SIGNATURE = b \"_FVH\" # # EFI_FIRMWARE_VOLUME_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_HEADER structure/byte buffer. # # typedef struct { # UINT8 ZeroVector[16]; # EFI_GUID FileSystemGuid; # UINT64 FvLength; # UINT32 Signature; # EFI_FVB_ATTRIBUTES_2 Attributes; # UINT16 HeaderLength; # UINT16 Checksum; # UINT16 ExtHeaderOffset; # UINT8 Reserved[1]; # UINT8 Revision; # EFI_FV_BLOCK_MAP_ENTRY BlockMap[1]; # } EFI_FIRMWARE_VOLUME_HEADER; class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" # spell-checker: disable-line self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) # # EFI_FIRMWARE_VOLUME_EXT_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_EXT_HEADER structure/byte buffer. # # typedef struct { # EFI_GUID FileSystemGuid; # UINT32 ExtHeaderSize; # } EFI_FIRMWARE_VOLUME_EXT_HEADER; class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"Module edk2toollib.uefi.pi_firmware_volume"},{"location":"edk2toollib/uefi/pi_firmware_volume/#variables","text":"EFI_FVH_SIGNATURE EfiSystemNvDataFvGuid","title":"Variables"},{"location":"edk2toollib/uefi/pi_firmware_volume/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/pi_firmware_volume/#efifirmwarevolumeextheader","text":"class EfiFirmwareVolumeExtHeader ( ) View Source class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"EfiFirmwareVolumeExtHeader"},{"location":"edk2toollib/uefi/pi_firmware_volume/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_volume/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_volume/#efifirmwarevolumeheader","text":"class EfiFirmwareVolumeHeader ( ) View Source class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" # spell-checker: disable-line self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE: raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"EfiFirmwareVolumeHeader"},{"location":"edk2toollib/uefi/pi_firmware_volume/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_volume/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is . if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_volume/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"serialize"},{"location":"edk2toollib/uefi/status_codes/","text":"Module edk2toollib.uefi.status_codes View Source # @file # Code to help convert an Int to StatusCode string # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## class UefiStatusCode ( object ) : # See appendix D of the UEFI spec # high bit set ErrorCodeStrings = [ \"NOT VALID\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\", \"IP Address Conflict\", \"HTTP Error\" ] NonErrorCodeStrings = [ \"Success\", \"Unknown Glyph\", \"Delete Failure\", \"Write Failure\", \"Buffer Too Small\", \"Stale Data\", \"File System\", \"Reset Required\" ] def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) Classes UefiStatusCode class UefiStatusCode ( / , * args , ** kwargs ) View Source class UefiStatusCode ( object ) : # See appendix D of the UEFI spec # high bit set ErrorCodeStrings = [ \"NOT VALID\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\", \"IP Address Conflict\", \"HTTP Error\" ] NonErrorCodeStrings = [ \"Success\", \"Unknown Glyph\", \"Delete Failure\", \"Write Failure\", \"Buffer Too Small\", \"Stale Data\", \"File System\", \"Reset Required\" ] def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) Class variables ErrorCodeStrings NonErrorCodeStrings Methods Convert32BitToString def Convert32BitToString ( self , value : int ) -> str convert 32 bit int to a friendly UEFI status code string value View Source def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] Convert64BitToString def Convert64BitToString ( self , value : int ) -> str convert 64 bit int to a friendly UEFI status code string value View Source def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] ConvertHexString32ToString def ConvertHexString32ToString ( self , hexstring ) convert 32 bit hexstring in 0x format to a UEFI status code View Source def ConvertHexString32ToString ( self , hexstring ): ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) ConvertHexString64ToString def ConvertHexString64ToString ( self , hexstring : str ) -> str convert 64 bit hexstring in 0x format to a UEFI status code View Source def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value )","title":"Status codes"},{"location":"edk2toollib/uefi/status_codes/#module-edk2toollibuefistatus_codes","text":"View Source # @file # Code to help convert an Int to StatusCode string # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## class UefiStatusCode ( object ) : # See appendix D of the UEFI spec # high bit set ErrorCodeStrings = [ \"NOT VALID\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\", \"IP Address Conflict\", \"HTTP Error\" ] NonErrorCodeStrings = [ \"Success\", \"Unknown Glyph\", \"Delete Failure\", \"Write Failure\", \"Buffer Too Small\", \"Stale Data\", \"File System\", \"Reset Required\" ] def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"Module edk2toollib.uefi.status_codes"},{"location":"edk2toollib/uefi/status_codes/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/status_codes/#uefistatuscode","text":"class UefiStatusCode ( / , * args , ** kwargs ) View Source class UefiStatusCode ( object ) : # See appendix D of the UEFI spec # high bit set ErrorCodeStrings = [ \"NOT VALID\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\", \"IP Address Conflict\", \"HTTP Error\" ] NonErrorCodeStrings = [ \"Success\", \"Unknown Glyph\", \"Delete Failure\", \"Write Failure\", \"Buffer Too Small\", \"Stale Data\", \"File System\", \"Reset Required\" ] def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ] def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"UefiStatusCode"},{"location":"edk2toollib/uefi/status_codes/#class-variables","text":"ErrorCodeStrings NonErrorCodeStrings","title":"Class variables"},{"location":"edk2toollib/uefi/status_codes/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/status_codes/#convert32bittostring","text":"def Convert32BitToString ( self , value : int ) -> str convert 32 bit int to a friendly UEFI status code string value View Source def Convert32BitToString ( self , value : int ) -> str : ''' convert 32 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 31 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ]","title":"Convert32BitToString"},{"location":"edk2toollib/uefi/status_codes/#convert64bittostring","text":"def Convert64BitToString ( self , value : int ) -> str convert 64 bit int to a friendly UEFI status code string value View Source def Convert64BitToString ( self , value : int ) -> str : ''' convert 64 bit int to a friendly UEFI status code string value''' StatusStrings = UefiStatusCode . NonErrorCodeStrings if ( value >> 63 ) & 1 == 1 : # error StatusStrings = UefiStatusCode . ErrorCodeStrings value = value & 0x7FFFFFFFFFFFFFFF # mask off upper bit if ( value >= len ( StatusStrings )) : return \"Undefined StatusCode\" return StatusStrings [ value ]","title":"Convert64BitToString"},{"location":"edk2toollib/uefi/status_codes/#converthexstring32tostring","text":"def ConvertHexString32ToString ( self , hexstring ) convert 32 bit hexstring in 0x format to a UEFI status code View Source def ConvertHexString32ToString ( self , hexstring ): ''' convert 32 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"ConvertHexString32ToString"},{"location":"edk2toollib/uefi/status_codes/#converthexstring64tostring","text":"def ConvertHexString64ToString ( self , hexstring : str ) -> str convert 64 bit hexstring in 0x format to a UEFI status code View Source def ConvertHexString64ToString ( self , hexstring : str ) -> str : ''' convert 64 bit hexstring in 0x format to a UEFI status code ''' value = int ( hexstring , 16 ) return self . Convert64BitToString ( value )","title":"ConvertHexString64ToString"},{"location":"edk2toollib/uefi/uefi_capsule_header/","text":"Module edk2toollib.uefi.uefi_capsule_header UefiCapsuleHeader View Source ## @file # Module that encodes and decodes a EFI_CAPSULE_HEADER with a payload # # Copyright (c) 2018, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' UefiCapsuleHeader ''' import struct import uuid from edk2toollib.uefi.fmp_capsule_header import FmpCapsuleHeaderClass class UefiCapsuleHeaderClass ( object ): # typedef struct { # /// # /// A GUID that defines the contents of a capsule. # /// # EFI_GUID CapsuleGuid; # /// # /// The size of the capsule header. This may be larger than the size of # /// the EFI_CAPSULE_HEADER since CapsuleGuid may imply # /// extended header entries # /// # UINT32 HeaderSize; # /// # /// Bit-mapped list describing the capsule attributes. The Flag values # /// of 0x0000 - 0xFFFF are defined by CapsuleGuid. Flag values # /// of 0x10000 - 0xFFFFFFFF are defined by this specification # /// # UINT32 Flags; # /// # /// Size in bytes of the capsule. # /// # UINT32 CapsuleImageSize; # } EFI_CAPSULE_HEADER; # # #define CAPSULE_FLAGS_PERSIST_ACROSS_RESET 0x00010000 # #define CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE 0x00020000 # #define CAPSULE_FLAGS_INITIATE_RESET 0x00040000 # _StructFormat = '<16sIIII' _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID = uuid . UUID ( '6DCBD5ED-E82D-4C44-BDA1-7194199AD92A' ) _CAPSULE_FLAGS_PERSIST_ACROSS_RESET = 0x00010000 _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE = 0x00020000 _CAPSULE_FLAGS_INITIATE_RESET = 0x00040000 def __init__ ( self ): self . CapsuleGuid = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID self . HeaderSize = self . _StructSize self . OemFlags = 0x0000 self . PersistAcrossReset = False self . PopulateSystemTable = False self . InitiateReset = False self . CapsuleImageSize = self . HeaderSize self . Payload = b '' self . FmpCapsuleHeader = None def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader, let's collapse that now. if self . FmpCapsuleHeader is not None : self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize : raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize :] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID : self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ) . upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset : print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable : print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset : print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None : self . FmpCapsuleHeader . DumpInfo () Classes UefiCapsuleHeaderClass class UefiCapsuleHeaderClass ( ) View Source class UefiCapsuleHeaderClass ( object ): # typedef struct { # /// # /// A GUID that defines the contents of a capsule. # /// # EFI_GUID CapsuleGuid; # /// # /// The size of the capsule header. This may be larger than the size of # /// the EFI_CAPSULE_HEADER since CapsuleGuid may imply # /// extended header entries # /// # UINT32 HeaderSize; # /// # /// Bit-mapped list describing the capsule attributes. The Flag values # /// of 0x0000 - 0xFFFF are defined by CapsuleGuid. Flag values # /// of 0x10000 - 0xFFFFFFFF are defined by this specification # /// # UINT32 Flags; # /// # /// Size in bytes of the capsule. # /// # UINT32 CapsuleImageSize; # } EFI_CAPSULE_HEADER; # # #define CAPSULE_FLAGS_PERSIST_ACROSS_RESET 0x00010000 # #define CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE 0x00020000 # #define CAPSULE_FLAGS_INITIATE_RESET 0x00040000 # _StructFormat = '<16sIIII' _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID = uuid . UUID ( '6DCBD5ED-E82D-4C44-BDA1-7194199AD92A' ) _CAPSULE_FLAGS_PERSIST_ACROSS_RESET = 0x00010000 _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE = 0x00020000 _CAPSULE_FLAGS_INITIATE_RESET = 0x00040000 def __init__ ( self ): self . CapsuleGuid = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID self . HeaderSize = self . _StructSize self . OemFlags = 0x0000 self . PersistAcrossReset = False self . PopulateSystemTable = False self . InitiateReset = False self . CapsuleImageSize = self . HeaderSize self . Payload = b'' self . FmpCapsuleHeader = None def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset: Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable: Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset: Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader, let's collapse that now. if self . FmpCapsuleHeader is not None: self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize: raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize: ] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID: self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset: Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable: Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset: Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ). upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset: print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable: print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset: print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None: self . FmpCapsuleHeader . DumpInfo () Class variables EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID Methods Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize : raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0 xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize :] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID : self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ). upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset : print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable : print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset : print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None : self . FmpCapsuleHeader . DumpInfo () Encode def Encode ( self ) View Source def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader , let ' s collapse that now . if self . FmpCapsuleHeader is not None : self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload","title":"Uefi capsule header"},{"location":"edk2toollib/uefi/uefi_capsule_header/#module-edk2toollibuefiuefi_capsule_header","text":"UefiCapsuleHeader View Source ## @file # Module that encodes and decodes a EFI_CAPSULE_HEADER with a payload # # Copyright (c) 2018, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' UefiCapsuleHeader ''' import struct import uuid from edk2toollib.uefi.fmp_capsule_header import FmpCapsuleHeaderClass class UefiCapsuleHeaderClass ( object ): # typedef struct { # /// # /// A GUID that defines the contents of a capsule. # /// # EFI_GUID CapsuleGuid; # /// # /// The size of the capsule header. This may be larger than the size of # /// the EFI_CAPSULE_HEADER since CapsuleGuid may imply # /// extended header entries # /// # UINT32 HeaderSize; # /// # /// Bit-mapped list describing the capsule attributes. The Flag values # /// of 0x0000 - 0xFFFF are defined by CapsuleGuid. Flag values # /// of 0x10000 - 0xFFFFFFFF are defined by this specification # /// # UINT32 Flags; # /// # /// Size in bytes of the capsule. # /// # UINT32 CapsuleImageSize; # } EFI_CAPSULE_HEADER; # # #define CAPSULE_FLAGS_PERSIST_ACROSS_RESET 0x00010000 # #define CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE 0x00020000 # #define CAPSULE_FLAGS_INITIATE_RESET 0x00040000 # _StructFormat = '<16sIIII' _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID = uuid . UUID ( '6DCBD5ED-E82D-4C44-BDA1-7194199AD92A' ) _CAPSULE_FLAGS_PERSIST_ACROSS_RESET = 0x00010000 _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE = 0x00020000 _CAPSULE_FLAGS_INITIATE_RESET = 0x00040000 def __init__ ( self ): self . CapsuleGuid = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID self . HeaderSize = self . _StructSize self . OemFlags = 0x0000 self . PersistAcrossReset = False self . PopulateSystemTable = False self . InitiateReset = False self . CapsuleImageSize = self . HeaderSize self . Payload = b '' self . FmpCapsuleHeader = None def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader, let's collapse that now. if self . FmpCapsuleHeader is not None : self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize : raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize :] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID : self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ) . upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset : print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable : print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset : print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None : self . FmpCapsuleHeader . DumpInfo ()","title":"Module edk2toollib.uefi.uefi_capsule_header"},{"location":"edk2toollib/uefi/uefi_capsule_header/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/uefi_capsule_header/#ueficapsuleheaderclass","text":"class UefiCapsuleHeaderClass ( ) View Source class UefiCapsuleHeaderClass ( object ): # typedef struct { # /// # /// A GUID that defines the contents of a capsule. # /// # EFI_GUID CapsuleGuid; # /// # /// The size of the capsule header. This may be larger than the size of # /// the EFI_CAPSULE_HEADER since CapsuleGuid may imply # /// extended header entries # /// # UINT32 HeaderSize; # /// # /// Bit-mapped list describing the capsule attributes. The Flag values # /// of 0x0000 - 0xFFFF are defined by CapsuleGuid. Flag values # /// of 0x10000 - 0xFFFFFFFF are defined by this specification # /// # UINT32 Flags; # /// # /// Size in bytes of the capsule. # /// # UINT32 CapsuleImageSize; # } EFI_CAPSULE_HEADER; # # #define CAPSULE_FLAGS_PERSIST_ACROSS_RESET 0x00010000 # #define CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE 0x00020000 # #define CAPSULE_FLAGS_INITIATE_RESET 0x00040000 # _StructFormat = '<16sIIII' _StructSize = struct . calcsize ( _StructFormat ) EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID = uuid . UUID ( '6DCBD5ED-E82D-4C44-BDA1-7194199AD92A' ) _CAPSULE_FLAGS_PERSIST_ACROSS_RESET = 0x00010000 _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE = 0x00020000 _CAPSULE_FLAGS_INITIATE_RESET = 0x00040000 def __init__ ( self ): self . CapsuleGuid = self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID self . HeaderSize = self . _StructSize self . OemFlags = 0x0000 self . PersistAcrossReset = False self . PopulateSystemTable = False self . InitiateReset = False self . CapsuleImageSize = self . HeaderSize self . Payload = b'' self . FmpCapsuleHeader = None def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset: Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable: Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset: Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader, let's collapse that now. if self . FmpCapsuleHeader is not None: self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize: raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize: ] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID: self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset: Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable: Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset: Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ). upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset: print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable: print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset: print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None: self . FmpCapsuleHeader . DumpInfo ()","title":"UefiCapsuleHeaderClass"},{"location":"edk2toollib/uefi/uefi_capsule_header/#class-variables","text":"EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID","title":"Class variables"},{"location":"edk2toollib/uefi/uefi_capsule_header/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/uefi_capsule_header/#decode","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( CapsuleGuid , HeaderSize , Flags , CapsuleImageSize , Reserved ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if HeaderSize < self . _StructSize : raise ValueError if CapsuleImageSize != len ( Buffer ): raise ValueError self . CapsuleGuid = uuid . UUID ( bytes_le = CapsuleGuid ) self . HeaderSize = HeaderSize self . OemFlags = Flags & 0 xffff self . PersistAcrossReset = ( Flags & self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET ) != 0 self . PopulateSystemTable = ( Flags & self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE ) != 0 self . InitiateReset = ( Flags & self . _CAPSULE_FLAGS_INITIATE_RESET ) != 0 self . CapsuleImageSize = CapsuleImageSize self . Payload = Buffer [ self . HeaderSize :] if len ( self . Payload ) > 0 and self . CapsuleGuid == self . EFI_FIRMWARE_MANAGEMENT_CAPSULE_ID_GUID : self . FmpCapsuleHeader = FmpCapsuleHeaderClass () self . FmpCapsuleHeader . Decode ( self . Payload ) return self . Payload","title":"Decode"},{"location":"edk2toollib/uefi/uefi_capsule_header/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET print ( 'EFI_CAPSULE_HEADER.CapsuleGuid = {Guid}' . format ( Guid = str ( self . CapsuleGuid ). upper ())) print ( 'EFI_CAPSULE_HEADER.HeaderSize = {Size:08X}' . format ( Size = self . HeaderSize )) print ( 'EFI_CAPSULE_HEADER.Flags = {Flags:08X}' . format ( Flags = Flags )) print ( ' OEM Flags = {Flags:04X}' . format ( Flags = self . OemFlags )) if self . PersistAcrossReset : print ( ' CAPSULE_FLAGS_PERSIST_ACROSS_RESET' ) if self . PopulateSystemTable : print ( ' CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE' ) if self . InitiateReset : print ( ' CAPSULE_FLAGS_INITIATE_RESET' ) print ( 'EFI_CAPSULE_HEADER.CapsuleImageSize = {Size:08X}' . format ( Size = self . CapsuleImageSize )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) if self . FmpCapsuleHeader is not None : self . FmpCapsuleHeader . DumpInfo ()","title":"DumpInfo"},{"location":"edk2toollib/uefi/uefi_capsule_header/#encode","text":"def Encode ( self ) View Source def Encode ( self ): Flags = self . OemFlags if self . PersistAcrossReset : Flags = Flags | self . _CAPSULE_FLAGS_PERSIST_ACROSS_RESET if self . PopulateSystemTable : Flags = Flags | self . _CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE if self . InitiateReset : Flags = Flags | self . _CAPSULE_FLAGS_INITIATE_RESET # If we have an FmpCapsuleHeader , let ' s collapse that now . if self . FmpCapsuleHeader is not None : self . Payload = self . FmpCapsuleHeader . Encode () self . CapsuleImageSize = self . HeaderSize + len ( self . Payload ) UefiCapsuleHeader = struct . pack ( self . _StructFormat , self . CapsuleGuid . bytes_le , self . HeaderSize , Flags , self . CapsuleImageSize , 0 ) return UefiCapsuleHeader + self . Payload","title":"Encode"},{"location":"edk2toollib/uefi/uefi_multi_phase/","text":"Module edk2toollib.uefi.uefi_multi_phase View Source # @file # Module contains defintions and structures from the UefiMultiPhase header file . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## EFI_VARIABLE_NON_VOLATILE = 0x00000001 EFI_VARIABLE_BOOTSERVICE_ACCESS = 0x00000002 EFI_VARIABLE_RUNTIME_ACCESS = 0x00000004 EFI_VARIABLE_HARDWARE_ERROR_RECORD = 0x00000008 EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS = 0x00000010 EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS = 0x00000020 EFI_VARIABLE_APPEND_WRITE = 0x00000040 Variables EFI_VARIABLE_APPEND_WRITE EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS EFI_VARIABLE_BOOTSERVICE_ACCESS EFI_VARIABLE_HARDWARE_ERROR_RECORD EFI_VARIABLE_NON_VOLATILE EFI_VARIABLE_RUNTIME_ACCESS EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS","title":"Uefi multi phase"},{"location":"edk2toollib/uefi/uefi_multi_phase/#module-edk2toollibuefiuefi_multi_phase","text":"View Source # @file # Module contains defintions and structures from the UefiMultiPhase header file . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## EFI_VARIABLE_NON_VOLATILE = 0x00000001 EFI_VARIABLE_BOOTSERVICE_ACCESS = 0x00000002 EFI_VARIABLE_RUNTIME_ACCESS = 0x00000004 EFI_VARIABLE_HARDWARE_ERROR_RECORD = 0x00000008 EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS = 0x00000010 EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS = 0x00000020 EFI_VARIABLE_APPEND_WRITE = 0x00000040","title":"Module edk2toollib.uefi.uefi_multi_phase"},{"location":"edk2toollib/uefi/uefi_multi_phase/#variables","text":"EFI_VARIABLE_APPEND_WRITE EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS EFI_VARIABLE_BOOTSERVICE_ACCESS EFI_VARIABLE_HARDWARE_ERROR_RECORD EFI_VARIABLE_NON_VOLATILE EFI_VARIABLE_RUNTIME_ACCESS EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS","title":"Variables"},{"location":"edk2toollib/uefi/wincert/","text":"Module edk2toollib.uefi.wincert View Source # @file wincert.py # Code to work with UEFI WinCert data # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import io import struct import uuid from edk2toollib.utility_functions import PrintByteList class WinCertPkcs1 ( object ): # /// # /// Certificate which encapsulates the RSASSA_PKCS1-v1_5 digital signature. # /// # /// The WIN_CERTIFICATE_UEFI_PKCS1_15 structure is derived from # /// WIN_CERTIFICATE and encapsulate the information needed to # /// implement the RSASSA-PKCS1-v1_5 digital signature algorithm as # /// specified in RFC2437. # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header, where # /// wCertificateType is set to WIN_CERT_TYPE_UEFI_PKCS1_15. # /// # WIN_CERTIFICATE Hdr; # /// # /// This is the hashing algorithm which was performed on the # /// UEFI executable when creating the digital signature. # /// # EFI_GUID HashAlgorithm; # /// # /// The following is the actual digital signature. The # /// size of the signature is the same size as the key # /// (1024-bit key is 128 bytes) and can be determined by # /// subtracting the length of the other parts of this header # /// from the total length of the certificate as found in # /// Hdr.dwLength. # /// # /// UINT8 Signature[]; # /// # } WIN_CERTIFICATE_EFI_PKCS1_15; # # /// # /// The WIN_CERTIFICATE structure is part of the PE/COFF specification. # /// # typedef struct { # /// # /// The length of the entire certificate, # /// including the length of the header, in bytes. # /// # UINT32 dwLength; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure. The current revision level is 0x0200. # /// # UINT16 wRevision; # /// # /// The certificate type. See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types. The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF. # /// # UINT16 wCertificateType; # /// # /// The following is the actual certificate. The format of # /// the certificate depends on wCertificateType. # /// # /// UINT8 bCertificate[ANYSIZE_ARRAY]; # /// # } WIN_CERTIFICATE; STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s \" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) class WinCertUefiGuid ( object ): # /// # /// Certificate which encapsulates a GUID-specific digital signature # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header, where # /// wCertificateType is set to WIN_CERT_TYPE_EFI_GUID. # /// # WIN_CERTIFICATE Hdr; # /// # /// This is the unique id which determines the # /// format of the CertData. . # /// # EFI_GUID CertType; # /// # /// The following is the certificate data. The format of # /// the data is determined by the CertType. # /// If CertType is EFI_CERT_TYPE_RSA2048_SHA256_GUID, # /// the CertData will be EFI_CERT_BLOCK_RSA_2048_SHA256 structure. # /// # UINT8 CertData[1]; # } WIN_CERTIFICATE_UEFI_GUID; # # /// # /// The WIN_CERTIFICATE structure is part of the PE/COFF specification. # /// # typedef struct { # /// # /// The length of the entire certificate, # /// including the length of the header, in bytes. # /// # UINT32 dwLength; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure. The current revision level is 0x0200. # /// # UINT16 wRevision; # /// # /// The certificate type. See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types. The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF. # /// # UINT16 wCertificateType; # /// # /// The following is the actual certificate. The format of # /// the certificate depends on wCertificateType. # /// # /// UINT8 bCertificate[ANYSIZE_ARRAY]; # /// # } WIN_CERTIFICATE; _StructFormat = '<IHH16s' _StructSize = struct . calcsize ( _StructFormat ) _EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( '4aafd29d-68df-49ee-8aa9-347d375665a7' ) # Preserved for back compat. STATIC_STRUCT_SIZE = _StructSize PKCS7Guid = _EFI_CERT_TYPE_PKCS7_GUID def __init__ ( self , in_data = None ): self . Hdr_dwLength = self . _StructSize self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = self . _EFI_CERT_TYPE_PKCS7_GUID self . CertData = b '' if in_data is not None : # Account for back compat. Behave differently for file streams. if hasattr ( in_data , 'seek' ): self . PopulateFromFileStream ( in_data ) else : self . Decode ( in_data ) def Encode ( self ): if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self . _StructSize : self . Hdr_dwLength ] # Return the remaining buffer, if any exists. return Buffer [ self . Hdr_dwLength :] def AddCertData ( self , in_data ): # Account for back compat. Behave differently for file streams. if hasattr ( in_data , 'seek' ): self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise ValueError # Determine the end of the stream. current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field. field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field. ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer ) def Print ( self ): self . DumpInfo () def DumpInfo ( self ): print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ) . upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData ))) def Write ( self , fs ): fs . write ( self . Encode ()) class WinCert ( object ): STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE.wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ): return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ): return WinCertPkcs1 ( fs ) else : return None Classes WinCert class WinCert ( / , * args , ** kwargs ) View Source class WinCert ( object ) : STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE . wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None Class variables REVISION STATIC_STRUCT_SIZE WIN_CERT_TYPE_EFI_GUID WIN_CERT_TYPE_EFI_PKCS115 WIN_CERT_TYPE_NONE WIN_CERT_TYPE_PKCS_SIGNED_DATA Static methods Factory def Factory ( fs ) View Source @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None WinCertPkcs1 class WinCertPkcs1 ( filestream = None ) View Source class WinCertPkcs1 ( object ) : # /// # /// Certificate which encapsulates the RSASSA_PKCS1 - v1_5 digital signature . # /// # /// The WIN_CERTIFICATE_UEFI_PKCS1_15 structure is derived from # /// WIN_CERTIFICATE and encapsulate the information needed to # /// implement the RSASSA - PKCS1 - v1_5 digital signature algorithm as # /// specified in RFC2437 . # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header , where # /// wCertificateType is set to WIN_CERT_TYPE_UEFI_PKCS1_15 . # /// # WIN_CERTIFICATE Hdr ; # /// # /// This is the hashing algorithm which was performed on the # /// UEFI executable when creating the digital signature . # /// # EFI_GUID HashAlgorithm ; # /// # /// The following is the actual digital signature . The # /// size of the signature is the same size as the key # /// ( 1024 - bit key is 128 bytes ) and can be determined by # /// subtracting the length of the other parts of this header # /// from the total length of the certificate as found in # /// Hdr . dwLength . # /// # /// UINT8 Signature [] ; # /// # } WIN_CERTIFICATE_EFI_PKCS1_15 ; # # /// # /// The WIN_CERTIFICATE structure is part of the PE / COFF specification . # /// # typedef struct { # /// # /// The length of the entire certificate , # /// including the length of the header , in bytes . # /// # UINT32 dwLength ; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure . The current revision level is 0x0200 . # /// # UINT16 wRevision ; # /// # /// The certificate type . See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types . The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF . # /// # UINT16 wCertificateType ; # /// # /// The following is the actual certificate . The format of # /// the certificate depends on wCertificateType . # /// # /// UINT8 bCertificate [ ANYSIZE_ARRAY ] ; # /// # } WIN_CERTIFICATE ; STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ) : if ( filestream is None ) : self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ) : if ( self . CertData is not None ) : raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ) : raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ) : raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) : raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ) : print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ) : fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) Class variables EFI_HASH_SHA256 STATIC_STRUCT_SIZE Methods AddCertData def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) Print def Print ( self ) View Source def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) WinCertUefiGuid class WinCertUefiGuid ( in_data = None ) View Source class WinCertUefiGuid ( object ) : # /// # /// Certificate which encapsulates a GUID - specific digital signature # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header , where # /// wCertificateType is set to WIN_CERT_TYPE_EFI_GUID . # /// # WIN_CERTIFICATE Hdr ; # /// # /// This is the unique id which determines the # /// format of the CertData . . # /// # EFI_GUID CertType ; # /// # /// The following is the certificate data . The format of # /// the data is determined by the CertType . # /// If CertType is EFI_CERT_TYPE_RSA2048_SHA256_GUID , # /// the CertData will be EFI_CERT_BLOCK_RSA_2048_SHA256 structure . # /// # UINT8 CertData [ 1 ] ; # } WIN_CERTIFICATE_UEFI_GUID ; # # /// # /// The WIN_CERTIFICATE structure is part of the PE / COFF specification . # /// # typedef struct { # /// # /// The length of the entire certificate , # /// including the length of the header , in bytes . # /// # UINT32 dwLength ; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure . The current revision level is 0x0200 . # /// # UINT16 wRevision ; # /// # /// The certificate type . See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types . The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF . # /// # UINT16 wCertificateType ; # /// # /// The following is the actual certificate . The format of # /// the certificate depends on wCertificateType . # /// # /// UINT8 bCertificate [ ANYSIZE_ARRAY ] ; # /// # } WIN_CERTIFICATE ; _StructFormat = '<IHH16s' _StructSize = struct . calcsize ( _StructFormat ) _EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( '4aafd29d-68df-49ee-8aa9-347d375665a7' ) # Preserved for back compat . STATIC_STRUCT_SIZE = _StructSize PKCS7Guid = _EFI_CERT_TYPE_PKCS7_GUID def __init__ ( self , in_data = None ) : self . Hdr_dwLength = self . _StructSize self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = self . _EFI_CERT_TYPE_PKCS7_GUID self . CertData = b '' if in_data is not None : # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ) : self . PopulateFromFileStream ( in_data ) else : self . Decode ( in_data ) def Encode ( self ) : if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self._StructSize:self.Hdr_dwLength ] # Return the remaining buffer , if any exists . return Buffer [ self.Hdr_dwLength: ] def AddCertData ( self , in_data ) : # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ) : self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise ValueError # Determine the end of the stream . current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field . field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field . ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer ) def Print ( self ) : self . DumpInfo () def DumpInfo ( self ) : print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ). upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData ))) def Write ( self , fs ) : fs . write ( self . Encode ()) Class variables PKCS7Guid STATIC_STRUCT_SIZE Methods AddCertData def AddCertData ( self , in_data ) View Source def AddCertData ( self , in_data ): # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ): self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self . _StructSize : self . Hdr_dwLength ] # Return the remaining buffer , if any exists . return Buffer [ self . Hdr_dwLength :] DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ). upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData ))) Encode def Encode ( self ) View Source def Encode ( self ): if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise ValueError # Determine the end of the stream . current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field . field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field . ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer ) Print def Print ( self ) View Source def Print ( self ): self . DumpInfo () Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( self . Encode ())","title":"Wincert"},{"location":"edk2toollib/uefi/wincert/#module-edk2toollibuefiwincert","text":"View Source # @file wincert.py # Code to work with UEFI WinCert data # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import io import struct import uuid from edk2toollib.utility_functions import PrintByteList class WinCertPkcs1 ( object ): # /// # /// Certificate which encapsulates the RSASSA_PKCS1-v1_5 digital signature. # /// # /// The WIN_CERTIFICATE_UEFI_PKCS1_15 structure is derived from # /// WIN_CERTIFICATE and encapsulate the information needed to # /// implement the RSASSA-PKCS1-v1_5 digital signature algorithm as # /// specified in RFC2437. # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header, where # /// wCertificateType is set to WIN_CERT_TYPE_UEFI_PKCS1_15. # /// # WIN_CERTIFICATE Hdr; # /// # /// This is the hashing algorithm which was performed on the # /// UEFI executable when creating the digital signature. # /// # EFI_GUID HashAlgorithm; # /// # /// The following is the actual digital signature. The # /// size of the signature is the same size as the key # /// (1024-bit key is 128 bytes) and can be determined by # /// subtracting the length of the other parts of this header # /// from the total length of the certificate as found in # /// Hdr.dwLength. # /// # /// UINT8 Signature[]; # /// # } WIN_CERTIFICATE_EFI_PKCS1_15; # # /// # /// The WIN_CERTIFICATE structure is part of the PE/COFF specification. # /// # typedef struct { # /// # /// The length of the entire certificate, # /// including the length of the header, in bytes. # /// # UINT32 dwLength; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure. The current revision level is 0x0200. # /// # UINT16 wRevision; # /// # /// The certificate type. See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types. The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF. # /// # UINT16 wCertificateType; # /// # /// The following is the actual certificate. The format of # /// the certificate depends on wCertificateType. # /// # /// UINT8 bCertificate[ANYSIZE_ARRAY]; # /// # } WIN_CERTIFICATE; STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s \" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) class WinCertUefiGuid ( object ): # /// # /// Certificate which encapsulates a GUID-specific digital signature # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header, where # /// wCertificateType is set to WIN_CERT_TYPE_EFI_GUID. # /// # WIN_CERTIFICATE Hdr; # /// # /// This is the unique id which determines the # /// format of the CertData. . # /// # EFI_GUID CertType; # /// # /// The following is the certificate data. The format of # /// the data is determined by the CertType. # /// If CertType is EFI_CERT_TYPE_RSA2048_SHA256_GUID, # /// the CertData will be EFI_CERT_BLOCK_RSA_2048_SHA256 structure. # /// # UINT8 CertData[1]; # } WIN_CERTIFICATE_UEFI_GUID; # # /// # /// The WIN_CERTIFICATE structure is part of the PE/COFF specification. # /// # typedef struct { # /// # /// The length of the entire certificate, # /// including the length of the header, in bytes. # /// # UINT32 dwLength; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure. The current revision level is 0x0200. # /// # UINT16 wRevision; # /// # /// The certificate type. See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types. The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF. # /// # UINT16 wCertificateType; # /// # /// The following is the actual certificate. The format of # /// the certificate depends on wCertificateType. # /// # /// UINT8 bCertificate[ANYSIZE_ARRAY]; # /// # } WIN_CERTIFICATE; _StructFormat = '<IHH16s' _StructSize = struct . calcsize ( _StructFormat ) _EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( '4aafd29d-68df-49ee-8aa9-347d375665a7' ) # Preserved for back compat. STATIC_STRUCT_SIZE = _StructSize PKCS7Guid = _EFI_CERT_TYPE_PKCS7_GUID def __init__ ( self , in_data = None ): self . Hdr_dwLength = self . _StructSize self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = self . _EFI_CERT_TYPE_PKCS7_GUID self . CertData = b '' if in_data is not None : # Account for back compat. Behave differently for file streams. if hasattr ( in_data , 'seek' ): self . PopulateFromFileStream ( in_data ) else : self . Decode ( in_data ) def Encode ( self ): if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self . _StructSize : self . Hdr_dwLength ] # Return the remaining buffer, if any exists. return Buffer [ self . Hdr_dwLength :] def AddCertData ( self , in_data ): # Account for back compat. Behave differently for file streams. if hasattr ( in_data , 'seek' ): self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise ValueError # Determine the end of the stream. current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field. field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field. ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer ) def Print ( self ): self . DumpInfo () def DumpInfo ( self ): print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ) . upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData ))) def Write ( self , fs ): fs . write ( self . Encode ()) class WinCert ( object ): STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE.wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ): return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ): return WinCertPkcs1 ( fs ) else : return None","title":"Module edk2toollib.uefi.wincert"},{"location":"edk2toollib/uefi/wincert/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/wincert/#wincert","text":"class WinCert ( / , * args , ** kwargs ) View Source class WinCert ( object ) : STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE . wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None","title":"WinCert"},{"location":"edk2toollib/uefi/wincert/#class-variables","text":"REVISION STATIC_STRUCT_SIZE WIN_CERT_TYPE_EFI_GUID WIN_CERT_TYPE_EFI_PKCS115 WIN_CERT_TYPE_NONE WIN_CERT_TYPE_PKCS_SIGNED_DATA","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/wincert/#factory","text":"def Factory ( fs ) View Source @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None","title":"Factory"},{"location":"edk2toollib/uefi/wincert/#wincertpkcs1","text":"class WinCertPkcs1 ( filestream = None ) View Source class WinCertPkcs1 ( object ) : # /// # /// Certificate which encapsulates the RSASSA_PKCS1 - v1_5 digital signature . # /// # /// The WIN_CERTIFICATE_UEFI_PKCS1_15 structure is derived from # /// WIN_CERTIFICATE and encapsulate the information needed to # /// implement the RSASSA - PKCS1 - v1_5 digital signature algorithm as # /// specified in RFC2437 . # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header , where # /// wCertificateType is set to WIN_CERT_TYPE_UEFI_PKCS1_15 . # /// # WIN_CERTIFICATE Hdr ; # /// # /// This is the hashing algorithm which was performed on the # /// UEFI executable when creating the digital signature . # /// # EFI_GUID HashAlgorithm ; # /// # /// The following is the actual digital signature . The # /// size of the signature is the same size as the key # /// ( 1024 - bit key is 128 bytes ) and can be determined by # /// subtracting the length of the other parts of this header # /// from the total length of the certificate as found in # /// Hdr . dwLength . # /// # /// UINT8 Signature [] ; # /// # } WIN_CERTIFICATE_EFI_PKCS1_15 ; # # /// # /// The WIN_CERTIFICATE structure is part of the PE / COFF specification . # /// # typedef struct { # /// # /// The length of the entire certificate , # /// including the length of the header , in bytes . # /// # UINT32 dwLength ; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure . The current revision level is 0x0200 . # /// # UINT16 wRevision ; # /// # /// The certificate type . See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types . The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF . # /// # UINT16 wCertificateType ; # /// # /// The following is the actual certificate . The format of # /// the certificate depends on wCertificateType . # /// # /// UINT8 bCertificate [ ANYSIZE_ARRAY ] ; # /// # } WIN_CERTIFICATE ; STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ) : if ( filestream is None ) : self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ) : if ( self . CertData is not None ) : raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ) : raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ) : raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) : raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ) : print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ) : fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData )","title":"WinCertPkcs1"},{"location":"edk2toollib/uefi/wincert/#class-variables_1","text":"EFI_HASH_SHA256 STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/wincert/#addcertdata","text":"def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData )","title":"AddCertData"},{"location":"edk2toollib/uefi/wincert/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/wincert/#print","text":"def Print ( self ) View Source def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl )","title":"Print"},{"location":"edk2toollib/uefi/wincert/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData )","title":"Write"},{"location":"edk2toollib/uefi/wincert/#wincertuefiguid","text":"class WinCertUefiGuid ( in_data = None ) View Source class WinCertUefiGuid ( object ) : # /// # /// Certificate which encapsulates a GUID - specific digital signature # /// # typedef struct { # /// # /// This is the standard WIN_CERTIFICATE header , where # /// wCertificateType is set to WIN_CERT_TYPE_EFI_GUID . # /// # WIN_CERTIFICATE Hdr ; # /// # /// This is the unique id which determines the # /// format of the CertData . . # /// # EFI_GUID CertType ; # /// # /// The following is the certificate data . The format of # /// the data is determined by the CertType . # /// If CertType is EFI_CERT_TYPE_RSA2048_SHA256_GUID , # /// the CertData will be EFI_CERT_BLOCK_RSA_2048_SHA256 structure . # /// # UINT8 CertData [ 1 ] ; # } WIN_CERTIFICATE_UEFI_GUID ; # # /// # /// The WIN_CERTIFICATE structure is part of the PE / COFF specification . # /// # typedef struct { # /// # /// The length of the entire certificate , # /// including the length of the header , in bytes . # /// # UINT32 dwLength ; # /// # /// The revision level of the WIN_CERTIFICATE # /// structure . The current revision level is 0x0200 . # /// # UINT16 wRevision ; # /// # /// The certificate type . See WIN_CERT_TYPE_xxx for the UEFI # /// certificate types . The UEFI specification reserves the range of # /// certificate type values from 0x0EF0 to 0x0EFF . # /// # UINT16 wCertificateType ; # /// # /// The following is the actual certificate . The format of # /// the certificate depends on wCertificateType . # /// # /// UINT8 bCertificate [ ANYSIZE_ARRAY ] ; # /// # } WIN_CERTIFICATE ; _StructFormat = '<IHH16s' _StructSize = struct . calcsize ( _StructFormat ) _EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( '4aafd29d-68df-49ee-8aa9-347d375665a7' ) # Preserved for back compat . STATIC_STRUCT_SIZE = _StructSize PKCS7Guid = _EFI_CERT_TYPE_PKCS7_GUID def __init__ ( self , in_data = None ) : self . Hdr_dwLength = self . _StructSize self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = self . _EFI_CERT_TYPE_PKCS7_GUID self . CertData = b '' if in_data is not None : # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ) : self . PopulateFromFileStream ( in_data ) else : self . Decode ( in_data ) def Encode ( self ) : if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData def Decode ( self , Buffer ) : if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0:self._StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self._StructSize:self.Hdr_dwLength ] # Return the remaining buffer , if any exists . return Buffer [ self.Hdr_dwLength: ] def AddCertData ( self , in_data ) : # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ) : self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise ValueError # Determine the end of the stream . current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field . field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field . ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer ) def Print ( self ) : self . DumpInfo () def DumpInfo ( self ) : print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ). upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData ))) def Write ( self , fs ) : fs . write ( self . Encode ())","title":"WinCertUefiGuid"},{"location":"edk2toollib/uefi/wincert/#class-variables_2","text":"PKCS7Guid STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/wincert/#addcertdata_1","text":"def AddCertData ( self , in_data ) View Source def AddCertData ( self , in_data ): # Account for back compat . Behave differently for file streams . if hasattr ( in_data , 'seek' ): self . CertData = in_data . read () else : self . CertData = in_data self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData )","title":"AddCertData"},{"location":"edk2toollib/uefi/wincert/#decode","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( dwLength , wRevision , wCertificateType , CertType ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if dwLength < self . _StructSize : raise ValueError if wRevision != WinCert . REVISION : raise ValueError if wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if CertType != self . _EFI_CERT_TYPE_PKCS7_GUID . bytes_le : raise ValueError self . Hdr_dwLength = dwLength self . Hdr_wRevision = wRevision self . Hdr_wCertificateType = wCertificateType self . CertType = uuid . UUID ( bytes_le = CertType ) self . CertData = Buffer [ self . _StructSize : self . Hdr_dwLength ] # Return the remaining buffer , if any exists . return Buffer [ self . Hdr_dwLength :]","title":"Decode"},{"location":"edk2toollib/uefi/wincert/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'WIN_CERTIFICATE.dwLength = {dwLength:08X}' . format ( dwLength = self . Hdr_dwLength )) print ( 'WIN_CERTIFICATE.wRevision = {wRevision:04X}' . format ( wRevision = self . Hdr_wRevision )) print ( 'WIN_CERTIFICATE.wCertificateType = {wCertificateType:04X}' . format ( wCertificateType = self . Hdr_wCertificateType )) print ( 'WIN_CERTIFICATE_UEFI_GUID.CertType = {Guid}' . format ( Guid = str ( self . CertType ). upper ())) print ( 'sizeof (WIN_CERTIFICATE_UEFI_GUID.CertData) = {Size:08X}' . format ( Size = len ( self . CertData )))","title":"DumpInfo"},{"location":"edk2toollib/uefi/wincert/#encode","text":"def Encode ( self ) View Source def Encode ( self ): if self . Hdr_wRevision != WinCert . REVISION : raise ValueError if self . Hdr_wCertificateType != WinCert . WIN_CERT_TYPE_EFI_GUID : raise ValueError if self . CertType != self . _EFI_CERT_TYPE_PKCS7_GUID : raise ValueError self . Hdr_dwLength = self . _StructSize + len ( self . CertData ) WinCertHeader = struct . pack ( self . _StructFormat , self . Hdr_dwLength , self . Hdr_wRevision , self . Hdr_wCertificateType , self . CertType . bytes_le ) return WinCertHeader + self . CertData","title":"Encode"},{"location":"edk2toollib/uefi/wincert/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise ValueError # Determine the end of the stream . current = fs . tell () end = fs . seek ( 0 , io . SEEK_END ) fs . seek ( current ) # Make sure that we can at least parse the size field . field_string = \"<I\" field_size = struct . calcsize ( field_string ) if ( end - current ) < field_size : raise ValueError # Parse the size field . ( buffer_size ,) = struct . unpack ( field_string , fs . read ( field_size )) if ( end - current ) < buffer_size : raise ValueError fs . seek ( current ) object_buffer = fs . read ( buffer_size ) return self . Decode ( object_buffer )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/wincert/#print_1","text":"def Print ( self ) View Source def Print ( self ): self . DumpInfo ()","title":"Print"},{"location":"edk2toollib/uefi/wincert/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( self . Encode ())","title":"Write"},{"location":"edk2toollib/uefi/edk2/","text":"Module edk2toollib.uefi.edk2 View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.edk2.build_objects edk2toollib.uefi.edk2.fmp_payload_header edk2toollib.uefi.edk2.ftw_working_block_format edk2toollib.uefi.edk2.guid_list edk2toollib.uefi.edk2.guid_list_test edk2toollib.uefi.edk2.parsers edk2toollib.uefi.edk2.path_utilities edk2toollib.uefi.edk2.path_utilities_test edk2toollib.uefi.edk2.variable_format edk2toollib.uefi.edk2.variable_format_test edk2toollib.uefi.edk2.variablestore_manulipulations","title":"Index"},{"location":"edk2toollib/uefi/edk2/#module-edk2toollibuefiedk2","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi.edk2"},{"location":"edk2toollib/uefi/edk2/#sub-modules","text":"edk2toollib.uefi.edk2.build_objects edk2toollib.uefi.edk2.fmp_payload_header edk2toollib.uefi.edk2.ftw_working_block_format edk2toollib.uefi.edk2.guid_list edk2toollib.uefi.edk2.guid_list_test edk2toollib.uefi.edk2.parsers edk2toollib.uefi.edk2.path_utilities edk2toollib.uefi.edk2.path_utilities_test edk2toollib.uefi.edk2.variable_format edk2toollib.uefi.edk2.variable_format_test edk2toollib.uefi.edk2.variablestore_manulipulations","title":"Sub-modules"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/","text":"Module edk2toollib.uefi.edk2.fmp_payload_header FmpPayloadHeader View Source ## @file # Module that encodes and decodes a FMP_PAYLOAD_HEADER with a payload. # The FMP_PAYLOAD_HEADER is processed by the FmpPayloadHeaderLib in the # FmpDevicePkg. # # Copyright (c) 2018, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpPayloadHeader ''' import struct def _SIGNATURE_32 ( A , B , C , D ): return struct . unpack ( '=I' , bytearray ( A + B + C + D , 'ascii' ))[ 0 ] def _SIGNATURE_32_TO_STRING ( Signature ): return struct . pack ( \"<I\" , Signature ) . decode () class FmpPayloadHeaderClass ( object ): # # typedef struct { # UINT32 Signature; # UINT32 HeaderSize; # UINT32 FwVersion; # UINT32 LowestSupportedVersion; # } FMP_PAYLOAD_HEADER; # # #define FMP_PAYLOAD_HEADER_SIGNATURE SIGNATURE_32 ('M', 'S', 'S', '1') # _StructFormat = '<IIII' _StructSize = struct . calcsize ( _StructFormat ) _FMP_PAYLOAD_HEADER_SIGNATURE = _SIGNATURE_32 ( 'M' , 'S' , 'S' , '1' ) def __init__ ( self ): self . Signature = self . _FMP_PAYLOAD_HEADER_SIGNATURE self . HeaderSize = self . _StructSize self . FwVersion = 0x00000000 self . LowestSupportedVersion = 0x00000000 self . Payload = b '' def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE : raise ValueError if HeaderSize < self . _StructSize : raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize :] return self . Payload def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) Classes FmpPayloadHeaderClass class FmpPayloadHeaderClass ( ) View Source class FmpPayloadHeaderClass ( object ): # # typedef struct { # UINT32 Signature; # UINT32 HeaderSize; # UINT32 FwVersion; # UINT32 LowestSupportedVersion; # } FMP_PAYLOAD_HEADER; # # #define FMP_PAYLOAD_HEADER_SIGNATURE SIGNATURE_32 ('M', 'S', 'S', '1') # _StructFormat = '<IIII' _StructSize = struct . calcsize ( _StructFormat ) _FMP_PAYLOAD_HEADER_SIGNATURE = _SIGNATURE_32 ( 'M' , 'S' , 'S' , '1' ) def __init__ ( self ): self . Signature = self . _FMP_PAYLOAD_HEADER_SIGNATURE self . HeaderSize = self . _StructSize self . FwVersion = 0x00000000 self . LowestSupportedVersion = 0x00000000 self . Payload = b'' def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE: raise ValueError if HeaderSize < self . _StructSize: raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize: ] return self . Payload def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) Methods Decode def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE : raise ValueError if HeaderSize < self . _StructSize : raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize :] return self . Payload DumpInfo def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload ))) Encode def Encode ( self ) View Source def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload","title":"Fmp payload header"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#module-edk2toollibuefiedk2fmp_payload_header","text":"FmpPayloadHeader View Source ## @file # Module that encodes and decodes a FMP_PAYLOAD_HEADER with a payload. # The FMP_PAYLOAD_HEADER is processed by the FmpPayloadHeaderLib in the # FmpDevicePkg. # # Copyright (c) 2018, Intel Corporation. All rights reserved.<BR> # SPDX-License-Identifier: BSD-2-Clause-Patent # ''' FmpPayloadHeader ''' import struct def _SIGNATURE_32 ( A , B , C , D ): return struct . unpack ( '=I' , bytearray ( A + B + C + D , 'ascii' ))[ 0 ] def _SIGNATURE_32_TO_STRING ( Signature ): return struct . pack ( \"<I\" , Signature ) . decode () class FmpPayloadHeaderClass ( object ): # # typedef struct { # UINT32 Signature; # UINT32 HeaderSize; # UINT32 FwVersion; # UINT32 LowestSupportedVersion; # } FMP_PAYLOAD_HEADER; # # #define FMP_PAYLOAD_HEADER_SIGNATURE SIGNATURE_32 ('M', 'S', 'S', '1') # _StructFormat = '<IIII' _StructSize = struct . calcsize ( _StructFormat ) _FMP_PAYLOAD_HEADER_SIGNATURE = _SIGNATURE_32 ( 'M' , 'S' , 'S' , '1' ) def __init__ ( self ): self . Signature = self . _FMP_PAYLOAD_HEADER_SIGNATURE self . HeaderSize = self . _StructSize self . FwVersion = 0x00000000 self . LowestSupportedVersion = 0x00000000 self . Payload = b '' def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE : raise ValueError if HeaderSize < self . _StructSize : raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize :] return self . Payload def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload )))","title":"Module edk2toollib.uefi.edk2.fmp_payload_header"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#fmppayloadheaderclass","text":"class FmpPayloadHeaderClass ( ) View Source class FmpPayloadHeaderClass ( object ): # # typedef struct { # UINT32 Signature; # UINT32 HeaderSize; # UINT32 FwVersion; # UINT32 LowestSupportedVersion; # } FMP_PAYLOAD_HEADER; # # #define FMP_PAYLOAD_HEADER_SIGNATURE SIGNATURE_32 ('M', 'S', 'S', '1') # _StructFormat = '<IIII' _StructSize = struct . calcsize ( _StructFormat ) _FMP_PAYLOAD_HEADER_SIGNATURE = _SIGNATURE_32 ( 'M' , 'S' , 'S' , '1' ) def __init__ ( self ): self . Signature = self . _FMP_PAYLOAD_HEADER_SIGNATURE self . HeaderSize = self . _StructSize self . FwVersion = 0x00000000 self . LowestSupportedVersion = 0x00000000 self . Payload = b'' def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize: raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE: raise ValueError if HeaderSize < self . _StructSize: raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize: ] return self . Payload def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload )))","title":"FmpPayloadHeaderClass"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#decode","text":"def Decode ( self , Buffer ) View Source def Decode ( self , Buffer ): if len ( Buffer ) < self . _StructSize : raise ValueError ( Signature , HeaderSize , FwVersion , LowestSupportedVersion ) = struct . unpack ( self . _StructFormat , Buffer [ 0 : self . _StructSize ] ) if Signature != self . _FMP_PAYLOAD_HEADER_SIGNATURE : raise ValueError if HeaderSize < self . _StructSize : raise ValueError self . Signature = Signature self . HeaderSize = HeaderSize self . FwVersion = FwVersion self . LowestSupportedVersion = LowestSupportedVersion self . Payload = Buffer [ self . HeaderSize :] return self . Payload","title":"Decode"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#dumpinfo","text":"def DumpInfo ( self ) View Source def DumpInfo ( self ): print ( 'FMP_PAYLOAD_HEADER.Signature = {Signature:08X} ({SignatureString})' . format ( Signature = self . Signature , SignatureString = _SIGNATURE_32_TO_STRING ( self . Signature ))) print ( 'FMP_PAYLOAD_HEADER.HeaderSize = {HeaderSize:08X}' . format ( HeaderSize = self . HeaderSize )) print ( 'FMP_PAYLOAD_HEADER.FwVersion = {FwVersion:08X}' . format ( FwVersion = self . FwVersion )) print ( 'FMP_PAYLOAD_HEADER.LowestSupportedVersion = {LowestSupportedVersion:08X}' . format ( LowestSupportedVersion = self . LowestSupportedVersion )) print ( 'sizeof (Payload) = {Size:08X}' . format ( Size = len ( self . Payload )))","title":"DumpInfo"},{"location":"edk2toollib/uefi/edk2/fmp_payload_header/#encode","text":"def Encode ( self ) View Source def Encode ( self ): FmpPayloadHeader = struct . pack ( self . _StructFormat , self . Signature , self . HeaderSize , self . FwVersion , self . LowestSupportedVersion ) return FmpPayloadHeader + self . Payload","title":"Encode"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/","text":"Module edk2toollib.uefi.edk2.ftw_working_block_format View Source # @file # Module contains helper classes for working with Fault Tolerant Working block content # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid import sys # # UEFI GUIDs # EdkiiWorkingBlockSignatureGuid = uuid . UUID ( fields = ( 0x9E58292B , 0x7C68 , 0x497D , 0xA0 , 0xCE , 0x6500FD9F1B95 )) # # The EDKII Fault tolerant working block header. # The header is immediately followed by the write queue data. # # typedef struct { # EFI_GUID Signature; # UINT32 Crc; # UINT8 WorkingBlockValid : 1; # UINT8 WorkingBlockInvalid : 1; # UINT8 Reserved : 6; # UINT8 Reserved3[3]; # UINT64 WriteQueueSize; # } EFI_FAULT_TOLERANT_WORKING_BLOCK_HEADER; class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" # spell-checker: disable-line self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s \" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) # # EFI Fault tolerant block update write queue entry. # # typedef struct { # UINT8 HeaderAllocated : 1; # UINT8 WritesAllocated : 1; # UINT8 Complete : 1; # UINT8 Reserved : 5; # EFI_GUID CallerId; # UINT64 NumberOfWrites; # UINT64 PrivateDataSize; # } EFI_FAULT_TOLERANT_WRITE_HEADER; class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) # # EFI Fault tolerant block update write queue record. # # typedef struct { # UINT8 BootBlockUpdate : 1; # UINT8 SpareComplete : 1; # UINT8 DestinationComplete : 1; # UINT8 Reserved : 5; # EFI_LBA Lba; # UINT64 Offset; # UINT64 Length; # INT64 RelativeOffset; # } EFI_FAULT_TOLERANT_WRITE_RECORD; class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" # spell-checker: disable-line self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) Variables EdkiiWorkingBlockSignatureGuid Classes EfiFtwWorkingBlockHeader class EfiFtwWorkingBlockHeader ( ) View Source class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" # spell-checker: disable-line self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid: raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self serialize def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) EfiFtwWriteHeader class EfiFtwWriteHeader ( ) View Source class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self serialize def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) EfiFtwWriteRecord class EfiFtwWriteRecord ( ) View Source class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" # spell-checker: disable-line self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self serialize def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"Ftw working block format"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#module-edk2toollibuefiedk2ftw_working_block_format","text":"View Source # @file # Module contains helper classes for working with Fault Tolerant Working block content # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid import sys # # UEFI GUIDs # EdkiiWorkingBlockSignatureGuid = uuid . UUID ( fields = ( 0x9E58292B , 0x7C68 , 0x497D , 0xA0 , 0xCE , 0x6500FD9F1B95 )) # # The EDKII Fault tolerant working block header. # The header is immediately followed by the write queue data. # # typedef struct { # EFI_GUID Signature; # UINT32 Crc; # UINT8 WorkingBlockValid : 1; # UINT8 WorkingBlockInvalid : 1; # UINT8 Reserved : 6; # UINT8 Reserved3[3]; # UINT64 WriteQueueSize; # } EFI_FAULT_TOLERANT_WORKING_BLOCK_HEADER; class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" # spell-checker: disable-line self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s \" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) # # EFI Fault tolerant block update write queue entry. # # typedef struct { # UINT8 HeaderAllocated : 1; # UINT8 WritesAllocated : 1; # UINT8 Complete : 1; # UINT8 Reserved : 5; # EFI_GUID CallerId; # UINT64 NumberOfWrites; # UINT64 PrivateDataSize; # } EFI_FAULT_TOLERANT_WRITE_HEADER; class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) # # EFI Fault tolerant block update write queue record. # # typedef struct { # UINT8 BootBlockUpdate : 1; # UINT8 SpareComplete : 1; # UINT8 DestinationComplete : 1; # UINT8 Reserved : 5; # EFI_LBA Lba; # UINT64 Offset; # UINT64 Length; # INT64 RelativeOffset; # } EFI_FAULT_TOLERANT_WRITE_RECORD; class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" # spell-checker: disable-line self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"Module edk2toollib.uefi.edk2.ftw_working_block_format"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#variables","text":"EdkiiWorkingBlockSignatureGuid","title":"Variables"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwworkingblockheader","text":"class EfiFtwWorkingBlockHeader ( ) View Source class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" # spell-checker: disable-line self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid: raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize )","title":"EfiFtwWorkingBlockHeader"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwwriteheader","text":"class EfiFtwWriteHeader ( ) View Source class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize )","title":"EfiFtwWriteHeader"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize_1","text":"def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwwriterecord","text":"class EfiFtwWriteRecord ( ) View Source class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" # spell-checker: disable-line self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"EfiFtwWriteRecord"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file_2","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize_2","text":"def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/guid_list/","text":"Module edk2toollib.uefi.edk2.guid_list View Source # @file guid_list # # Simple list of GuidListEntry objects parsed from edk2 specific files. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import os from edk2toollib.gitignore_parser import parse_gitignore_lines from edk2toollib.uefi.edk2.parsers.dec_parser import DecParser from edk2toollib.uefi.edk2.parsers.inf_parser import InfParser class GuidListEntry (): def __init__ ( self , name : str , guid : str , filepath : str ): \"\"\" Create GuidListEntry for later review and compare. name: name of guid guid: registry format guid in string format filepath: absolute path to file where this guid was found \"\"\" self . name = name self . guid = guid self . absfilepath = filepath def __str__ ( self ): return f \"GUID: {self.guid} NAME: {self.name} FILE: {self.absfilepath}\" class GuidList (): @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ): for d in dirs [:]: fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )): logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )): logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower () . endswith ( \".dec\" )): with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower () . endswith ( \".inf\" )): return GuidList . parse_guids_from_inf ( filename ) else : return [] @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ], dec . Dict [ \"PACKAGE_GUID\" ], filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry ( inf . Dict [ \"BASE_NAME\" ], inf . Dict [ \"FILE_GUID\" ] . upper (), filename )] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return [] Classes GuidList class GuidList ( / , * args , ** kwargs ) View Source class GuidList () : @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ) : for d in dirs [ : ] : fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower (). endswith ( \".dec\" )) : with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower (). endswith ( \".inf\" )) : return GuidList . parse_guids_from_inf ( filename ) else : return [] @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ] , dec . Dict [ \"PACKAGE_GUID\" ] , filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry(inf.Dict[\"BASE_NAME\" ] , inf . Dict [ \"FILE_GUID\" ] . upper (), filename ) ] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return [] Static methods guidlist_from_filesystem def guidlist_from_filesystem ( folder : str , ignore_lines : list = [] ) -> list Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders View Source @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ) : for d in dirs [ : ] : fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids parse_guids_from_dec def parse_guids_from_dec ( stream , filename : str ) -> list find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file View Source @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ] , dec . Dict [ \"PACKAGE_GUID\" ] , filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results parse_guids_from_edk2_file def parse_guids_from_edk2_file ( filename : str ) -> list parse edk2 files for guids filename: abspath to dec file View Source @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower (). endswith ( \".dec\" )) : with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower (). endswith ( \".inf\" )) : return GuidList . parse_guids_from_inf ( filename ) else : return [] parse_guids_from_inf def parse_guids_from_inf ( filename : str ) -> list find the module guid in an Edk2 inf file filename: abspath to inf file View Source @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry(inf.Dict[\"BASE_NAME\" ] , inf . Dict [ \"FILE_GUID\" ] . upper (), filename ) ] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return [] GuidListEntry class GuidListEntry ( name : str , guid : str , filepath : str ) View Source class GuidListEntry (): def __init__ ( self , name: str , guid: str , filepath: str ): \"\"\" Create GuidListEntry for later review and compare. name: name of guid guid: registry format guid in string format filepath: absolute path to file where this guid was found \"\"\" self . name = name self . guid = guid self . absfilepath = filepath def __str__ ( self ): return f \"GUID: {self.guid} NAME: {self.name} FILE: {self.absfilepath}\"","title":"Guid list"},{"location":"edk2toollib/uefi/edk2/guid_list/#module-edk2toollibuefiedk2guid_list","text":"View Source # @file guid_list # # Simple list of GuidListEntry objects parsed from edk2 specific files. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import os from edk2toollib.gitignore_parser import parse_gitignore_lines from edk2toollib.uefi.edk2.parsers.dec_parser import DecParser from edk2toollib.uefi.edk2.parsers.inf_parser import InfParser class GuidListEntry (): def __init__ ( self , name : str , guid : str , filepath : str ): \"\"\" Create GuidListEntry for later review and compare. name: name of guid guid: registry format guid in string format filepath: absolute path to file where this guid was found \"\"\" self . name = name self . guid = guid self . absfilepath = filepath def __str__ ( self ): return f \"GUID: {self.guid} NAME: {self.name} FILE: {self.absfilepath}\" class GuidList (): @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ): for d in dirs [:]: fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )): logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )): logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower () . endswith ( \".dec\" )): with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower () . endswith ( \".inf\" )): return GuidList . parse_guids_from_inf ( filename ) else : return [] @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ) . upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ], dec . Dict [ \"PACKAGE_GUID\" ], filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry ( inf . Dict [ \"BASE_NAME\" ], inf . Dict [ \"FILE_GUID\" ] . upper (), filename )] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return []","title":"Module edk2toollib.uefi.edk2.guid_list"},{"location":"edk2toollib/uefi/edk2/guid_list/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/guid_list/#guidlist","text":"class GuidList ( / , * args , ** kwargs ) View Source class GuidList () : @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ) : for d in dirs [ : ] : fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower (). endswith ( \".dec\" )) : with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower (). endswith ( \".inf\" )) : return GuidList . parse_guids_from_inf ( filename ) else : return [] @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ] , dec . Dict [ \"PACKAGE_GUID\" ] , filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry(inf.Dict[\"BASE_NAME\" ] , inf . Dict [ \"FILE_GUID\" ] . upper (), filename ) ] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return []","title":"GuidList"},{"location":"edk2toollib/uefi/edk2/guid_list/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/guid_list/#guidlist_from_filesystem","text":"def guidlist_from_filesystem ( folder : str , ignore_lines : list = [] ) -> list Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders View Source @staticmethod def guidlist_from_filesystem ( folder : str , ignore_lines : list = list ()) -> list : \"\"\" Create a list of GuidListEntry from files found in the file system folder: path string to root folder to walk ignore_lines: list of gitignore syntax to ignore files and folders \"\"\" guids = [] ignore = parse_gitignore_lines ( ignore_lines , os . path . join ( folder , \"nofile.txt\" ), folder ) for root , dirs , files in os . walk ( folder ) : for d in dirs [ : ] : fullpath = os . path . join ( root , d ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore folder: {fullpath}\" ) dirs . remove ( d ) for name in files : fullpath = os . path . join ( root , name ) if ( ignore ( fullpath )) : logging . debug ( f \"Ignore file: {fullpath}\" ) continue new_guids = GuidList . parse_guids_from_edk2_file ( fullpath ) guids . extend ( new_guids ) return guids","title":"guidlist_from_filesystem"},{"location":"edk2toollib/uefi/edk2/guid_list/#parse_guids_from_dec","text":"def parse_guids_from_dec ( stream , filename : str ) -> list find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file View Source @staticmethod def parse_guids_from_dec ( stream , filename : str ) -> list : \"\"\" find all guids in a dec file contents contained with stream stream: lines of dec file content filename: abspath to dec file \"\"\" results = [] dec = DecParser () dec . ParseStream ( stream ) for p in dec . Protocols : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . PPIs : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) for p in dec . Guids : results . append ( GuidListEntry ( p . name , str ( p . guid ). upper (), filename )) try : results . append ( GuidListEntry ( dec . Dict [ \"PACKAGE_NAME\" ] , dec . Dict [ \"PACKAGE_GUID\" ] , filename )) except : logging . warning ( \"Failed to find Package Guid from dec file: \" + filename ) return results","title":"parse_guids_from_dec"},{"location":"edk2toollib/uefi/edk2/guid_list/#parse_guids_from_edk2_file","text":"def parse_guids_from_edk2_file ( filename : str ) -> list parse edk2 files for guids filename: abspath to dec file View Source @staticmethod def parse_guids_from_edk2_file ( filename : str ) -> list : \"\"\" parse edk2 files for guids filename: abspath to dec file \"\"\" if ( filename . lower (). endswith ( \".dec\" )) : with open ( filename , \"r\" ) as f : return GuidList . parse_guids_from_dec ( f , filename ) elif ( filename . lower (). endswith ( \".inf\" )) : return GuidList . parse_guids_from_inf ( filename ) else : return []","title":"parse_guids_from_edk2_file"},{"location":"edk2toollib/uefi/edk2/guid_list/#parse_guids_from_inf","text":"def parse_guids_from_inf ( filename : str ) -> list find the module guid in an Edk2 inf file filename: abspath to inf file View Source @staticmethod def parse_guids_from_inf ( filename : str ) -> list : \"\"\" find the module guid in an Edk2 inf file filename: abspath to inf file \"\"\" inf = InfParser () inf . ParseFile ( filename ) try : return [ GuidListEntry(inf.Dict[\"BASE_NAME\" ] , inf . Dict [ \"FILE_GUID\" ] . upper (), filename ) ] except : logging . warning ( \"Failed to find info from INF file: \" + filename ) return []","title":"parse_guids_from_inf"},{"location":"edk2toollib/uefi/edk2/guid_list/#guidlistentry","text":"class GuidListEntry ( name : str , guid : str , filepath : str ) View Source class GuidListEntry (): def __init__ ( self , name: str , guid: str , filepath: str ): \"\"\" Create GuidListEntry for later review and compare. name: name of guid guid: registry format guid in string format filepath: absolute path to file where this guid was found \"\"\" self . name = name self . guid = guid self . absfilepath = filepath def __str__ ( self ): return f \"GUID: {self.guid} NAME: {self.name} FILE: {self.absfilepath}\"","title":"GuidListEntry"},{"location":"edk2toollib/uefi/edk2/path_utilities/","text":"Module edk2toollib.uefi.edk2.path_utilities View Source # @file path_utilities.py # Code to help convert Edk2, absolute, and relative file paths # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import fnmatch # # Class to help convert from absolute path to EDK2 build path # using workspace and packagepath variables # class Edk2Path ( object ): # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path. Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ): self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )): self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )): self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )): self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )): self . PackagePathList . append ( wsr ) else : # assume current working dir relative. Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )): self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ): raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ): if os . path . normcase ( abspath ) . startswith ( a ): # found our path...now use original strings to avoid # change in case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s \" % ( abspath , a )) break if ( not found ): # Does path start with workspace if os . path . normcase ( abspath ) . startswith ( os . path . normcase ( self . WorkspacePath )): # found our path...now use original strings to avoid # change in case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s \" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn't find the path for conversion. self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s \" % abspath ) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): ''' Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn't match the case in the filesystem. If not valid or doesn't exist return None''' if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s \" % relpath ) return None # Find the package this path belongs to using # some Heuristic. This isn't perfect but at least # identifies the directory consistently # # @param InputPath: absolute path to module # # @ret Name of Package that the module is in. def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s \" % InputPath ) # Make a list that has the path case normalized for comparison. # This only does anything on Windows NormCasePackagesPathList = [ os . path . normcase ( x ) for x in self . PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ): # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ): found_in_pp = True break if ( not found_in_pp ): self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario. dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ): # 100 is just a counter to avoid infinite loops. Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s . Pkg is: %s \" , dirpath , a ) return a # # if at the root of the workspace return the previous dir. # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s \" % a ) return a # # if at the root of a packagepath return the previous dir. # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s \" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s \" % InputPath ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None # Find the list of modules (infs) that file path is in # # for now just assume any inf in the same dir or if none # then check parent dir. # # @param InputPath: absolute path to file # # @ret list of abs path file paths for module infs def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s \" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ): return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.inf' ): self . logger . debug ( \"Found INF file in %s . INf is: %s \" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if ( len ( modules ) == 0 ): dirpath = os . path . dirname ( dirpath ) for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.inf' ): self . logger . debug ( \"Found INF file in %s . INf is: %s \" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules Classes Edk2Path class Edk2Path ( ws , packagepathlist ) View Source class Edk2Path ( object ) : # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path . Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ) : self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )) : self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )) : self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )) : self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )) : self . PackagePathList . append ( wsr ) else : # assume current working dir relative . Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )) : self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ) : raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) : ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ) : if os . path . normcase ( abspath ). startswith ( a ) : # found our path ... now use original strings to avoid # change in case relpath = abspath [ len(a): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ) : # Does path start with workspace if os . path . normcase ( abspath ). startswith ( os . path . normcase ( self . WorkspacePath )) : # found our path ... now use original strings to avoid # change in case relpath = abspath [ len(self.WorkspacePath): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ) : relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn 't find the path for conversion. self.logger.error(\"Failed to convert AbsPath to Edk2Relative Path\") self.logger.error(\"AbsolutePath: %s\" % abspath) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath(self, relpath): ''' Given a edk2 relative path return an absolute path to the file in this workspace . Note : For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn 't match the case in the filesystem. If not valid or doesn' t exist return None ''' if relpath is None: return None relpath = relpath.replace(\"/\", os.sep) abspath = os.path.join(self.WorkspacePath, relpath) if os.path.exists(abspath): return abspath for a in self.PackagePathList: abspath = os.path.join(a, relpath) if(os.path.exists(abspath)): return abspath self.logger.error(\"Failed to convert Edk2Relative Path to an Absolute Path on this system.\") self.logger.error(\"Relative Path: %s\" % relpath) return None # Find the package this path belongs to using # some Heuristic. This isn' t perfect but at least # identifies the directory consistently # # @param InputPath : absolute path to module # # @ret Name of Package that the module is in . def GetContainingPackage ( self , InputPath ) : self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) # Make a list that has the path case normalized for comparison . # This only does anything on Windows NormCasePackagesPathList = [ os.path.normcase(x) for x in self.PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ) : # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ) : found_in_pp = True break if ( not found_in_pp ) : self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario . dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ) : # 100 is just a counter to avoid infinite loops . Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.dec' ) : a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # Find the list of modules ( infs ) that file path is in # # for now just assume any inf in the same dir or if none # then check parent dir . # # @param InputPath : absolute path to file # # @ret list of abs path file paths for module infs def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s\" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ) : return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.inf' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn 't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if(len(modules) == 0): dirpath = os.path.dirname(dirpath) for f in os.listdir(dirpath): if fnmatch.fnmatch(f.lower(), ' * . inf ' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules Methods GetAbsolutePathOnThisSytemFromEdk2RelativePath def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ) Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn\u2019t match the case in the filesystem. If not valid or doesn\u2019t exist return None View Source def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): ''' Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn' t match the case in the filesystem . If not valid or doesn 't exist return None''' if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s\" % relpath ) return None GetContainingModules def GetContainingModules ( self , InputPath : str ) -> list View Source def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s\" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ) : return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.inf' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn 't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if(len(modules) == 0): dirpath = os.path.dirname(dirpath) for f in os.listdir(dirpath): if fnmatch.fnmatch(f.lower(), ' * . inf ' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules GetContainingPackage def GetContainingPackage ( self , InputPath ) View Source def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) # Make a list that has the path case normalized for comparison . # This only does anything on Windows NormCasePackagesPathList = [ os . path . normcase ( x ) for x in self . PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ): # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ): found_in_pp = True break if ( not found_in_pp ): self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario . dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ): # 100 is just a counter to avoid infinite loops . Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None GetEdk2RelativePathFromAbsolutePath def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None View Source def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ): if os . path . normcase ( abspath ). startswith ( a ): # found our path ... now use original strings to avoid # change in case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ): # Does path start with workspace if os . path . normcase ( abspath ). startswith ( os . path . normcase ( self . WorkspacePath )): # found our path ... now use original strings to avoid # change in case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn ' t find the path for conversion . self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s\" % abspath ) return None","title":"Path utilities"},{"location":"edk2toollib/uefi/edk2/path_utilities/#module-edk2toollibuefiedk2path_utilities","text":"View Source # @file path_utilities.py # Code to help convert Edk2, absolute, and relative file paths # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import fnmatch # # Class to help convert from absolute path to EDK2 build path # using workspace and packagepath variables # class Edk2Path ( object ): # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path. Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ): self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )): self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )): self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )): self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )): self . PackagePathList . append ( wsr ) else : # assume current working dir relative. Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )): self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ): raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ): if os . path . normcase ( abspath ) . startswith ( a ): # found our path...now use original strings to avoid # change in case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s \" % ( abspath , a )) break if ( not found ): # Does path start with workspace if os . path . normcase ( abspath ) . startswith ( os . path . normcase ( self . WorkspacePath )): # found our path...now use original strings to avoid # change in case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s \" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn't find the path for conversion. self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s \" % abspath ) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): ''' Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn't match the case in the filesystem. If not valid or doesn't exist return None''' if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s \" % relpath ) return None # Find the package this path belongs to using # some Heuristic. This isn't perfect but at least # identifies the directory consistently # # @param InputPath: absolute path to module # # @ret Name of Package that the module is in. def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s \" % InputPath ) # Make a list that has the path case normalized for comparison. # This only does anything on Windows NormCasePackagesPathList = [ os . path . normcase ( x ) for x in self . PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ): # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ): found_in_pp = True break if ( not found_in_pp ): self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario. dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ): # 100 is just a counter to avoid infinite loops. Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s . Pkg is: %s \" , dirpath , a ) return a # # if at the root of the workspace return the previous dir. # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s \" % a ) return a # # if at the root of a packagepath return the previous dir. # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s \" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s \" % InputPath ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None # Find the list of modules (infs) that file path is in # # for now just assume any inf in the same dir or if none # then check parent dir. # # @param InputPath: absolute path to file # # @ret list of abs path file paths for module infs def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s \" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ): return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.inf' ): self . logger . debug ( \"Found INF file in %s . INf is: %s \" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if ( len ( modules ) == 0 ): dirpath = os . path . dirname ( dirpath ) for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.inf' ): self . logger . debug ( \"Found INF file in %s . INf is: %s \" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules","title":"Module edk2toollib.uefi.edk2.path_utilities"},{"location":"edk2toollib/uefi/edk2/path_utilities/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/path_utilities/#edk2path","text":"class Edk2Path ( ws , packagepathlist ) View Source class Edk2Path ( object ) : # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path . Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ) : self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )) : self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )) : self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )) : self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )) : self . PackagePathList . append ( wsr ) else : # assume current working dir relative . Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )) : self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ) : raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) : ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ) : if os . path . normcase ( abspath ). startswith ( a ) : # found our path ... now use original strings to avoid # change in case relpath = abspath [ len(a): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ) : # Does path start with workspace if os . path . normcase ( abspath ). startswith ( os . path . normcase ( self . WorkspacePath )) : # found our path ... now use original strings to avoid # change in case relpath = abspath [ len(self.WorkspacePath): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ) : relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn 't find the path for conversion. self.logger.error(\"Failed to convert AbsPath to Edk2Relative Path\") self.logger.error(\"AbsolutePath: %s\" % abspath) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath(self, relpath): ''' Given a edk2 relative path return an absolute path to the file in this workspace . Note : For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn 't match the case in the filesystem. If not valid or doesn' t exist return None ''' if relpath is None: return None relpath = relpath.replace(\"/\", os.sep) abspath = os.path.join(self.WorkspacePath, relpath) if os.path.exists(abspath): return abspath for a in self.PackagePathList: abspath = os.path.join(a, relpath) if(os.path.exists(abspath)): return abspath self.logger.error(\"Failed to convert Edk2Relative Path to an Absolute Path on this system.\") self.logger.error(\"Relative Path: %s\" % relpath) return None # Find the package this path belongs to using # some Heuristic. This isn' t perfect but at least # identifies the directory consistently # # @param InputPath : absolute path to module # # @ret Name of Package that the module is in . def GetContainingPackage ( self , InputPath ) : self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) # Make a list that has the path case normalized for comparison . # This only does anything on Windows NormCasePackagesPathList = [ os.path.normcase(x) for x in self.PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ) : # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ) : found_in_pp = True break if ( not found_in_pp ) : self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario . dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ) : # 100 is just a counter to avoid infinite loops . Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.dec' ) : a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # Find the list of modules ( infs ) that file path is in # # for now just assume any inf in the same dir or if none # then check parent dir . # # @param InputPath : absolute path to file # # @ret list of abs path file paths for module infs def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s\" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ) : return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.inf' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn 't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if(len(modules) == 0): dirpath = os.path.dirname(dirpath) for f in os.listdir(dirpath): if fnmatch.fnmatch(f.lower(), ' * . inf ' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules","title":"Edk2Path"},{"location":"edk2toollib/uefi/edk2/path_utilities/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getabsolutepathonthissytemfromedk2relativepath","text":"def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ) Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn\u2019t match the case in the filesystem. If not valid or doesn\u2019t exist return None View Source def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): ''' Given a edk2 relative path return an absolute path to the file in this workspace. Note: For case insensitive operating systems the case of the input relpath will be used for the return value even if it doesn' t match the case in the filesystem . If not valid or doesn 't exist return None''' if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s\" % relpath ) return None","title":"GetAbsolutePathOnThisSytemFromEdk2RelativePath"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getcontainingmodules","text":"def GetContainingModules ( self , InputPath : str ) -> list View Source def GetContainingModules ( self , InputPath : str ) -> list : self . logger . debug ( \"GetContainingModules: %s\" % InputPath ) # if INF return self if fnmatch . fnmatch ( InputPath . lower (), '*.inf' ) : return [ InputPath ] modules = [] # Check current dir dirpath = os . path . dirname ( InputPath ) for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f . lower (), '*.inf' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) # if didn 't find any in current dir go to parent dir. # this handles cases like: # ModuleDir/ # Module.inf # x64/ # file.c # if(len(modules) == 0): dirpath = os.path.dirname(dirpath) for f in os.listdir(dirpath): if fnmatch.fnmatch(f.lower(), ' * . inf ' ) : self . logger . debug ( \"Found INF file in %s. INf is: %s\" , dirpath , f ) modules . append ( os . path . join ( dirpath , f )) return modules","title":"GetContainingModules"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getcontainingpackage","text":"def GetContainingPackage ( self , InputPath ) View Source def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) # Make a list that has the path case normalized for comparison . # This only does anything on Windows NormCasePackagesPathList = [ os . path . normcase ( x ) for x in self . PackagePathList ] # check InputPath to make sure it is at least in the folder structure of the code tree if os . path . normcase ( self . WorkspacePath ) not in os . path . normcase ( InputPath ): # not in workspace - check all the packages paths found_in_pp = False for p in NormCasePackagesPathList : if p in os . path . normcase ( InputPath ): found_in_pp = True break if ( not found_in_pp ): self . logger . error ( f \"{InputPath} not in code tree\" ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None # InputPath is in workspace or PackagesPath for worst case scenario . dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) for _ in range ( 100 ): # 100 is just a counter to avoid infinite loops . Path nodes are unlikely to exceed 100 # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f . lower (), '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) == os . path . normcase ( self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if os . path . normcase ( dirpath ) in NormCasePackagesPathList : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None","title":"GetContainingPackage"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getedk2relativepathfromabsolutepath","text":"def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None View Source def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): ''' Given an absolute path return a edk2 path relative to workspace or packagespath. If not valid return None ''' relpath = None found = False if abspath is None : return None for a in ( os . path . normcase ( p ) for p in self . PackagePathList ): if os . path . normcase ( abspath ). startswith ( a ): # found our path ... now use original strings to avoid # change in case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ): # Does path start with workspace if os . path . normcase ( abspath ). startswith ( os . path . normcase ( self . WorkspacePath )): # found our path ... now use original strings to avoid # change in case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn ' t find the path for conversion . self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s\" % abspath ) return None","title":"GetEdk2RelativePathFromAbsolutePath"},{"location":"edk2toollib/uefi/edk2/variable_format/","text":"Module edk2toollib.uefi.edk2.variable_format View Source # @file variable_format . py # Module contains helper classes and functions to work with UEFI Variables . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import uuid import struct import sys import edk2toollib . uefi . uefi_multi_phase as ump # # UEFI GUIDs # EfiVariableGuid = uuid . UUID ( fields= ( 0xDDCF3616 , 0x3275 , 0x4164 , 0x98 , 0xB6 , 0xFE85707FFE7D )) EfiAuthenticatedVariableGuid = uuid . UUID ( fields= ( 0xAAF32C78 , 0x947B , 0x439A , 0xA1 , 0x80 , 0x2E144EC37792 )) # # UEFI # Defines # HEADER_ALIGNMENT = 4 VARIABLE_STORE_FORMATTED = 0x5A VARIABLE_STORE_HEALTHY = 0xFE VARIABLE_DATA = 0x55AA VAR_IN_DELETED_TRANSITION = 0xFE # Variable is in obsolete transition . VAR_DELETED = 0xFD # Variable is obsolete . VAR_HEADER_VALID_ONLY = 0x7F # Variable header has been valid . VAR_ADDED = 0x3F # Variable has been completely added . # # VARIABLE_STORE_HEADER # Can parse or produce an VARIABLE_STORE_HEADER structure / byte buffer . # # typedef struct { # EFI_GUID Signature ; # UINT32 Size ; # UINT8 Format ; # UINT8 State ; # UINT16 Reserved ; # UINT32 Reserved1 ; # } VARIABLE_STORE_HEADER ; class VariableStoreHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=16sLBBHL\" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature ! = EfiVariableGuid and self . Signature ! = EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self.Signature) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self def serialize ( self ) : signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) # # TODO : VariableHeader and AuthenticatedVariableHeader are not truly # header structures . They 're entire variables. This code should be # cleaned up. # # # VARIABLE_HEADER # Can parse or produce an VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } VARIABLE_HEADER; class VariableHeader(object): def __init__(self): self.StructString = \"=HBBLLL16s\" # spell-checker: disable-line self.StructSize = struct.calcsize(self.StructString) self.StartId = VARIABLE_DATA self.State = VAR_ADDED self.Attributes = (ump.EFI_VARIABLE_NON_VOLATILE | ump.EFI_VARIABLE_BOOTSERVICE_ACCESS) self.NameSize = 0 self.DataSize = 0 self.VendorGuid = uuid.uuid4() self.Name = None self.Data = None def populate_structure_fields(self, in_bytes): (self.StartId, self.State, reserved, self.Attributes, self.NameSize, self.DataSize, self.VendorGuid) = struct.unpack(self.StructString, in_bytes) def load_from_bytes(self, in_bytes): # Load this object with the contents of the data. self.populate_structure_fields(in_bytes[0:self.StructSize]) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: raise EOFError(\"No variable data!\") # Finally, load the data. data_offset = self.StructSize self.Name = in_bytes[data_offset:(data_offset + self.NameSize)].decode('utf - 16 ') self.Name = self.Name[:-1] # Strip the terminating char. data_offset += self.NameSize self.Data = in_bytes[data_offset:(data_offset + self.DataSize)] return self def load_from_file(self, file): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file.tell() struct_bytes = file.read(struct.calcsize(self.StructString)) # Load this object with the contents of the data. self.populate_structure_fields(struct_bytes) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: file.seek(orig_seek) raise EOFError(\"No variable data!\") # Finally, load the data. self.Name = file.read(self.NameSize).decode('utf - 16 ')[:-1] # Strip the terminating char. self.Data = file.read(self.DataSize) file.seek(orig_seek) return self def get_buffer_data_size(self): return self.StructSize + self.NameSize + self.DataSize def get_buffer_padding_size(self): buffer_data_size = self.get_buffer_data_size() padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - (buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size(self): return self.get_buffer_data_size() + self.get_buffer_padding_size() def get_packed_name(self): # Make sure to replace the terminating char. # name_bytes = b\"\\x00\".join([char for char in (self.Name + b'\\x00')]) name_bytes = self.Name.encode('utf - 16 ') # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type. UEFI does not use this. name_bytes = name_bytes[2:] # Python encode skips the terminating character, so let's add that . name_bytes += b \"\\x00\\x00\" return name_bytes def set_name ( self , new_name ) : self . Name = new_name self . NameSize = len ( self . get_packed_name ()) def set_data ( self , new_data ) : self . Data = new_data self . DataSize = len ( new_data ) def pack_struct ( self ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self.get_buffer_padding_size() return bytes # # AUTHENTICATED_VARIABLE_HEADER # Can parse or produce an AUTHENTICATED_VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT64 MonotonicCount; # EFI_TIME TimeStamp; # UINT32 PubKeyIndex; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } AUTHENTICATED_VARIABLE_HEADER; class AuthenticatedVariableHeader(VariableHeader): def __init__(self): super(AuthenticatedVariableHeader, self).__init__() self.StructString = \" = HBBLQ16sLLL16s \" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) if __ name__ == '__main__': pass Variables EfiAuthenticatedVariableGuid EfiVariableGuid HEADER_ALIGNMENT VARIABLE_DATA VARIABLE_STORE_FORMATTED VARIABLE_STORE_HEALTHY VAR_ADDED VAR_DELETED VAR_HEADER_VALID_ONLY VAR_IN_DELETED_TRANSITION Classes AuthenticatedVariableHeader class AuthenticatedVariableHeader ( ) View Source class AuthenticatedVariableHeader ( VariableHeader ): def __init__ ( self ): super ( AuthenticatedVariableHeader , self ). __init__ () self . StructString = \"=HBBLQ16sLLL16s\" # spell-checker: disable-line self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) Ancestors (in MRO) edk2toollib.uefi.edk2.variable_format.VariableHeader Methods get_buffer_data_size def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize get_buffer_padding_size def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size get_buffer_size def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size () get_packed_name def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes load_from_bytes def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self pack_struct def pack_struct ( self , with_padding = False ) View Source def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) populate_structure_fields def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) serialize def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes set_data def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data ) set_name def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ()) VariableHeader class VariableHeader ( ) View Source class VariableHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=HBBLLL16s\" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . StartId = VARIABLE_DATA self . State = VAR_ADDED self . Attributes = ( ump . EFI_VARIABLE_NON_VOLATILE | ump . EFI_VARIABLE_BOOTSERVICE_ACCESS ) self . NameSize = 0 self . DataSize = 0 self . VendorGuid = uuid . uuid4 () self . Name = None self . Data = None def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self def get_buffer_data_size ( self ) : return self . StructSize + self . NameSize + self . DataSize def get_buffer_padding_size ( self ) : buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size ( self ) : return self . get_buffer_data_size () + self . get_buffer_padding_size () def get_packed_name ( self ) : # Make sure to replace the terminating char . # name_bytes = b \" \\x00 \" . join ([ char for char in ( self . Name + b'\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 : ] # Python encode skips the terminating character , so let's add that. name_bytes += b\"\\x00\\x00\" return name_bytes def set_name(self, new_name): self.Name = new_name self.NameSize = len(self.get_packed_name()) def set_data(self, new_data): self.Data = new_data self.DataSize = len(new_data) def pack_struct(self): vendor_guid = self.VendorGuid.bytes if sys.byteorder == 'big ' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self . get_buffer_padding_size () return bytes Descendants edk2toollib.uefi.edk2.variable_format.AuthenticatedVariableHeader Methods get_buffer_data_size def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize get_buffer_padding_size def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size get_buffer_size def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size () get_packed_name def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes load_from_bytes def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self pack_struct def pack_struct ( self ) View Source def pack_struct ( self ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) populate_structure_fields def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) serialize def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes set_data def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data ) set_name def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ()) VariableStoreHeader class VariableStoreHeader ( ) View Source class VariableStoreHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBHL\" # spell-checker: disable-line self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing. if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid: raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid: self . Type = 'AuthVar' return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self serialize def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"Variable format"},{"location":"edk2toollib/uefi/edk2/variable_format/#module-edk2toollibuefiedk2variable_format","text":"View Source # @file variable_format . py # Module contains helper classes and functions to work with UEFI Variables . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import uuid import struct import sys import edk2toollib . uefi . uefi_multi_phase as ump # # UEFI GUIDs # EfiVariableGuid = uuid . UUID ( fields= ( 0xDDCF3616 , 0x3275 , 0x4164 , 0x98 , 0xB6 , 0xFE85707FFE7D )) EfiAuthenticatedVariableGuid = uuid . UUID ( fields= ( 0xAAF32C78 , 0x947B , 0x439A , 0xA1 , 0x80 , 0x2E144EC37792 )) # # UEFI # Defines # HEADER_ALIGNMENT = 4 VARIABLE_STORE_FORMATTED = 0x5A VARIABLE_STORE_HEALTHY = 0xFE VARIABLE_DATA = 0x55AA VAR_IN_DELETED_TRANSITION = 0xFE # Variable is in obsolete transition . VAR_DELETED = 0xFD # Variable is obsolete . VAR_HEADER_VALID_ONLY = 0x7F # Variable header has been valid . VAR_ADDED = 0x3F # Variable has been completely added . # # VARIABLE_STORE_HEADER # Can parse or produce an VARIABLE_STORE_HEADER structure / byte buffer . # # typedef struct { # EFI_GUID Signature ; # UINT32 Size ; # UINT8 Format ; # UINT8 State ; # UINT16 Reserved ; # UINT32 Reserved1 ; # } VARIABLE_STORE_HEADER ; class VariableStoreHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=16sLBBHL\" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature ! = EfiVariableGuid and self . Signature ! = EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self.Signature) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self def serialize ( self ) : signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) # # TODO : VariableHeader and AuthenticatedVariableHeader are not truly # header structures . They 're entire variables. This code should be # cleaned up. # # # VARIABLE_HEADER # Can parse or produce an VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } VARIABLE_HEADER; class VariableHeader(object): def __init__(self): self.StructString = \"=HBBLLL16s\" # spell-checker: disable-line self.StructSize = struct.calcsize(self.StructString) self.StartId = VARIABLE_DATA self.State = VAR_ADDED self.Attributes = (ump.EFI_VARIABLE_NON_VOLATILE | ump.EFI_VARIABLE_BOOTSERVICE_ACCESS) self.NameSize = 0 self.DataSize = 0 self.VendorGuid = uuid.uuid4() self.Name = None self.Data = None def populate_structure_fields(self, in_bytes): (self.StartId, self.State, reserved, self.Attributes, self.NameSize, self.DataSize, self.VendorGuid) = struct.unpack(self.StructString, in_bytes) def load_from_bytes(self, in_bytes): # Load this object with the contents of the data. self.populate_structure_fields(in_bytes[0:self.StructSize]) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: raise EOFError(\"No variable data!\") # Finally, load the data. data_offset = self.StructSize self.Name = in_bytes[data_offset:(data_offset + self.NameSize)].decode('utf - 16 ') self.Name = self.Name[:-1] # Strip the terminating char. data_offset += self.NameSize self.Data = in_bytes[data_offset:(data_offset + self.DataSize)] return self def load_from_file(self, file): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file.tell() struct_bytes = file.read(struct.calcsize(self.StructString)) # Load this object with the contents of the data. self.populate_structure_fields(struct_bytes) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: file.seek(orig_seek) raise EOFError(\"No variable data!\") # Finally, load the data. self.Name = file.read(self.NameSize).decode('utf - 16 ')[:-1] # Strip the terminating char. self.Data = file.read(self.DataSize) file.seek(orig_seek) return self def get_buffer_data_size(self): return self.StructSize + self.NameSize + self.DataSize def get_buffer_padding_size(self): buffer_data_size = self.get_buffer_data_size() padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - (buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size(self): return self.get_buffer_data_size() + self.get_buffer_padding_size() def get_packed_name(self): # Make sure to replace the terminating char. # name_bytes = b\"\\x00\".join([char for char in (self.Name + b'\\x00')]) name_bytes = self.Name.encode('utf - 16 ') # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type. UEFI does not use this. name_bytes = name_bytes[2:] # Python encode skips the terminating character, so let's add that . name_bytes += b \"\\x00\\x00\" return name_bytes def set_name ( self , new_name ) : self . Name = new_name self . NameSize = len ( self . get_packed_name ()) def set_data ( self , new_data ) : self . Data = new_data self . DataSize = len ( new_data ) def pack_struct ( self ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self.get_buffer_padding_size() return bytes # # AUTHENTICATED_VARIABLE_HEADER # Can parse or produce an AUTHENTICATED_VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT64 MonotonicCount; # EFI_TIME TimeStamp; # UINT32 PubKeyIndex; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } AUTHENTICATED_VARIABLE_HEADER; class AuthenticatedVariableHeader(VariableHeader): def __init__(self): super(AuthenticatedVariableHeader, self).__init__() self.StructString = \" = HBBLQ16sLLL16s \" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) if __ name__ == '__main__': pass","title":"Module edk2toollib.uefi.edk2.variable_format"},{"location":"edk2toollib/uefi/edk2/variable_format/#variables","text":"EfiAuthenticatedVariableGuid EfiVariableGuid HEADER_ALIGNMENT VARIABLE_DATA VARIABLE_STORE_FORMATTED VARIABLE_STORE_HEALTHY VAR_ADDED VAR_DELETED VAR_HEADER_VALID_ONLY VAR_IN_DELETED_TRANSITION","title":"Variables"},{"location":"edk2toollib/uefi/edk2/variable_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/variable_format/#authenticatedvariableheader","text":"class AuthenticatedVariableHeader ( ) View Source class AuthenticatedVariableHeader ( VariableHeader ): def __init__ ( self ): super ( AuthenticatedVariableHeader , self ). __init__ () self . StructString = \"=HBBLQ16sLLL16s\" # spell-checker: disable-line self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid )","title":"AuthenticatedVariableHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.variable_format.VariableHeader","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_data_size","text":"def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize","title":"get_buffer_data_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_padding_size","text":"def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size","title":"get_buffer_padding_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_size","text":"def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size ()","title":"get_buffer_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_packed_name","text":"def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes","title":"get_packed_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_bytes","text":"def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self","title":"load_from_bytes"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#pack_struct","text":"def pack_struct ( self , with_padding = False ) View Source def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid )","title":"pack_struct"},{"location":"edk2toollib/uefi/edk2/variable_format/#populate_structure_fields","text":"def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes )","title":"populate_structure_fields"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize","text":"def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_data","text":"def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data )","title":"set_data"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_name","text":"def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ())","title":"set_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#variableheader","text":"class VariableHeader ( ) View Source class VariableHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=HBBLLL16s\" # spell - checker : disable - line self . StructSize = struct . calcsize ( self . StructString ) self . StartId = VARIABLE_DATA self . State = VAR_ADDED self . Attributes = ( ump . EFI_VARIABLE_NON_VOLATILE | ump . EFI_VARIABLE_BOOTSERVICE_ACCESS ) self . NameSize = 0 self . DataSize = 0 self . VendorGuid = uuid . uuid4 () self . Name = None self . Data = None def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self def get_buffer_data_size ( self ) : return self . StructSize + self . NameSize + self . DataSize def get_buffer_padding_size ( self ) : buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size ( self ) : return self . get_buffer_data_size () + self . get_buffer_padding_size () def get_packed_name ( self ) : # Make sure to replace the terminating char . # name_bytes = b \" \\x00 \" . join ([ char for char in ( self . Name + b'\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 : ] # Python encode skips the terminating character , so let's add that. name_bytes += b\"\\x00\\x00\" return name_bytes def set_name(self, new_name): self.Name = new_name self.NameSize = len(self.get_packed_name()) def set_data(self, new_data): self.Data = new_data self.DataSize = len(new_data) def pack_struct(self): vendor_guid = self.VendorGuid.bytes if sys.byteorder == 'big ' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self . get_buffer_padding_size () return bytes","title":"VariableHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#descendants","text":"edk2toollib.uefi.edk2.variable_format.AuthenticatedVariableHeader","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_data_size_1","text":"def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize","title":"get_buffer_data_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_padding_size_1","text":"def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size","title":"get_buffer_padding_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_size_1","text":"def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size ()","title":"get_buffer_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_packed_name_1","text":"def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes","title":"get_packed_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_bytes_1","text":"def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self","title":"load_from_bytes"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#pack_struct_1","text":"def pack_struct ( self ) View Source def pack_struct ( self ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid )","title":"pack_struct"},{"location":"edk2toollib/uefi/edk2/variable_format/#populate_structure_fields_1","text":"def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes )","title":"populate_structure_fields"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize_1","text":"def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_data_1","text":"def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data )","title":"set_data"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_name_1","text":"def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ())","title":"set_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#variablestoreheader","text":"class VariableStoreHeader ( ) View Source class VariableStoreHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBHL\" # spell-checker: disable-line self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing. if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid: raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid: self . Type = 'AuthVar' return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"VariableStoreHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file_2","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize_2","text":"def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/","text":"Module edk2toollib.uefi.edk2.variablestore_manulipulations View Source # @file # Contains classes and helper functions to modify variables in a UEFI ROM image. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.uefi.pi_firmware_volume as PiFV import edk2toollib.uefi.edk2.variable_format as VF import os import mmap class VariableStore ( object ): def __init__ ( self , romfile , store_base = None , store_size = None ): self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ): raise Exception ( \"' %s ' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things. file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ): raise Exception ( \"ROM file is %d bytes. Cannot seek to %d + %d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header. self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader () . load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d !\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header. self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader () . load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we're finally ready to read some variables. self . variables = [] self . rom_file . seek ( self . var_store_header . StructSize , os . SEEK_CUR ) try : while True : new_var = self . get_new_var_class () . load_from_file ( self . rom_file ) # Seek past the current variable in the store. self . rom_file . seek ( new_var . get_buffer_size (), os . SEEK_CUR ) # Add the variable to the array. self . variables . append ( new_var ) except EOFError : pass except : raise # Finally, reset the file cursor to the beginning of the VarStore FV. self . rom_file . seek ( self . store_base ) def __del__ ( self ): if self . rom_file_map is not None : self . rom_file_map . flush () self . rom_file_map . close () if self . rom_file is not None : self . rom_file . close () def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var def add_variable ( self , new_var ): self . variables . append ( new_var ) def flush_to_file ( self ): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header. dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d !\" % ( var_size , self . var_store_header . Size )) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header. self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b ' \\xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file. self . rom_file_map . flush () Classes VariableStore class VariableStore ( romfile , store_base = None , store_size = None ) View Source class VariableStore ( object ) : def __init__ ( self , romfile , store_base = None , store_size = None ) : self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ) : raise Exception ( \"'%s' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things . file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ) : raise Exception ( \"ROM file is %d bytes. Cannot seek to %d+%d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header . self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader (). load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d!\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header . self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader (). load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we 're finally ready to read some variables. self.variables = [] self.rom_file.seek(self.var_store_header.StructSize, os.SEEK_CUR) try: while True: new_var = self.get_new_var_class().load_from_file(self.rom_file) # Seek past the current variable in the store. self.rom_file.seek(new_var.get_buffer_size(), os.SEEK_CUR) # Add the variable to the array. self.variables.append(new_var) except EOFError: pass except: raise # Finally, reset the file cursor to the beginning of the VarStore FV. self.rom_file.seek(self.store_base) def __del__(self): if self.rom_file_map is not None: self.rom_file_map.flush() self.rom_file_map.close() if self.rom_file is not None: self.rom_file.close() def get_new_var_class(self): if self.var_store_header.Type == ' Var ': new_var = VF.VariableHeader() else: new_var = VF.AuthenticatedVariableHeader() return new_var def add_variable(self, new_var): self.variables.append(new_var) def flush_to_file(self): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum([var.get_buffer_size() for var in self.variables]) # Add the terminating var header. dummy_var = self.get_new_var_class() var_size += dummy_var.StructSize if var_size > self.var_store_header.Size: raise Exception(\"Total variable size %d is too large to fit in VarStore %d!\" % (var_size, self.var_store_header.Size)) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self.store_base + self.fv_header.HeaderLength + self.var_store_header.StructSize for var in self.variables: var_buffer_size = var.get_buffer_size() self.rom_file_map[var_offset:(var_offset + var_buffer_size)] = var.serialize(True) var_offset += var_buffer_size # Add a terminating Variable Header. self.rom_file_map[var_offset:(var_offset + dummy_var.StructSize)] = b' \\ xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush () Methods add_variable def add_variable ( self , new_var ) View Source def add_variable ( self , new_var ): self . variables . append ( new_var ) flush_to_file def flush_to_file ( self ) View Source def flush_to_file ( self ): # First , we need to make sure that our variables will fit in the VarStore . var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header . dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d!\" % ( var_size , self . var_store_header . Size )) # Now , we just have to serialize each variable in turn and write them to the mmap buffer . var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header . self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b '\\xFF' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush () get_new_var_class def get_new_var_class ( self ) View Source def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var","title":"Variablestore manulipulations"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#module-edk2toollibuefiedk2variablestore_manulipulations","text":"View Source # @file # Contains classes and helper functions to modify variables in a UEFI ROM image. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.uefi.pi_firmware_volume as PiFV import edk2toollib.uefi.edk2.variable_format as VF import os import mmap class VariableStore ( object ): def __init__ ( self , romfile , store_base = None , store_size = None ): self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ): raise Exception ( \"' %s ' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things. file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ): raise Exception ( \"ROM file is %d bytes. Cannot seek to %d + %d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header. self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader () . load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d !\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header. self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader () . load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we're finally ready to read some variables. self . variables = [] self . rom_file . seek ( self . var_store_header . StructSize , os . SEEK_CUR ) try : while True : new_var = self . get_new_var_class () . load_from_file ( self . rom_file ) # Seek past the current variable in the store. self . rom_file . seek ( new_var . get_buffer_size (), os . SEEK_CUR ) # Add the variable to the array. self . variables . append ( new_var ) except EOFError : pass except : raise # Finally, reset the file cursor to the beginning of the VarStore FV. self . rom_file . seek ( self . store_base ) def __del__ ( self ): if self . rom_file_map is not None : self . rom_file_map . flush () self . rom_file_map . close () if self . rom_file is not None : self . rom_file . close () def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var def add_variable ( self , new_var ): self . variables . append ( new_var ) def flush_to_file ( self ): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header. dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d !\" % ( var_size , self . var_store_header . Size )) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header. self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b ' \\xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file. self . rom_file_map . flush ()","title":"Module edk2toollib.uefi.edk2.variablestore_manulipulations"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#variablestore","text":"class VariableStore ( romfile , store_base = None , store_size = None ) View Source class VariableStore ( object ) : def __init__ ( self , romfile , store_base = None , store_size = None ) : self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ) : raise Exception ( \"'%s' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things . file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ) : raise Exception ( \"ROM file is %d bytes. Cannot seek to %d+%d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header . self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader (). load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d!\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header . self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader (). load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we 're finally ready to read some variables. self.variables = [] self.rom_file.seek(self.var_store_header.StructSize, os.SEEK_CUR) try: while True: new_var = self.get_new_var_class().load_from_file(self.rom_file) # Seek past the current variable in the store. self.rom_file.seek(new_var.get_buffer_size(), os.SEEK_CUR) # Add the variable to the array. self.variables.append(new_var) except EOFError: pass except: raise # Finally, reset the file cursor to the beginning of the VarStore FV. self.rom_file.seek(self.store_base) def __del__(self): if self.rom_file_map is not None: self.rom_file_map.flush() self.rom_file_map.close() if self.rom_file is not None: self.rom_file.close() def get_new_var_class(self): if self.var_store_header.Type == ' Var ': new_var = VF.VariableHeader() else: new_var = VF.AuthenticatedVariableHeader() return new_var def add_variable(self, new_var): self.variables.append(new_var) def flush_to_file(self): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum([var.get_buffer_size() for var in self.variables]) # Add the terminating var header. dummy_var = self.get_new_var_class() var_size += dummy_var.StructSize if var_size > self.var_store_header.Size: raise Exception(\"Total variable size %d is too large to fit in VarStore %d!\" % (var_size, self.var_store_header.Size)) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self.store_base + self.fv_header.HeaderLength + self.var_store_header.StructSize for var in self.variables: var_buffer_size = var.get_buffer_size() self.rom_file_map[var_offset:(var_offset + var_buffer_size)] = var.serialize(True) var_offset += var_buffer_size # Add a terminating Variable Header. self.rom_file_map[var_offset:(var_offset + dummy_var.StructSize)] = b' \\ xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush ()","title":"VariableStore"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#add_variable","text":"def add_variable ( self , new_var ) View Source def add_variable ( self , new_var ): self . variables . append ( new_var )","title":"add_variable"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#flush_to_file","text":"def flush_to_file ( self ) View Source def flush_to_file ( self ): # First , we need to make sure that our variables will fit in the VarStore . var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header . dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d!\" % ( var_size , self . var_store_header . Size )) # Now , we just have to serialize each variable in turn and write them to the mmap buffer . var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header . self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b '\\xFF' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush ()","title":"flush_to_file"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#get_new_var_class","text":"def get_new_var_class ( self ) View Source def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var","title":"get_new_var_class"},{"location":"edk2toollib/uefi/edk2/build_objects/","text":"Module edk2toollib.uefi.edk2.build_objects View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.edk2.build_objects.dsc edk2toollib.uefi.edk2.build_objects.dsc_test edk2toollib.uefi.edk2.build_objects.dsc_translator edk2toollib.uefi.edk2.build_objects.dsc_translator_test Build Objects What are they? Data model or build objects are data objects that allow for a DSC or other build file to be converted into an python object. This allows transformations, verifications, and other things to do be done much more easily as they can be done in-memory. The current proposal is three separate data models, detailed below. Generally the data model is composed of sets and maps of sets. The sets will be checked for uniqueness and will be restricted in what can be added to them. The maps will have various section header types as keys and restricted sets as values. DSC This is the data model that represents the DSC file, macros fully resolved with conditional paths taken. This is a fairly standard 1:1 mapping from the spec to the DSC object. No higher level verification is to be done by the data model object itself (for example, checking that the SKU that a PCD references is in fact legal or INF paths exist). This higher level verification can be done by a separate class, perhaps once the object has been created in the parser itself. Low level verifications (for example, anything specified with specific values in the spec) may be done as the file is being processed as long as it can be immediately verified. A good example of this would be checking that the module type specified exists in the list of allowed EDKII values (DXE_RUNTIME_DRIVER, PEIM, etc). FDF This is the data model that represents the FDF file, macros fully resolved with conditional paths taken. Similar to DSCs, no higher level verification should be done in the data model itself. Low lever verifications may be done by the data model. Recipe The central class is the recipe . This holds all the components that need to be built and their respective library classes, PCD\u2019s, and defines. It does not contain general library classes. In the future, it will also contain the flash map information. We\u2019ve written a parser for DSC files to convert them into recipes. In the future, we hope to include FDF files as well. Who are they for? Build objects are for anyone dealing with complex and large projects. In projects, more and more DSC files are taking advantage of the !include functionality. However, there are a few problems with that fact. 1. DSC files are fragile 2. Includes have no idea what is already in your file. An include might expect you to be in a defines section. You have no way to know this from the main DSC file. 3. Why were they made? To better abstract away the essence of what a build is doing. DSC is a way to communicate a recipe. How are they being used? DSC compositing/transformations Build state verification Best practice checking","title":"Index"},{"location":"edk2toollib/uefi/edk2/build_objects/#module-edk2toollibuefiedk2build_objects","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi.edk2.build_objects"},{"location":"edk2toollib/uefi/edk2/build_objects/#sub-modules","text":"edk2toollib.uefi.edk2.build_objects.dsc edk2toollib.uefi.edk2.build_objects.dsc_test edk2toollib.uefi.edk2.build_objects.dsc_translator edk2toollib.uefi.edk2.build_objects.dsc_translator_test","title":"Sub-modules"},{"location":"edk2toollib/uefi/edk2/build_objects/#build-objects","text":"","title":"Build Objects"},{"location":"edk2toollib/uefi/edk2/build_objects/#what-are-they","text":"Data model or build objects are data objects that allow for a DSC or other build file to be converted into an python object. This allows transformations, verifications, and other things to do be done much more easily as they can be done in-memory. The current proposal is three separate data models, detailed below. Generally the data model is composed of sets and maps of sets. The sets will be checked for uniqueness and will be restricted in what can be added to them. The maps will have various section header types as keys and restricted sets as values.","title":"What are they?"},{"location":"edk2toollib/uefi/edk2/build_objects/#dsc","text":"This is the data model that represents the DSC file, macros fully resolved with conditional paths taken. This is a fairly standard 1:1 mapping from the spec to the DSC object. No higher level verification is to be done by the data model object itself (for example, checking that the SKU that a PCD references is in fact legal or INF paths exist). This higher level verification can be done by a separate class, perhaps once the object has been created in the parser itself. Low level verifications (for example, anything specified with specific values in the spec) may be done as the file is being processed as long as it can be immediately verified. A good example of this would be checking that the module type specified exists in the list of allowed EDKII values (DXE_RUNTIME_DRIVER, PEIM, etc).","title":"DSC"},{"location":"edk2toollib/uefi/edk2/build_objects/#fdf","text":"This is the data model that represents the FDF file, macros fully resolved with conditional paths taken. Similar to DSCs, no higher level verification should be done in the data model itself. Low lever verifications may be done by the data model.","title":"FDF"},{"location":"edk2toollib/uefi/edk2/build_objects/#recipe","text":"The central class is the recipe . This holds all the components that need to be built and their respective library classes, PCD\u2019s, and defines. It does not contain general library classes. In the future, it will also contain the flash map information. We\u2019ve written a parser for DSC files to convert them into recipes. In the future, we hope to include FDF files as well.","title":"Recipe"},{"location":"edk2toollib/uefi/edk2/build_objects/#who-are-they-for","text":"Build objects are for anyone dealing with complex and large projects. In projects, more and more DSC files are taking advantage of the !include functionality. However, there are a few problems with that fact. 1. DSC files are fragile 2. Includes have no idea what is already in your file. An include might expect you to be in a defines section. You have no way to know this from the main DSC file. 3.","title":"Who are they for?"},{"location":"edk2toollib/uefi/edk2/build_objects/#why-were-they-made","text":"To better abstract away the essence of what a build is doing. DSC is a way to communicate a recipe.","title":"Why were they made?"},{"location":"edk2toollib/uefi/edk2/build_objects/#how-are-they-being-used","text":"DSC compositing/transformations Build state verification Best practice checking","title":"How are they being used?"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/","text":"Module edk2toollib.uefi.edk2.build_objects.dsc View Source # @file dsc.py # Data model for the EDK II DSC # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## # There will be some overlap between the objects for DSC files and FDF files import collections DEFAULT_SECTION_TYPE = \"COMMON\" class dsc_set ( set ): def __init__ ( self , allowed_classes = None ): if allowed_classes is None : allowed_classes = [] self . _allowed_classes = set ( allowed_classes ) def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes : raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self : super () . discard ( item ) # NEXTVER: get add the old_item to item super () . add ( item ) class dsc_dict ( collections . OrderedDict ): ''' A dictionary that allows specific classes as headers and sections ''' def __init__ ( self , allowed_key_classes = None , allowed_value_classes = None ): if allowed_key_classes is None : allowed_key_classes = [] if allowed_value_classes is None : allowed_value_classes = [] self . _allowed_key_classes = set ( allowed_key_classes ) self . _allowed_value_classes = set ( allowed_value_classes ) def __missing__ ( self , key ): if len ( self . _allowed_value_classes ) > 0 : # if we have specified allowed value classes, make a new dsc_set self [ key ] = dsc_set ( self . _allowed_value_classes ) return self [ key ] raise KeyError ( key ) def __setitem__ ( self , key , val ): if len ( self . _allowed_key_classes ) > 0 and type ( key ) not in self . _allowed_key_classes : raise ValueError ( f \"Cannot add {type(key)} to restricted set: {self._allowed_key_classes}\" ) if len ( self . _allowed_value_classes ) > 0 : if type ( val ) == set and len ( val ) == 0 : # if it's an empty set, convert it to a dsc_set val = dsc_set ( allowed_classes = self . _allowed_value_classes ) if type ( val ) == dsc_set : if val . _allowed_classes != self . _allowed_value_classes : raise ValueError ( f \"Cannot add set:{val._allowed_classes} to restricted dict: {self._allowed_value_classes}\" ) elif type ( val ) not in self . _allowed_value_classes : raise ValueError ( f \"Cannot add {type(val)} to restricted dict: {self._allowed_value_classes}\" ) if key in self : # NEXTVER merge these together? raise ValueError ( f \"Cannot add section {key} since it already exists\" ) dict . __setitem__ ( self , key , val ) class dsc : def __init__ ( self , file_path = None ): # The EDK2 path to this particular DSC, if is is None it means it was created from a stream and has no file self . file_path = file_path # parameters added for clarity self . skus = dsc_set ( allowed_classes = [ definition , sku_id ]) # this is a set of SKUs self . components = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ component , definition ]) self . libraries = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ library , definition ]) self . library_classes = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ library_class , definition ]) self . build_options = dsc_dict ( allowed_key_classes = [ dsc_buildoption_section_type , ], allowed_value_classes = [ build_option , definition ]) self . pcds = dsc_dict ( allowed_key_classes = [ dsc_pcd_section_type , ], allowed_value_classes = [ pcd , pcd_typed , pcd_variable ]) self . defines = dsc_set ( allowed_classes = [ definition , ]) self . default_stores = dsc_set ( allowed_classes = [ definition , default_store ]) # NEXTVER: should we populate the default information into the DSC object? # FOR EXAMPLE: default_stores and skus def __eq__ ( self , other ): ''' This doesn't check for a perfect copy of everything ''' ''' this is mainly focused on does it define the same things ''' if type ( other ) is not dsc : return False if other . skus != self . skus : return False if other . components != self . components : return False if other . library_classes != self . library_classes : return False if other . build_options != self . build_options : return False if other . pcds != self . pcds : return False if other . defines != self . defines : return False return True class dsc_section_type : dsc_module_types = [ \"COMMON\" , \"BASE\" , \"SEC\" , \"PEI_CORE\" , \"PEIM\" , \"DXE_CORE\" , \"DXE_DRIVER\" , \"DXE_RUNTIME_DRIVER\" , \"DXE_SAL_DRIVER\" , \"DXE_SMM_DRIVER\" , \"SMM_CORE\" , \"UEFI_DRIVER\" , \"UEFI_APPLICATION\" , \"USER_DEFINED\" ] def __init__ ( self , arch = \"common\" , module_type = \"common\" ): self . arch = arch . upper () . strip () self . module_type = module_type . upper () . strip () if not dsc_section_type . IsValidModuleType ( self . module_type ): raise ValueError ( f \"{module_type} is not a proper module type for dsc section\" ) def __hash__ ( self ): arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch return hash (( arch , self . module_type )) def __eq__ ( self , other ): if type ( other ) is not dsc_section_type : return False arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch arch2 = \"*\" if ( other . arch == \"COMMON\" or other . arch == \"DEFAULT\" ) else other . arch return self . module_type == other . module_type or arch == arch2 def __repr__ ( self ): attributes = f \".{self.arch}.{self.module_type}\" return attributes @classmethod def IsValidModuleType ( cls , name ): return name in cls . dsc_module_types class dsc_buildoption_section_type ( dsc_section_type ): ''' [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] ''' def __init__ ( self , arch = \"common\" , codebase = \"common\" , module_type = \"common\" ): super () . __init__ ( arch , module_type ) self . codebase = codebase . upper () . strip () if not self . IsValidCodeBase ( self . codebase ): raise ValueError ( f \"{codebase} is not a valid codebase type\" ) @classmethod def IsValidCodeBase ( cls , codebase ): return codebase in [ \"COMMON\" , \"EDK\" , \"EDKII\" ] def __hash__ ( self ): return hash (( super () . __hash__ (), self . codebase )) def __eq__ ( self , other ): if type ( other ) is not dsc_buildoption_section_type : return False if not ( other . module_type == self . module_type and other . codebase == self . codebase ): return False return other . module_type == self . module_type def __repr__ ( self ): return f \"{self.arch}.{self.codebase}.{self.module_type}\" dsc_pcd_types = [ \"FEATUREFLAG\" , \"PATCHABLEINMODULE\" , \"FIXEDATBUILD\" , \"DYNAMIC\" , \"DYNAMICEX\" , \"DYNAMICDEFAULT\" , \"DYNAMICHII\" , \"DYNAMICVPD\" , \"DYNAMICEXHII\" , \"DYNAMICEXVPD\" ] class dsc_pcd_section_type (): def __init__ ( self , pcdtype , arch = \"common\" , sku = \"DEFAULT\" , store = None ): # if store is none, then we don't have anything done self . arch = arch . upper () . strip () self . pcd_type = pcdtype . upper () . strip () self . default_store = None if store is None else store . strip () if self . pcd_type not in dsc_pcd_types : raise ValueError ( f \"{pcdtype} is not a proper PCD type\" ) if not self . pcd_type . endswith ( \"HII\" ) and self . default_store is not None : raise ValueError ( f \"{pcdtype} does not allow for a store to be specified\" ) self . sku = sku . upper () def __hash__ ( self ): return hash (( self . arch , self . pcd_type )) def __repr__ ( self ): store = \"\" if self . default_store is None else f \".{self.default_store}\" return f \"Pcds{self.pcd_type}.{self.arch}.{self.sku}{store}\" def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_section_type : return False return self . pcd_type == other . pcd_type and self . arch == other . arch class dsc_pcd_component_type ( dsc_pcd_section_type ): ''' This class is uses to define the PCD type inside a component ''' def __init__ ( self , pcdtype ): super () . __init__ ( pcdtype ) def __repr__ ( self ): return f \"Pcds{self.pcd_type}\" def __hash__ ( self ): return hash ( self . pcd_type ) def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_component_type : return False return self . pcd_type == other . pcd_type class sku_id : ''' contains the data for a sku ''' def __init__ ( self , id = 0 , name = \"DEFAULT\" , parent = \"DEFAULT\" , source_info = None ): self . id = id self . name = name self . parent = parent # the default parent is default self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not sku_id : return False return self . id == other . id or self . name == other . name def __hash__ ( self ): # we return zero because we want all the skus to hash to the same bucket # this won't be performant for large numbers of skus, which hopefully won't happen # we instead rely on __eq__ since we want to collide on two different attributes # since we want to make sure names and id's are unique return 0 def __repr__ ( self ): return f \"{self.id}|{self.name}|{self.parent}\" class component : ''' Contains the data for a component for the EDK build system to build ''' def __init__ ( self , inf , source_info = None ): self . library_classes = set () # a list of libraries that this component uses self . pcds = {} # a dictionary of PCD's that are keyed by dsc_pcd_component_type, they are sets self . defines = set () # a set of defines self . build_options = set () # a set of build options for this component self . inf = inf # the EDK2 relative path to the source INF self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not component ): return False return self . inf == other . inf # NEXTVER: should this be case insensitive? def __hash__ ( self ): return hash ( self . inf ) def __repr__ ( self ): source = str ( self . source_info ) if source_info is not None else \"\" return f \"{self.inf} @ {source}\" class definition : ''' contains the information on a definition. ''' def __init__ ( self , name , value , local = False , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . name = name self . value = value self . local = local self . source_info = source_info def __repr__ ( self ): string = \"\" if self . local : string = \"DEFINE \" string += f \"{self.name} = {self.value} @ {self.source_info}\" return string def __hash__ ( self ): return hash ( self . name ) def __eq__ ( self , other ): if ( type ( other ) is not definition ): return False return other . name == self . name class library : ''' Contains the data for a specific EDK library''' def __init__ ( self , inf : str , source_info = None ): self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not library : return False return self . inf == other . inf def __hash__ ( self ): return hash ( self . inf ) # NEXTVER how to figure out if they hash to the same spot? def __repr__ ( self ): return f \"{self.inf} @ {self.source_info}\" class library_class : ''' Contains the data for a specific EDK2 library class''' def __init__ ( self , libraryclass : str , inf : str , source_info = None ): self . libraryclass = libraryclass self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not library_class ): return False # if they're both null if self . libraryclass . lower () == \"null\" and other . libraryclass . lower () == \"null\" : return self . inf == other . inf return self . libraryclass . lower () == other . libraryclass . lower () def __hash__ ( self ): # if we're a null lib, we want the hash to be based on the inf path if ( self . libraryclass . lower () == \"null\" ): return hash ( self . inf ) else : return hash ( self . libraryclass ) def __repr__ ( self ): return f \"{self.libraryclass}|{self.inf} @ {self.source_info}\" class pcd : ''' Contains the data for a specific pcd ''' ''' PcdTokenSpaceGuidCName.PcdCName|Value ''' def __init__ ( self , namespace , name , value , source_info = None ): self . namespace = namespace self . name = name self . value = value self . source_info = source_info def __eq__ ( self , other ): if not issubclass ( other . __class__ , pcd ): return False return self . namespace == other . namespace and self . name == other . name def __hash__ ( self ): return hash ( f \"{self.namespace}.{self.name}\" ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} @ {self.source_info}\" class pcd_typed ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] ''' def __init__ ( self , namespace , name , value , datum_type , max_size = 0 , source_info = None ): super () . __init__ ( namespace , name , value , source_info ) self . datum_type = datum_type self . max_size = int ( max_size ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} |{self.datum_type}|{self.max_size} @ {self.source_info}\" pcd_variable_attributes = [ \"NV\" , \"BS\" , \"RT\" , \"RO\" ] class pcd_variable ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] ''' def __init__ ( self , namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ): super () . __init__ ( namespace , name , \"\" , source_info ) if attributes is None : attributes = [] self . var_name = var_name self . var_guid = var_guid self . var_offset = var_offset self . default = default if type ( attributes ) is str : attributes = attributes . split ( \",\" ) attributes = [ str ( x ) . upper () . strip () for x in attributes ] if any ([ x not in pcd_variable_attributes for x in attributes ]): raise ValueError ( f \"Invalid PcdHiiAttribute values: {attributes}\" ) self . attributes = attributes def __repr__ ( self ): pcd_data = f \"{self.var_guid}|{self.var_offset}|{self.default}|{self.attributes}\" return f \"{self.namespace}.{self.name} = {self.var_name} |{pcd_data} @ {self.source_info}\" class build_option : ''' Contains the data for a build option ''' ''' EX: MSFT:*_*_*_CC_FLAGS = /D MDEPKG_NDEBUG ''' # {FAMILY}:{TARGET}_{TAGNAME}_{ARCH}_{TOOLCODE}_{ATTRIBUTE} def __init__ ( self , tool_code , attribute , data , target = \"*\" , tagname = \"*\" , arch = \"*\" , family = None , replace = False , source_info = None ): \"\"\" tool_code - The tool code must be one of the defined tool codes in the Conf/tools_def.txt file. The flags defined in this section are appended to flags defined in the tools_def.txt file for individual tools. attribute - for example flags, d_path, path data - the actual flags or path you want to set target - DEBUG, RELEASE, or other tagname - the tool chain tag arch - ARM, AARCH64, IA32, X64, etc family - Conf/tools_def.txt defines FAMILY as one of MSFT, INTEL or GCC. Typically, this field is used to help the build tools determine whether the line is used for Microsoft style Makefiles or the GNU style Makefile replace - whether or not this replaces the default from tools_def, if this is false, we append \"\"\" self . family = family self . target = target self . tagname = tagname self . arch = arch self . tool_code = tool_code self . attribute = attribute self . replace = replace self . data = data self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not build_option ): return False if self . family != other . family : return False if self . target != other . target : return False if self . tagname != other . tagname : return False if self . arch != other . arch : return False if self . tool_code != other . tool_code : return False if self . attribute != other . attribute : return False return True def __hash__ ( self ): return hash ( self . __repr__ ( False )) def __repr__ ( self , include_data = True ): rep = \"\" if self . family is None else f \"{self.family}:\" rep += \"_\" . join (( self . target , self . tagname , self . arch , self . tool_code , self . attribute )) if include_data : rep += f \"= {self.data}\" return rep class default_store : ''' contains the information on a default store. ''' ''' 0 | Standard # UEFI Standard default ''' def __init__ ( self , index = 0 , value = \"Standard\" , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . index = int ( index ) self . value = value self . source_info = source_info def __repr__ ( self ): return f \"{self.index} | {self.value}\" def __hash__ ( self ): return hash ( self . index ) def __eq__ ( self , other ): if ( type ( other ) is not default_store ): return False return other . index == self . index class source_info : def __init__ ( self , file : str , lineno : int = None ): self . file = file self . lineno = lineno def __repr__ ( self ): if self . lineno is None : return self . file return f \"{self.file}:{self.lineno}\" Variables DEFAULT_SECTION_TYPE dsc_pcd_types pcd_variable_attributes Classes build_option class build_option ( tool_code , attribute , data , target = '*' , tagname = '*' , arch = '*' , family = None , replace = False , source_info = None ) Contains the data for a build option View Source class build_option : '' ' Contains the data for a build option ''' ''' EX: MSFT:*_*_*_CC_FLAGS = /D MDEPKG_NDEBUG ''' # {FAMILY}:{TARGET}_{TAGNAME}_{ARCH}_{TOOLCODE}_{ATTRIBUTE} def __init__(self, tool_code, attribute, data, target=\"*\", tagname=\"*\", arch=\"*\", family=None, replace=False, source_info=None): \"\"\" tool_code - The tool code must be one of the defined tool codes in the Conf/tools_def.txt file. The flags defined in this section are appended to flags defined in the tools_def.txt file for individual tools. attribute - for example flags, d_path, path data - the actual flags or path you want to set target - DEBUG, RELEASE, or other tagname - the tool chain tag arch - ARM, AARCH64, IA32, X64, etc family - Conf/tools_def.txt defines FAMILY as one of MSFT, INTEL or GCC. Typically, this field is used to help the build tools determine whether the line is used for Microsoft style Makefiles or the GNU style Makefile replace - whether or not this replaces the default from tools_def, if this is false, we append \"\"\" self.family = family self.target = target self.tagname = tagname self.arch = arch self.tool_code = tool_code self.attribute = attribute self.replace = replace self.data = data self.source_info = source_info def __eq__(self, other): if (type(other) is not build_option): return False if self.family != other.family: return False if self.target != other.target: return False if self.tagname != other.tagname: return False if self.arch != other.arch: return False if self.tool_code != other.tool_code: return False if self.attribute != other.attribute: return False return True def __hash__(self): return hash(self.__repr__(False)) def __repr__(self, include_data=True): rep = \"\" if self.family is None else f\"{self.family}:\" rep += \"_\".join((self.target, self.tagname, self.arch, self.tool_code, self.attribute)) if include_data: rep += f\"= {self.data}\" return rep component class component ( inf , source_info = None ) Contains the data for a component for the EDK build system to build View Source class component: ''' Contains the data for a component for the EDK build system to build ''' def __init__ ( self , inf , source_info = None ): self . library_classes = set () # a list of libraries that this component uses self . pcds = {} # a dictionary of PCD's that are keyed by dsc_pcd_component_type, they are sets self . defines = set () # a set of defines self . build_options = set () # a set of build options for this component self . inf = inf # the EDK2 relative path to the source INF self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not component ): return False return self . inf == other . inf # NEXTVER: should this be case insensitive? def __hash__ ( self ): return hash ( self . inf ) def __repr__ ( self ): source = str ( self . source_info ) if source_info is not None else \"\" return f \"{self.inf} @ {source}\" default_store class default_store ( index = 0 , value = 'Standard' , source_info = None ) contains the information on a default store. View Source class default_store: ''' contains the information on a default store. ''' ''' 0 | Standard # UEFI Standard default ''' def __init__ ( self , index = 0 , value = \"Standard\" , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . index = int ( index ) self . value = value self . source_info = source_info def __repr__ ( self ): return f \"{self.index} | {self.value}\" def __hash__ ( self ): return hash ( self . index ) def __eq__ ( self , other ): if ( type ( other ) is not default_store ): return False return other . index == self . index definition class definition ( name , value , local = False , source_info = None ) contains the information on a definition. View Source class definition: ''' contains the information on a definition. ''' def __init__ ( self , name , value , local = False , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . name = name self . value = value self . local = local self . source_info = source_info def __repr__ ( self ): string = \"\" if self . local: string = \"DEFINE \" string += f \"{self.name} = {self.value} @ {self.source_info}\" return string def __hash__ ( self ): return hash ( self . name ) def __eq__ ( self , other ): if ( type ( other ) is not definition ): return False return other . name == self . name dsc class dsc ( file_path = None ) View Source class dsc: def __init__ ( self , file_path = None ): # The EDK2 path to this particular DSC, if is is None it means it was created from a stream and has no file self . file_path = file_path # parameters added for clarity self . skus = dsc_set ( allowed_classes =[ definition , sku_id ]) # this is a set of SKUs self . components = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ component , definition ]) self . libraries = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ library , definition ]) self . library_classes = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ library_class , definition ]) self . build_options = dsc_dict ( allowed_key_classes =[ dsc_buildoption_section_type , ], allowed_value_classes =[ build_option , definition ]) self . pcds = dsc_dict ( allowed_key_classes =[ dsc_pcd_section_type , ], allowed_value_classes =[ pcd , pcd_typed , pcd_variable ]) self . defines = dsc_set ( allowed_classes =[ definition , ]) self . default_stores = dsc_set ( allowed_classes =[ definition , default_store ]) # NEXTVER: should we populate the default information into the DSC object? # FOR EXAMPLE: default_stores and skus def __eq__ ( self , other ): ''' This doesn' t check for a perfect copy of everything ''' ''' this is mainly focused on does it define the same things '' ' if type ( other ) is not dsc: return False if other . skus != self . skus: return False if other . components != self . components: return False if other . library_classes != self . library_classes: return False if other . build_options != self . build_options: return False if other . pcds != self . pcds: return False if other . defines != self . defines: return False return True dsc_buildoption_section_type class dsc_buildoption_section_type ( arch = 'common' , codebase = 'common' , module_type = 'common' ) [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] View Source class dsc_buildoption_section_type ( dsc_section_type ) : ''' [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] ''' def __init__ ( self , arch = \"common\" , codebase = \"common\" , module_type = \"common\" ) : super (). __init__ ( arch , module_type ) self . codebase = codebase . upper (). strip () if not self . IsValidCodeBase ( self . codebase ) : raise ValueError ( f \"{codebase} is not a valid codebase type\" ) @classmethod def IsValidCodeBase ( cls , codebase ) : return codebase in [ \"COMMON\", \"EDK\", \"EDKII\" ] def __hash__ ( self ) : return hash (( super (). __hash__ (), self . codebase )) def __eq__ ( self , other ) : if type ( other ) is not dsc_buildoption_section_type : return False if not ( other . module_type == self . module_type and other . codebase == self . codebase ) : return False return other . module_type == self . module_type def __repr__ ( self ) : return f \"{self.arch}.{self.codebase}.{self.module_type}\" Ancestors (in MRO) edk2toollib.uefi.edk2.build_objects.dsc.dsc_section_type Class variables dsc_module_types Static methods IsValidCodeBase def IsValidCodeBase ( codebase ) View Source @classmethod def IsValidCodeBase ( cls , codebase ) : return codebase in [ \"COMMON\", \"EDK\", \"EDKII\" ] IsValidModuleType def IsValidModuleType ( name ) View Source @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types dsc_dict class dsc_dict ( allowed_key_classes = None , allowed_value_classes = None ) A dictionary that allows specific classes as headers and sections View Source class dsc_dict ( collections . OrderedDict ) : ''' A dictionary that allows specific classes as headers and sections ''' def __init__ ( self , allowed_key_classes = None , allowed_value_classes = None ) : if allowed_key_classes is None : allowed_key_classes = [] if allowed_value_classes is None : allowed_value_classes = [] self . _allowed_key_classes = set ( allowed_key_classes ) self . _allowed_value_classes = set ( allowed_value_classes ) def __missing__ ( self , key ) : if len ( self . _allowed_value_classes ) > 0 : # if we have specified allowed value classes , make a new dsc_set self [ key ] = dsc_set ( self . _allowed_value_classes ) return self [ key ] raise KeyError ( key ) def __setitem__ ( self , key , val ) : if len ( self . _allowed_key_classes ) > 0 and type ( key ) not in self . _allowed_key_classes : raise ValueError ( f \"Cannot add {type(key)} to restricted set: {self._allowed_key_classes}\" ) if len ( self . _allowed_value_classes ) > 0 : if type ( val ) == set and len ( val ) == 0 : # if it ' s an empty set , convert it to a dsc_set val = dsc_set ( allowed_classes = self . _allowed_value_classes ) if type ( val ) == dsc_set : if val . _allowed_classes != self . _allowed_value_classes : raise ValueError ( f \"Cannot add set:{val._allowed_classes} to restricted dict: {self._allowed_value_classes}\" ) elif type ( val ) not in self . _allowed_value_classes : raise ValueError ( f \"Cannot add {type(val)} to restricted dict: {self._allowed_value_classes}\" ) if key in self : # NEXTVER merge these together ? raise ValueError ( f \"Cannot add section {key} since it already exists\" ) dict . __setitem__ ( self , key , val ) Ancestors (in MRO) collections.OrderedDict builtins.dict Methods clear def clear ( ... ) od.clear() -> None. Remove all items from od. copy def copy ( ... ) od.copy() -> a shallow copy of od fromkeys def fromkeys ( iterable , value = None ) Create a new ordered dictionary with keys from iterable and values set to value. get def get ( self , key , default = None , / ) Return the value for key if key is in the dictionary, else default. items def items ( ... ) D.items() -> a set-like object providing a view on D\u2019s items keys def keys ( ... ) D.keys() -> a set-like object providing a view on D\u2019s keys move_to_end def move_to_end ( self , / , key , last = True ) Move an existing element to the end (or beginning if last is false). Raise KeyError if the element does not exist. pop def pop ( ... ) od.pop(k[,d]) -> v, remove specified key and return the corresponding value. If key is not found, d is returned if given, otherwise KeyError is raised. popitem def popitem ( self , / , last = True ) Remove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO order if last is true or FIFO order if false. setdefault def setdefault ( self , / , key , default = None ) Insert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default. update def update ( ... ) D.update([E, ]**F) -> None. Update D from dict/iterable E and F. If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k] values def values ( ... ) D.values() -> an object providing a view on D\u2019s values dsc_pcd_component_type class dsc_pcd_component_type ( pcdtype ) This class is uses to define the PCD type inside a component View Source class dsc_pcd_component_type ( dsc_pcd_section_type ): ''' This class is uses to define the PCD type inside a component ''' def __init__ ( self , pcdtype ): super (). __init__ ( pcdtype ) def __repr__ ( self ): return f \"Pcds{self.pcd_type}\" def __hash__ ( self ): return hash ( self . pcd_type ) def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_component_type: return False return self . pcd_type == other . pcd_type Ancestors (in MRO) edk2toollib.uefi.edk2.build_objects.dsc.dsc_pcd_section_type dsc_pcd_section_type class dsc_pcd_section_type ( pcdtype , arch = 'common' , sku = 'DEFAULT' , store = None ) View Source class dsc_pcd_section_type (): def __init__ ( self , pcdtype , arch = \"common\" , sku = \"DEFAULT\" , store = None ): # if store is none, then we don't have anything done self . arch = arch . upper (). strip () self . pcd_type = pcdtype . upper (). strip () self . default_store = None if store is None else store . strip () if self . pcd_type not in dsc_pcd_types: raise ValueError ( f \"{pcdtype} is not a proper PCD type\" ) if not self . pcd_type . endswith ( \"HII\" ) and self . default_store is not None: raise ValueError ( f \"{pcdtype} does not allow for a store to be specified\" ) self . sku = sku . upper () def __hash__ ( self ): return hash (( self . arch , self . pcd_type )) def __repr__ ( self ): store = \"\" if self . default_store is None else f \".{self.default_store}\" return f \"Pcds{self.pcd_type}.{self.arch}.{self.sku}{store}\" def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_section_type: return False return self . pcd_type == other . pcd_type and self . arch == other . arch Descendants edk2toollib.uefi.edk2.build_objects.dsc.dsc_pcd_component_type dsc_section_type class dsc_section_type ( arch = 'common' , module_type = 'common' ) View Source class dsc_section_type : dsc_module_types = [ \"COMMON\", \"BASE\", \"SEC\", \"PEI_CORE\", \"PEIM\", \"DXE_CORE\", \"DXE_DRIVER\", \"DXE_RUNTIME_DRIVER\", \"DXE_SAL_DRIVER\", \"DXE_SMM_DRIVER\", \"SMM_CORE\", \"UEFI_DRIVER\", \"UEFI_APPLICATION\", \"USER_DEFINED\" ] def __init__ ( self , arch = \"common\" , module_type = \"common\" ) : self . arch = arch . upper (). strip () self . module_type = module_type . upper (). strip () if not dsc_section_type . IsValidModuleType ( self . module_type ) : raise ValueError ( f \"{module_type} is not a proper module type for dsc section\" ) def __hash__ ( self ) : arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch return hash (( arch , self . module_type )) def __eq__ ( self , other ) : if type ( other ) is not dsc_section_type : return False arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch arch2 = \"*\" if ( other . arch == \"COMMON\" or other . arch == \"DEFAULT\" ) else other . arch return self . module_type == other . module_type or arch == arch2 def __repr__ ( self ) : attributes = f \".{self.arch}.{self.module_type}\" return attributes @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types Descendants edk2toollib.uefi.edk2.build_objects.dsc.dsc_buildoption_section_type Class variables dsc_module_types Static methods IsValidModuleType def IsValidModuleType ( name ) View Source @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types dsc_set class dsc_set ( allowed_classes = None ) set() -> new empty set object set(iterable) -> new set object Build an unordered collection of unique elements. View Source class dsc_set ( set ): def __init__ ( self , allowed_classes = None ): if allowed_classes is None: allowed_classes = [] self . _allowed_classes = set ( allowed_classes ) def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes: raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self: super (). discard ( item ) # NEXTVER: get add the old_item to item super (). add ( item ) Ancestors (in MRO) builtins.set Methods add def add ( self , item ) Add an element to a set. This has no effect if the element is already present. View Source def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes : raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self : super (). discard ( item ) # NEXTVER : get add the old_item to item super (). add ( item ) clear def clear ( ... ) Remove all elements from this set. copy def copy ( ... ) Return a shallow copy of a set. difference def difference ( ... ) Return the difference of two or more sets as a new set. (i.e. all elements that are in this set but not the others.) difference_update def difference_update ( ... ) Remove all elements of another set from this set. discard def discard ( ... ) Remove an element from a set if it is a member. If the element is not a member, do nothing. intersection def intersection ( ... ) Return the intersection of two sets as a new set. (i.e. all elements that are in both sets.) intersection_update def intersection_update ( ... ) Update a set with the intersection of itself and another. isdisjoint def isdisjoint ( ... ) Return True if two sets have a null intersection. issubset def issubset ( ... ) Report whether another set contains this set. issuperset def issuperset ( ... ) Report whether this set contains another set. pop def pop ( ... ) Remove and return an arbitrary set element. Raises KeyError if the set is empty. remove def remove ( ... ) Remove an element from a set; it must be a member. If the element is not a member, raise a KeyError. symmetric_difference def symmetric_difference ( ... ) Return the symmetric difference of two sets as a new set. (i.e. all elements that are in exactly one of the sets.) symmetric_difference_update def symmetric_difference_update ( ... ) Update a set with the symmetric difference of itself and another. union def union ( ... ) Return the union of sets as a new set. (i.e. all elements that are in either set.) update def update ( ... ) Update a set with the union of itself and others. library class library ( inf : str , source_info = None ) Contains the data for a specific EDK library View Source class library: ''' Contains the data for a specific EDK library''' def __init__ ( self , inf: str , source_info = None ): self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not library: return False return self . inf == other . inf def __hash__ ( self ): return hash ( self . inf ) # NEXTVER how to figure out if they hash to the same spot? def __repr__ ( self ): return f \"{self.inf} @ {self.source_info}\" library_class class library_class ( libraryclass : str , inf : str , source_info = None ) Contains the data for a specific EDK2 library class View Source class library_class: ''' Contains the data for a specific EDK2 library class''' def __init__ ( self , libraryclass: str , inf: str , source_info = None ): self . libraryclass = libraryclass self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not library_class ): return False # if they're both null if self . libraryclass . lower () == \"null\" and other . libraryclass . lower () == \"null\" : return self . inf == other . inf return self . libraryclass . lower () == other . libraryclass . lower () def __hash__ ( self ): # if we're a null lib, we want the hash to be based on the inf path if ( self . libraryclass . lower () == \"null\" ): return hash ( self . inf ) else: return hash ( self . libraryclass ) def __repr__ ( self ): return f \"{self.libraryclass}|{self.inf} @ {self.source_info}\" pcd class pcd ( namespace , name , value , source_info = None ) Contains the data for a specific pcd View Source class pcd: ''' Contains the data for a specific pcd ''' ''' PcdTokenSpaceGuidCName.PcdCName|Value ''' def __init__ ( self , namespace , name , value , source_info = None ): self . namespace = namespace self . name = name self . value = value self . source_info = source_info def __eq__ ( self , other ): if not issubclass ( other . __class__ , pcd ): return False return self . namespace == other . namespace and self . name == other . name def __hash__ ( self ): return hash ( f \"{self.namespace}.{self.name}\" ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} @ {self.source_info}\" Descendants edk2toollib.uefi.edk2.build_objects.dsc.pcd_typed edk2toollib.uefi.edk2.build_objects.dsc.pcd_variable pcd_typed class pcd_typed ( namespace , name , value , datum_type , max_size = 0 , source_info = None ) PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] View Source class pcd_typed ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] ''' def __init__ ( self , namespace , name , value , datum_type , max_size = 0 , source_info = None ): super (). __init__ ( namespace , name , value , source_info ) self . datum_type = datum_type self . max_size = int ( max_size ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} |{self.datum_type}|{self.max_size} @ {self.source_info}\" Ancestors (in MRO) edk2toollib.uefi.edk2.build_objects.dsc.pcd pcd_variable class pcd_variable ( namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ) PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] View Source class pcd_variable ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] ''' def __init__ ( self , namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ): super (). __init__ ( namespace , name , \"\" , source_info ) if attributes is None: attributes = [] self . var_name = var_name self . var_guid = var_guid self . var_offset = var_offset self . default = default if type ( attributes ) is str: attributes = attributes . split ( \",\" ) attributes = [ str ( x ). upper (). strip () for x in attributes ] if any ([ x not in pcd_variable_attributes for x in attributes ]): raise ValueError ( f \"Invalid PcdHiiAttribute values: {attributes}\" ) self . attributes = attributes def __repr__ ( self ): pcd_data = f \"{self.var_guid}|{self.var_offset}|{self.default}|{self.attributes}\" return f \"{self.namespace}.{self.name} = {self.var_name} |{pcd_data} @ {self.source_info}\" Ancestors (in MRO) edk2toollib.uefi.edk2.build_objects.dsc.pcd sku_id class sku_id ( id = 0 , name = 'DEFAULT' , parent = 'DEFAULT' , source_info = None ) contains the data for a sku View Source class sku_id: ''' contains the data for a sku ''' def __init__ ( self , id = 0 , name = \"DEFAULT\" , parent = \"DEFAULT\" , source_info = None ): self . id = id self . name = name self . parent = parent # the default parent is default self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not sku_id: return False return self . id == other . id or self . name == other . name def __hash__ ( self ): # we return zero because we want all the skus to hash to the same bucket # this won't be performant for large numbers of skus, which hopefully won't happen # we instead rely on __eq__ since we want to collide on two different attributes # since we want to make sure names and id's are unique return 0 def __repr__ ( self ): return f \"{self.id}|{self.name}|{self.parent}\" source_info class source_info ( file : str , lineno : int = None ) View Source class source_info: def __init__ ( self , file: str , lineno: int = None ): self . file = file self . lineno = lineno def __repr__ ( self ): if self . lineno is None: return self . file return f \"{self.file}:{self.lineno}\"","title":"Dsc"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#module-edk2toollibuefiedk2build_objectsdsc","text":"View Source # @file dsc.py # Data model for the EDK II DSC # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## # There will be some overlap between the objects for DSC files and FDF files import collections DEFAULT_SECTION_TYPE = \"COMMON\" class dsc_set ( set ): def __init__ ( self , allowed_classes = None ): if allowed_classes is None : allowed_classes = [] self . _allowed_classes = set ( allowed_classes ) def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes : raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self : super () . discard ( item ) # NEXTVER: get add the old_item to item super () . add ( item ) class dsc_dict ( collections . OrderedDict ): ''' A dictionary that allows specific classes as headers and sections ''' def __init__ ( self , allowed_key_classes = None , allowed_value_classes = None ): if allowed_key_classes is None : allowed_key_classes = [] if allowed_value_classes is None : allowed_value_classes = [] self . _allowed_key_classes = set ( allowed_key_classes ) self . _allowed_value_classes = set ( allowed_value_classes ) def __missing__ ( self , key ): if len ( self . _allowed_value_classes ) > 0 : # if we have specified allowed value classes, make a new dsc_set self [ key ] = dsc_set ( self . _allowed_value_classes ) return self [ key ] raise KeyError ( key ) def __setitem__ ( self , key , val ): if len ( self . _allowed_key_classes ) > 0 and type ( key ) not in self . _allowed_key_classes : raise ValueError ( f \"Cannot add {type(key)} to restricted set: {self._allowed_key_classes}\" ) if len ( self . _allowed_value_classes ) > 0 : if type ( val ) == set and len ( val ) == 0 : # if it's an empty set, convert it to a dsc_set val = dsc_set ( allowed_classes = self . _allowed_value_classes ) if type ( val ) == dsc_set : if val . _allowed_classes != self . _allowed_value_classes : raise ValueError ( f \"Cannot add set:{val._allowed_classes} to restricted dict: {self._allowed_value_classes}\" ) elif type ( val ) not in self . _allowed_value_classes : raise ValueError ( f \"Cannot add {type(val)} to restricted dict: {self._allowed_value_classes}\" ) if key in self : # NEXTVER merge these together? raise ValueError ( f \"Cannot add section {key} since it already exists\" ) dict . __setitem__ ( self , key , val ) class dsc : def __init__ ( self , file_path = None ): # The EDK2 path to this particular DSC, if is is None it means it was created from a stream and has no file self . file_path = file_path # parameters added for clarity self . skus = dsc_set ( allowed_classes = [ definition , sku_id ]) # this is a set of SKUs self . components = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ component , definition ]) self . libraries = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ library , definition ]) self . library_classes = dsc_dict ( allowed_key_classes = [ dsc_section_type , ], allowed_value_classes = [ library_class , definition ]) self . build_options = dsc_dict ( allowed_key_classes = [ dsc_buildoption_section_type , ], allowed_value_classes = [ build_option , definition ]) self . pcds = dsc_dict ( allowed_key_classes = [ dsc_pcd_section_type , ], allowed_value_classes = [ pcd , pcd_typed , pcd_variable ]) self . defines = dsc_set ( allowed_classes = [ definition , ]) self . default_stores = dsc_set ( allowed_classes = [ definition , default_store ]) # NEXTVER: should we populate the default information into the DSC object? # FOR EXAMPLE: default_stores and skus def __eq__ ( self , other ): ''' This doesn't check for a perfect copy of everything ''' ''' this is mainly focused on does it define the same things ''' if type ( other ) is not dsc : return False if other . skus != self . skus : return False if other . components != self . components : return False if other . library_classes != self . library_classes : return False if other . build_options != self . build_options : return False if other . pcds != self . pcds : return False if other . defines != self . defines : return False return True class dsc_section_type : dsc_module_types = [ \"COMMON\" , \"BASE\" , \"SEC\" , \"PEI_CORE\" , \"PEIM\" , \"DXE_CORE\" , \"DXE_DRIVER\" , \"DXE_RUNTIME_DRIVER\" , \"DXE_SAL_DRIVER\" , \"DXE_SMM_DRIVER\" , \"SMM_CORE\" , \"UEFI_DRIVER\" , \"UEFI_APPLICATION\" , \"USER_DEFINED\" ] def __init__ ( self , arch = \"common\" , module_type = \"common\" ): self . arch = arch . upper () . strip () self . module_type = module_type . upper () . strip () if not dsc_section_type . IsValidModuleType ( self . module_type ): raise ValueError ( f \"{module_type} is not a proper module type for dsc section\" ) def __hash__ ( self ): arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch return hash (( arch , self . module_type )) def __eq__ ( self , other ): if type ( other ) is not dsc_section_type : return False arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch arch2 = \"*\" if ( other . arch == \"COMMON\" or other . arch == \"DEFAULT\" ) else other . arch return self . module_type == other . module_type or arch == arch2 def __repr__ ( self ): attributes = f \".{self.arch}.{self.module_type}\" return attributes @classmethod def IsValidModuleType ( cls , name ): return name in cls . dsc_module_types class dsc_buildoption_section_type ( dsc_section_type ): ''' [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] ''' def __init__ ( self , arch = \"common\" , codebase = \"common\" , module_type = \"common\" ): super () . __init__ ( arch , module_type ) self . codebase = codebase . upper () . strip () if not self . IsValidCodeBase ( self . codebase ): raise ValueError ( f \"{codebase} is not a valid codebase type\" ) @classmethod def IsValidCodeBase ( cls , codebase ): return codebase in [ \"COMMON\" , \"EDK\" , \"EDKII\" ] def __hash__ ( self ): return hash (( super () . __hash__ (), self . codebase )) def __eq__ ( self , other ): if type ( other ) is not dsc_buildoption_section_type : return False if not ( other . module_type == self . module_type and other . codebase == self . codebase ): return False return other . module_type == self . module_type def __repr__ ( self ): return f \"{self.arch}.{self.codebase}.{self.module_type}\" dsc_pcd_types = [ \"FEATUREFLAG\" , \"PATCHABLEINMODULE\" , \"FIXEDATBUILD\" , \"DYNAMIC\" , \"DYNAMICEX\" , \"DYNAMICDEFAULT\" , \"DYNAMICHII\" , \"DYNAMICVPD\" , \"DYNAMICEXHII\" , \"DYNAMICEXVPD\" ] class dsc_pcd_section_type (): def __init__ ( self , pcdtype , arch = \"common\" , sku = \"DEFAULT\" , store = None ): # if store is none, then we don't have anything done self . arch = arch . upper () . strip () self . pcd_type = pcdtype . upper () . strip () self . default_store = None if store is None else store . strip () if self . pcd_type not in dsc_pcd_types : raise ValueError ( f \"{pcdtype} is not a proper PCD type\" ) if not self . pcd_type . endswith ( \"HII\" ) and self . default_store is not None : raise ValueError ( f \"{pcdtype} does not allow for a store to be specified\" ) self . sku = sku . upper () def __hash__ ( self ): return hash (( self . arch , self . pcd_type )) def __repr__ ( self ): store = \"\" if self . default_store is None else f \".{self.default_store}\" return f \"Pcds{self.pcd_type}.{self.arch}.{self.sku}{store}\" def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_section_type : return False return self . pcd_type == other . pcd_type and self . arch == other . arch class dsc_pcd_component_type ( dsc_pcd_section_type ): ''' This class is uses to define the PCD type inside a component ''' def __init__ ( self , pcdtype ): super () . __init__ ( pcdtype ) def __repr__ ( self ): return f \"Pcds{self.pcd_type}\" def __hash__ ( self ): return hash ( self . pcd_type ) def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_component_type : return False return self . pcd_type == other . pcd_type class sku_id : ''' contains the data for a sku ''' def __init__ ( self , id = 0 , name = \"DEFAULT\" , parent = \"DEFAULT\" , source_info = None ): self . id = id self . name = name self . parent = parent # the default parent is default self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not sku_id : return False return self . id == other . id or self . name == other . name def __hash__ ( self ): # we return zero because we want all the skus to hash to the same bucket # this won't be performant for large numbers of skus, which hopefully won't happen # we instead rely on __eq__ since we want to collide on two different attributes # since we want to make sure names and id's are unique return 0 def __repr__ ( self ): return f \"{self.id}|{self.name}|{self.parent}\" class component : ''' Contains the data for a component for the EDK build system to build ''' def __init__ ( self , inf , source_info = None ): self . library_classes = set () # a list of libraries that this component uses self . pcds = {} # a dictionary of PCD's that are keyed by dsc_pcd_component_type, they are sets self . defines = set () # a set of defines self . build_options = set () # a set of build options for this component self . inf = inf # the EDK2 relative path to the source INF self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not component ): return False return self . inf == other . inf # NEXTVER: should this be case insensitive? def __hash__ ( self ): return hash ( self . inf ) def __repr__ ( self ): source = str ( self . source_info ) if source_info is not None else \"\" return f \"{self.inf} @ {source}\" class definition : ''' contains the information on a definition. ''' def __init__ ( self , name , value , local = False , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . name = name self . value = value self . local = local self . source_info = source_info def __repr__ ( self ): string = \"\" if self . local : string = \"DEFINE \" string += f \"{self.name} = {self.value} @ {self.source_info}\" return string def __hash__ ( self ): return hash ( self . name ) def __eq__ ( self , other ): if ( type ( other ) is not definition ): return False return other . name == self . name class library : ''' Contains the data for a specific EDK library''' def __init__ ( self , inf : str , source_info = None ): self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not library : return False return self . inf == other . inf def __hash__ ( self ): return hash ( self . inf ) # NEXTVER how to figure out if they hash to the same spot? def __repr__ ( self ): return f \"{self.inf} @ {self.source_info}\" class library_class : ''' Contains the data for a specific EDK2 library class''' def __init__ ( self , libraryclass : str , inf : str , source_info = None ): self . libraryclass = libraryclass self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not library_class ): return False # if they're both null if self . libraryclass . lower () == \"null\" and other . libraryclass . lower () == \"null\" : return self . inf == other . inf return self . libraryclass . lower () == other . libraryclass . lower () def __hash__ ( self ): # if we're a null lib, we want the hash to be based on the inf path if ( self . libraryclass . lower () == \"null\" ): return hash ( self . inf ) else : return hash ( self . libraryclass ) def __repr__ ( self ): return f \"{self.libraryclass}|{self.inf} @ {self.source_info}\" class pcd : ''' Contains the data for a specific pcd ''' ''' PcdTokenSpaceGuidCName.PcdCName|Value ''' def __init__ ( self , namespace , name , value , source_info = None ): self . namespace = namespace self . name = name self . value = value self . source_info = source_info def __eq__ ( self , other ): if not issubclass ( other . __class__ , pcd ): return False return self . namespace == other . namespace and self . name == other . name def __hash__ ( self ): return hash ( f \"{self.namespace}.{self.name}\" ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} @ {self.source_info}\" class pcd_typed ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] ''' def __init__ ( self , namespace , name , value , datum_type , max_size = 0 , source_info = None ): super () . __init__ ( namespace , name , value , source_info ) self . datum_type = datum_type self . max_size = int ( max_size ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} |{self.datum_type}|{self.max_size} @ {self.source_info}\" pcd_variable_attributes = [ \"NV\" , \"BS\" , \"RT\" , \"RO\" ] class pcd_variable ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] ''' def __init__ ( self , namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ): super () . __init__ ( namespace , name , \"\" , source_info ) if attributes is None : attributes = [] self . var_name = var_name self . var_guid = var_guid self . var_offset = var_offset self . default = default if type ( attributes ) is str : attributes = attributes . split ( \",\" ) attributes = [ str ( x ) . upper () . strip () for x in attributes ] if any ([ x not in pcd_variable_attributes for x in attributes ]): raise ValueError ( f \"Invalid PcdHiiAttribute values: {attributes}\" ) self . attributes = attributes def __repr__ ( self ): pcd_data = f \"{self.var_guid}|{self.var_offset}|{self.default}|{self.attributes}\" return f \"{self.namespace}.{self.name} = {self.var_name} |{pcd_data} @ {self.source_info}\" class build_option : ''' Contains the data for a build option ''' ''' EX: MSFT:*_*_*_CC_FLAGS = /D MDEPKG_NDEBUG ''' # {FAMILY}:{TARGET}_{TAGNAME}_{ARCH}_{TOOLCODE}_{ATTRIBUTE} def __init__ ( self , tool_code , attribute , data , target = \"*\" , tagname = \"*\" , arch = \"*\" , family = None , replace = False , source_info = None ): \"\"\" tool_code - The tool code must be one of the defined tool codes in the Conf/tools_def.txt file. The flags defined in this section are appended to flags defined in the tools_def.txt file for individual tools. attribute - for example flags, d_path, path data - the actual flags or path you want to set target - DEBUG, RELEASE, or other tagname - the tool chain tag arch - ARM, AARCH64, IA32, X64, etc family - Conf/tools_def.txt defines FAMILY as one of MSFT, INTEL or GCC. Typically, this field is used to help the build tools determine whether the line is used for Microsoft style Makefiles or the GNU style Makefile replace - whether or not this replaces the default from tools_def, if this is false, we append \"\"\" self . family = family self . target = target self . tagname = tagname self . arch = arch self . tool_code = tool_code self . attribute = attribute self . replace = replace self . data = data self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not build_option ): return False if self . family != other . family : return False if self . target != other . target : return False if self . tagname != other . tagname : return False if self . arch != other . arch : return False if self . tool_code != other . tool_code : return False if self . attribute != other . attribute : return False return True def __hash__ ( self ): return hash ( self . __repr__ ( False )) def __repr__ ( self , include_data = True ): rep = \"\" if self . family is None else f \"{self.family}:\" rep += \"_\" . join (( self . target , self . tagname , self . arch , self . tool_code , self . attribute )) if include_data : rep += f \"= {self.data}\" return rep class default_store : ''' contains the information on a default store. ''' ''' 0 | Standard # UEFI Standard default ''' def __init__ ( self , index = 0 , value = \"Standard\" , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . index = int ( index ) self . value = value self . source_info = source_info def __repr__ ( self ): return f \"{self.index} | {self.value}\" def __hash__ ( self ): return hash ( self . index ) def __eq__ ( self , other ): if ( type ( other ) is not default_store ): return False return other . index == self . index class source_info : def __init__ ( self , file : str , lineno : int = None ): self . file = file self . lineno = lineno def __repr__ ( self ): if self . lineno is None : return self . file return f \"{self.file}:{self.lineno}\"","title":"Module edk2toollib.uefi.edk2.build_objects.dsc"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#variables","text":"DEFAULT_SECTION_TYPE dsc_pcd_types pcd_variable_attributes","title":"Variables"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#build_option","text":"class build_option ( tool_code , attribute , data , target = '*' , tagname = '*' , arch = '*' , family = None , replace = False , source_info = None ) Contains the data for a build option View Source class build_option : '' ' Contains the data for a build option ''' ''' EX: MSFT:*_*_*_CC_FLAGS = /D MDEPKG_NDEBUG ''' # {FAMILY}:{TARGET}_{TAGNAME}_{ARCH}_{TOOLCODE}_{ATTRIBUTE} def __init__(self, tool_code, attribute, data, target=\"*\", tagname=\"*\", arch=\"*\", family=None, replace=False, source_info=None): \"\"\" tool_code - The tool code must be one of the defined tool codes in the Conf/tools_def.txt file. The flags defined in this section are appended to flags defined in the tools_def.txt file for individual tools. attribute - for example flags, d_path, path data - the actual flags or path you want to set target - DEBUG, RELEASE, or other tagname - the tool chain tag arch - ARM, AARCH64, IA32, X64, etc family - Conf/tools_def.txt defines FAMILY as one of MSFT, INTEL or GCC. Typically, this field is used to help the build tools determine whether the line is used for Microsoft style Makefiles or the GNU style Makefile replace - whether or not this replaces the default from tools_def, if this is false, we append \"\"\" self.family = family self.target = target self.tagname = tagname self.arch = arch self.tool_code = tool_code self.attribute = attribute self.replace = replace self.data = data self.source_info = source_info def __eq__(self, other): if (type(other) is not build_option): return False if self.family != other.family: return False if self.target != other.target: return False if self.tagname != other.tagname: return False if self.arch != other.arch: return False if self.tool_code != other.tool_code: return False if self.attribute != other.attribute: return False return True def __hash__(self): return hash(self.__repr__(False)) def __repr__(self, include_data=True): rep = \"\" if self.family is None else f\"{self.family}:\" rep += \"_\".join((self.target, self.tagname, self.arch, self.tool_code, self.attribute)) if include_data: rep += f\"= {self.data}\" return rep","title":"build_option"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#component","text":"class component ( inf , source_info = None ) Contains the data for a component for the EDK build system to build View Source class component: ''' Contains the data for a component for the EDK build system to build ''' def __init__ ( self , inf , source_info = None ): self . library_classes = set () # a list of libraries that this component uses self . pcds = {} # a dictionary of PCD's that are keyed by dsc_pcd_component_type, they are sets self . defines = set () # a set of defines self . build_options = set () # a set of build options for this component self . inf = inf # the EDK2 relative path to the source INF self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not component ): return False return self . inf == other . inf # NEXTVER: should this be case insensitive? def __hash__ ( self ): return hash ( self . inf ) def __repr__ ( self ): source = str ( self . source_info ) if source_info is not None else \"\" return f \"{self.inf} @ {source}\"","title":"component"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#default_store","text":"class default_store ( index = 0 , value = 'Standard' , source_info = None ) contains the information on a default store. View Source class default_store: ''' contains the information on a default store. ''' ''' 0 | Standard # UEFI Standard default ''' def __init__ ( self , index = 0 , value = \"Standard\" , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . index = int ( index ) self . value = value self . source_info = source_info def __repr__ ( self ): return f \"{self.index} | {self.value}\" def __hash__ ( self ): return hash ( self . index ) def __eq__ ( self , other ): if ( type ( other ) is not default_store ): return False return other . index == self . index","title":"default_store"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#definition","text":"class definition ( name , value , local = False , source_info = None ) contains the information on a definition. View Source class definition: ''' contains the information on a definition. ''' def __init__ ( self , name , value , local = False , source_info = None ): ''' Local means DEFINE is in front and is localized to that particular section''' self . name = name self . value = value self . local = local self . source_info = source_info def __repr__ ( self ): string = \"\" if self . local: string = \"DEFINE \" string += f \"{self.name} = {self.value} @ {self.source_info}\" return string def __hash__ ( self ): return hash ( self . name ) def __eq__ ( self , other ): if ( type ( other ) is not definition ): return False return other . name == self . name","title":"definition"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc","text":"class dsc ( file_path = None ) View Source class dsc: def __init__ ( self , file_path = None ): # The EDK2 path to this particular DSC, if is is None it means it was created from a stream and has no file self . file_path = file_path # parameters added for clarity self . skus = dsc_set ( allowed_classes =[ definition , sku_id ]) # this is a set of SKUs self . components = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ component , definition ]) self . libraries = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ library , definition ]) self . library_classes = dsc_dict ( allowed_key_classes =[ dsc_section_type , ], allowed_value_classes =[ library_class , definition ]) self . build_options = dsc_dict ( allowed_key_classes =[ dsc_buildoption_section_type , ], allowed_value_classes =[ build_option , definition ]) self . pcds = dsc_dict ( allowed_key_classes =[ dsc_pcd_section_type , ], allowed_value_classes =[ pcd , pcd_typed , pcd_variable ]) self . defines = dsc_set ( allowed_classes =[ definition , ]) self . default_stores = dsc_set ( allowed_classes =[ definition , default_store ]) # NEXTVER: should we populate the default information into the DSC object? # FOR EXAMPLE: default_stores and skus def __eq__ ( self , other ): ''' This doesn' t check for a perfect copy of everything ''' ''' this is mainly focused on does it define the same things '' ' if type ( other ) is not dsc: return False if other . skus != self . skus: return False if other . components != self . components: return False if other . library_classes != self . library_classes: return False if other . build_options != self . build_options: return False if other . pcds != self . pcds: return False if other . defines != self . defines: return False return True","title":"dsc"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_buildoption_section_type","text":"class dsc_buildoption_section_type ( arch = 'common' , codebase = 'common' , module_type = 'common' ) [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] View Source class dsc_buildoption_section_type ( dsc_section_type ) : ''' [BuildOptions.$(arch).CodeBase.Edk2ModuleType] [BuildOptions.$(arch).CodeBase] [BuildOptions.common.CodeBase] [BuildOptions.$(arch)] [BuildOptions.common] [BuildOptions] ''' def __init__ ( self , arch = \"common\" , codebase = \"common\" , module_type = \"common\" ) : super (). __init__ ( arch , module_type ) self . codebase = codebase . upper (). strip () if not self . IsValidCodeBase ( self . codebase ) : raise ValueError ( f \"{codebase} is not a valid codebase type\" ) @classmethod def IsValidCodeBase ( cls , codebase ) : return codebase in [ \"COMMON\", \"EDK\", \"EDKII\" ] def __hash__ ( self ) : return hash (( super (). __hash__ (), self . codebase )) def __eq__ ( self , other ) : if type ( other ) is not dsc_buildoption_section_type : return False if not ( other . module_type == self . module_type and other . codebase == self . codebase ) : return False return other . module_type == self . module_type def __repr__ ( self ) : return f \"{self.arch}.{self.codebase}.{self.module_type}\"","title":"dsc_buildoption_section_type"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.build_objects.dsc.dsc_section_type","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#class-variables","text":"dsc_module_types","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#isvalidcodebase","text":"def IsValidCodeBase ( codebase ) View Source @classmethod def IsValidCodeBase ( cls , codebase ) : return codebase in [ \"COMMON\", \"EDK\", \"EDKII\" ]","title":"IsValidCodeBase"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#isvalidmoduletype","text":"def IsValidModuleType ( name ) View Source @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types","title":"IsValidModuleType"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_dict","text":"class dsc_dict ( allowed_key_classes = None , allowed_value_classes = None ) A dictionary that allows specific classes as headers and sections View Source class dsc_dict ( collections . OrderedDict ) : ''' A dictionary that allows specific classes as headers and sections ''' def __init__ ( self , allowed_key_classes = None , allowed_value_classes = None ) : if allowed_key_classes is None : allowed_key_classes = [] if allowed_value_classes is None : allowed_value_classes = [] self . _allowed_key_classes = set ( allowed_key_classes ) self . _allowed_value_classes = set ( allowed_value_classes ) def __missing__ ( self , key ) : if len ( self . _allowed_value_classes ) > 0 : # if we have specified allowed value classes , make a new dsc_set self [ key ] = dsc_set ( self . _allowed_value_classes ) return self [ key ] raise KeyError ( key ) def __setitem__ ( self , key , val ) : if len ( self . _allowed_key_classes ) > 0 and type ( key ) not in self . _allowed_key_classes : raise ValueError ( f \"Cannot add {type(key)} to restricted set: {self._allowed_key_classes}\" ) if len ( self . _allowed_value_classes ) > 0 : if type ( val ) == set and len ( val ) == 0 : # if it ' s an empty set , convert it to a dsc_set val = dsc_set ( allowed_classes = self . _allowed_value_classes ) if type ( val ) == dsc_set : if val . _allowed_classes != self . _allowed_value_classes : raise ValueError ( f \"Cannot add set:{val._allowed_classes} to restricted dict: {self._allowed_value_classes}\" ) elif type ( val ) not in self . _allowed_value_classes : raise ValueError ( f \"Cannot add {type(val)} to restricted dict: {self._allowed_value_classes}\" ) if key in self : # NEXTVER merge these together ? raise ValueError ( f \"Cannot add section {key} since it already exists\" ) dict . __setitem__ ( self , key , val )","title":"dsc_dict"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro_1","text":"collections.OrderedDict builtins.dict","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#clear","text":"def clear ( ... ) od.clear() -> None. Remove all items from od.","title":"clear"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#copy","text":"def copy ( ... ) od.copy() -> a shallow copy of od","title":"copy"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#fromkeys","text":"def fromkeys ( iterable , value = None ) Create a new ordered dictionary with keys from iterable and values set to value.","title":"fromkeys"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#get","text":"def get ( self , key , default = None , / ) Return the value for key if key is in the dictionary, else default.","title":"get"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#items","text":"def items ( ... ) D.items() -> a set-like object providing a view on D\u2019s items","title":"items"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#keys","text":"def keys ( ... ) D.keys() -> a set-like object providing a view on D\u2019s keys","title":"keys"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#move_to_end","text":"def move_to_end ( self , / , key , last = True ) Move an existing element to the end (or beginning if last is false). Raise KeyError if the element does not exist.","title":"move_to_end"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#pop","text":"def pop ( ... ) od.pop(k[,d]) -> v, remove specified key and return the corresponding value. If key is not found, d is returned if given, otherwise KeyError is raised.","title":"pop"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#popitem","text":"def popitem ( self , / , last = True ) Remove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO order if last is true or FIFO order if false.","title":"popitem"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#setdefault","text":"def setdefault ( self , / , key , default = None ) Insert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default.","title":"setdefault"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#update","text":"def update ( ... ) D.update([E, ]**F) -> None. Update D from dict/iterable E and F. If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]","title":"update"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#values","text":"def values ( ... ) D.values() -> an object providing a view on D\u2019s values","title":"values"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_pcd_component_type","text":"class dsc_pcd_component_type ( pcdtype ) This class is uses to define the PCD type inside a component View Source class dsc_pcd_component_type ( dsc_pcd_section_type ): ''' This class is uses to define the PCD type inside a component ''' def __init__ ( self , pcdtype ): super (). __init__ ( pcdtype ) def __repr__ ( self ): return f \"Pcds{self.pcd_type}\" def __hash__ ( self ): return hash ( self . pcd_type ) def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_component_type: return False return self . pcd_type == other . pcd_type","title":"dsc_pcd_component_type"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro_2","text":"edk2toollib.uefi.edk2.build_objects.dsc.dsc_pcd_section_type","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_pcd_section_type","text":"class dsc_pcd_section_type ( pcdtype , arch = 'common' , sku = 'DEFAULT' , store = None ) View Source class dsc_pcd_section_type (): def __init__ ( self , pcdtype , arch = \"common\" , sku = \"DEFAULT\" , store = None ): # if store is none, then we don't have anything done self . arch = arch . upper (). strip () self . pcd_type = pcdtype . upper (). strip () self . default_store = None if store is None else store . strip () if self . pcd_type not in dsc_pcd_types: raise ValueError ( f \"{pcdtype} is not a proper PCD type\" ) if not self . pcd_type . endswith ( \"HII\" ) and self . default_store is not None: raise ValueError ( f \"{pcdtype} does not allow for a store to be specified\" ) self . sku = sku . upper () def __hash__ ( self ): return hash (( self . arch , self . pcd_type )) def __repr__ ( self ): store = \"\" if self . default_store is None else f \".{self.default_store}\" return f \"Pcds{self.pcd_type}.{self.arch}.{self.sku}{store}\" def __eq__ ( self , other ): if type ( other ) is not dsc_pcd_section_type: return False return self . pcd_type == other . pcd_type and self . arch == other . arch","title":"dsc_pcd_section_type"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#descendants","text":"edk2toollib.uefi.edk2.build_objects.dsc.dsc_pcd_component_type","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_section_type","text":"class dsc_section_type ( arch = 'common' , module_type = 'common' ) View Source class dsc_section_type : dsc_module_types = [ \"COMMON\", \"BASE\", \"SEC\", \"PEI_CORE\", \"PEIM\", \"DXE_CORE\", \"DXE_DRIVER\", \"DXE_RUNTIME_DRIVER\", \"DXE_SAL_DRIVER\", \"DXE_SMM_DRIVER\", \"SMM_CORE\", \"UEFI_DRIVER\", \"UEFI_APPLICATION\", \"USER_DEFINED\" ] def __init__ ( self , arch = \"common\" , module_type = \"common\" ) : self . arch = arch . upper (). strip () self . module_type = module_type . upper (). strip () if not dsc_section_type . IsValidModuleType ( self . module_type ) : raise ValueError ( f \"{module_type} is not a proper module type for dsc section\" ) def __hash__ ( self ) : arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch return hash (( arch , self . module_type )) def __eq__ ( self , other ) : if type ( other ) is not dsc_section_type : return False arch = \"*\" if ( self . arch == \"COMMON\" or self . arch == \"DEFAULT\" ) else self . arch arch2 = \"*\" if ( other . arch == \"COMMON\" or other . arch == \"DEFAULT\" ) else other . arch return self . module_type == other . module_type or arch == arch2 def __repr__ ( self ) : attributes = f \".{self.arch}.{self.module_type}\" return attributes @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types","title":"dsc_section_type"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#descendants_1","text":"edk2toollib.uefi.edk2.build_objects.dsc.dsc_buildoption_section_type","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#class-variables_1","text":"dsc_module_types","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#static-methods_1","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#isvalidmoduletype_1","text":"def IsValidModuleType ( name ) View Source @classmethod def IsValidModuleType ( cls , name ) : return name in cls . dsc_module_types","title":"IsValidModuleType"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#dsc_set","text":"class dsc_set ( allowed_classes = None ) set() -> new empty set object set(iterable) -> new set object Build an unordered collection of unique elements. View Source class dsc_set ( set ): def __init__ ( self , allowed_classes = None ): if allowed_classes is None: allowed_classes = [] self . _allowed_classes = set ( allowed_classes ) def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes: raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self: super (). discard ( item ) # NEXTVER: get add the old_item to item super (). add ( item )","title":"dsc_set"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro_3","text":"builtins.set","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#add","text":"def add ( self , item ) Add an element to a set. This has no effect if the element is already present. View Source def add ( self , item ): if len ( self . _allowed_classes ) > 0 and type ( item ) not in self . _allowed_classes : raise ValueError ( f \"Cannot add {type(item)} to restricted set: {self._allowed_classes}\" ) if item in self : super (). discard ( item ) # NEXTVER : get add the old_item to item super (). add ( item )","title":"add"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#clear_1","text":"def clear ( ... ) Remove all elements from this set.","title":"clear"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#copy_1","text":"def copy ( ... ) Return a shallow copy of a set.","title":"copy"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#difference","text":"def difference ( ... ) Return the difference of two or more sets as a new set. (i.e. all elements that are in this set but not the others.)","title":"difference"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#difference_update","text":"def difference_update ( ... ) Remove all elements of another set from this set.","title":"difference_update"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#discard","text":"def discard ( ... ) Remove an element from a set if it is a member. If the element is not a member, do nothing.","title":"discard"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#intersection","text":"def intersection ( ... ) Return the intersection of two sets as a new set. (i.e. all elements that are in both sets.)","title":"intersection"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#intersection_update","text":"def intersection_update ( ... ) Update a set with the intersection of itself and another.","title":"intersection_update"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#isdisjoint","text":"def isdisjoint ( ... ) Return True if two sets have a null intersection.","title":"isdisjoint"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#issubset","text":"def issubset ( ... ) Report whether another set contains this set.","title":"issubset"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#issuperset","text":"def issuperset ( ... ) Report whether this set contains another set.","title":"issuperset"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#pop_1","text":"def pop ( ... ) Remove and return an arbitrary set element. Raises KeyError if the set is empty.","title":"pop"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#remove","text":"def remove ( ... ) Remove an element from a set; it must be a member. If the element is not a member, raise a KeyError.","title":"remove"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#symmetric_difference","text":"def symmetric_difference ( ... ) Return the symmetric difference of two sets as a new set. (i.e. all elements that are in exactly one of the sets.)","title":"symmetric_difference"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#symmetric_difference_update","text":"def symmetric_difference_update ( ... ) Update a set with the symmetric difference of itself and another.","title":"symmetric_difference_update"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#union","text":"def union ( ... ) Return the union of sets as a new set. (i.e. all elements that are in either set.)","title":"union"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#update_1","text":"def update ( ... ) Update a set with the union of itself and others.","title":"update"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#library","text":"class library ( inf : str , source_info = None ) Contains the data for a specific EDK library View Source class library: ''' Contains the data for a specific EDK library''' def __init__ ( self , inf: str , source_info = None ): self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not library: return False return self . inf == other . inf def __hash__ ( self ): return hash ( self . inf ) # NEXTVER how to figure out if they hash to the same spot? def __repr__ ( self ): return f \"{self.inf} @ {self.source_info}\"","title":"library"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#library_class","text":"class library_class ( libraryclass : str , inf : str , source_info = None ) Contains the data for a specific EDK2 library class View Source class library_class: ''' Contains the data for a specific EDK2 library class''' def __init__ ( self , libraryclass: str , inf: str , source_info = None ): self . libraryclass = libraryclass self . inf = inf self . source_info = source_info def __eq__ ( self , other ): if ( type ( other ) is not library_class ): return False # if they're both null if self . libraryclass . lower () == \"null\" and other . libraryclass . lower () == \"null\" : return self . inf == other . inf return self . libraryclass . lower () == other . libraryclass . lower () def __hash__ ( self ): # if we're a null lib, we want the hash to be based on the inf path if ( self . libraryclass . lower () == \"null\" ): return hash ( self . inf ) else: return hash ( self . libraryclass ) def __repr__ ( self ): return f \"{self.libraryclass}|{self.inf} @ {self.source_info}\"","title":"library_class"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#pcd","text":"class pcd ( namespace , name , value , source_info = None ) Contains the data for a specific pcd View Source class pcd: ''' Contains the data for a specific pcd ''' ''' PcdTokenSpaceGuidCName.PcdCName|Value ''' def __init__ ( self , namespace , name , value , source_info = None ): self . namespace = namespace self . name = name self . value = value self . source_info = source_info def __eq__ ( self , other ): if not issubclass ( other . __class__ , pcd ): return False return self . namespace == other . namespace and self . name == other . name def __hash__ ( self ): return hash ( f \"{self.namespace}.{self.name}\" ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} @ {self.source_info}\"","title":"pcd"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#descendants_2","text":"edk2toollib.uefi.edk2.build_objects.dsc.pcd_typed edk2toollib.uefi.edk2.build_objects.dsc.pcd_variable","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#pcd_typed","text":"class pcd_typed ( namespace , name , value , datum_type , max_size = 0 , source_info = None ) PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] View Source class pcd_typed ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|Value[|DatumType[|MaximumDatumSize]] ''' def __init__ ( self , namespace , name , value , datum_type , max_size = 0 , source_info = None ): super (). __init__ ( namespace , name , value , source_info ) self . datum_type = datum_type self . max_size = int ( max_size ) def __repr__ ( self ): return f \"{self.namespace}.{self.name} = {self.value} |{self.datum_type}|{self.max_size} @ {self.source_info}\"","title":"pcd_typed"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro_4","text":"edk2toollib.uefi.edk2.build_objects.dsc.pcd","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#pcd_variable","text":"class pcd_variable ( namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ) PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] View Source class pcd_variable ( pcd ): ''' PcdTokenSpaceGuidCName.PcdCName|VariableName|VariableGuid|VariableOffset[|HiiDefaultValue[|HiiAttribute]] ''' def __init__ ( self , namespace , name , var_name , var_guid , var_offset , default = None , attributes = None , source_info = None ): super (). __init__ ( namespace , name , \"\" , source_info ) if attributes is None: attributes = [] self . var_name = var_name self . var_guid = var_guid self . var_offset = var_offset self . default = default if type ( attributes ) is str: attributes = attributes . split ( \",\" ) attributes = [ str ( x ). upper (). strip () for x in attributes ] if any ([ x not in pcd_variable_attributes for x in attributes ]): raise ValueError ( f \"Invalid PcdHiiAttribute values: {attributes}\" ) self . attributes = attributes def __repr__ ( self ): pcd_data = f \"{self.var_guid}|{self.var_offset}|{self.default}|{self.attributes}\" return f \"{self.namespace}.{self.name} = {self.var_name} |{pcd_data} @ {self.source_info}\"","title":"pcd_variable"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#ancestors-in-mro_5","text":"edk2toollib.uefi.edk2.build_objects.dsc.pcd","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#sku_id","text":"class sku_id ( id = 0 , name = 'DEFAULT' , parent = 'DEFAULT' , source_info = None ) contains the data for a sku View Source class sku_id: ''' contains the data for a sku ''' def __init__ ( self , id = 0 , name = \"DEFAULT\" , parent = \"DEFAULT\" , source_info = None ): self . id = id self . name = name self . parent = parent # the default parent is default self . source_info = source_info def __eq__ ( self , other ): if type ( other ) is not sku_id: return False return self . id == other . id or self . name == other . name def __hash__ ( self ): # we return zero because we want all the skus to hash to the same bucket # this won't be performant for large numbers of skus, which hopefully won't happen # we instead rely on __eq__ since we want to collide on two different attributes # since we want to make sure names and id's are unique return 0 def __repr__ ( self ): return f \"{self.id}|{self.name}|{self.parent}\"","title":"sku_id"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc/#source_info","text":"class source_info ( file : str , lineno : int = None ) View Source class source_info: def __init__ ( self , file: str , lineno: int = None ): self . file = file self . lineno = lineno def __repr__ ( self ): if self . lineno is None: return self . file return f \"{self.file}:{self.lineno}\"","title":"source_info"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/","text":"Module edk2toollib.uefi.edk2.build_objects.dsc_translator View Source # @file dsc_translator # Translates a DSC object into a file # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent import os import logging from edk2toollib.uefi.edk2.build_objects.dsc import dsc from edk2toollib.uefi.edk2.build_objects.dsc import sku_id from edk2toollib.uefi.edk2.build_objects.dsc import dsc_set from edk2toollib.uefi.edk2.build_objects.dsc import library_class from edk2toollib.uefi.edk2.build_objects.dsc import definition from edk2toollib.uefi.edk2.build_objects.dsc import component from edk2toollib.uefi.edk2.build_objects.dsc import pcd from edk2toollib.uefi.edk2.build_objects.dsc import pcd_typed from edk2toollib.uefi.edk2.build_objects.dsc import pcd_variable from edk2toollib.uefi.edk2.build_objects.dsc import build_option class DscTranslator (): @classmethod def dsc_to_file ( cls , dsc_obj , filepath ): file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \" \\n \" ) f . close () @classmethod def _GetDscLinesFromDscObj ( cls , obj , depth = 0 ) -> list : ''' gets the DSC strings for an data model objects ''' lines = [] depth_pad = '' . ljust ( depth ) org_depth = depth depth += 2 if type ( obj ) is list or type ( obj ) is set or type ( obj ) is dsc_set : for item in obj : lines += cls . _GetDscLinesFromDscObj ( item , org_depth ) elif type ( obj ) is dsc : lines . append ( f \"{depth_pad}[Defines]\" ) lines += cls . _GetDscLinesFromDscObj ( obj . defines , depth ) # Second do the Skus lines . append ( f \"{depth_pad}[SkuIds]\" ) for x in obj . skus : lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Third, library classes for header , x in obj . library_classes . items (): lines . append ( f \"{depth_pad}[LibraryClasses{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Next do the components for header , x in obj . components . items (): lines . append ( f \"{depth_pad}[Components{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then PCD's for header , x in obj . pcds . items (): lines . append ( f \"{depth_pad}[{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then Build Options print ( obj . build_options . items ()) for header , x in obj . build_options . items (): lines . append ( f \"{depth_pad}[BuildOptions{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) elif type ( obj ) is sku_id : lines . append ( f \"{depth_pad}{obj.id}|{obj.name}|{obj.parent}\" ) elif type ( obj ) is library_class : lines . append ( f \"{depth_pad}{obj.libraryclass}|{obj.inf}\" ) elif type ( obj ) is definition : def_str = f \"{obj.name} = \\t {obj.value}\" if obj . local : def_str = \"DEFINE \" + def_str lines . append ( depth_pad + def_str ) elif type ( obj ) is component : lines += cls . _FormatComponent ( obj , depth ) elif type ( obj ) is pcd : lines . append ( f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}\" ) elif type ( obj ) is pcd_typed : pcd_str = f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}|{obj.datum_type}\" if obj . max_size > 0 : pcd_str += f \"|{obj.max_size}\" lines . append ( pcd_str ) elif type ( obj ) is pcd_variable : pcd_name = f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.var_name}\" if obj . default is None : lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}\" ) elif len ( obj . attributes ) == 0 : lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}\" ) else : attr = \", \" . join ( obj . attributes ) lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}|{attr}\" ) elif type ( obj ) is build_option : rep = depth_pad if obj . family is None else f \"{depth_pad}{obj.family}:\" rep += \"_\" . join (( obj . target , obj . tagname , obj . arch , obj . tool_code , obj . attribute )) rep += f \"= {obj.data}\" lines . append ( rep ) else : logging . warning ( f \"UNKNOWN OBJECT {obj}\" ) return lines @classmethod def _FormatComponent ( cls , comp , depth = 0 ): has_subsection = len ( comp . pcds ) > 0 or len ( comp . defines ) > 0 or len ( comp . build_options ) > 0 or len ( comp . library_classes ) > 0 depth_pad = '' . ljust ( depth ) if not has_subsection : return [ f \"{depth_pad}{comp.inf}\" , ] lines = [] org_depth_pad = depth_pad depth_pad += \" \" # add two more onto our pad depth += 4 lines . append ( f \"{org_depth_pad}{comp.inf} {{\" ) if len ( comp . pcds ) > 0 : for section , pcds in comp . pcds . items (): lines . append ( f \"{depth_pad}<{section}>\" ) lines += cls . _GetDscLinesFromDscObj ( pcds , depth ) pass if len ( comp . library_classes ) > 0 : lines . append ( f \"{depth_pad}<LibraryClasses>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . library_classes , depth ) if len ( comp . defines ) > 0 : lines . append ( f \"{depth_pad}<Defines>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . defines , depth ) if len ( comp . build_options ) > 0 : lines . append ( f \"{depth_pad}<BuildOptions>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . build_options , depth ) lines . append ( f \"{org_depth_pad}}}\" ) return lines Classes DscTranslator class DscTranslator ( / , * args , ** kwargs ) View Source class DscTranslator () : @classmethod def dsc_to_file ( cls , dsc_obj , filepath ) : file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \"\\n\" ) f . close () @classmethod def _GetDscLinesFromDscObj ( cls , obj , depth = 0 ) -> list : ''' gets the DSC strings for an data model objects ''' lines = [] depth_pad = '' . ljust ( depth ) org_depth = depth depth += 2 if type ( obj ) is list or type ( obj ) is set or type ( obj ) is dsc_set : for item in obj : lines += cls . _GetDscLinesFromDscObj ( item , org_depth ) elif type ( obj ) is dsc : lines . append ( f \"{depth_pad}[Defines]\" ) lines += cls . _GetDscLinesFromDscObj ( obj . defines , depth ) # Second do the Skus lines . append ( f \"{depth_pad}[SkuIds]\" ) for x in obj . skus : lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Third , library classes for header , x in obj . library_classes . items () : lines . append ( f \"{depth_pad}[LibraryClasses{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Next do the components for header , x in obj . components . items () : lines . append ( f \"{depth_pad}[Components{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then PCD 's for header, x in obj.pcds.items(): lines.append(f\"{depth_pad}[{header}]\") lines += cls._GetDscLinesFromDscObj(x, depth) # Then Build Options print(obj.build_options.items()) for header, x in obj.build_options.items(): lines.append(f\"{depth_pad}[BuildOptions{header}]\") lines += cls._GetDscLinesFromDscObj(x, depth) elif type(obj) is sku_id: lines.append(f\"{depth_pad}{obj.id}|{obj.name}|{obj.parent}\") elif type(obj) is library_class: lines.append(f\"{depth_pad}{obj.libraryclass}|{obj.inf}\") elif type(obj) is definition: def_str = f\"{obj.name} =\\t{obj.value}\" if obj.local: def_str = \"DEFINE \" + def_str lines.append(depth_pad + def_str) elif type(obj) is component: lines += cls._FormatComponent(obj, depth) elif type(obj) is pcd: lines.append(f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}\") elif type(obj) is pcd_typed: pcd_str = f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}|{obj.datum_type}\" if obj.max_size > 0: pcd_str += f\"|{obj.max_size}\" lines.append(pcd_str) elif type(obj) is pcd_variable: pcd_name = f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.var_name}\" if obj.default is None: lines.append(f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}\") elif len(obj.attributes) == 0: lines.append( f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}\") else: attr = \", \".join(obj.attributes) lines.append( f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}|{attr}\") elif type(obj) is build_option: rep = depth_pad if obj.family is None else f\"{depth_pad}{obj.family}:\" rep += \"_\".join((obj.target, obj.tagname, obj.arch, obj.tool_code, obj.attribute)) rep += f\"= {obj.data}\" lines.append(rep) else: logging.warning(f\"UNKNOWN OBJECT {obj}\") return lines @classmethod def _FormatComponent(cls, comp, depth=0): has_subsection = len(comp.pcds) > 0 or len(comp.defines) > 0 or len( comp.build_options) > 0 or len(comp.library_classes) > 0 depth_pad = ' ' . ljust ( depth ) if not has_subsection : return [ f\"{depth_pad}{comp.inf}\", ] lines = [] org_depth_pad = depth_pad depth_pad += \" \" # add two more onto our pad depth += 4 lines . append ( f \"{org_depth_pad}{comp.inf} {{\" ) if len ( comp . pcds ) > 0 : for section , pcds in comp . pcds . items () : lines . append ( f \"{depth_pad}<{section}>\" ) lines += cls . _GetDscLinesFromDscObj ( pcds , depth ) pass if len ( comp . library_classes ) > 0 : lines . append ( f \"{depth_pad}<LibraryClasses>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . library_classes , depth ) if len ( comp . defines ) > 0 : lines . append ( f \"{depth_pad}<Defines>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . defines , depth ) if len ( comp . build_options ) > 0 : lines . append ( f \"{depth_pad}<BuildOptions>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . build_options , depth ) lines . append ( f \"{org_depth_pad}}}\" ) return lines Static methods dsc_to_file def dsc_to_file ( dsc_obj , filepath ) View Source @classmethod def dsc_to_file ( cls , dsc_obj , filepath ) : file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \"\\n\" ) f . close ()","title":"Dsc translator"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/#module-edk2toollibuefiedk2build_objectsdsc_translator","text":"View Source # @file dsc_translator # Translates a DSC object into a file # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent import os import logging from edk2toollib.uefi.edk2.build_objects.dsc import dsc from edk2toollib.uefi.edk2.build_objects.dsc import sku_id from edk2toollib.uefi.edk2.build_objects.dsc import dsc_set from edk2toollib.uefi.edk2.build_objects.dsc import library_class from edk2toollib.uefi.edk2.build_objects.dsc import definition from edk2toollib.uefi.edk2.build_objects.dsc import component from edk2toollib.uefi.edk2.build_objects.dsc import pcd from edk2toollib.uefi.edk2.build_objects.dsc import pcd_typed from edk2toollib.uefi.edk2.build_objects.dsc import pcd_variable from edk2toollib.uefi.edk2.build_objects.dsc import build_option class DscTranslator (): @classmethod def dsc_to_file ( cls , dsc_obj , filepath ): file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \" \\n \" ) f . close () @classmethod def _GetDscLinesFromDscObj ( cls , obj , depth = 0 ) -> list : ''' gets the DSC strings for an data model objects ''' lines = [] depth_pad = '' . ljust ( depth ) org_depth = depth depth += 2 if type ( obj ) is list or type ( obj ) is set or type ( obj ) is dsc_set : for item in obj : lines += cls . _GetDscLinesFromDscObj ( item , org_depth ) elif type ( obj ) is dsc : lines . append ( f \"{depth_pad}[Defines]\" ) lines += cls . _GetDscLinesFromDscObj ( obj . defines , depth ) # Second do the Skus lines . append ( f \"{depth_pad}[SkuIds]\" ) for x in obj . skus : lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Third, library classes for header , x in obj . library_classes . items (): lines . append ( f \"{depth_pad}[LibraryClasses{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Next do the components for header , x in obj . components . items (): lines . append ( f \"{depth_pad}[Components{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then PCD's for header , x in obj . pcds . items (): lines . append ( f \"{depth_pad}[{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then Build Options print ( obj . build_options . items ()) for header , x in obj . build_options . items (): lines . append ( f \"{depth_pad}[BuildOptions{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) elif type ( obj ) is sku_id : lines . append ( f \"{depth_pad}{obj.id}|{obj.name}|{obj.parent}\" ) elif type ( obj ) is library_class : lines . append ( f \"{depth_pad}{obj.libraryclass}|{obj.inf}\" ) elif type ( obj ) is definition : def_str = f \"{obj.name} = \\t {obj.value}\" if obj . local : def_str = \"DEFINE \" + def_str lines . append ( depth_pad + def_str ) elif type ( obj ) is component : lines += cls . _FormatComponent ( obj , depth ) elif type ( obj ) is pcd : lines . append ( f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}\" ) elif type ( obj ) is pcd_typed : pcd_str = f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}|{obj.datum_type}\" if obj . max_size > 0 : pcd_str += f \"|{obj.max_size}\" lines . append ( pcd_str ) elif type ( obj ) is pcd_variable : pcd_name = f \"{depth_pad}{obj.namespace}.{obj.name}|{obj.var_name}\" if obj . default is None : lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}\" ) elif len ( obj . attributes ) == 0 : lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}\" ) else : attr = \", \" . join ( obj . attributes ) lines . append ( f \"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}|{attr}\" ) elif type ( obj ) is build_option : rep = depth_pad if obj . family is None else f \"{depth_pad}{obj.family}:\" rep += \"_\" . join (( obj . target , obj . tagname , obj . arch , obj . tool_code , obj . attribute )) rep += f \"= {obj.data}\" lines . append ( rep ) else : logging . warning ( f \"UNKNOWN OBJECT {obj}\" ) return lines @classmethod def _FormatComponent ( cls , comp , depth = 0 ): has_subsection = len ( comp . pcds ) > 0 or len ( comp . defines ) > 0 or len ( comp . build_options ) > 0 or len ( comp . library_classes ) > 0 depth_pad = '' . ljust ( depth ) if not has_subsection : return [ f \"{depth_pad}{comp.inf}\" , ] lines = [] org_depth_pad = depth_pad depth_pad += \" \" # add two more onto our pad depth += 4 lines . append ( f \"{org_depth_pad}{comp.inf} {{\" ) if len ( comp . pcds ) > 0 : for section , pcds in comp . pcds . items (): lines . append ( f \"{depth_pad}<{section}>\" ) lines += cls . _GetDscLinesFromDscObj ( pcds , depth ) pass if len ( comp . library_classes ) > 0 : lines . append ( f \"{depth_pad}<LibraryClasses>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . library_classes , depth ) if len ( comp . defines ) > 0 : lines . append ( f \"{depth_pad}<Defines>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . defines , depth ) if len ( comp . build_options ) > 0 : lines . append ( f \"{depth_pad}<BuildOptions>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . build_options , depth ) lines . append ( f \"{org_depth_pad}}}\" ) return lines","title":"Module edk2toollib.uefi.edk2.build_objects.dsc_translator"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/#dsctranslator","text":"class DscTranslator ( / , * args , ** kwargs ) View Source class DscTranslator () : @classmethod def dsc_to_file ( cls , dsc_obj , filepath ) : file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \"\\n\" ) f . close () @classmethod def _GetDscLinesFromDscObj ( cls , obj , depth = 0 ) -> list : ''' gets the DSC strings for an data model objects ''' lines = [] depth_pad = '' . ljust ( depth ) org_depth = depth depth += 2 if type ( obj ) is list or type ( obj ) is set or type ( obj ) is dsc_set : for item in obj : lines += cls . _GetDscLinesFromDscObj ( item , org_depth ) elif type ( obj ) is dsc : lines . append ( f \"{depth_pad}[Defines]\" ) lines += cls . _GetDscLinesFromDscObj ( obj . defines , depth ) # Second do the Skus lines . append ( f \"{depth_pad}[SkuIds]\" ) for x in obj . skus : lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Third , library classes for header , x in obj . library_classes . items () : lines . append ( f \"{depth_pad}[LibraryClasses{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Next do the components for header , x in obj . components . items () : lines . append ( f \"{depth_pad}[Components{header}]\" ) lines += cls . _GetDscLinesFromDscObj ( x , depth ) # Then PCD 's for header, x in obj.pcds.items(): lines.append(f\"{depth_pad}[{header}]\") lines += cls._GetDscLinesFromDscObj(x, depth) # Then Build Options print(obj.build_options.items()) for header, x in obj.build_options.items(): lines.append(f\"{depth_pad}[BuildOptions{header}]\") lines += cls._GetDscLinesFromDscObj(x, depth) elif type(obj) is sku_id: lines.append(f\"{depth_pad}{obj.id}|{obj.name}|{obj.parent}\") elif type(obj) is library_class: lines.append(f\"{depth_pad}{obj.libraryclass}|{obj.inf}\") elif type(obj) is definition: def_str = f\"{obj.name} =\\t{obj.value}\" if obj.local: def_str = \"DEFINE \" + def_str lines.append(depth_pad + def_str) elif type(obj) is component: lines += cls._FormatComponent(obj, depth) elif type(obj) is pcd: lines.append(f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}\") elif type(obj) is pcd_typed: pcd_str = f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.value}|{obj.datum_type}\" if obj.max_size > 0: pcd_str += f\"|{obj.max_size}\" lines.append(pcd_str) elif type(obj) is pcd_variable: pcd_name = f\"{depth_pad}{obj.namespace}.{obj.name}|{obj.var_name}\" if obj.default is None: lines.append(f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}\") elif len(obj.attributes) == 0: lines.append( f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}\") else: attr = \", \".join(obj.attributes) lines.append( f\"{pcd_name}|{obj.var_guid}|{obj.var_offset}|{obj.default}|{attr}\") elif type(obj) is build_option: rep = depth_pad if obj.family is None else f\"{depth_pad}{obj.family}:\" rep += \"_\".join((obj.target, obj.tagname, obj.arch, obj.tool_code, obj.attribute)) rep += f\"= {obj.data}\" lines.append(rep) else: logging.warning(f\"UNKNOWN OBJECT {obj}\") return lines @classmethod def _FormatComponent(cls, comp, depth=0): has_subsection = len(comp.pcds) > 0 or len(comp.defines) > 0 or len( comp.build_options) > 0 or len(comp.library_classes) > 0 depth_pad = ' ' . ljust ( depth ) if not has_subsection : return [ f\"{depth_pad}{comp.inf}\", ] lines = [] org_depth_pad = depth_pad depth_pad += \" \" # add two more onto our pad depth += 4 lines . append ( f \"{org_depth_pad}{comp.inf} {{\" ) if len ( comp . pcds ) > 0 : for section , pcds in comp . pcds . items () : lines . append ( f \"{depth_pad}<{section}>\" ) lines += cls . _GetDscLinesFromDscObj ( pcds , depth ) pass if len ( comp . library_classes ) > 0 : lines . append ( f \"{depth_pad}<LibraryClasses>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . library_classes , depth ) if len ( comp . defines ) > 0 : lines . append ( f \"{depth_pad}<Defines>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . defines , depth ) if len ( comp . build_options ) > 0 : lines . append ( f \"{depth_pad}<BuildOptions>\" ) lines += cls . _GetDscLinesFromDscObj ( comp . build_options , depth ) lines . append ( f \"{org_depth_pad}}}\" ) return lines","title":"DscTranslator"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/build_objects/dsc_translator/#dsc_to_file","text":"def dsc_to_file ( dsc_obj , filepath ) View Source @classmethod def dsc_to_file ( cls , dsc_obj , filepath ) : file_path = os . path . abspath ( filepath ) f = open ( file_path , \"w\" ) lines = cls . _GetDscLinesFromDscObj ( dsc_obj ) for l in lines : f . write ( l + \"\\n\" ) f . close ()","title":"dsc_to_file"},{"location":"edk2toollib/uefi/edk2/parsers/","text":"Module edk2toollib.uefi.edk2.parsers View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.edk2.parsers.base_parser edk2toollib.uefi.edk2.parsers.base_parser_test edk2toollib.uefi.edk2.parsers.buildreport_parser edk2toollib.uefi.edk2.parsers.dec_parser edk2toollib.uefi.edk2.parsers.dec_parser_test edk2toollib.uefi.edk2.parsers.dsc_parser edk2toollib.uefi.edk2.parsers.dsc_parser_test edk2toollib.uefi.edk2.parsers.fdf_parser edk2toollib.uefi.edk2.parsers.guid_parser edk2toollib.uefi.edk2.parsers.guid_parser_test edk2toollib.uefi.edk2.parsers.hash_file_parser_test edk2toollib.uefi.edk2.parsers.inf_parser edk2toollib.uefi.edk2.parsers.override_parser edk2toollib.uefi.edk2.parsers.override_parser_test edk2toollib.uefi.edk2.parsers.targettxt_parser","title":"Index"},{"location":"edk2toollib/uefi/edk2/parsers/#module-edk2toollibuefiedk2parsers","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi.edk2.parsers"},{"location":"edk2toollib/uefi/edk2/parsers/#sub-modules","text":"edk2toollib.uefi.edk2.parsers.base_parser edk2toollib.uefi.edk2.parsers.base_parser_test edk2toollib.uefi.edk2.parsers.buildreport_parser edk2toollib.uefi.edk2.parsers.dec_parser edk2toollib.uefi.edk2.parsers.dec_parser_test edk2toollib.uefi.edk2.parsers.dsc_parser edk2toollib.uefi.edk2.parsers.dsc_parser_test edk2toollib.uefi.edk2.parsers.fdf_parser edk2toollib.uefi.edk2.parsers.guid_parser edk2toollib.uefi.edk2.parsers.guid_parser_test edk2toollib.uefi.edk2.parsers.hash_file_parser_test edk2toollib.uefi.edk2.parsers.inf_parser edk2toollib.uefi.edk2.parsers.override_parser edk2toollib.uefi.edk2.parsers.override_parser_test edk2toollib.uefi.edk2.parsers.targettxt_parser","title":"Sub-modules"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/","text":"Module edk2toollib.uefi.edk2.parsers.base_parser View Source # @file BaseParser.py # Code to support parsing EDK2 files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging class BaseParser ( object ): \"\"\" \"\"\" operators = [ \"OR\" , \"AND\" , \"IN\" , \"==\" , \"!=\" , \">\" , \"<\" , \"<=\" , \">=\" ] def __init__ ( self , log = \"\" ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None self . CurrentLine = - 1 self . _MacroNotDefinedValue = \"0\" # value to used for undefined macro # # For include files set the base root path # def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s \" % Path ) return Path def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s \" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \" \\n \" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \" \\\" \" ) if isinstance ( value2 , str ): ivalue2 = value2 . strip ( \" \\\" \" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) # # convert to int based on prefix # def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper () . startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d \" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. def _FindReplacementForToken ( self , token , replace_if_not_found = False ): v = self . LocalVars . get ( token ) if ( v is None ): v = self . InputVars . get ( token ) if ( v is None and replace_if_not_found ): v = self . _MacroNotDefinedValue elif ( v is None ): return None if ( type ( v ) is bool ): v = \"true\" if v else \"false\" if ( type ( v ) is str and ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" )): v = v . upper () return str ( v ) # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $. This must be done first otherwise # both syntax options can not be supported. result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ] . startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s \" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ] . split () + [ tokens [ 1 ]] + tokens [ 2 ] . split () else : tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can't do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ] . lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False def EvaluateConditional ( self , text ): ''' Uses a pushdown resolver ''' text = str ( text ) . strip () if not text . lower () . startswith ( \"!if \" ): raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3 :] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ): if self . _IsOperator ( item ): first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand, then squish it all together new_expression = expression [: first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result , ] + expression [ first_operand_index + 1 :] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ) . startswith ( \"!+\" ): operand = operand [ 2 :] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand, then smoosh it all together new_expression = expression [: first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result , ] + expression [ first_operand_index + 1 :] expression = new_expression final = self . ConvertToInt ( expression [ 0 ]) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) @classmethod def _TokenizeConditional ( cls , text ): ''' takes in a string that has macros replaced ''' # TOKENIZER # first we create tokens TEXT_MODE = 0 QUOTE_MODE = 1 MACRO_MODE = 2 token = \"\" mode = 0 tokens = [] for character in text : if character == \" \\\" \" and len ( token ) == 0 : mode = QUOTE_MODE elif character == \" \\\" \" and mode == QUOTE_MODE : if len ( token ) > 0 : tokens . append ( f \" \\\" {token} \\\" \" ) token = \"\" mode = TEXT_MODE elif character == \"$\" and len ( token ) == 0 : token += character mode = MACRO_MODE elif character == ')' and mode == MACRO_MODE : token += character tokens . append ( token ) token = \"\" mode = TEXT_MODE elif mode == TEXT_MODE and ( character == \"(\" or character == \")\" ): if len ( token ) > 0 : tokens . append ( token ) token = \"\" tokens . append ( character ) elif character == \" \" and ( mode == TEXT_MODE or mode == MACRO_MODE ): if len ( token ) > 0 : tokens . append ( token ) token = \"\" mode = TEXT_MODE else : token += character # make sure to add in the last token just in case if len ( token ) > 0 : tokens . append ( token ) # then we do the lexer and convert operands as necessary for index in range ( len ( tokens )): token = tokens [ index ] token_upper = token . upper () if token_upper in cls . operators : token = token_upper elif token_upper == \"||\" : token = \"OR\" elif token_upper == \"&&\" : token = \"AND\" elif token_upper == \"EQ\" : token = \"==\" elif token_upper == \"NE\" : token = \"!=\" elif token == \"!\" : token = \"NOT\" tokens [ index ] = token # collapse the not collapsed_tokens = [] found_not = False for token in tokens : if str ( token ) . upper () == \"NOT\" : found_not = True continue if not found_not : collapsed_tokens . append ( token ) elif token in cls . operators : collapsed_tokens . append ( \"!+\" + token ) found_not = False else : # add the not back found_not = False collapsed_tokens . append ( \"NOT\" ) collapsed_tokens . append ( token ) return collapsed_tokens @classmethod def _ConvertTokensToPostFix ( cls , tokens ): # convert infix into post fix stack = [ \"(\" ] tokens . append ( \")\" ) # add an extra parathesis expression = [] for token in tokens : # If the incoming symbol is a left parenthesis, push it on the stack. if token == \"(\" : stack . append ( token ) # If the incoming symbol is a right parenthesis, # pop the stack and print the operators until you see a left parenthesis. # Discard the pair of parentheses. elif token == \")\" : while len ( stack ) > 0 and stack [ - 1 ] != '(' : expression . append ( stack . pop ()) stack . pop () # pop the last ( # If this isn't a operator ignore it elif not cls . _IsOperator ( token ): expression . append ( token ) # If the stack is empty or contains a left parenthesis on top, push the incoming operator onto the stack. elif len ( stack ) == 0 or stack [ - 1 ] == '(' : stack . append ( token ) # If the incoming symbol has higher precedence than the top of the stack, push it on the stack. elif len ( stack ) == 0 or cls . _GetOperatorPrecedence ( token ) > cls . _GetOperatorPrecedence ( stack [ - 1 ]): stack . append ( token ) # If the incoming symbol has equal precedence with the top of the stack, use association. # If the association is left to right, pop and print the top of the stack and # then push the incoming operator. If the association is right to left, push the incoming operator. elif len ( stack ) != 0 and cls . _GetOperatorPrecedence ( token ) == cls . _GetOperatorPrecedence ( stack [ - 1 ]): expression . append ( stack . pop ()) stack . append ( token ) # If the incoming symbol has lower precedence than the symbol on the top of the stack, # pop the stack and print the top operator. # Then test the incoming operator against the new top of stack. elif len ( stack ) != 0 and cls . _GetOperatorPrecedence ( token ) < cls . _GetOperatorPrecedence ( stack [ - 1 ]): while len ( stack ) > 0 and cls . _GetOperatorPrecedence ( token ) <= cls . _GetOperatorPrecedence ( stack [ - 1 ]): expression . append ( stack . pop ()) stack . append ( token ) else : logging . error ( \"We don't know what to do with \" + token ) while len ( stack ) > 0 : val = stack . pop () expression . append ( val ) return expression @classmethod def _IsOperator ( cls , token ): if type ( token ) is not str : return False if token . startswith ( \"!+\" ): token = token [ 2 :] if token == \"NOT\" : # technically an operator return True return token in cls . operators @classmethod def _GetOperatorPrecedence ( cls , token ): if not cls . _IsOperator ( token ): return - 1 if token == \"(\" or token == \")\" : return 100 if token == \"NOT\" : # not is the lowest return - 2 if token == \"IN\" : return 1 return 0 # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ) . rstrip ( ' }' ) . split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ] . lstrip ( ' { 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ] . split ()[ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . rstrip ( ' } ' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False # # Base Class for Edk2 build files that use # for comments # class HashFileParser ( BaseParser ): \"\"\" \"\"\" def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ] . strip () def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip () . lstrip ( \"[\" ) . split ( \".\" )[ 0 ] . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () self . CurrentFullSection = l . strip () . lstrip ( \"[\" ) . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () return ( True , section ) return ( False , \"\" ) Classes BaseParser class BaseParser ( log = '' ) View Source class BaseParser ( object ) : \"\"\" \"\"\" operators = [ \"OR\", \"AND\", \"IN\", \"==\", \"!=\", \">\", \"<\", \"<=\", \">=\" ] def __init__ ( self , log = \"\" ) : self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None self . CurrentLine = - 1 self . _MacroNotDefinedValue = \"0\" # value to used for undefined macro # # For include files set the base root path # def SetBaseAbsPath ( self , path ) : \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self def SetPackagePaths ( self , pps = [] ) : \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self def SetInputVars ( self , inputdict ) : \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self def FindPath ( self , * p ) : \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ) : return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ) : return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ) : return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path def WriteLinesToFile ( self , filepath ) : \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ) : \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ) : ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ) : # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ) : ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ) : return ivalue or ivalue2 if ( cond . upper () == \"AND\" ) : return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ) : # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ) : # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ) : self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ) : self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ) : return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ) : return ( ivalue <= ivalue2 ) elif ( cond == \">\" ) : return ( ivalue > ivalue2 ) elif ( cond == \">=\" ) : return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) # # convert to int based on prefix # def ConvertToInt ( self , value ) : \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ) : return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ) : return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ) : \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ) : \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ) : return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . def _FindReplacementForToken ( self , token , replace_if_not_found = False ) : v = self . LocalVars . get ( token ) if ( v is None ) : v = self . InputVars . get ( token ) if ( v is None and replace_if_not_found ) : v = self . _MacroNotDefinedValue elif ( v is None ) : return None if ( type ( v ) is bool ) : v = \"true\" if v else \"false\" if ( type ( v ) is str and ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" )) : v = v . upper () return str ( v ) # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ) : \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\", \"!ifndef\", \"!if\", \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\", \"!ifndef\" ] : if not tokens [ 1 ] . startswith ( \"$(\" ) : v = self . _FindReplacementForToken ( tokens [ 1 ] , replace ) if v is not None : result = result . replace ( tokens [ 1 ] , v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ) : start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2:end ] replacement_token = line [ start:end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ) : \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ] . split () + [ tokens[1 ] ] + tokens [ 2 ] . split () else : tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ) : self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ) : if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ) : if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ) : if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can 't do multiple else statements self.PushConditional(not v) return True elif(tokens[0].lower() == \"!endif\"): if len(tokens) != 1: self.Logger.error(\"!ifdef conditionals need to be formatted correctly (spaces between each token)\") raise RuntimeError(\"Invalid conditional\", text) self.PopConditional() return True return False def EvaluateConditional(self, text): ''' Uses a pushdown resolver ''' text = str(text).strip() if not text.lower().startswith(\"!if \"): raise RuntimeError(f\"Invalid conditional cannot be validated: {text}\") text = text[3:].strip() logging.debug(f\"STAGE 1: {text}\") text = self.ReplaceVariables(text) logging.debug(f\"STAGE 2: {text}\") tokens = self._TokenizeConditional(text) logging.debug(f\"STAGE 3: {tokens}\") expression = self._ConvertTokensToPostFix(tokens) logging.debug(f\"STAGE 4: {expression}\") # Now we evaluate the post fix expression if len(expression) == 0: raise RuntimeError(f\"Malformed !if conditional expression {text} {expression}\") while len(expression) != 1: first_operand_index = -1 # find the first operator for index, item in enumerate(expression): if self._IsOperator(item): first_operand_index = index break if first_operand_index == -1: raise RuntimeError(f\"We didn' t find an operator to execute in { expression }: { text } \") operand = expression[first_operand_index] if operand == \" NOT \": # Special logic for handling the not if first_operand_index < 1: raise RuntimeError(f\" We have a stray operand { operand } \") # grab the operand right before the NOT and invert it operator1_raw = expression[first_operand_index - 1] operator1 = self.ConvertToInt(operator1_raw) result = not operator1 # grab what was before the operator and the operand, then squish it all together new_expression = expression[:first_operand_index - 1] if first_operand_index > 1 else [] new_expression += [result, ] + expression[first_operand_index + 1:] expression = new_expression else: if first_operand_index < 2: raise RuntimeError(f\" We have a stray operand { operand } \") operator1 = expression[first_operand_index - 2] operator2 = expression[first_operand_index - 1] do_invert = False # check if we have a special operator that has a combined not on it if str(operand).startswith(\" ! + \"): operand = operand[2:] do_invert = True # compute the result now that we have the three things we need result = self.ComputeResult(operator1, operand, operator2) if do_invert: result = not result # grab what was before the operator and the operand, then smoosh it all together new_expression = expression[:first_operand_index - 2] if first_operand_index > 2 else [] new_expression += [result, ] + expression[first_operand_index + 1:] expression = new_expression final = self.ConvertToInt(expression[0]) logging.debug(f\" FINAL { expression } { final } \") return bool(final) @classmethod def _TokenizeConditional(cls, text): ''' takes in a string that has macros replaced ''' # TOKENIZER # first we create tokens TEXT_MODE = 0 QUOTE_MODE = 1 MACRO_MODE = 2 token = \"\" mode = 0 tokens = [] for character in text: if character == \" \\ \"\" and len ( token ) == 0 : mode = QUOTE_MODE elif character == \"\\\"\" and mode == QUOTE_MODE: if len(token) > 0: tokens.append(f\" \\ \"{token}\\\"\") token = \"\" mode = TEXT_MODE elif character == \" $ \" and len(token) == 0: token += character mode = MACRO_MODE elif character == ')' and mode == MACRO_MODE: token += character tokens.append(token) token = \"\" mode = TEXT_MODE elif mode == TEXT_MODE and (character == \" ( \" or character == \" ) \"): if len(token) > 0: tokens.append(token) token = \"\" tokens.append(character) elif character == \" \" and (mode == TEXT_MODE or mode == MACRO_MODE): if len(token) > 0: tokens.append(token) token = \"\" mode = TEXT_MODE else: token += character # make sure to add in the last token just in case if len(token) > 0: tokens.append(token) # then we do the lexer and convert operands as necessary for index in range(len(tokens)): token = tokens[index] token_upper = token.upper() if token_upper in cls.operators: token = token_upper elif token_upper == \" || \": token = \" OR \" elif token_upper == \" && \": token = \" AND \" elif token_upper == \" EQ \": token = \" == \" elif token_upper == \" NE \": token = \" != \" elif token == \" ! \": token = \" NOT \" tokens[index] = token # collapse the not collapsed_tokens = [] found_not = False for token in tokens: if str(token).upper() == \" NOT \": found_not = True continue if not found_not: collapsed_tokens.append(token) elif token in cls.operators: collapsed_tokens.append(\" ! + \" + token) found_not = False else: # add the not back found_not = False collapsed_tokens.append(\" NOT \") collapsed_tokens.append(token) return collapsed_tokens @classmethod def _ConvertTokensToPostFix(cls, tokens): # convert infix into post fix stack = [\" ( \"] tokens.append(\" ) \") # add an extra parathesis expression = [] for token in tokens: # If the incoming symbol is a left parenthesis, push it on the stack. if token == \" ( \": stack.append(token) # If the incoming symbol is a right parenthesis, # pop the stack and print the operators until you see a left parenthesis. # Discard the pair of parentheses. elif token == \" ) \": while len(stack) > 0 and stack[-1] != '(': expression.append(stack.pop()) stack.pop() # pop the last ( # If this isn't a operator ignore it elif not cls._IsOperator(token): expression.append(token) # If the stack is empty or contains a left parenthesis on top, push the incoming operator onto the stack. elif len(stack) == 0 or stack[-1] == '(': stack.append(token) # If the incoming symbol has higher precedence than the top of the stack, push it on the stack. elif len(stack) == 0 or cls._GetOperatorPrecedence(token) > cls._GetOperatorPrecedence(stack[-1]): stack.append(token) # If the incoming symbol has equal precedence with the top of the stack, use association. # If the association is left to right, pop and print the top of the stack and # then push the incoming operator. If the association is right to left, push the incoming operator. elif len(stack) != 0 and cls._GetOperatorPrecedence(token) == cls._GetOperatorPrecedence(stack[-1]): expression.append(stack.pop()) stack.append(token) # If the incoming symbol has lower precedence than the symbol on the top of the stack, # pop the stack and print the top operator. # Then test the incoming operator against the new top of stack. elif len(stack) != 0 and cls._GetOperatorPrecedence(token) < cls._GetOperatorPrecedence(stack[-1]): while len(stack) > 0 and cls._GetOperatorPrecedence(token) <= cls._GetOperatorPrecedence(stack[-1]): expression.append(stack.pop()) stack.append(token) else: logging.error(\" We don 't know what to do with \" + token) while len(stack) > 0: val = stack.pop() expression.append(val) return expression @classmethod def _IsOperator(cls, token): if type(token) is not str: return False if token.startswith(\"!+\"): token = token[2:] if token == \"NOT\": # technically an operator return True return token in cls.operators @classmethod def _GetOperatorPrecedence(cls, token): if not cls._IsOperator(token): return -1 if token == \"(\" or token == \")\": return 100 if token == \"NOT\": # not is the lowest return -2 if token == \"IN\": return 1 return 0 # # returns true or false depending on what state of conditional you are currently in # def InActiveCode(self): \"\"\" \"\"\" ret = True for a in self.ConditionalStack: if not a: ret = False break return ret def IsGuidString(self, l): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if(l.count(\"{\") == 2 and l.count(\"}\") == 2 and l.count(\",\") == 10 and l.count(\"=\") == 1): return True return False def ParseGuid(self, l): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn' t long enough Args : l : the guid to parse ex : { 0xD3B36F2C , 0xD551 , 0x11D4 , { 0x9A , 0x46 , 0x00 , 0x90 , 0x27 , 0x3F , 0xC1 , 0x4D }} Returns : a string of the guid . ex : D3B36F2C - D551 - 11 D4 - 9 A46 - 0090273 FC14D \"\"\" entries = l.lstrip(' {').rstrip(' }').split(',') if len(entries) != 11: raise RuntimeError(f\" Invalid GUID found { l } . We are missing some parts since we only found : { len ( entries ) } \") gu = entries[0].lstrip(' 0').lstrip('x').strip() # pad front until 8 chars while(len(gu) < 8): gu = \" 0 \" + gu gut = entries[1].lstrip(' 0').lstrip('x').strip() while(len(gut) < 4): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[2].lstrip(' 0').lstrip('x').strip() while(len(gut) < 4): gut = \" 0 \" + gut gu = gu + \" - \" + gut # strip off extra { gut = entries[3].lstrip(' { 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[4].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[5].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[6].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[7].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[8].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[9].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[10].split()[0].lstrip(' 0').lstrip('x').rstrip(' } ').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut proper_guid_length = 36 if len(gu) > proper_guid_length: raise RuntimeError(f\" The guid we parsed was too long : { gu } \") if len(gu) < proper_guid_length: raise RuntimeError(f\" The guid we parsed was too short : { gu } \") return gu.upper() def ResetParserState(self): \"\"\" \"\" \" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False Descendants edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close () HashFileParser class HashFileParser ( log ) View Source class HashFileParser ( BaseParser ): \"\"\" \"\"\" def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Descendants edk2toollib.uefi.edk2.parsers.dsc_parser.DscParser edk2toollib.uefi.edk2.parsers.dec_parser.DecParser edk2toollib.uefi.edk2.parsers.inf_parser.InfParser edk2toollib.uefi.edk2.parsers.fdf_parser.FdfParser edk2toollib.uefi.edk2.parsers.targettxt_parser.TargetTxtParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Base parser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#module-edk2toollibuefiedk2parsersbase_parser","text":"View Source # @file BaseParser.py # Code to support parsing EDK2 files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging class BaseParser ( object ): \"\"\" \"\"\" operators = [ \"OR\" , \"AND\" , \"IN\" , \"==\" , \"!=\" , \">\" , \"<\" , \"<=\" , \">=\" ] def __init__ ( self , log = \"\" ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None self . CurrentLine = - 1 self . _MacroNotDefinedValue = \"0\" # value to used for undefined macro # # For include files set the base root path # def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s \" % Path ) return Path def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s \" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \" \\n \" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \" \\\" \" ) if isinstance ( value2 , str ): ivalue2 = value2 . strip ( \" \\\" \" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) # # convert to int based on prefix # def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper () . startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d \" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. def _FindReplacementForToken ( self , token , replace_if_not_found = False ): v = self . LocalVars . get ( token ) if ( v is None ): v = self . InputVars . get ( token ) if ( v is None and replace_if_not_found ): v = self . _MacroNotDefinedValue elif ( v is None ): return None if ( type ( v ) is bool ): v = \"true\" if v else \"false\" if ( type ( v ) is str and ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" )): v = v . upper () return str ( v ) # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $. This must be done first otherwise # both syntax options can not be supported. result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ] . startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s \" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ] . split () + [ tokens [ 1 ]] + tokens [ 2 ] . split () else : tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can't do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ] . lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False def EvaluateConditional ( self , text ): ''' Uses a pushdown resolver ''' text = str ( text ) . strip () if not text . lower () . startswith ( \"!if \" ): raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3 :] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ): if self . _IsOperator ( item ): first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand, then squish it all together new_expression = expression [: first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result , ] + expression [ first_operand_index + 1 :] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ) . startswith ( \"!+\" ): operand = operand [ 2 :] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand, then smoosh it all together new_expression = expression [: first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result , ] + expression [ first_operand_index + 1 :] expression = new_expression final = self . ConvertToInt ( expression [ 0 ]) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) @classmethod def _TokenizeConditional ( cls , text ): ''' takes in a string that has macros replaced ''' # TOKENIZER # first we create tokens TEXT_MODE = 0 QUOTE_MODE = 1 MACRO_MODE = 2 token = \"\" mode = 0 tokens = [] for character in text : if character == \" \\\" \" and len ( token ) == 0 : mode = QUOTE_MODE elif character == \" \\\" \" and mode == QUOTE_MODE : if len ( token ) > 0 : tokens . append ( f \" \\\" {token} \\\" \" ) token = \"\" mode = TEXT_MODE elif character == \"$\" and len ( token ) == 0 : token += character mode = MACRO_MODE elif character == ')' and mode == MACRO_MODE : token += character tokens . append ( token ) token = \"\" mode = TEXT_MODE elif mode == TEXT_MODE and ( character == \"(\" or character == \")\" ): if len ( token ) > 0 : tokens . append ( token ) token = \"\" tokens . append ( character ) elif character == \" \" and ( mode == TEXT_MODE or mode == MACRO_MODE ): if len ( token ) > 0 : tokens . append ( token ) token = \"\" mode = TEXT_MODE else : token += character # make sure to add in the last token just in case if len ( token ) > 0 : tokens . append ( token ) # then we do the lexer and convert operands as necessary for index in range ( len ( tokens )): token = tokens [ index ] token_upper = token . upper () if token_upper in cls . operators : token = token_upper elif token_upper == \"||\" : token = \"OR\" elif token_upper == \"&&\" : token = \"AND\" elif token_upper == \"EQ\" : token = \"==\" elif token_upper == \"NE\" : token = \"!=\" elif token == \"!\" : token = \"NOT\" tokens [ index ] = token # collapse the not collapsed_tokens = [] found_not = False for token in tokens : if str ( token ) . upper () == \"NOT\" : found_not = True continue if not found_not : collapsed_tokens . append ( token ) elif token in cls . operators : collapsed_tokens . append ( \"!+\" + token ) found_not = False else : # add the not back found_not = False collapsed_tokens . append ( \"NOT\" ) collapsed_tokens . append ( token ) return collapsed_tokens @classmethod def _ConvertTokensToPostFix ( cls , tokens ): # convert infix into post fix stack = [ \"(\" ] tokens . append ( \")\" ) # add an extra parathesis expression = [] for token in tokens : # If the incoming symbol is a left parenthesis, push it on the stack. if token == \"(\" : stack . append ( token ) # If the incoming symbol is a right parenthesis, # pop the stack and print the operators until you see a left parenthesis. # Discard the pair of parentheses. elif token == \")\" : while len ( stack ) > 0 and stack [ - 1 ] != '(' : expression . append ( stack . pop ()) stack . pop () # pop the last ( # If this isn't a operator ignore it elif not cls . _IsOperator ( token ): expression . append ( token ) # If the stack is empty or contains a left parenthesis on top, push the incoming operator onto the stack. elif len ( stack ) == 0 or stack [ - 1 ] == '(' : stack . append ( token ) # If the incoming symbol has higher precedence than the top of the stack, push it on the stack. elif len ( stack ) == 0 or cls . _GetOperatorPrecedence ( token ) > cls . _GetOperatorPrecedence ( stack [ - 1 ]): stack . append ( token ) # If the incoming symbol has equal precedence with the top of the stack, use association. # If the association is left to right, pop and print the top of the stack and # then push the incoming operator. If the association is right to left, push the incoming operator. elif len ( stack ) != 0 and cls . _GetOperatorPrecedence ( token ) == cls . _GetOperatorPrecedence ( stack [ - 1 ]): expression . append ( stack . pop ()) stack . append ( token ) # If the incoming symbol has lower precedence than the symbol on the top of the stack, # pop the stack and print the top operator. # Then test the incoming operator against the new top of stack. elif len ( stack ) != 0 and cls . _GetOperatorPrecedence ( token ) < cls . _GetOperatorPrecedence ( stack [ - 1 ]): while len ( stack ) > 0 and cls . _GetOperatorPrecedence ( token ) <= cls . _GetOperatorPrecedence ( stack [ - 1 ]): expression . append ( stack . pop ()) stack . append ( token ) else : logging . error ( \"We don't know what to do with \" + token ) while len ( stack ) > 0 : val = stack . pop () expression . append ( val ) return expression @classmethod def _IsOperator ( cls , token ): if type ( token ) is not str : return False if token . startswith ( \"!+\" ): token = token [ 2 :] if token == \"NOT\" : # technically an operator return True return token in cls . operators @classmethod def _GetOperatorPrecedence ( cls , token ): if not cls . _IsOperator ( token ): return - 1 if token == \"(\" or token == \")\" : return 100 if token == \"NOT\" : # not is the lowest return - 2 if token == \"IN\" : return 1 return 0 # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ) . rstrip ( ' }' ) . split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ] . lstrip ( ' { 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ] . split ()[ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . rstrip ( ' } ' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False # # Base Class for Edk2 build files that use # for comments # class HashFileParser ( BaseParser ): \"\"\" \"\"\" def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ] . strip () def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip () . lstrip ( \"[\" ) . split ( \".\" )[ 0 ] . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () self . CurrentFullSection = l . strip () . lstrip ( \"[\" ) . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () return ( True , section ) return ( False , \"\" )","title":"Module edk2toollib.uefi.edk2.parsers.base_parser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#baseparser","text":"class BaseParser ( log = '' ) View Source class BaseParser ( object ) : \"\"\" \"\"\" operators = [ \"OR\", \"AND\", \"IN\", \"==\", \"!=\", \">\", \"<\", \"<=\", \">=\" ] def __init__ ( self , log = \"\" ) : self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None self . CurrentLine = - 1 self . _MacroNotDefinedValue = \"0\" # value to used for undefined macro # # For include files set the base root path # def SetBaseAbsPath ( self , path ) : \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self def SetPackagePaths ( self , pps = [] ) : \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self def SetInputVars ( self , inputdict ) : \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self def FindPath ( self , * p ) : \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ) : return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ) : return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ) : return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path def WriteLinesToFile ( self , filepath ) : \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ) : \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ) : ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ) : # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ) : ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ) : return ivalue or ivalue2 if ( cond . upper () == \"AND\" ) : return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ) : # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ) : # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ) : self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ) : self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ) : return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ) : return ( ivalue <= ivalue2 ) elif ( cond == \">\" ) : return ( ivalue > ivalue2 ) elif ( cond == \">=\" ) : return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) # # convert to int based on prefix # def ConvertToInt ( self , value ) : \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ) : return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ) : return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ) : \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ) : \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ) : return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . def _FindReplacementForToken ( self , token , replace_if_not_found = False ) : v = self . LocalVars . get ( token ) if ( v is None ) : v = self . InputVars . get ( token ) if ( v is None and replace_if_not_found ) : v = self . _MacroNotDefinedValue elif ( v is None ) : return None if ( type ( v ) is bool ) : v = \"true\" if v else \"false\" if ( type ( v ) is str and ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" )) : v = v . upper () return str ( v ) # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ) : \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\", \"!ifndef\", \"!if\", \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ] . lower () in [ \"!ifdef\", \"!ifndef\" ] : if not tokens [ 1 ] . startswith ( \"$(\" ) : v = self . _FindReplacementForToken ( tokens [ 1 ] , replace ) if v is not None : result = result . replace ( tokens [ 1 ] , v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ) : start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2:end ] replacement_token = line [ start:end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ) : \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ] . split () + [ tokens[1 ] ] + tokens [ 2 ] . split () else : tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ) : self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ) : if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ) : if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ) : if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can 't do multiple else statements self.PushConditional(not v) return True elif(tokens[0].lower() == \"!endif\"): if len(tokens) != 1: self.Logger.error(\"!ifdef conditionals need to be formatted correctly (spaces between each token)\") raise RuntimeError(\"Invalid conditional\", text) self.PopConditional() return True return False def EvaluateConditional(self, text): ''' Uses a pushdown resolver ''' text = str(text).strip() if not text.lower().startswith(\"!if \"): raise RuntimeError(f\"Invalid conditional cannot be validated: {text}\") text = text[3:].strip() logging.debug(f\"STAGE 1: {text}\") text = self.ReplaceVariables(text) logging.debug(f\"STAGE 2: {text}\") tokens = self._TokenizeConditional(text) logging.debug(f\"STAGE 3: {tokens}\") expression = self._ConvertTokensToPostFix(tokens) logging.debug(f\"STAGE 4: {expression}\") # Now we evaluate the post fix expression if len(expression) == 0: raise RuntimeError(f\"Malformed !if conditional expression {text} {expression}\") while len(expression) != 1: first_operand_index = -1 # find the first operator for index, item in enumerate(expression): if self._IsOperator(item): first_operand_index = index break if first_operand_index == -1: raise RuntimeError(f\"We didn' t find an operator to execute in { expression }: { text } \") operand = expression[first_operand_index] if operand == \" NOT \": # Special logic for handling the not if first_operand_index < 1: raise RuntimeError(f\" We have a stray operand { operand } \") # grab the operand right before the NOT and invert it operator1_raw = expression[first_operand_index - 1] operator1 = self.ConvertToInt(operator1_raw) result = not operator1 # grab what was before the operator and the operand, then squish it all together new_expression = expression[:first_operand_index - 1] if first_operand_index > 1 else [] new_expression += [result, ] + expression[first_operand_index + 1:] expression = new_expression else: if first_operand_index < 2: raise RuntimeError(f\" We have a stray operand { operand } \") operator1 = expression[first_operand_index - 2] operator2 = expression[first_operand_index - 1] do_invert = False # check if we have a special operator that has a combined not on it if str(operand).startswith(\" ! + \"): operand = operand[2:] do_invert = True # compute the result now that we have the three things we need result = self.ComputeResult(operator1, operand, operator2) if do_invert: result = not result # grab what was before the operator and the operand, then smoosh it all together new_expression = expression[:first_operand_index - 2] if first_operand_index > 2 else [] new_expression += [result, ] + expression[first_operand_index + 1:] expression = new_expression final = self.ConvertToInt(expression[0]) logging.debug(f\" FINAL { expression } { final } \") return bool(final) @classmethod def _TokenizeConditional(cls, text): ''' takes in a string that has macros replaced ''' # TOKENIZER # first we create tokens TEXT_MODE = 0 QUOTE_MODE = 1 MACRO_MODE = 2 token = \"\" mode = 0 tokens = [] for character in text: if character == \" \\ \"\" and len ( token ) == 0 : mode = QUOTE_MODE elif character == \"\\\"\" and mode == QUOTE_MODE: if len(token) > 0: tokens.append(f\" \\ \"{token}\\\"\") token = \"\" mode = TEXT_MODE elif character == \" $ \" and len(token) == 0: token += character mode = MACRO_MODE elif character == ')' and mode == MACRO_MODE: token += character tokens.append(token) token = \"\" mode = TEXT_MODE elif mode == TEXT_MODE and (character == \" ( \" or character == \" ) \"): if len(token) > 0: tokens.append(token) token = \"\" tokens.append(character) elif character == \" \" and (mode == TEXT_MODE or mode == MACRO_MODE): if len(token) > 0: tokens.append(token) token = \"\" mode = TEXT_MODE else: token += character # make sure to add in the last token just in case if len(token) > 0: tokens.append(token) # then we do the lexer and convert operands as necessary for index in range(len(tokens)): token = tokens[index] token_upper = token.upper() if token_upper in cls.operators: token = token_upper elif token_upper == \" || \": token = \" OR \" elif token_upper == \" && \": token = \" AND \" elif token_upper == \" EQ \": token = \" == \" elif token_upper == \" NE \": token = \" != \" elif token == \" ! \": token = \" NOT \" tokens[index] = token # collapse the not collapsed_tokens = [] found_not = False for token in tokens: if str(token).upper() == \" NOT \": found_not = True continue if not found_not: collapsed_tokens.append(token) elif token in cls.operators: collapsed_tokens.append(\" ! + \" + token) found_not = False else: # add the not back found_not = False collapsed_tokens.append(\" NOT \") collapsed_tokens.append(token) return collapsed_tokens @classmethod def _ConvertTokensToPostFix(cls, tokens): # convert infix into post fix stack = [\" ( \"] tokens.append(\" ) \") # add an extra parathesis expression = [] for token in tokens: # If the incoming symbol is a left parenthesis, push it on the stack. if token == \" ( \": stack.append(token) # If the incoming symbol is a right parenthesis, # pop the stack and print the operators until you see a left parenthesis. # Discard the pair of parentheses. elif token == \" ) \": while len(stack) > 0 and stack[-1] != '(': expression.append(stack.pop()) stack.pop() # pop the last ( # If this isn't a operator ignore it elif not cls._IsOperator(token): expression.append(token) # If the stack is empty or contains a left parenthesis on top, push the incoming operator onto the stack. elif len(stack) == 0 or stack[-1] == '(': stack.append(token) # If the incoming symbol has higher precedence than the top of the stack, push it on the stack. elif len(stack) == 0 or cls._GetOperatorPrecedence(token) > cls._GetOperatorPrecedence(stack[-1]): stack.append(token) # If the incoming symbol has equal precedence with the top of the stack, use association. # If the association is left to right, pop and print the top of the stack and # then push the incoming operator. If the association is right to left, push the incoming operator. elif len(stack) != 0 and cls._GetOperatorPrecedence(token) == cls._GetOperatorPrecedence(stack[-1]): expression.append(stack.pop()) stack.append(token) # If the incoming symbol has lower precedence than the symbol on the top of the stack, # pop the stack and print the top operator. # Then test the incoming operator against the new top of stack. elif len(stack) != 0 and cls._GetOperatorPrecedence(token) < cls._GetOperatorPrecedence(stack[-1]): while len(stack) > 0 and cls._GetOperatorPrecedence(token) <= cls._GetOperatorPrecedence(stack[-1]): expression.append(stack.pop()) stack.append(token) else: logging.error(\" We don 't know what to do with \" + token) while len(stack) > 0: val = stack.pop() expression.append(val) return expression @classmethod def _IsOperator(cls, token): if type(token) is not str: return False if token.startswith(\"!+\"): token = token[2:] if token == \"NOT\": # technically an operator return True return token in cls.operators @classmethod def _GetOperatorPrecedence(cls, token): if not cls._IsOperator(token): return -1 if token == \"(\" or token == \")\": return 100 if token == \"NOT\": # not is the lowest return -2 if token == \"IN\": return 1 return 0 # # returns true or false depending on what state of conditional you are currently in # def InActiveCode(self): \"\"\" \"\"\" ret = True for a in self.ConditionalStack: if not a: ret = False break return ret def IsGuidString(self, l): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if(l.count(\"{\") == 2 and l.count(\"}\") == 2 and l.count(\",\") == 10 and l.count(\"=\") == 1): return True return False def ParseGuid(self, l): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn' t long enough Args : l : the guid to parse ex : { 0xD3B36F2C , 0xD551 , 0x11D4 , { 0x9A , 0x46 , 0x00 , 0x90 , 0x27 , 0x3F , 0xC1 , 0x4D }} Returns : a string of the guid . ex : D3B36F2C - D551 - 11 D4 - 9 A46 - 0090273 FC14D \"\"\" entries = l.lstrip(' {').rstrip(' }').split(',') if len(entries) != 11: raise RuntimeError(f\" Invalid GUID found { l } . We are missing some parts since we only found : { len ( entries ) } \") gu = entries[0].lstrip(' 0').lstrip('x').strip() # pad front until 8 chars while(len(gu) < 8): gu = \" 0 \" + gu gut = entries[1].lstrip(' 0').lstrip('x').strip() while(len(gut) < 4): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[2].lstrip(' 0').lstrip('x').strip() while(len(gut) < 4): gut = \" 0 \" + gut gu = gu + \" - \" + gut # strip off extra { gut = entries[3].lstrip(' { 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[4].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[5].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + \" - \" + gut gut = entries[6].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[7].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[8].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[9].lstrip(' 0').lstrip('x').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut gut = entries[10].split()[0].lstrip(' 0').lstrip('x').rstrip(' } ').strip() while(len(gut) < 2): gut = \" 0 \" + gut gu = gu + gut proper_guid_length = 36 if len(gu) > proper_guid_length: raise RuntimeError(f\" The guid we parsed was too long : { gu } \") if len(gu) < proper_guid_length: raise RuntimeError(f\" The guid we parsed was too short : { gu } \") return gu.upper() def ResetParserState(self): \"\"\" \"\" \" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"BaseParser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#descendants","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#hashfileparser","text":"class HashFileParser ( log ) View Source class HashFileParser ( BaseParser ): \"\"\" \"\"\" def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"HashFileParser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#descendants_1","text":"edk2toollib.uefi.edk2.parsers.dsc_parser.DscParser edk2toollib.uefi.edk2.parsers.dec_parser.DecParser edk2toollib.uefi.edk2.parsers.inf_parser.InfParser edk2toollib.uefi.edk2.parsers.fdf_parser.FdfParser edk2toollib.uefi.edk2.parsers.targettxt_parser.TargetTxtParser","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#class-variables_1","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#computeresult_1","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#converttoint_1","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#evaluateconditional_1","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#findpath_1","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#inactivecode_1","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#isguidstring_1","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parseguid_1","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#popconditional_1","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#processconditional_1","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#pushconditional_1","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#replacevariables_1","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#resetparserstate_1","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setbaseabspath_1","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setinputvars_1","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setpackagepaths_1","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#writelinestofile_1","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/","text":"Module edk2toollib.uefi.edk2.parsers.buildreport_parser View Source # @file buildreport_parser . py # Code to help parse an EDk2 Build Report # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import os import logging import edk2toollib . utility_functions as uf import edk2toollib . uefi . edk2 . path_utilities as pu # # Class to represent a module within the Build Report # class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise # # Class to parse and objectify the Build report so that # tools can interact with the Build Report . # This should simplify the Build Report based interactions # but should not contain tool specific logic or tests . # class BuildReport ( object ) : RegionTypes = uf . Enum ([ 'PCD' , 'FD' , 'MODULE' , 'UNKNOWN' ]) def __ init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ ReportContents = \"\" self . _ Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ ReportContents = [ x . strip () for x in f . readlines ()] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ ReportContents = [ x . replace ( k , v ) for x in self . _ ReportContents ] logging . debug ( \"Report File is: %s\" % self.ReportFile) logging . debug ( \"Input report had %d lines of content\" % len(self._ReportContents)) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(':') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FV_DXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn't find new region return None # # Get the end of region # def _ GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ ReportContents )) : if self . _ ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number) # didn ' t find new region return None def _ GetRegionType ( self , lineNumber ) : line = self . _ ReportContents [ lineNumber ]. strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN Classes BuildReport class BuildReport ( filepath , ws , packagepathcsv , protectedWordsDict ) View Source class BuildReport ( object ) : RegionTypes = uf . Enum ( [ 'PCD', 'FD', 'MODULE', 'UNKNOWN' ] ) def __init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ReportContents = \"\" self . _Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' : ') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FV_DXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn' t find new region return None # # Get the end of region # def _GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ReportContents )) : if self . _ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number ) # didn ' t find new region return None def _GetRegionType ( self , lineNumber ) : line = self . _ReportContents [ lineNumber ] . strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN Class variables RegionTypes Methods BasicParse def BasicParse ( self ) View Source def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' :' ) if ( line_partitioned [ 2 ] == \"\" ) : continue key = line_partitioned [ 0 ] . strip (). lower () value = line_partitioned [ 2 ] . strip () if ( key == \"platform name\" ) : self . PlatformName = value elif ( key == \"platform dsc path\" ) : self . DscPath = value elif ( key == \"output path\" ) : self . BuildOutputDir = value # # now for each module summary # parse it for r in self . _Regions : if ( r [ 0 ] == BuildReport . RegionTypes . MODULE ) : mod = ModuleSummary ( self . _ReportContents [ r[1 ] : r [ 2 ] ] , self . Workspace , self . PackagePathList ) mod . Parse () self . Modules [ mod.Guid ] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self . _Regions : # if FD region parse out all INFs in the all of the flash if ( r [ 0 ] == BuildReport . RegionTypes . FD ) : self . _ParseFdRegionForModules ( self . _ReportContents [ r[1 ] : r [ 2 ] ] ) FindComponentByInfPath def FindComponentByInfPath ( self , InfPath ) View Source def FindComponentByInfPath ( self , InfPath ): for ( k , v ) in self . Modules . items (): if ( v . InfPath . lower () == InfPath . lower ()): logging . debug ( \"Found Module by InfPath: %s\" % InfPath ) return v logging . error ( \"Failed to find Module by InfPath %s\" % InfPath ) return None ModuleSummary class ModuleSummary ( content , ws , packagepatahlist ) View Source class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise Methods Parse def Parse ( self ) View Source def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"Buildreport parser"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#module-edk2toollibuefiedk2parsersbuildreport_parser","text":"View Source # @file buildreport_parser . py # Code to help parse an EDk2 Build Report # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import os import logging import edk2toollib . utility_functions as uf import edk2toollib . uefi . edk2 . path_utilities as pu # # Class to represent a module within the Build Report # class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise # # Class to parse and objectify the Build report so that # tools can interact with the Build Report . # This should simplify the Build Report based interactions # but should not contain tool specific logic or tests . # class BuildReport ( object ) : RegionTypes = uf . Enum ([ 'PCD' , 'FD' , 'MODULE' , 'UNKNOWN' ]) def __ init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ ReportContents = \"\" self . _ Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ ReportContents = [ x . strip () for x in f . readlines ()] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ ReportContents = [ x . replace ( k , v ) for x in self . _ ReportContents ] logging . debug ( \"Report File is: %s\" % self.ReportFile) logging . debug ( \"Input report had %d lines of content\" % len(self._ReportContents)) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(':') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FV_DXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn't find new region return None # # Get the end of region # def _ GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ ReportContents )) : if self . _ ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number) # didn ' t find new region return None def _ GetRegionType ( self , lineNumber ) : line = self . _ ReportContents [ lineNumber ]. strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN","title":"Module edk2toollib.uefi.edk2.parsers.buildreport_parser"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#buildreport","text":"class BuildReport ( filepath , ws , packagepathcsv , protectedWordsDict ) View Source class BuildReport ( object ) : RegionTypes = uf . Enum ( [ 'PCD', 'FD', 'MODULE', 'UNKNOWN' ] ) def __init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ReportContents = \"\" self . _Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' : ') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FV_DXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn' t find new region return None # # Get the end of region # def _GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ReportContents )) : if self . _ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number ) # didn ' t find new region return None def _GetRegionType ( self , lineNumber ) : line = self . _ReportContents [ lineNumber ] . strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN","title":"BuildReport"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#class-variables","text":"RegionTypes","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#basicparse","text":"def BasicParse ( self ) View Source def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' :' ) if ( line_partitioned [ 2 ] == \"\" ) : continue key = line_partitioned [ 0 ] . strip (). lower () value = line_partitioned [ 2 ] . strip () if ( key == \"platform name\" ) : self . PlatformName = value elif ( key == \"platform dsc path\" ) : self . DscPath = value elif ( key == \"output path\" ) : self . BuildOutputDir = value # # now for each module summary # parse it for r in self . _Regions : if ( r [ 0 ] == BuildReport . RegionTypes . MODULE ) : mod = ModuleSummary ( self . _ReportContents [ r[1 ] : r [ 2 ] ] , self . Workspace , self . PackagePathList ) mod . Parse () self . Modules [ mod.Guid ] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self . _Regions : # if FD region parse out all INFs in the all of the flash if ( r [ 0 ] == BuildReport . RegionTypes . FD ) : self . _ParseFdRegionForModules ( self . _ReportContents [ r[1 ] : r [ 2 ] ] )","title":"BasicParse"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#findcomponentbyinfpath","text":"def FindComponentByInfPath ( self , InfPath ) View Source def FindComponentByInfPath ( self , InfPath ): for ( k , v ) in self . Modules . items (): if ( v . InfPath . lower () == InfPath . lower ()): logging . debug ( \"Found Module by InfPath: %s\" % InfPath ) return v logging . error ( \"Failed to find Module by InfPath %s\" % InfPath ) return None","title":"FindComponentByInfPath"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#modulesummary","text":"class ModuleSummary ( content , ws , packagepatahlist ) View Source class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"ModuleSummary"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#parse","text":"def Parse ( self ) View Source def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class lib_class = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () lib_instance = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( lib_instance ) if ( RelativePath is not None ) : self . Libraries [ lib_class ] = RelativePath else : self . Libraries [ lib_class ] = lib_instance i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"Parse"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/","text":"Module edk2toollib.uefi.edk2.parsers.dec_parser View Source # @file dec_parser.py # Code to help parse DEC file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser from edk2toollib.uefi.edk2.parsers.guid_parser import GuidParser class LibraryClassDeclarationEntry (): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a library Class Declaration Entry\"\"\" self . path = \"\" self . name = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ) -> None : \"\"\"Parses the rawtext line to collect the Library Class declaration information (name and package root relative path). Args: rawtext: str expected format is <library class name> | <package relative path to header file> Returns: None \"\"\" t = rawtext . partition ( \"|\" ) self . name = t [ 0 ] . strip () self . path = t [ 2 ] . strip () class GuidedDeclarationEntry (): \"\"\"A baseclass for declaration types that have a name and guid.\"\"\" PROTOCOL = 1 PPI = 2 GUID = 3 def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a protocol/Ppi/or Guid declaration entry\"\"\" self . name = \"\" self . guidstring = \"\" self . guid = None self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ) -> None : \"\"\"Parses the name and guid of a declaration Args: rawtext: str: Returns: \"\"\" t = rawtext . partition ( \"=\" ) self . name = t [ 0 ] . strip () self . guidstring = t [ 2 ] . strip () self . guid = GuidParser . uuid_from_guidstring ( self . guidstring ) if ( self . guid is None ): raise ValueError ( \"Could not parse guid\" ) class ProtocolDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a protocol declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PROTOCOL class PpiDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PPI class GuidDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . GUID class PcdDeclarationEntry (): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Creates a PCD Declaration Entry for one PCD\"\"\" self . token_space_name = \"\" self . name = \"\" self . default_value = \"\" self . type = \"\" self . id = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ): \"\"\" Args: rawtext: str: Returns: \"\"\" sp = rawtext . partition ( \".\" ) self . token_space_name = sp [ 0 ] . strip () op = sp [ 2 ] . split ( \"|\" ) # if it's 2 long, we need to check that it's a structured PCD if ( len ( op ) == 2 and op [ 0 ] . count ( \".\" ) > 0 ): pass # otherwise it needs at least 4 parts elif ( len ( op ) < 4 ): raise Exception ( f \"Too few parts: {op}\" ) # but also less than 5 elif ( len ( op ) > 5 ): raise Exception ( f \"Too many parts: {rawtext}\" ) elif ( len ( op ) == 5 and op [ 4 ] . strip () != '{' ): raise Exception ( f \"Too many parts: {rawtext}\" ) self . name = op [ 0 ] . strip () self . default_value = op [ 1 ] . strip () # if we don't know what the type and id, it's because it's structured self . type = op [ 2 ] . strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" self . id = op [ 3 ] . strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" class DecParser ( HashFileParser ): \"\"\"Parses an EDK2 DEC file\"\"\" def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClasses = [] self . PPIs = [] self . Protocols = [] self . Guids = [] self . Pcds = [] self . IncludePaths = [] self . Path = \"\" self . PackageName = None def _Parse ( self ) -> None : InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InStructuredPcdDeclaration = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () if ( self . PackageName is None and tokens [ 0 ] . strip () == \"PACKAGE_NAME\" ): self . PackageName = self . Dict [ \"PACKAGE_NAME\" ] continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = LibraryClassDeclarationEntry ( self . PackageName , sline ) self . LibraryClasses . append ( t ) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = ProtocolDeclarationEntry ( self . PackageName , sline ) self . Protocols . append ( t ) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = GuidDeclarationEntry ( self . PackageName , sline ) self . Guids . append ( t ) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False elif sline . strip ()[ 0 ] == '}' : InStructuredPcdDeclaration = False else : if InStructuredPcdDeclaration : continue t = PcdDeclarationEntry ( self . PackageName , sline ) self . Pcds . append ( t ) if sline . rstrip ()[ - 1 ] == '{' : InStructuredPcdDeclaration = True continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludePaths . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = PpiDeclarationEntry ( self . PackageName , sline ) self . PPIs . append ( t ) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPPISection = True elif sline . strip () . lower () . startswith ( '[pcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[includes' ): InIncludesSection = True self . Parsed = True def ParseStream ( self , stream ) -> None : \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse () def ParseFile ( self , filepath : str ) -> None : \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse () Classes DecParser class DecParser ( ) Parses an EDK2 DEC file View Source class DecParser ( HashFileParser ): \"\"\"Parses an EDK2 DEC file\"\"\" def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClasses = [] self . PPIs = [] self . Protocols = [] self . Guids = [] self . Pcds = [] self . IncludePaths = [] self . Path = \"\" self . PackageName = None def _Parse ( self ) -> None: InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InStructuredPcdDeclaration = False InIncludesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () if ( self . PackageName is None and tokens [ 0 ]. strip () == \"PACKAGE_NAME\" ): self . PackageName = self . Dict [ \"PACKAGE_NAME\" ] continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: t = LibraryClassDeclarationEntry ( self . PackageName , sline ) self . LibraryClasses . append ( t ) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: t = ProtocolDeclarationEntry ( self . PackageName , sline ) self . Protocols . append ( t ) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: t = GuidDeclarationEntry ( self . PackageName , sline ) self . Guids . append ( t ) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False elif sline . strip ()[ 0 ] == '}' : InStructuredPcdDeclaration = False else: if InStructuredPcdDeclaration: continue t = PcdDeclarationEntry ( self . PackageName , sline ) self . Pcds . append ( t ) if sline . rstrip ()[- 1 ] == '{' : InStructuredPcdDeclaration = True continue elif InIncludesSection: if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else: self . IncludePaths . append ( sline . strip ()) continue elif InPPISection: if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else: t = PpiDeclarationEntry ( self . PackageName , sline ) self . PPIs . append ( t ) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True def ParseStream ( self , stream ) -> None: \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse () def ParseFile ( self , filepath: str ) -> None: \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse () Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath : str ) -> None Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data View Source def ParseFile ( self , filepath : str ) -> None : \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse () ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) ParseStream def ParseStream ( self , stream ) -> None parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data View Source def ParseStream ( self , stream ) -> None : \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse () PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close () GuidDeclarationEntry class GuidDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class GuidDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . GUID Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry Class variables GUID PPI PROTOCOL GuidedDeclarationEntry class GuidedDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class GuidedDeclarationEntry (): \"\"\"A baseclass for declaration types that have a name and guid.\"\"\" PROTOCOL = 1 PPI = 2 GUID = 3 def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a protocol/Ppi/or Guid declaration entry\"\"\" self . name = \"\" self . guidstring = \"\" self . guid = None self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ) -> None: \"\"\"Parses the name and guid of a declaration Args: rawtext: str: Returns: \"\"\" t = rawtext . partition ( \"=\" ) self . name = t [ 0 ]. strip () self . guidstring = t [ 2 ]. strip () self . guid = GuidParser . uuid_from_guidstring ( self . guidstring ) if ( self . guid is None ): raise ValueError ( \"Could not parse guid\" ) Descendants edk2toollib.uefi.edk2.parsers.dec_parser.ProtocolDeclarationEntry edk2toollib.uefi.edk2.parsers.dec_parser.PpiDeclarationEntry edk2toollib.uefi.edk2.parsers.dec_parser.GuidDeclarationEntry Class variables GUID PPI PROTOCOL LibraryClassDeclarationEntry class LibraryClassDeclarationEntry ( packagename : str , rawtext : str = None ) View Source class LibraryClassDeclarationEntry (): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a library Class Declaration Entry\"\"\" self . path = \"\" self . name = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ) -> None: \"\"\"Parses the rawtext line to collect the Library Class declaration information (name and package root relative path). Args: rawtext: str expected format is <library class name> | <package relative path to header file> Returns: None \"\"\" t = rawtext . partition ( \"|\" ) self . name = t [ 0 ]. strip () self . path = t [ 2 ]. strip () PcdDeclarationEntry class PcdDeclarationEntry ( packagename : str , rawtext : str = None ) View Source class PcdDeclarationEntry (): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Creates a PCD Declaration Entry for one PCD\"\"\" self . token_space_name = \"\" self . name = \"\" self . default_value = \"\" self . type = \"\" self . id = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ): \"\"\" Args: rawtext: str: Returns: \"\"\" sp = rawtext . partition ( \".\" ) self . token_space_name = sp [ 0 ]. strip () op = sp [ 2 ]. split ( \"|\" ) # if it's 2 long, we need to check that it's a structured PCD if ( len ( op ) == 2 and op [ 0 ]. count ( \".\" ) > 0 ): pass # otherwise it needs at least 4 parts elif ( len ( op ) < 4 ): raise Exception ( f \"Too few parts: {op}\" ) # but also less than 5 elif ( len ( op ) > 5 ): raise Exception ( f \"Too many parts: {rawtext}\" ) elif ( len ( op ) == 5 and op [ 4 ]. strip () != '{' ): raise Exception ( f \"Too many parts: {rawtext}\" ) self . name = op [ 0 ]. strip () self . default_value = op [ 1 ]. strip () # if we don't know what the type and id, it's because it's structured self . type = op [ 2 ]. strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" self . id = op [ 3 ]. strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" PpiDeclarationEntry class PpiDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class PpiDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PPI Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry Class variables GUID PPI PROTOCOL ProtocolDeclarationEntry class ProtocolDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class ProtocolDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a protocol declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PROTOCOL Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry Class variables GUID PPI PROTOCOL","title":"Dec parser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#module-edk2toollibuefiedk2parsersdec_parser","text":"View Source # @file dec_parser.py # Code to help parse DEC file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser from edk2toollib.uefi.edk2.parsers.guid_parser import GuidParser class LibraryClassDeclarationEntry (): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a library Class Declaration Entry\"\"\" self . path = \"\" self . name = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ) -> None : \"\"\"Parses the rawtext line to collect the Library Class declaration information (name and package root relative path). Args: rawtext: str expected format is <library class name> | <package relative path to header file> Returns: None \"\"\" t = rawtext . partition ( \"|\" ) self . name = t [ 0 ] . strip () self . path = t [ 2 ] . strip () class GuidedDeclarationEntry (): \"\"\"A baseclass for declaration types that have a name and guid.\"\"\" PROTOCOL = 1 PPI = 2 GUID = 3 def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a protocol/Ppi/or Guid declaration entry\"\"\" self . name = \"\" self . guidstring = \"\" self . guid = None self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ) -> None : \"\"\"Parses the name and guid of a declaration Args: rawtext: str: Returns: \"\"\" t = rawtext . partition ( \"=\" ) self . name = t [ 0 ] . strip () self . guidstring = t [ 2 ] . strip () self . guid = GuidParser . uuid_from_guidstring ( self . guidstring ) if ( self . guid is None ): raise ValueError ( \"Could not parse guid\" ) class ProtocolDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a protocol declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PROTOCOL class PpiDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PPI class GuidDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super () . __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . GUID class PcdDeclarationEntry (): def __init__ ( self , packagename : str , rawtext : str = None ): \"\"\"Creates a PCD Declaration Entry for one PCD\"\"\" self . token_space_name = \"\" self . name = \"\" self . default_value = \"\" self . type = \"\" self . id = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext : str ): \"\"\" Args: rawtext: str: Returns: \"\"\" sp = rawtext . partition ( \".\" ) self . token_space_name = sp [ 0 ] . strip () op = sp [ 2 ] . split ( \"|\" ) # if it's 2 long, we need to check that it's a structured PCD if ( len ( op ) == 2 and op [ 0 ] . count ( \".\" ) > 0 ): pass # otherwise it needs at least 4 parts elif ( len ( op ) < 4 ): raise Exception ( f \"Too few parts: {op}\" ) # but also less than 5 elif ( len ( op ) > 5 ): raise Exception ( f \"Too many parts: {rawtext}\" ) elif ( len ( op ) == 5 and op [ 4 ] . strip () != '{' ): raise Exception ( f \"Too many parts: {rawtext}\" ) self . name = op [ 0 ] . strip () self . default_value = op [ 1 ] . strip () # if we don't know what the type and id, it's because it's structured self . type = op [ 2 ] . strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" self . id = op [ 3 ] . strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" class DecParser ( HashFileParser ): \"\"\"Parses an EDK2 DEC file\"\"\" def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClasses = [] self . PPIs = [] self . Protocols = [] self . Guids = [] self . Pcds = [] self . IncludePaths = [] self . Path = \"\" self . PackageName = None def _Parse ( self ) -> None : InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InStructuredPcdDeclaration = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () if ( self . PackageName is None and tokens [ 0 ] . strip () == \"PACKAGE_NAME\" ): self . PackageName = self . Dict [ \"PACKAGE_NAME\" ] continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = LibraryClassDeclarationEntry ( self . PackageName , sline ) self . LibraryClasses . append ( t ) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = ProtocolDeclarationEntry ( self . PackageName , sline ) self . Protocols . append ( t ) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = GuidDeclarationEntry ( self . PackageName , sline ) self . Guids . append ( t ) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False elif sline . strip ()[ 0 ] == '}' : InStructuredPcdDeclaration = False else : if InStructuredPcdDeclaration : continue t = PcdDeclarationEntry ( self . PackageName , sline ) self . Pcds . append ( t ) if sline . rstrip ()[ - 1 ] == '{' : InStructuredPcdDeclaration = True continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludePaths . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = PpiDeclarationEntry ( self . PackageName , sline ) self . PPIs . append ( t ) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPPISection = True elif sline . strip () . lower () . startswith ( '[pcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[includes' ): InIncludesSection = True self . Parsed = True def ParseStream ( self , stream ) -> None : \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse () def ParseFile ( self , filepath : str ) -> None : \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse ()","title":"Module edk2toollib.uefi.edk2.parsers.dec_parser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#decparser","text":"class DecParser ( ) Parses an EDK2 DEC file View Source class DecParser ( HashFileParser ): \"\"\"Parses an EDK2 DEC file\"\"\" def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClasses = [] self . PPIs = [] self . Protocols = [] self . Guids = [] self . Pcds = [] self . IncludePaths = [] self . Path = \"\" self . PackageName = None def _Parse ( self ) -> None: InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InStructuredPcdDeclaration = False InIncludesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () if ( self . PackageName is None and tokens [ 0 ]. strip () == \"PACKAGE_NAME\" ): self . PackageName = self . Dict [ \"PACKAGE_NAME\" ] continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: t = LibraryClassDeclarationEntry ( self . PackageName , sline ) self . LibraryClasses . append ( t ) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: t = ProtocolDeclarationEntry ( self . PackageName , sline ) self . Protocols . append ( t ) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: t = GuidDeclarationEntry ( self . PackageName , sline ) self . Guids . append ( t ) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False elif sline . strip ()[ 0 ] == '}' : InStructuredPcdDeclaration = False else: if InStructuredPcdDeclaration: continue t = PcdDeclarationEntry ( self . PackageName , sline ) self . Pcds . append ( t ) if sline . rstrip ()[- 1 ] == '{' : InStructuredPcdDeclaration = True continue elif InIncludesSection: if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else: self . IncludePaths . append ( sline . strip ()) continue elif InPPISection: if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else: t = PpiDeclarationEntry ( self . PackageName , sline ) self . PPIs . append ( t ) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True def ParseStream ( self , stream ) -> None: \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse () def ParseFile ( self , filepath: str ) -> None: \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse ()","title":"DecParser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parsefile","text":"def ParseFile ( self , filepath : str ) -> None Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data View Source def ParseFile ( self , filepath : str ) -> None : \"\"\" Parse the supplied file. Args: filepath: path to dec file to parse. Can be either an absolute path or relative to your CWD Returns: None - Existing object now contains parsed data \"\"\" self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () self . _Parse ()","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parsestream","text":"def ParseStream ( self , stream ) -> None parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data View Source def ParseStream ( self , stream ) -> None : \"\"\" parse the supplied IO as a DEC file Args: stream: a file-like/stream object in which DEC file contents can be read Returns: None - Existing object now contains parsed data \"\"\" self . Path = \"None:stream_given\" self . Lines = stream . readlines () self . _Parse ()","title":"ParseStream"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#guiddeclarationentry","text":"class GuidDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class GuidDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . GUID","title":"GuidDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ancestors-in-mro_1","text":"edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#class-variables_1","text":"GUID PPI PROTOCOL","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#guideddeclarationentry","text":"class GuidedDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class GuidedDeclarationEntry (): \"\"\"A baseclass for declaration types that have a name and guid.\"\"\" PROTOCOL = 1 PPI = 2 GUID = 3 def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a protocol/Ppi/or Guid declaration entry\"\"\" self . name = \"\" self . guidstring = \"\" self . guid = None self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ) -> None: \"\"\"Parses the name and guid of a declaration Args: rawtext: str: Returns: \"\"\" t = rawtext . partition ( \"=\" ) self . name = t [ 0 ]. strip () self . guidstring = t [ 2 ]. strip () self . guid = GuidParser . uuid_from_guidstring ( self . guidstring ) if ( self . guid is None ): raise ValueError ( \"Could not parse guid\" )","title":"GuidedDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#descendants","text":"edk2toollib.uefi.edk2.parsers.dec_parser.ProtocolDeclarationEntry edk2toollib.uefi.edk2.parsers.dec_parser.PpiDeclarationEntry edk2toollib.uefi.edk2.parsers.dec_parser.GuidDeclarationEntry","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#class-variables_2","text":"GUID PPI PROTOCOL","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#libraryclassdeclarationentry","text":"class LibraryClassDeclarationEntry ( packagename : str , rawtext : str = None ) View Source class LibraryClassDeclarationEntry (): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a library Class Declaration Entry\"\"\" self . path = \"\" self . name = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ) -> None: \"\"\"Parses the rawtext line to collect the Library Class declaration information (name and package root relative path). Args: rawtext: str expected format is <library class name> | <package relative path to header file> Returns: None \"\"\" t = rawtext . partition ( \"|\" ) self . name = t [ 0 ]. strip () self . path = t [ 2 ]. strip ()","title":"LibraryClassDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#pcddeclarationentry","text":"class PcdDeclarationEntry ( packagename : str , rawtext : str = None ) View Source class PcdDeclarationEntry (): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Creates a PCD Declaration Entry for one PCD\"\"\" self . token_space_name = \"\" self . name = \"\" self . default_value = \"\" self . type = \"\" self . id = \"\" self . package_name = packagename if ( rawtext is not None ): self . _parse ( rawtext ) def _parse ( self , rawtext: str ): \"\"\" Args: rawtext: str: Returns: \"\"\" sp = rawtext . partition ( \".\" ) self . token_space_name = sp [ 0 ]. strip () op = sp [ 2 ]. split ( \"|\" ) # if it's 2 long, we need to check that it's a structured PCD if ( len ( op ) == 2 and op [ 0 ]. count ( \".\" ) > 0 ): pass # otherwise it needs at least 4 parts elif ( len ( op ) < 4 ): raise Exception ( f \"Too few parts: {op}\" ) # but also less than 5 elif ( len ( op ) > 5 ): raise Exception ( f \"Too many parts: {rawtext}\" ) elif ( len ( op ) == 5 and op [ 4 ]. strip () != '{' ): raise Exception ( f \"Too many parts: {rawtext}\" ) self . name = op [ 0 ]. strip () self . default_value = op [ 1 ]. strip () # if we don't know what the type and id, it's because it's structured self . type = op [ 2 ]. strip () if len ( op ) > 2 else \"STRUCTURED_PCD\" self . id = op [ 3 ]. strip () if len ( op ) > 2 else \"STRUCTURED_PCD\"","title":"PcdDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ppideclarationentry","text":"class PpiDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class PpiDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a Ppi declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PPI","title":"PpiDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ancestors-in-mro_2","text":"edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#class-variables_3","text":"GUID PPI PROTOCOL","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#protocoldeclarationentry","text":"class ProtocolDeclarationEntry ( packagename : str , rawtext : str = None ) A baseclass for declaration types that have a name and guid. View Source class ProtocolDeclarationEntry ( GuidedDeclarationEntry ): def __init__ ( self , packagename: str , rawtext: str = None ): \"\"\"Init a protocol declaration entry\"\"\" super (). __init__ ( packagename , rawtext ) self . type = GuidedDeclarationEntry . PROTOCOL","title":"ProtocolDeclarationEntry"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ancestors-in-mro_3","text":"edk2toollib.uefi.edk2.parsers.dec_parser.GuidedDeclarationEntry","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#class-variables_4","text":"GUID PPI PROTOCOL","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/","text":"Module edk2toollib.uefi.edk2.parsers.dsc_parser View Source # @file dsc_parser.py # Code to help parse DSC files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DscParser ( HashFileParser ): def __init__ ( self ): super ( DscParser , self ) . __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] self . _dsc_file_paths = set () # This includes the full paths for every DSC that makes up the file def __ParseLine ( self , Line , file_name = None , lineno = None ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , [], None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , [], None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , [], None ) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , tokens [ 1 ])) sp = self . FindPath ( tokens [ 1 ]) self . _dsc_file_paths . add ( sp ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , [], None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 64bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 32bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in library class section (don't use full name) elif ( self . CurrentSection . upper () == \"LIBRARYCLASSES\" ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in Library Class Section: %s \" % p ) return ( line_resolved , [], None ) # process line in PCD section elif ( self . CurrentSection . upper () . startswith ( \"PCDS\" )): if \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s \" % p [ 0 ] . strip ()) return ( line_resolved , [], None ) else : return ( line_resolved , [], None ) def __ParseDefineLine ( self , Line ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , []) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , []) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , tokens [ 1 ])) sp = self . FindPath ( tokens [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , []) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ): if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ): left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s \" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ]) return ( line_resolved , []) else : return ( line_resolved , []) def ParseInfPathLib ( self , line ): if ( line . count ( \"|\" ) > 0 ): line_parts = [] c = line . split ( \"|\" )[ 0 ] . strip () i = line . split ( \"|\" )[ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ): line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" )[ 1 ] . strip () else : return line . strip () . split ()[ 0 ] def ParseInfPathMod ( self , line ): return line . strip () . split ()[ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ): if ( len ( lines ) > 0 ): for index in range ( 0 , len ( lines )): ( line , add , new_file ) = self . __ParseLine ( lines [ index ], file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ): self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ): if ( len ( lines ) > 0 ): for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ): # # add more DSC parser based state reset here, if necessary # super ( DscParser , self ) . ResetParserState () def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) sp = os . path . join ( filepath ) self . _dsc_file_paths . add ( sp ) f = open ( sp , \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = sp ) f . close () self . Parsed = True def GetMods ( self ): return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ): return self . Libs def GetLibsEnhanced ( self ): return self . LibsEnhanced def GetAllDscPaths ( self ): ''' returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files ''' return self . _dsc_file_paths Classes DscParser class DscParser ( ) View Source class DscParser ( HashFileParser ) : def __init__ ( self ) : super ( DscParser , self ). __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] self . _dsc_file_paths = set () # This includes the full paths for every DSC that makes up the file def __ParseLine ( self , Line , file_name = None , lineno = None ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] , None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] , None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] , None ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , tokens [ 1 ] )) sp = self . FindPath ( tokens [ 1 ] ) self . _dsc_file_paths . add ( sp ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] , None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 64bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 32bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in library class section ( don 't use full name) elif(self.CurrentSection.upper() == \"LIBRARYCLASSES\"): if(\".inf\" in line_resolved.lower()): p = self.ParseInfPathLib(line_resolved) self.Libs.append(p) self.Logger.debug(\"Found Library in Library Class Section: %s\" % p) return (line_resolved, [], None) # process line in PCD section elif(self.CurrentSection.upper().startswith(\"PCDS\")): if \"tokenspaceguid\" in line_resolved.lower() and \\ line_resolved.count(' | ') > 0 and line_resolved.count(' . ') > 0: # should be a pcd statement p = line_resolved.partition(' | ') self.Pcds.append(p[0].strip()) self.Logger.debug(\"Found a Pcd in a PCD section: %s\" % p[0].strip()) return (line_resolved, [], None) else: return (line_resolved, [], None) def __ParseDefineLine(self, Line): line_stripped = self.StripComment(Line).strip() if(len(line_stripped) < 1): return (\"\", []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self.ReplaceVariables(line_stripped) if(self.ProcessConditional(line_resolved)): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return (\"\", []) # not conditional keep procesing # check if conditional is active if(not self.InActiveCode()): return (\"\", []) # check for include file and import lines from file if(line_resolved.strip().lower().startswith(\"!include\")): # include line. tokens = line_resolved.split() self.Logger.debug(\"Opening Include File %s\" % os.path.join(self.RootPath, tokens[1])) sp = self.FindPath(tokens[1]) lf = open(sp, \"r\") loc = lf.readlines() lf.close() return (\"\", loc) # check for new section (IsNew, Section) = self.ParseNewSection(line_resolved) if(IsNew): self.CurrentSection = Section.upper() self.Logger.debug(\"New Section: %s\" % self.CurrentSection) self.Logger.debug(\"FullSection: %s\" % self.CurrentFullSection) return (line_resolved, []) # process line based on section we are in if(self.CurrentSection == \"DEFINES\") or (self.CurrentSection == \"BUILDOPTIONS\"): if line_resolved.count(\"=\") >= 1: tokens = line_resolved.split(\"=\", 1) leftside = tokens[0].split() if(len(leftside) == 2): left = leftside[1] else: left = leftside[0] right = tokens[1].strip() self.LocalVars[left] = right self.Logger.debug(\"Key,values found: %s = %s\" % (left, right)) # iterate through the existed LocalVars and try to resolve the symbols for var in self.LocalVars: self.LocalVars[var] = self.ReplaceVariables(self.LocalVars[var]) return (line_resolved, []) else: return (line_resolved, []) def ParseInfPathLib(self, line): if(line.count(\"|\") > 0): line_parts = [] c = line.split(\"|\")[0].strip() i = line.split(\"|\")[1].strip() if(c in self.LibraryClassToInstanceDict): line_parts = self.LibraryClassToInstanceDict.get(c) sp = self.FindPath(i) line_parts.append(sp) self.LibraryClassToInstanceDict[c] = line_parts return line.split(\"|\")[1].strip() else: return line.strip().split()[0] def ParseInfPathMod(self, line): return line.strip().split()[0].rstrip(\"{\") def __ProcessMore(self, lines, file_name=None): if(len(lines) > 0): for index in range(0, len(lines)): (line, add, new_file) = self.__ParseLine(lines[index], file_name=file_name, lineno=index + 1) if(len(line) > 0): self.Lines.append(line) self.__ProcessMore(add, file_name=new_file) def __ProcessDefines(self, lines): if(len(lines) > 0): for l in lines: (line, add) = self.__ParseDefineLine(l) self.__ProcessDefines(add) def ResetParserState(self): # # add more DSC parser based state reset here, if necessary # super(DscParser, self).ResetParserState() def ParseFile(self, filepath): self.Logger.debug(\"Parsing file: %s\" % filepath) self.TargetFile = os.path.abspath(filepath) self.TargetFilePath = os.path.dirname(self.TargetFile) sp = os.path.join(filepath) self._dsc_file_paths.add(sp) f = open(sp, \"r\") # expand all the lines and include other files file_lines = f.readlines() self.__ProcessDefines(file_lines) # reset the parser state before processing more self.ResetParserState() self.__ProcessMore(file_lines, file_name=sp) f.close() self.Parsed = True def GetMods(self): return self.ThreeMods + self.SixMods def GetModsEnhanced(self): return self.ThreeModsEnhanced + self.SixModsEnhanced def GetLibs(self): return self.Libs def GetLibsEnhanced(self): return self.LibsEnhanced def GetAllDscPaths(self): ''' returns an iterable with all the paths that this DSC uses ( the base file and any includes ). They are not all guaranteed to be DSC files '' ' return self . _dsc_file_paths Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path GetAllDscPaths def GetAllDscPaths ( self ) returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files View Source def GetAllDscPaths ( self ): ''' returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files ''' return self . _dsc_file_paths GetLibs def GetLibs ( self ) View Source def GetLibs ( self ): return self . Libs GetLibsEnhanced def GetLibsEnhanced ( self ) View Source def GetLibsEnhanced ( self ): return self . LibsEnhanced GetMods def GetMods ( self ) View Source def GetMods ( self ): return self . ThreeMods + self . SixMods GetModsEnhanced def GetModsEnhanced ( self ) View Source def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) sp = os . path . join ( filepath ) self . _dsc_file_paths . add ( sp ) f = open ( sp , \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = sp ) f . close () self . Parsed = True ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseInfPathLib def ParseInfPathLib ( self , line ) View Source def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ] ParseInfPathMod def ParseInfPathMod ( self , line ) View Source def ParseInfPathMod ( self , line ): return line . strip (). split ()[ 0 ]. rstrip ( \"{\" ) ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState () SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Dsc parser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#module-edk2toollibuefiedk2parsersdsc_parser","text":"View Source # @file dsc_parser.py # Code to help parse DSC files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DscParser ( HashFileParser ): def __init__ ( self ): super ( DscParser , self ) . __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] self . _dsc_file_paths = set () # This includes the full paths for every DSC that makes up the file def __ParseLine ( self , Line , file_name = None , lineno = None ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , [], None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , [], None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , [], None ) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , tokens [ 1 ])) sp = self . FindPath ( tokens [ 1 ]) self . _dsc_file_paths . add ( sp ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , [], None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 64bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 32bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in library class section (don't use full name) elif ( self . CurrentSection . upper () == \"LIBRARYCLASSES\" ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in Library Class Section: %s \" % p ) return ( line_resolved , [], None ) # process line in PCD section elif ( self . CurrentSection . upper () . startswith ( \"PCDS\" )): if \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s \" % p [ 0 ] . strip ()) return ( line_resolved , [], None ) else : return ( line_resolved , [], None ) def __ParseDefineLine ( self , Line ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , []) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , []) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , tokens [ 1 ])) sp = self . FindPath ( tokens [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , []) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ): if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ): left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s \" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ]) return ( line_resolved , []) else : return ( line_resolved , []) def ParseInfPathLib ( self , line ): if ( line . count ( \"|\" ) > 0 ): line_parts = [] c = line . split ( \"|\" )[ 0 ] . strip () i = line . split ( \"|\" )[ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ): line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" )[ 1 ] . strip () else : return line . strip () . split ()[ 0 ] def ParseInfPathMod ( self , line ): return line . strip () . split ()[ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ): if ( len ( lines ) > 0 ): for index in range ( 0 , len ( lines )): ( line , add , new_file ) = self . __ParseLine ( lines [ index ], file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ): self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ): if ( len ( lines ) > 0 ): for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ): # # add more DSC parser based state reset here, if necessary # super ( DscParser , self ) . ResetParserState () def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) sp = os . path . join ( filepath ) self . _dsc_file_paths . add ( sp ) f = open ( sp , \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = sp ) f . close () self . Parsed = True def GetMods ( self ): return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ): return self . Libs def GetLibsEnhanced ( self ): return self . LibsEnhanced def GetAllDscPaths ( self ): ''' returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files ''' return self . _dsc_file_paths","title":"Module edk2toollib.uefi.edk2.parsers.dsc_parser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#dscparser","text":"class DscParser ( ) View Source class DscParser ( HashFileParser ) : def __init__ ( self ) : super ( DscParser , self ). __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] self . _dsc_file_paths = set () # This includes the full paths for every DSC that makes up the file def __ParseLine ( self , Line , file_name = None , lineno = None ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] , None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] , None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] , None ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . tokens = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , tokens [ 1 ] )) sp = self . FindPath ( tokens [ 1 ] ) self . _dsc_file_paths . add ( sp ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] , None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 64bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 32bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in library class section ( don 't use full name) elif(self.CurrentSection.upper() == \"LIBRARYCLASSES\"): if(\".inf\" in line_resolved.lower()): p = self.ParseInfPathLib(line_resolved) self.Libs.append(p) self.Logger.debug(\"Found Library in Library Class Section: %s\" % p) return (line_resolved, [], None) # process line in PCD section elif(self.CurrentSection.upper().startswith(\"PCDS\")): if \"tokenspaceguid\" in line_resolved.lower() and \\ line_resolved.count(' | ') > 0 and line_resolved.count(' . ') > 0: # should be a pcd statement p = line_resolved.partition(' | ') self.Pcds.append(p[0].strip()) self.Logger.debug(\"Found a Pcd in a PCD section: %s\" % p[0].strip()) return (line_resolved, [], None) else: return (line_resolved, [], None) def __ParseDefineLine(self, Line): line_stripped = self.StripComment(Line).strip() if(len(line_stripped) < 1): return (\"\", []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self.ReplaceVariables(line_stripped) if(self.ProcessConditional(line_resolved)): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return (\"\", []) # not conditional keep procesing # check if conditional is active if(not self.InActiveCode()): return (\"\", []) # check for include file and import lines from file if(line_resolved.strip().lower().startswith(\"!include\")): # include line. tokens = line_resolved.split() self.Logger.debug(\"Opening Include File %s\" % os.path.join(self.RootPath, tokens[1])) sp = self.FindPath(tokens[1]) lf = open(sp, \"r\") loc = lf.readlines() lf.close() return (\"\", loc) # check for new section (IsNew, Section) = self.ParseNewSection(line_resolved) if(IsNew): self.CurrentSection = Section.upper() self.Logger.debug(\"New Section: %s\" % self.CurrentSection) self.Logger.debug(\"FullSection: %s\" % self.CurrentFullSection) return (line_resolved, []) # process line based on section we are in if(self.CurrentSection == \"DEFINES\") or (self.CurrentSection == \"BUILDOPTIONS\"): if line_resolved.count(\"=\") >= 1: tokens = line_resolved.split(\"=\", 1) leftside = tokens[0].split() if(len(leftside) == 2): left = leftside[1] else: left = leftside[0] right = tokens[1].strip() self.LocalVars[left] = right self.Logger.debug(\"Key,values found: %s = %s\" % (left, right)) # iterate through the existed LocalVars and try to resolve the symbols for var in self.LocalVars: self.LocalVars[var] = self.ReplaceVariables(self.LocalVars[var]) return (line_resolved, []) else: return (line_resolved, []) def ParseInfPathLib(self, line): if(line.count(\"|\") > 0): line_parts = [] c = line.split(\"|\")[0].strip() i = line.split(\"|\")[1].strip() if(c in self.LibraryClassToInstanceDict): line_parts = self.LibraryClassToInstanceDict.get(c) sp = self.FindPath(i) line_parts.append(sp) self.LibraryClassToInstanceDict[c] = line_parts return line.split(\"|\")[1].strip() else: return line.strip().split()[0] def ParseInfPathMod(self, line): return line.strip().split()[0].rstrip(\"{\") def __ProcessMore(self, lines, file_name=None): if(len(lines) > 0): for index in range(0, len(lines)): (line, add, new_file) = self.__ParseLine(lines[index], file_name=file_name, lineno=index + 1) if(len(line) > 0): self.Lines.append(line) self.__ProcessMore(add, file_name=new_file) def __ProcessDefines(self, lines): if(len(lines) > 0): for l in lines: (line, add) = self.__ParseDefineLine(l) self.__ProcessDefines(add) def ResetParserState(self): # # add more DSC parser based state reset here, if necessary # super(DscParser, self).ResetParserState() def ParseFile(self, filepath): self.Logger.debug(\"Parsing file: %s\" % filepath) self.TargetFile = os.path.abspath(filepath) self.TargetFilePath = os.path.dirname(self.TargetFile) sp = os.path.join(filepath) self._dsc_file_paths.add(sp) f = open(sp, \"r\") # expand all the lines and include other files file_lines = f.readlines() self.__ProcessDefines(file_lines) # reset the parser state before processing more self.ResetParserState() self.__ProcessMore(file_lines, file_name=sp) f.close() self.Parsed = True def GetMods(self): return self.ThreeMods + self.SixMods def GetModsEnhanced(self): return self.ThreeModsEnhanced + self.SixModsEnhanced def GetLibs(self): return self.Libs def GetLibsEnhanced(self): return self.LibsEnhanced def GetAllDscPaths(self): ''' returns an iterable with all the paths that this DSC uses ( the base file and any includes ). They are not all guaranteed to be DSC files '' ' return self . _dsc_file_paths","title":"DscParser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getalldscpaths","text":"def GetAllDscPaths ( self ) returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files View Source def GetAllDscPaths ( self ): ''' returns an iterable with all the paths that this DSC uses (the base file and any includes). They are not all guaranteed to be DSC files ''' return self . _dsc_file_paths","title":"GetAllDscPaths"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getlibs","text":"def GetLibs ( self ) View Source def GetLibs ( self ): return self . Libs","title":"GetLibs"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getlibsenhanced","text":"def GetLibsEnhanced ( self ) View Source def GetLibsEnhanced ( self ): return self . LibsEnhanced","title":"GetLibsEnhanced"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getmods","text":"def GetMods ( self ) View Source def GetMods ( self ): return self . ThreeMods + self . SixMods","title":"GetMods"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getmodsenhanced","text":"def GetModsEnhanced ( self ) View Source def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced","title":"GetModsEnhanced"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) sp = os . path . join ( filepath ) self . _dsc_file_paths . add ( sp ) f = open ( sp , \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = sp ) f . close () self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseinfpathlib","text":"def ParseInfPathLib ( self , line ) View Source def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ]","title":"ParseInfPathLib"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseinfpathmod","text":"def ParseInfPathMod ( self , line ) View Source def ParseInfPathMod ( self , line ): return line . strip (). split ()[ 0 ]. rstrip ( \"{\" )","title":"ParseInfPathMod"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState ()","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/","text":"Module edk2toollib.uefi.edk2.parsers.fdf_parser View Source # @file fdf_parser.py # Code to help parse EDK2 Fdf files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class FdfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip () . startswith ( \"[\" ) and sline . strip () . endswith ( \"]\" ): # if we're starting a new section # this basically gets what's after the . or if it doesn't have a period # the whole thing for every comma separated item in sline self . CurrentSection = [ x . split ( \".\" , 1 )[ 1 ] if \".\" in x else x for x in sline . strip ( \"[] \" ) . strip () . split ( \",\" )] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self . LocalVars = {} self . LocalVars . update ( self . Dict ) if InDefinesSection : if sline . count ( \"=\" ) == 1 : tokens = sline . replace ( \"DEFINE\" , \"\" ) . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . info ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InFdSection : for section in self . CurrentSection : if section not in self . FVs : self . FDs [ section ] = { \"Dict\" : {}} # TODO finish the FD section continue elif InFvSection : for section in self . CurrentSection : if section not in self . FVs : self . FVs [ section ] = { \"Dict\" : {}, \"Infs\" : [], \"Files\" : {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline . upper () . startswith ( \"INF \" ): InfValue = sline [ 3 :] . strip () self . FVs [ section ][ \"Infs\" ] . append ( InfValue ) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline . upper () . startswith ( \"FILE\" ): sline = sline . strip ( \"}\" ) . strip ( \"{\" ) . strip () # make sure we take off the { and } file_def = sline [ 4 :] . strip () . split ( \"=\" , 1 ) # split by = if len ( file_def ) != 2 : # check to make sure we can parse this file raise RuntimeError ( \"Unable to properly parse \" + sline ) currentType = file_def [ 0 ] . strip () # get the type FILE currentName = file_def [ 1 ] . strip () # get the name (guid or otherwise) if currentType not in self . FVs [ section ]: self . FVs [ section ][ \"Files\" ][ currentName ] = {} self . FVs [ section ][ \"Files\" ][ currentName ][ \"type\" ] = currentType while self . _BracketCount > 0 : # go until we get our bracket back sline = self . GetNextLine () . strip ( \"}{ \" ) # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline . upper () . startswith ( \"SECTION GUIDED\" ): # get the guided section section_def = sline [ 14 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline . upper () . startswith ( \"SECTION\" ): # get the section section_def = sline [ 7 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = [] self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] . append ( sectionValue ) else : self . Logger . info ( \"Unknown line: {}\" . format ( sline )) continue elif InCapsuleSection : # TODO: finish capsule section continue elif InFmpPayloadSection : # TODO finish FMP payload section continue elif InRuleSection : # TODO finish rule section continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[fd.' ): InFdSection = True elif sline . strip () . lower () . startswith ( '[fv.' ): InFvSection = True elif sline . strip () . lower () . startswith ( '[capsule.' ): InCapsuleSection = True elif sline . strip () . lower () . startswith ( '[fmpPayload.' ): InFmpPayloadSection = True elif sline . strip () . lower () . startswith ( '[rule.' ): InRuleSection = True self . Parsed = True Classes FdfParser class FdfParser ( ) View Source class FdfParser ( HashFileParser ) : def __init__ ( self ) : HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ) : if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ) : return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ) : # was a conditional so skip return self . GetNextLine () if not self . InActiveCode () : return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma separated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path GetNextLine def GetNextLine ( self ) View Source def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma separated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Fdf parser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#module-edk2toollibuefiedk2parsersfdf_parser","text":"View Source # @file fdf_parser.py # Code to help parse EDK2 Fdf files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class FdfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip () . startswith ( \"[\" ) and sline . strip () . endswith ( \"]\" ): # if we're starting a new section # this basically gets what's after the . or if it doesn't have a period # the whole thing for every comma separated item in sline self . CurrentSection = [ x . split ( \".\" , 1 )[ 1 ] if \".\" in x else x for x in sline . strip ( \"[] \" ) . strip () . split ( \",\" )] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self . LocalVars = {} self . LocalVars . update ( self . Dict ) if InDefinesSection : if sline . count ( \"=\" ) == 1 : tokens = sline . replace ( \"DEFINE\" , \"\" ) . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . info ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InFdSection : for section in self . CurrentSection : if section not in self . FVs : self . FDs [ section ] = { \"Dict\" : {}} # TODO finish the FD section continue elif InFvSection : for section in self . CurrentSection : if section not in self . FVs : self . FVs [ section ] = { \"Dict\" : {}, \"Infs\" : [], \"Files\" : {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline . upper () . startswith ( \"INF \" ): InfValue = sline [ 3 :] . strip () self . FVs [ section ][ \"Infs\" ] . append ( InfValue ) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline . upper () . startswith ( \"FILE\" ): sline = sline . strip ( \"}\" ) . strip ( \"{\" ) . strip () # make sure we take off the { and } file_def = sline [ 4 :] . strip () . split ( \"=\" , 1 ) # split by = if len ( file_def ) != 2 : # check to make sure we can parse this file raise RuntimeError ( \"Unable to properly parse \" + sline ) currentType = file_def [ 0 ] . strip () # get the type FILE currentName = file_def [ 1 ] . strip () # get the name (guid or otherwise) if currentType not in self . FVs [ section ]: self . FVs [ section ][ \"Files\" ][ currentName ] = {} self . FVs [ section ][ \"Files\" ][ currentName ][ \"type\" ] = currentType while self . _BracketCount > 0 : # go until we get our bracket back sline = self . GetNextLine () . strip ( \"}{ \" ) # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline . upper () . startswith ( \"SECTION GUIDED\" ): # get the guided section section_def = sline [ 14 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline . upper () . startswith ( \"SECTION\" ): # get the section section_def = sline [ 7 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = [] self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] . append ( sectionValue ) else : self . Logger . info ( \"Unknown line: {}\" . format ( sline )) continue elif InCapsuleSection : # TODO: finish capsule section continue elif InFmpPayloadSection : # TODO finish FMP payload section continue elif InRuleSection : # TODO finish rule section continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[fd.' ): InFdSection = True elif sline . strip () . lower () . startswith ( '[fv.' ): InFvSection = True elif sline . strip () . lower () . startswith ( '[capsule.' ): InCapsuleSection = True elif sline . strip () . lower () . startswith ( '[fmpPayload.' ): InFmpPayloadSection = True elif sline . strip () . lower () . startswith ( '[rule.' ): InRuleSection = True self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.fdf_parser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#fdfparser","text":"class FdfParser ( ) View Source class FdfParser ( HashFileParser ) : def __init__ ( self ) : HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ) : if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ) : return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ) : # was a conditional so skip return self . GetNextLine () if not self . InActiveCode () : return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma separated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True","title":"FdfParser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#getnextline","text":"def GetNextLine ( self ) View Source def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline","title":"GetNextLine"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma separated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/","text":"Module edk2toollib.uefi.edk2.parsers.guid_parser View Source # @file guid_parser.py # Code to help parse guid formats and make into UUIDs # # Some functionality copied from Tianocore/edk2 basetools # # Copyright (c) Microsoft Corporation # Copyright (c) 2007 - 2019, Intel Corporation. All rights reserved.<BR> # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import re class GuidParser (): \"\"\" Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx \"\"\" _HexChar = r \"[0-9a-fA-F]\" # Regular expression for GUID c structure format _GuidCFormatPattern = r \"{{\\s*0[xX]{Hex}{{1,8}}\\s*,\\s*0[xX]{Hex}{{1,4}}\\s*,\\s*0[xX]{Hex}{{1,4}}\" \\ r \"\\s*,\\s*{{\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*}}\\s*}}\" . format ( Hex = _HexChar ) GuidCFormatRegEx = re . compile ( r \"{}\" . format ( _GuidCFormatPattern )) _GuidPattern = r \"{Hex}{{8}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{12}}\" . format ( Hex = _HexChar ) # Regular expressions for GUID matching GuidRegFormatRegEx = re . compile ( r '{}' . format ( _GuidPattern )) @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring ) @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip () . strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring ) @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ): return '' guidValueString = guidstring . lower () . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . replace ( \" \" , \"\" ) . replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \" %08x - %04x - %04x - %02x%02x - %02x%02x%02x%02x%02x%02x \" % ( int ( guidValueList [ 0 ], 16 ), int ( guidValueList [ 1 ], 16 ), int ( guidValueList [ 2 ], 16 ), int ( guidValueList [ 3 ], 16 ), int ( guidValueList [ 4 ], 16 ), int ( guidValueList [ 5 ], 16 ), int ( guidValueList [ 6 ], 16 ), int ( guidValueList [ 7 ], 16 ), int ( guidValueList [ 8 ], 16 ), int ( guidValueList [ 9 ], 16 ), int ( guidValueList [ 10 ], 16 ) ) except : return '' @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip () . strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )): return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ): Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0 : 2 ] + ', 0x' + GuidList [ 3 ][ 2 : 4 ] for Index in range ( 0 , 12 , 2 ): Result = Result + ', 0x' + GuidList [ 4 ][ Index : Index + 2 ] Result += '}}' return Result @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )): return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )): guidstring = guidstring . strip () . strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg ) @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid ) Classes GuidParser class GuidParser ( / , * args , ** kwargs ) Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx View Source class GuidParser () : \"\"\" Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx \"\"\" _HexChar = r \"[0-9a-fA-F]\" # Regular expression for GUID c structure format _GuidCFormatPattern = r \"{{\\s*0[xX]{Hex}{{1,8}}\\s*,\\s*0[xX]{Hex}{{1,4}}\\s*,\\s*0[xX]{Hex}{{1,4}}\" \\ r \"\\s*,\\s*{{\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*}}\\s*}}\" . format ( Hex = _HexChar ) GuidCFormatRegEx = re . compile ( r \"{}\" . format ( _GuidCFormatPattern )) _GuidPattern = r \"{Hex}{{8}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{12}}\" . format ( Hex = _HexChar ) # Regular expressions for GUID matching GuidRegFormatRegEx = re . compile ( r '{}' . format ( _GuidPattern )) @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring ) @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring ) @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ) : return '' guidValueString = guidstring . lower (). replace ( \"{\" , \"\" ). replace ( \"}\" , \"\" ). replace ( \" \" , \"\" ). replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \"%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x\" % ( int ( guidValueList [ 0 ] , 16 ), int ( guidValueList [ 1 ] , 16 ), int ( guidValueList [ 2 ] , 16 ), int ( guidValueList [ 3 ] , 16 ), int ( guidValueList [ 4 ] , 16 ), int ( guidValueList [ 5 ] , 16 ), int ( guidValueList [ 6 ] , 16 ), int ( guidValueList [ 7 ] , 16 ), int ( guidValueList [ 8 ] , 16 ), int ( guidValueList [ 9 ] , 16 ), int ( guidValueList [ 10 ] , 16 ) ) except : return '' @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )) : return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ) : Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0:2 ] + ', 0x' + GuidList [ 3 ][ 2:4 ] for Index in range ( 0 , 12 , 2 ) : Result = Result + ', 0x' + GuidList [ 4 ][ Index:Index + 2 ] Result += '}}' return Result @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )) : return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )) : guidstring = guidstring . strip (). strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg ) @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid ) Class variables GuidCFormatRegEx GuidRegFormatRegEx Static methods c_guid_from_reg_format def c_guid_from_reg_format ( guidstring : str ) -> str Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string \u2018\u2019 View Source @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )) : return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ) : Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0:2 ] + ', 0x' + GuidList [ 3 ][ 2:4 ] for Index in range ( 0 , 12 , 2 ) : Result = Result + ', 0x' + GuidList [ 4 ][ Index:Index + 2 ] Result += '}}' return Result c_guid_str_from_uuid def c_guid_str_from_uuid ( guid : uuid . UUID ) -> str get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string \u2018\u2019 View Source @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg ) is_guid_in_c_format def is_guid_in_c_format ( guidstring : str ) -> bool determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False View Source @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring ) is_guid_in_reg_format def is_guid_in_reg_format ( guidstring : str ) -> bool determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False View Source @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring ) reg_guid_from_c_format def reg_guid_from_c_format ( guidstring : str ) -> str convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string \u2018\u2019 View Source @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ) : return '' guidValueString = guidstring . lower (). replace ( \"{\" , \"\" ). replace ( \"}\" , \"\" ). replace ( \" \" , \"\" ). replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \"%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x\" % ( int ( guidValueList [ 0 ] , 16 ), int ( guidValueList [ 1 ] , 16 ), int ( guidValueList [ 2 ] , 16 ), int ( guidValueList [ 3 ] , 16 ), int ( guidValueList [ 4 ] , 16 ), int ( guidValueList [ 5 ] , 16 ), int ( guidValueList [ 6 ] , 16 ), int ( guidValueList [ 7 ] , 16 ), int ( guidValueList [ 8 ] , 16 ), int ( guidValueList [ 9 ] , 16 ), int ( guidValueList [ 10 ] , 16 ) ) except : return '' reg_guid_str_from_uuid def reg_guid_str_from_uuid ( guid : uuid . UUID ) -> str get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string \u2018\u2019 View Source @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid ) uuid_from_guidstring def uuid_from_guidstring ( guidstring : str ) -> uuid . UUID create a uuid object from the supplied guidstring View Source @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )) : return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )) : guidstring = guidstring . strip (). strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None","title":"Guid parser"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#module-edk2toollibuefiedk2parsersguid_parser","text":"View Source # @file guid_parser.py # Code to help parse guid formats and make into UUIDs # # Some functionality copied from Tianocore/edk2 basetools # # Copyright (c) Microsoft Corporation # Copyright (c) 2007 - 2019, Intel Corporation. All rights reserved.<BR> # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import re class GuidParser (): \"\"\" Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx \"\"\" _HexChar = r \"[0-9a-fA-F]\" # Regular expression for GUID c structure format _GuidCFormatPattern = r \"{{\\s*0[xX]{Hex}{{1,8}}\\s*,\\s*0[xX]{Hex}{{1,4}}\\s*,\\s*0[xX]{Hex}{{1,4}}\" \\ r \"\\s*,\\s*{{\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*}}\\s*}}\" . format ( Hex = _HexChar ) GuidCFormatRegEx = re . compile ( r \"{}\" . format ( _GuidCFormatPattern )) _GuidPattern = r \"{Hex}{{8}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{12}}\" . format ( Hex = _HexChar ) # Regular expressions for GUID matching GuidRegFormatRegEx = re . compile ( r '{}' . format ( _GuidPattern )) @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring ) @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip () . strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring ) @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ): return '' guidValueString = guidstring . lower () . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . replace ( \" \" , \"\" ) . replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \" %08x - %04x - %04x - %02x%02x - %02x%02x%02x%02x%02x%02x \" % ( int ( guidValueList [ 0 ], 16 ), int ( guidValueList [ 1 ], 16 ), int ( guidValueList [ 2 ], 16 ), int ( guidValueList [ 3 ], 16 ), int ( guidValueList [ 4 ], 16 ), int ( guidValueList [ 5 ], 16 ), int ( guidValueList [ 6 ], 16 ), int ( guidValueList [ 7 ], 16 ), int ( guidValueList [ 8 ], 16 ), int ( guidValueList [ 9 ], 16 ), int ( guidValueList [ 10 ], 16 ) ) except : return '' @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip () . strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )): return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ): Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0 : 2 ] + ', 0x' + GuidList [ 3 ][ 2 : 4 ] for Index in range ( 0 , 12 , 2 ): Result = Result + ', 0x' + GuidList [ 4 ][ Index : Index + 2 ] Result += '}}' return Result @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )): return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )): guidstring = guidstring . strip () . strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg ) @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid )","title":"Module edk2toollib.uefi.edk2.parsers.guid_parser"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#guidparser","text":"class GuidParser ( / , * args , ** kwargs ) Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx View Source class GuidParser () : \"\"\" Provide support functions for converting between different guid formats. Also support str uuid and uuid to string. Common terms: C-Format: {0xD3B36F2C, 0xD551, 0x11D4, {0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D}} Reg-Format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx \"\"\" _HexChar = r \"[0-9a-fA-F]\" # Regular expression for GUID c structure format _GuidCFormatPattern = r \"{{\\s*0[xX]{Hex}{{1,8}}\\s*,\\s*0[xX]{Hex}{{1,4}}\\s*,\\s*0[xX]{Hex}{{1,4}}\" \\ r \"\\s*,\\s*{{\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\" \\ r \"\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*,\\s*0[xX]{Hex}{{1,2}}\\s*}}\\s*}}\" . format ( Hex = _HexChar ) GuidCFormatRegEx = re . compile ( r \"{}\" . format ( _GuidCFormatPattern )) _GuidPattern = r \"{Hex}{{8}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{4}}-{Hex}{{12}}\" . format ( Hex = _HexChar ) # Regular expressions for GUID matching GuidRegFormatRegEx = re . compile ( r '{}' . format ( _GuidPattern )) @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring ) @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring ) @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ) : return '' guidValueString = guidstring . lower (). replace ( \"{\" , \"\" ). replace ( \"}\" , \"\" ). replace ( \" \" , \"\" ). replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \"%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x\" % ( int ( guidValueList [ 0 ] , 16 ), int ( guidValueList [ 1 ] , 16 ), int ( guidValueList [ 2 ] , 16 ), int ( guidValueList [ 3 ] , 16 ), int ( guidValueList [ 4 ] , 16 ), int ( guidValueList [ 5 ] , 16 ), int ( guidValueList [ 6 ] , 16 ), int ( guidValueList [ 7 ] , 16 ), int ( guidValueList [ 8 ] , 16 ), int ( guidValueList [ 9 ] , 16 ), int ( guidValueList [ 10 ] , 16 ) ) except : return '' @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )) : return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ) : Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0:2 ] + ', 0x' + GuidList [ 3 ][ 2:4 ] for Index in range ( 0 , 12 , 2 ) : Result = Result + ', 0x' + GuidList [ 4 ][ Index:Index + 2 ] Result += '}}' return Result @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )) : return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )) : guidstring = guidstring . strip (). strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg ) @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid )","title":"GuidParser"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#class-variables","text":"GuidCFormatRegEx GuidRegFormatRegEx","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#c_guid_from_reg_format","text":"def c_guid_from_reg_format ( guidstring : str ) -> str Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string \u2018\u2019 View Source @classmethod def c_guid_from_reg_format ( cls , guidstring : str ) -> str : \"\"\"Convert registry format guidstring to c format guidstring Args: guidstring: str: registry format guidstring Returns: Success: guidstring in c format Failure: empty string '' \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) if ( not cls . is_guid_in_reg_format ( guidstring )) : return '' GuidList = guidstring . split ( '-' ) Result = '{' for Index in range ( 0 , 3 , 1 ) : Result = Result + '0x' + GuidList [ Index ] + ', ' Result = Result + '{0x' + GuidList [ 3 ][ 0:2 ] + ', 0x' + GuidList [ 3 ][ 2:4 ] for Index in range ( 0 , 12 , 2 ) : Result = Result + ', 0x' + GuidList [ 4 ][ Index:Index + 2 ] Result += '}}' return Result","title":"c_guid_from_reg_format"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#c_guid_str_from_uuid","text":"def c_guid_str_from_uuid ( guid : uuid . UUID ) -> str get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string \u2018\u2019 View Source @classmethod def c_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a C string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in C format Failure: empty string '' \"\"\" reg = str ( guid ) return cls . c_guid_from_reg_format ( reg )","title":"c_guid_str_from_uuid"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#is_guid_in_c_format","text":"def is_guid_in_c_format ( guidstring : str ) -> bool determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False View Source @classmethod def is_guid_in_c_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in c format Args: guidstring: str: string containing guid Returns: True if in C format. Otherwise False \"\"\" guidstring = guidstring . strip () return cls . GuidCFormatRegEx . match ( guidstring )","title":"is_guid_in_c_format"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#is_guid_in_reg_format","text":"def is_guid_in_reg_format ( guidstring : str ) -> bool determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False View Source @classmethod def is_guid_in_reg_format ( cls , guidstring : str ) -> bool : \"\"\" determine if guidstring is in registry format Args: guidstring: str: string containing guid Returns: True if in Registry format. Otherwise False \"\"\" guidstring = guidstring . strip (). strip ( '} {' ) return cls . GuidRegFormatRegEx . match ( guidstring )","title":"is_guid_in_reg_format"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#reg_guid_from_c_format","text":"def reg_guid_from_c_format ( guidstring : str ) -> str convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string \u2018\u2019 View Source @classmethod def reg_guid_from_c_format ( cls , guidstring : str ) -> str : \"\"\" convert a c formatted guidstring to a registry formatted guidstring Args: guidstring: str: c format guidstring Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" guidstring = guidstring . strip () if not cls . is_guid_in_c_format ( guidstring ) : return '' guidValueString = guidstring . lower (). replace ( \"{\" , \"\" ). replace ( \"}\" , \"\" ). replace ( \" \" , \"\" ). replace ( \";\" , \"\" ) guidValueList = guidValueString . split ( \",\" ) if len ( guidValueList ) != 11 : return '' try : return \"%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x\" % ( int ( guidValueList [ 0 ] , 16 ), int ( guidValueList [ 1 ] , 16 ), int ( guidValueList [ 2 ] , 16 ), int ( guidValueList [ 3 ] , 16 ), int ( guidValueList [ 4 ] , 16 ), int ( guidValueList [ 5 ] , 16 ), int ( guidValueList [ 6 ] , 16 ), int ( guidValueList [ 7 ] , 16 ), int ( guidValueList [ 8 ] , 16 ), int ( guidValueList [ 9 ] , 16 ), int ( guidValueList [ 10 ] , 16 ) ) except : return ''","title":"reg_guid_from_c_format"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#reg_guid_str_from_uuid","text":"def reg_guid_str_from_uuid ( guid : uuid . UUID ) -> str get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string \u2018\u2019 View Source @classmethod def reg_guid_str_from_uuid ( cls , guid : uuid . UUID ) -> str : \"\"\" get a registry string formatted guidstring from a uuid object Args: guid: uuid.UUID: valid uuid object Returns: Success: guidstring in registry format Failure: empty string '' \"\"\" return str ( guid )","title":"reg_guid_str_from_uuid"},{"location":"edk2toollib/uefi/edk2/parsers/guid_parser/#uuid_from_guidstring","text":"def uuid_from_guidstring ( guidstring : str ) -> uuid . UUID create a uuid object from the supplied guidstring View Source @classmethod def uuid_from_guidstring ( cls , guidstring : str ) -> uuid . UUID : \"\"\" create a uuid object from the supplied guidstring\"\"\" if ( cls . is_guid_in_c_format ( guidstring )) : return uuid . UUID ( cls . reg_guid_from_c_format ( guidstring )) elif ( cls . is_guid_in_reg_format ( guidstring )) : guidstring = guidstring . strip (). strip ( '} {' ) return uuid . UUID ( guidstring ) else : return None","title":"uuid_from_guidstring"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/","text":"Module edk2toollib.uefi.edk2.parsers.inf_parser View Source # @file inf_parser.py # Code to help parse EDK2 INF files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os AllPhases = [ \"SEC\" , \"PEIM\" , \"PEI_CORE\" , \"DXE_DRIVER\" , \"DXE_CORE\" , \"DXE_RUNTIME_DRIVER\" , \"UEFI_DRIVER\" , \"SMM_CORE\" , \"DXE_SMM_DRIVER\" , \"UEFI_APPLICATION\" ] class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ] . strip () . lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ] . partition ( \"|\" )[ 0 ] . strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . split () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[packages' ): InPackagesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPpiSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[pcd' ) or \\ sline . strip () . lower () . startswith ( '[patchpcd' ) or \\ sline . strip () . lower () . startswith ( '[fixedpcd' ) or \\ sline . strip () . lower () . startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[sources' ): InSourcesSection = True elif sline . strip () . lower () . startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True Variables AllPhases Classes InfParser class InfParser ( ) View Source class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else: self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection: if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else: self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection: if sline . strip ()[ 0 ] == '[' : InPpiSection = False else: self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection: if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else: self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection: if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else: self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Inf parser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#module-edk2toollibuefiedk2parsersinf_parser","text":"View Source # @file inf_parser.py # Code to help parse EDK2 INF files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os AllPhases = [ \"SEC\" , \"PEIM\" , \"PEI_CORE\" , \"DXE_DRIVER\" , \"DXE_CORE\" , \"DXE_RUNTIME_DRIVER\" , \"UEFI_DRIVER\" , \"SMM_CORE\" , \"DXE_SMM_DRIVER\" , \"UEFI_APPLICATION\" ] class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ] . strip () . lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ] . partition ( \"|\" )[ 0 ] . strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . split () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[packages' ): InPackagesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPpiSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[pcd' ) or \\ sline . strip () . lower () . startswith ( '[patchpcd' ) or \\ sline . strip () . lower () . startswith ( '[fixedpcd' ) or \\ sline . strip () . lower () . startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[sources' ): InSourcesSection = True elif sline . strip () . lower () . startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.inf_parser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#variables","text":"AllPhases","title":"Variables"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#infparser","text":"class InfParser ( ) View Source class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else: self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection: if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else: self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection: if sline . strip ()[ 0 ] == '[' : InPpiSection = False else: self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection: if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else: self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection: if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else: self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"InfParser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/","text":"Module edk2toollib.uefi.edk2.parsers.override_parser View Source ## @file override_parser.py # Contains classes to help with the parsing of INF files that # may contain OVERRIDE information. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import datetime FORMAT_VERSION_1 = ( 1 , 4 ) # Version 1: #OVERRIDE : VERSION | PATH_TO_MODULE | HASH | YYYY-MM-DDThh-mm-ss class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type ' %s '\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) class OverrideParser ( object ): \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ): super ( OverrideParser , self ) . __init__ () # Make sure that at least some data is provided. if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided. if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. ( %s , %s )\" % ( file_path , inf_contents )) # If a file path was provided, make sure it exists. if file_path is not None : if not os . path . isfile ( file_path ): raise ValueError ( \"File path ' %s ' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing. parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file ' %s '.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found, we're basically done here. if not self . override_lines : raise ValueError ( \"File ' %s ' did not contain any override lines.\" % self . file_path ) self . overrides = [] for override_line in self . override_lines : try : self . overrides . append ( self . parse_override_line ( override_line [ 'line' ])) except OpParseError as pe : raise ValueError ( \"Parse error ' %s ' occurred while processing line %d of ' %s '.\" % ( pe , override_line [ 'lineno' ], override_line [ 'line' ])) @staticmethod def get_override_lines ( parse_contents ): parse_lines = parse_contents . split ( ' \\n ' ) result = [] for i in range ( 0 , len ( parse_lines )): if parse_lines [ i ] . strip () . upper () . startswith ( \"#OVERRIDE\" ): result . append ({ 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip ()}) return result @staticmethod def parse_override_line ( line_contents ): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents . split ( \":\" ) line_parts = [ part . strip () for part in line_parts [ 1 ] . split ( \"|\" )] # Step 1: Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ]) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ]) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ])): raise OpParseError ( OpParseError . PE_VER ) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ]) # Step 3: Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4: Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ], \"%Y-%m- %d T%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result Variables FORMAT_VERSION_1 Classes OpParseError class OpParseError ( my_type ) Common base class for all non-exit exceptions. View Source class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type '%s'\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) Ancestors (in MRO) builtins.Exception builtins.BaseException Class variables PE_DATE PE_HASH PE_PATH PE_VER args Methods with_traceback def with_traceback ( ... ) Exception.with_traceback(tb) \u2013 set self. traceback to tb and return self. OverrideParser class OverrideParser ( file_path = None , inf_contents = None ) OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn\u2019t exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. View Source class OverrideParser ( object ) : \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ) : super ( OverrideParser , self ). __init__ () # Make sure that at least some data is provided . if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided . if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. (%s, %s)\" % ( file_path , inf_contents )) # If a file path was provided , make sure it exists . if file_path is not None : if not os . path . isfile ( file_path ) : raise ValueError ( \"File path '%s' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing . parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file '%s'.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found , we 're basically done here. if not self.override_lines: raise ValueError(\"File ' % s ' did not contain any override lines.\" % self.file_path) self.overrides = [] for override_line in self.override_lines: try: self.overrides.append(self.parse_override_line(override_line[' line '])) except OpParseError as pe: raise ValueError(\"Parse error ' % s ' occurred while processing line %d of ' % s '.\" % (pe, override_line[' lineno '], override_line[' line '])) @staticmethod def get_override_lines(parse_contents): parse_lines = parse_contents.split(' \\ n ') result = [] for i in range(0, len(parse_lines)): if parse_lines[i].strip().upper().startswith(\"#OVERRIDE\"): result.append({' lineno ': i + 1, ' line ': parse_lines[i].strip()}) return result @staticmethod def parse_override_line(line_contents): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents.split(\":\") line_parts = [part.strip() for part in line_parts[1].split(\"|\")] # Step 1: Check version and number of blocks in this entry try: result[' version '] = int(line_parts[0]) except ValueError: raise OpParseError(OpParseError.PE_VER) # Verify this is a known version and has valid number of entries if not ((result[' version '] == FORMAT_VERSION_1[0]) and (len(line_parts) == FORMAT_VERSION_1[1])): raise OpParseError(OpParseError.PE_VER) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result[' original_path '] = os.path.normpath(line_parts[1]) # Step 3: Grep hash entry result[' current_hash '] = line_parts[2] # Step 4: Parse the time of hash generation try: result[' datetime '] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result Static methods get_override_lines def get_override_lines ( parse_contents ) View Source @staticmethod def get_override_lines ( parse_contents ) : parse_lines = parse_contents . split ( '\\n' ) result = [] for i in range ( 0 , len ( parse_lines )) : if parse_lines [ i ] . strip (). upper (). startswith ( \"#OVERRIDE\" ) : result . append ( { 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip () } ) return result parse_override_line def parse_override_line ( line_contents ) View Source @staticmethod def parse_override_line ( line_contents ) : result = {} # Split the override string into pieces . # First the #OVERRIDE , which is separated by a : . # Then everything else by | . line_parts = line_contents . split ( \":\" ) line_parts = [ part.strip() for part in line_parts[1 ] . split ( \"|\" ) ] # Step 1 : Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ] ) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ] ) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ] )) : raise OpParseError ( OpParseError . PE_VER ) # Step 2 : Process the path to overridden module # Normalize the path to support different slashes . result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ] ) # Step 3 : Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4 : Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"Override parser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#module-edk2toollibuefiedk2parsersoverride_parser","text":"View Source ## @file override_parser.py # Contains classes to help with the parsing of INF files that # may contain OVERRIDE information. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import datetime FORMAT_VERSION_1 = ( 1 , 4 ) # Version 1: #OVERRIDE : VERSION | PATH_TO_MODULE | HASH | YYYY-MM-DDThh-mm-ss class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type ' %s '\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) class OverrideParser ( object ): \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ): super ( OverrideParser , self ) . __init__ () # Make sure that at least some data is provided. if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided. if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. ( %s , %s )\" % ( file_path , inf_contents )) # If a file path was provided, make sure it exists. if file_path is not None : if not os . path . isfile ( file_path ): raise ValueError ( \"File path ' %s ' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing. parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file ' %s '.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found, we're basically done here. if not self . override_lines : raise ValueError ( \"File ' %s ' did not contain any override lines.\" % self . file_path ) self . overrides = [] for override_line in self . override_lines : try : self . overrides . append ( self . parse_override_line ( override_line [ 'line' ])) except OpParseError as pe : raise ValueError ( \"Parse error ' %s ' occurred while processing line %d of ' %s '.\" % ( pe , override_line [ 'lineno' ], override_line [ 'line' ])) @staticmethod def get_override_lines ( parse_contents ): parse_lines = parse_contents . split ( ' \\n ' ) result = [] for i in range ( 0 , len ( parse_lines )): if parse_lines [ i ] . strip () . upper () . startswith ( \"#OVERRIDE\" ): result . append ({ 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip ()}) return result @staticmethod def parse_override_line ( line_contents ): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents . split ( \":\" ) line_parts = [ part . strip () for part in line_parts [ 1 ] . split ( \"|\" )] # Step 1: Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ]) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ]) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ])): raise OpParseError ( OpParseError . PE_VER ) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ]) # Step 3: Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4: Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ], \"%Y-%m- %d T%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"Module edk2toollib.uefi.edk2.parsers.override_parser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#variables","text":"FORMAT_VERSION_1","title":"Variables"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#opparseerror","text":"class OpParseError ( my_type ) Common base class for all non-exit exceptions. View Source class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type '%s'\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type )","title":"OpParseError"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#ancestors-in-mro","text":"builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#class-variables","text":"PE_DATE PE_HASH PE_PATH PE_VER args","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#with_traceback","text":"def with_traceback ( ... ) Exception.with_traceback(tb) \u2013 set self. traceback to tb and return self.","title":"with_traceback"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#overrideparser","text":"class OverrideParser ( file_path = None , inf_contents = None ) OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn\u2019t exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. View Source class OverrideParser ( object ) : \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ) : super ( OverrideParser , self ). __init__ () # Make sure that at least some data is provided . if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided . if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. (%s, %s)\" % ( file_path , inf_contents )) # If a file path was provided , make sure it exists . if file_path is not None : if not os . path . isfile ( file_path ) : raise ValueError ( \"File path '%s' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing . parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file '%s'.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found , we 're basically done here. if not self.override_lines: raise ValueError(\"File ' % s ' did not contain any override lines.\" % self.file_path) self.overrides = [] for override_line in self.override_lines: try: self.overrides.append(self.parse_override_line(override_line[' line '])) except OpParseError as pe: raise ValueError(\"Parse error ' % s ' occurred while processing line %d of ' % s '.\" % (pe, override_line[' lineno '], override_line[' line '])) @staticmethod def get_override_lines(parse_contents): parse_lines = parse_contents.split(' \\ n ') result = [] for i in range(0, len(parse_lines)): if parse_lines[i].strip().upper().startswith(\"#OVERRIDE\"): result.append({' lineno ': i + 1, ' line ': parse_lines[i].strip()}) return result @staticmethod def parse_override_line(line_contents): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents.split(\":\") line_parts = [part.strip() for part in line_parts[1].split(\"|\")] # Step 1: Check version and number of blocks in this entry try: result[' version '] = int(line_parts[0]) except ValueError: raise OpParseError(OpParseError.PE_VER) # Verify this is a known version and has valid number of entries if not ((result[' version '] == FORMAT_VERSION_1[0]) and (len(line_parts) == FORMAT_VERSION_1[1])): raise OpParseError(OpParseError.PE_VER) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result[' original_path '] = os.path.normpath(line_parts[1]) # Step 3: Grep hash entry result[' current_hash '] = line_parts[2] # Step 4: Parse the time of hash generation try: result[' datetime '] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"OverrideParser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#get_override_lines","text":"def get_override_lines ( parse_contents ) View Source @staticmethod def get_override_lines ( parse_contents ) : parse_lines = parse_contents . split ( '\\n' ) result = [] for i in range ( 0 , len ( parse_lines )) : if parse_lines [ i ] . strip (). upper (). startswith ( \"#OVERRIDE\" ) : result . append ( { 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip () } ) return result","title":"get_override_lines"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#parse_override_line","text":"def parse_override_line ( line_contents ) View Source @staticmethod def parse_override_line ( line_contents ) : result = {} # Split the override string into pieces . # First the #OVERRIDE , which is separated by a : . # Then everything else by | . line_parts = line_contents . split ( \":\" ) line_parts = [ part.strip() for part in line_parts[1 ] . split ( \"|\" ) ] # Step 1 : Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ] ) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ] ) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ] )) : raise OpParseError ( OpParseError . PE_VER ) # Step 2 : Process the path to overridden module # Normalize the path to support different slashes . result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ] ) # Step 3 : Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4 : Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"parse_override_line"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/","text":"Module edk2toollib.uefi.edk2.parsers.targettxt_parser View Source # @file targettxt_parser.py # Code to help parse Edk2 Conf/Target.txt file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue self . Parsed = True Classes TargetTxtParser class TargetTxtParser ( ) View Source class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Class variables operators Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" ) ConvertToInt def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 ) EvaluateConditional def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final ) FindPath def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True ParseGuid def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper () ParseNewSection def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self StripComment def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Targettxt parser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#module-edk2toollibuefiedk2parserstargettxt_parser","text":"View Source # @file targettxt_parser.py # Code to help parse Edk2 Conf/Target.txt file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.targettxt_parser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#targettxtparser","text":"class TargetTxtParser ( ) View Source class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True","title":"TargetTxtParser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#class-variables","text":"operators","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) Args: value: cond: value2: Returns: View Source def ComputeResult ( self , value , cond , value2 ): \"\"\" Args: value: cond: value2: Returns: \"\"\" ivalue = value ivalue2 = value2 if isinstance ( value , str ): ivalue = value . strip ( \"\\\"\") if isinstance(value2, str): ivalue2 = value2.strip(\" \\ \"\" ) # convert it to interpretted value if ( cond . upper () == \"IN\" ): # strip quotes self . Logger . debug ( f \"{ivalue} in {ivalue2}\" ) return ivalue in ivalue2 try : ivalue = self . ConvertToInt ( ivalue ) except ValueError : pass try : if ( cond . lower () == \"in\" ): ivalue2 = set ( ivalue2 . split ()) else : ivalue2 = self . ConvertToInt ( ivalue2 ) except ValueError : pass # First check our boolean operators if ( cond . upper () == \"OR\" ): return ivalue or ivalue2 if ( cond . upper () == \"AND\" ): return ivalue and ivalue2 # check our truthyness if ( cond == \"==\" ): # equal return ( ivalue == ivalue2 ) or ( value == value2 ) elif ( cond == \"!=\" ): # not equal return ( ivalue != ivalue2 ) and ( value != value2 ) # check to make sure we only have digits from here on out if not isinstance ( value , int ) and not str . isdigit ( value ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value} {ivalue.__class__}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond}{value2}\" ) raise ValueError ( \"Unknown value\" ) if not isinstance ( value2 , int ) and not str . isdigit ( value2 ): self . Logger . error ( f \"{self.__class__}: Unknown value: {value2} {ivalue2}\" ) self . Logger . debug ( f \"{self.__class__}: Conditional: {value} {cond} {value2}\" ) raise ValueError ( \"Unknown value\" ) if ( cond == \"<\" ): return ( ivalue < ivalue2 ) elif ( cond == \"<=\" ): return ( ivalue <= ivalue2 ) elif ( cond == \">\" ): return ( ivalue > ivalue2 ) elif ( cond == \">=\" ): return ( ivalue >= ivalue2 ) else : self . Logger . error ( f \"{self.__class__}: Unknown conditional: {cond}\" ) raise RuntimeError ( \"Unknown conditional\" )","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#converttoint","text":"def ConvertToInt ( self , value ) Args: value: must be str or int Returns: View Source def ConvertToInt ( self , value ): \"\"\" Args: value: must be str or int Returns: \"\"\" if isinstance ( value , int ): return value if isinstance ( value , str ) and value . upper () == \"TRUE\" : return 1 elif isinstance ( value , str ) and value . upper () == \"FALSE\" : return 0 elif isinstance ( value , str ) and value . upper (). startswith ( \"0X\" ): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#evaluateconditional","text":"def EvaluateConditional ( self , text ) Uses a pushdown resolver View Source def EvaluateConditional ( self , text ) : ''' Uses a pushdown resolver ''' text = str ( text ). strip () if not text . lower (). startswith ( \"!if \" ) : raise RuntimeError ( f \"Invalid conditional cannot be validated: {text}\" ) text = text [ 3: ] . strip () logging . debug ( f \"STAGE 1: {text}\" ) text = self . ReplaceVariables ( text ) logging . debug ( f \"STAGE 2: {text}\" ) tokens = self . _TokenizeConditional ( text ) logging . debug ( f \"STAGE 3: {tokens}\" ) expression = self . _ConvertTokensToPostFix ( tokens ) logging . debug ( f \"STAGE 4: {expression}\" ) # Now we evaluate the post fix expression if len ( expression ) == 0 : raise RuntimeError ( f \"Malformed !if conditional expression {text} {expression}\" ) while len ( expression ) != 1 : first_operand_index = - 1 # find the first operator for index , item in enumerate ( expression ) : if self . _IsOperator ( item ) : first_operand_index = index break if first_operand_index == - 1 : raise RuntimeError ( f \"We didn't find an operator to execute in {expression}: {text}\" ) operand = expression [ first_operand_index ] if operand == \"NOT\" : # Special logic for handling the not if first_operand_index < 1 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) # grab the operand right before the NOT and invert it operator1_raw = expression [ first_operand_index - 1 ] operator1 = self . ConvertToInt ( operator1_raw ) result = not operator1 # grab what was before the operator and the operand , then squish it all together new_expression = expression [ :first_operand_index - 1 ] if first_operand_index > 1 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression else : if first_operand_index < 2 : raise RuntimeError ( f \"We have a stray operand {operand}\" ) operator1 = expression [ first_operand_index - 2 ] operator2 = expression [ first_operand_index - 1 ] do_invert = False # check if we have a special operator that has a combined not on it if str ( operand ). startswith ( \"!+\" ) : operand = operand [ 2: ] do_invert = True # compute the result now that we have the three things we need result = self . ComputeResult ( operator1 , operand , operator2 ) if do_invert : result = not result # grab what was before the operator and the operand , then smoosh it all together new_expression = expression [ :first_operand_index - 2 ] if first_operand_index > 2 else [] new_expression += [ result, ] + expression [ first_operand_index + 1: ] expression = new_expression final = self . ConvertToInt ( expression [ 0 ] ) logging . debug ( f \" FINAL {expression} {final}\" ) return bool ( final )","title":"EvaluateConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#findpath","text":"def FindPath ( self , * p ) Args: *p: Returns: View Source def FindPath ( self , * p ): \"\"\" Args: *p: Returns: \"\"\" # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): \"\"\" \"\"\" ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#isguidstring","text":"def IsGuidString ( self , l ) will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: View Source def IsGuidString ( self , l ): \"\"\" will return true if the the line has = { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Args: l: Returns: \"\"\" if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parseguid","text":"def ParseGuid ( self , l ) parse a guid into a different format Will throw exception if missing any of the 11 parts of isn\u2019t long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D View Source def ParseGuid ( self , l ): \"\"\" parse a guid into a different format Will throw exception if missing any of the 11 parts of isn't long enough Args: l: the guid to parse ex: { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} Returns: a string of the guid. ex: D3B36F2C-D551-11D4-9A46-0090273FC14D \"\"\" entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) if len ( entries ) != 11 : raise RuntimeError ( f \"Invalid GUID found {l}. We are missing some parts since we only found: {len(entries)}\" ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut proper_guid_length = 36 if len ( gu ) > proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too long: {gu}\" ) if len ( gu ) < proper_guid_length : raise RuntimeError ( f \"The guid we parsed was too short: {gu}\" ) return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) Args: l: Returns: View Source def ParseNewSection ( self , l ): \"\"\" Args: l: Returns: \"\"\" if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): \"\"\" \"\"\" if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#processconditional","text":"def ProcessConditional ( self , text ) Args: text: Returns: View Source def ProcessConditional ( self , text ): \"\"\" Args: text: Returns: \"\"\" if '\"' in text : tokens = text . split ( '\"' ) tokens = tokens [ 0 ]. split () + [ tokens [ 1 ]] + tokens [ 2 ]. split () else : tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): self . PushConditional ( self . EvaluateConditional ( text )) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] != self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): if len ( tokens ) != 2 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PushConditional (( tokens [ 1 ] == self . _MacroNotDefinedValue )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) v = self . PopConditional () # TODO make sure we can ' t do multiple else statements self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): if len ( tokens ) != 1 : self . Logger . error ( \"!ifdef conditionals need to be formatted correctly (spaces between each token)\" ) raise RuntimeError ( \"Invalid conditional\" , text ) self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#pushconditional","text":"def PushConditional ( self , v ) Args: v: Returns: View Source def PushConditional ( self , v ): \"\"\" Args: v: Returns: \"\"\" self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) Args: line: Returns: View Source def ReplaceVariables ( self , line ): \"\"\" Args: line: Returns: \"\"\" # first tokenize and look for tokens require special macro # handling without $ . This must be done first otherwise # both syntax options can not be supported . result = line tokens = result . split () replace = len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" , \"!if\" , \"!elseif\" ] if len ( tokens ) > 1 and tokens [ 0 ]. lower () in [ \"!ifdef\" , \"!ifndef\" ]: if not tokens [ 1 ]. startswith ( \"$(\" ): v = self . _FindReplacementForToken ( tokens [ 1 ], replace ) if v is not None : result = result . replace ( tokens [ 1 ], v , 1 ) # use line to avoid change by handling above rep = line . count ( \"$\" ) index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] replacement_token = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . _FindReplacementForToken ( token , replace ) if v is not None : result = result . replace ( replacement_token , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): \"\"\" \"\"\" self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) Args: path: Returns: View Source def SetBaseAbsPath ( self , path ): \"\"\" Args: path: Returns: \"\"\" self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) Args: inputdict: Returns: View Source def SetInputVars ( self , inputdict ): \"\"\" Args: inputdict: Returns: \"\"\" self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) Args: pps: (Default value = []) Returns: View Source def SetPackagePaths ( self , pps = []): \"\"\" Args: pps: (Default value = []) Returns: \"\"\" self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#stripcomment","text":"def StripComment ( self , l ) Args: l: Returns: View Source def StripComment ( self , l ): \"\"\" Args: l: Returns: \"\"\" return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) Args: filepath: Returns: View Source def WriteLinesToFile ( self , filepath ): \"\"\" Args: filepath: Returns: \"\"\" self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/windows/","text":"Module edk2toollib.windows View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.windows.capsule edk2toollib.windows.locate_tools edk2toollib.windows.locate_tools_test edk2toollib.windows.policy","title":"Index"},{"location":"edk2toollib/windows/#module-edk2toollibwindows","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.windows"},{"location":"edk2toollib/windows/#sub-modules","text":"edk2toollib.windows.capsule edk2toollib.windows.locate_tools edk2toollib.windows.locate_tools_test edk2toollib.windows.policy","title":"Sub-modules"},{"location":"edk2toollib/windows/locate_tools/","text":"Module edk2toollib.windows.locate_tools View Source # @file locate_tools . py # This module provides python services that locate common development tools using vswhere . exe , # vsvars . bat , and other Windows based tools . This works best on systems running Windows # and with dev tools installed but will attempt to use known paths for WinSDK if the dev # tools are not available . This is only a best effort to locate the SDK tools in well # known / default install locations . # # Suggested Dev Tools : # Current Windows SDKs # Visual Studio 2017 Build Tools or newer # # Note : When this module is used in local develop mode it will download vswhere . exe from the github . # It will confirm the hash is a known good value . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import pkg_resources import os import logging import glob import subprocess from edk2toollib . utility_functions import RunCmd from edk2toollib . utility_functions import GetHostInfo import re try : from StringIO import StringIO except ImportError : from io import StringIO import urllib . error import urllib . request # Update this when you want a new version of VsWhere __ VERSION = \"2.6.7\" __ URL = \"https://github.com/microsoft/vswhere/releases/download/{}/vswhere.exe\" . format ( __ VERSION ) __ SHA256 = \"10abd21aeb5003d87c01f033fd7c170360e362be397f23b0b730324abbd92612\" # # Supported Versions that can be queried with vswhere # Use lower case for key as all comparisons will be lower case # supported_vs_versions = { \"vs2017\" : \"15.0,16.0\" , \"vs2019\" : \"16.0,17.0\" } # Downloads VSWhere def _ DownloadVsWhere ( unpack_folder: os . PathLike = None ) : if unpack_folder is None : unpack_folder = os . path . dirname ( __ VsWherePath ()) out_file_name = os . path . join ( unpack_folder , \"vswhere.exe\" ) logging . info ( \"Attempting to download vswhere to: {}. This may take a second.\" . format ( unpack_folder )) # check if we have the vswhere file already downloaded if not os . path . isfile ( out_file_name ) : try : # Download the file and save it locally under ` temp_file_name ` with urllib . request . urlopen ( __ URL ) as response , open ( out_file_name , 'wb' ) as out_file: out_file . write ( response . read ()) except urllib . error . HTTPError as e : logging . error ( f \"We ran into an issue when getting VsWhere\" ) raise e # do the hash to make sure the file is good with open ( out_file_name , \"rb\" ) as file : import hashlib temp_file_sha256 = hashlib . sha256 ( file . read ()). hexdigest () if temp_file_sha256 ! = __ SHA256 : # delete the file since it's not what we're expecting os . remove ( out_file_name ) raise RuntimeError ( f \"VsWhere - sha256 does not match\\n\\tdownloaded:\\t{temp_file_sha256}\\n\\t\" ) def __ VsWherePath () : file = \"vswhere.exe\" requirement = pkg_resources . Requirement . parse ( \"edk2-pytool-library\" ) file_path = os . path . join ( \"edk2toollib\" , \"bin\" , file ) vswhere_path = pkg_resources . resource_filename ( requirement , file_path ) return vswhere_path #### # # https : // docs . microsoft . com / en - us / vswhere / install - vswhere - client - tools # # @return string \"/PATH/TO/vswhere.exe\" or None #### def GetVsWherePath ( fail_on_not_found: bool = True ) : vswhere_path = __ VsWherePath () # check if we can't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can't find it , download it if not os . path . isfile ( vswhere_path ) : vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _ DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren't able to find vswhere ! \") return None return vswhere_path #### # Finds a product with VS Where # # product: is defined by vswhere tool # vs_version: helper to find version of supported VS version (example vs2019). #### def FindWithVsWhere(products: str = \" * \", vs_version: str = None): cmd = \" - latest - nologo - all - property installationPath \" vs_where_path = GetVsWherePath() if vs_where_path is None: logging.warning(\" We weren't able to find VSWhere\") return (1, None) if(products is not None): cmd += \" -products \" + products if(vs_version is not None): vs_version = vs_version.lower() if vs_version in supported_vs_versions.keys(): cmd += \" -version \" + supported_vs_versions[vs_version] else: logging.warning(\"Invalid or unsupported vs_version \" + vs_version) return (2, None) a = StringIO() ret = RunCmd(vs_where_path, cmd, outstream=a) if(ret != 0): a.close() return (ret, None) p1 = a.getvalue().strip() a.close() if(len(p1.strip()) > 0): return (0, p1) return (ret, None) # Run visual studio batch file and collect the # interesting environment values # # Inspiration taken from cpython for this method of env collection # # keys: enumerable list with names of env variables to collect after bat run # arch: arch to run. amd64, x86, ?? # product: value defined by vswhere.exe # vs_version: helper to find version of supported VS version (example vs2019). # returns a dictionary of the interesting environment variables def QueryVcVariables(keys: list, arch: str = None, product: str = None, vs_version: str = None): \"\"\"Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys\"\"\" if product is None: product = \"*\" if arch is None: # TODO: look up host architecture? arch = \"amd64\" interesting = set(x.upper() for x in keys) result = {} ret, vs_path = FindWithVsWhere(product, vs_version) if ret != 0 or vs_path is None: logging.warning(\"We didn't find VS path or otherwise failed to invoke vsWhere \") raise ValueError(\" Bad VC \") vcvarsall_path = os.path.join(vs_path, \" VC \", \" Auxiliary \", \" Build \", \" vcvarsall . bat \") logging.debug(\" Calling '%s %s' \", vcvarsall_path, arch) popen = subprocess.Popen('\" %s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key . upper () in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) result_set = set ( list ( result . keys ())) difference = list ( interesting . difference ( result_set )) logging . error ( \"We were not able to find on the keys requested from vcvarsall.\" ) logging . error ( \"We didn't find: %s\" % str(difference)) raise ValueError ( \"Missing keys when querying vcvarsall: \" + str ( difference )) return result # return 1 if a > b # return 0 if b == a # return - 1 if a < b def _ CompareWindowVersions ( a , b ) : a_periods = str ( a ). count ( \".\" ) b_periods = str ( b ). count ( \".\" ) if a_periods == 3 and b_periods ! = 3 : return 1 if b_periods == 3 and a_periods ! = 3 : return - 1 if a_periods ! = 3 and b_periods ! = 3 : return 0 a_parts = str ( a ). split ( \".\" ) b_parts = str ( b ). split ( \".\" ) for i in range ( 3 ) : a_p = int ( a_parts [ i ]) b_p = int ( b_parts [ i ]) if a_p > b_p: return 1 if a_p < b_p: return - 1 return 0 def _ CheckArchOfMatch ( match ) : ''' Returns if this binary matches our host returns true or false if no arch is in the match, then we return true ''' match = str ( match ). lower () isx86 = \"x86\" in match isx64 = \"x64\" in match or \"amd64\" in match isArm64 = \"aarch\" in match or \"aarch64\" in match or \"arm64\" in match isi386 = \"i386\" in match isArm = not isArm64 and ( \"arm\" in match ) count = 0 count += 1 if isx64 else 0 count += 1 if isx86 else 0 count += 1 if isArm else 0 count += 1 if isArm64 else 0 count += 1 if isi386 else 0 if count == 0 : # we don't know what arch this is? return True if count > 1: # there are more than one arch for this binary logging.warning(\"We found more than one architecture for {}. Results maybe inconsistent\".format(match)) return True _, arch, bits = GetHostInfo() bits = int(bits) if isx86 and (bits < 32 or arch != \"x86\"): return False if isx64 and (bits < 64 or arch != \"x86\"): return False if isi386: # TODO add i386 to GetHostInfo return False if isArm64 and (bits < 64 or arch != \"ARM\"): return False if isArm and (bits < 32 or arch != \"ARM\"): return False return True # does a glob in the folder that your sdk is # uses the environmental variable WindowsSdkDir and tries to use WindowsSDKVersion def FindToolInWinSdk(tool: str, product=None, arch=None): variables = [\"WindowsSdkDir\", \"WindowsSDKVersion\"] # get the value with QueryVcVariables try: results = QueryVcVariables(variables, product, arch) # Get the variables we care about sdk_dir = results[\"WindowsSdkDir\"] sdk_ver = results[\"WindowsSDKVersion\"] except ValueError: sdk_dir = os.path.join(os.getenv(\"ProgramFiles(x86)\"), \"Windows Kits\", \"10\", \"bin\") sdk_ver = \"0.0.0.0\" sdk_dir = os.path.realpath(sdk_dir) search_pattern = os.path.join(sdk_dir, \"**\", tool) match_offset = len(sdk_dir) # look for something like 10.0.12323.0123 windows_ver_regex = re.compile(r'\\d+\\.\\d+\\.\\d+\\.\\d+') top_version_so_far = -1 top_match = None # Look at in match in the tree for match in glob.iglob(search_pattern, recursive=True): match_file = match[match_offset:] # strip off the root match_front, match_end = os.path.split(match_file) # split off the filename versions = windows_ver_regex.findall(match_front) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch(match_front): # make sure it's a good arch for us continue if len ( versions ) == 0 : top_ver_match = \"0.0.0.0\" # if we have a bad version , we should fall to a bad version for version in versions : # find the highest version if there are multiple in this? is_current_sdk_version = _ CompareWindowVersions ( version , sdk_ver ) == 0 if _ CompareWindowVersions ( version , top_ver_match ) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _ CompareWindowVersions ( top_ver_match , sdk_ver ) == 0 if _ CompareWindowVersions ( top_ver_match , top_version_so_far ) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None : logging . critical ( \"We weren't able to find {}\" . format ( tool )) return top_match Variables supported_vs_versions Functions FindToolInWinSdk def FindToolInWinSdk ( tool : str , product = None , arch = None ) View Source def FindToolInWinSdk ( tool : str , product = None , arch = None ): variables = [ \"WindowsSdkDir\" , \"WindowsSDKVersion\" ] # get the value with QueryVcVariables try : results = QueryVcVariables ( variables , product , arch ) # Get the variables we care about sdk_dir = results [ \"WindowsSdkDir\" ] sdk_ver = results [ \"WindowsSDKVersion\" ] except ValueError : sdk_dir = os . path . join ( os . getenv ( \"ProgramFiles(x86)\" ), \"Windows Kits\" , \"10\" , \"bin\" ) sdk_ver = \"0.0.0.0\" sdk_dir = os . path . realpath ( sdk_dir ) search_pattern = os . path . join ( sdk_dir , \"**\" , tool ) match_offset = len ( sdk_dir ) # look for something like 10 . 0 . 12323 . 0123 windows_ver_regex = re . compile ( r '\\d+\\.\\d+\\.\\d+\\.\\d+' ) top_version_so_far = - 1 top_match = None # Look at in match in the tree for match in glob . iglob ( search_pattern , recursive = True ): match_file = match [ match_offset :] # strip off the root match_front , match_end = os . path . split ( match_file ) # split off the filename versions = windows_ver_regex . findall ( match_front ) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch ( match_front ): # make sure it 's a good arch for us continue if len(versions) == 0: top_ver_match = \"0.0.0.0\" # if we have a bad version, we should fall to a bad version for version in versions: # find the highest version if there are multiple in this? is_current_sdk_version = _CompareWindowVersions(version, sdk_ver) == 0 if _CompareWindowVersions(version, top_ver_match) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _CompareWindowVersions(top_ver_match, sdk_ver) == 0 if _CompareWindowVersions(top_ver_match, top_version_so_far) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None: logging.critical(\"We weren' t able to find {}\" . format ( tool )) return top_match FindWithVsWhere def FindWithVsWhere ( products : str = '*' , vs_version : str = None ) View Source def FindWithVsWhere ( products : str = \"*\" , vs_version : str = None ) : cmd = \"-latest -nologo -all -property installationPath\" vs_where_path = GetVsWherePath () if vs_where_path is None : logging . warning ( \"We weren't able to find VSWhere\" ) return ( 1 , None ) if ( products is not None ) : cmd += \" -products \" + products if ( vs_version is not None ) : vs_version = vs_version . lower () if vs_version in supported_vs_versions . keys () : cmd += \" -version \" + supported_vs_versions [ vs_version ] else : logging . warning ( \"Invalid or unsupported vs_version \" + vs_version ) return ( 2 , None ) a = StringIO () ret = RunCmd ( vs_where_path , cmd , outstream = a ) if ( ret != 0 ) : a . close () return ( ret , None ) p1 = a . getvalue (). strip () a . close () if ( len ( p1 . strip ()) > 0 ) : return ( 0 , p1 ) return ( ret , None ) GetVsWherePath def GetVsWherePath ( fail_on_not_found : bool = True ) View Source def GetVsWherePath ( fail_on_not_found : bool = True ): vswhere_path = __VsWherePath () # check if we can 't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can' t find it , download it if not os . path . isfile ( vswhere_path ): vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we 're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren' t able to find vswhere ! \" ) return None return vswhere_path QueryVcVariables def QueryVcVariables ( keys : list , arch : str = None , product : str = None , vs_version : str = None ) Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys View Source def QueryVcVariables ( keys : list , arch : str = None , product : str = None , vs_version: str = None ) : \"\"\"Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys\"\"\" if product is None : product = \"*\" if arch is None : # TODO : look up host architecture? arch = \"amd64\" interesting = set ( x . upper () for x in keys ) result = {} ret , vs_path = FindWithVsWhere ( product , vs_version ) if ret ! = 0 or vs_path is None : logging . warning ( \"We didn't find VS path or otherwise failed to invoke vsWhere\" ) raise ValueError ( \"Bad VC\" ) vcvarsall_path = os . path . join ( vs_path , \"VC\" , \"Auxiliary\" , \"Build\" , \"vcvarsall.bat\" ) logging . debug ( \"Calling '%s %s'\" , vcvarsall_path , arch ) popen = subprocess . Popen ( '\"%s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key . upper () in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) result_set = set ( list ( result . keys ())) difference = list ( interesting . difference ( result_set )) logging . error ( \"We were not able to find on the keys requested from vcvarsall.\" ) logging . error ( \"We didn't find: %s\" % str(difference)) raise ValueError ( \"Missing keys when querying vcvarsall: \" + str ( difference )) return result","title":"Locate tools"},{"location":"edk2toollib/windows/locate_tools/#module-edk2toollibwindowslocate_tools","text":"View Source # @file locate_tools . py # This module provides python services that locate common development tools using vswhere . exe , # vsvars . bat , and other Windows based tools . This works best on systems running Windows # and with dev tools installed but will attempt to use known paths for WinSDK if the dev # tools are not available . This is only a best effort to locate the SDK tools in well # known / default install locations . # # Suggested Dev Tools : # Current Windows SDKs # Visual Studio 2017 Build Tools or newer # # Note : When this module is used in local develop mode it will download vswhere . exe from the github . # It will confirm the hash is a known good value . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import pkg_resources import os import logging import glob import subprocess from edk2toollib . utility_functions import RunCmd from edk2toollib . utility_functions import GetHostInfo import re try : from StringIO import StringIO except ImportError : from io import StringIO import urllib . error import urllib . request # Update this when you want a new version of VsWhere __ VERSION = \"2.6.7\" __ URL = \"https://github.com/microsoft/vswhere/releases/download/{}/vswhere.exe\" . format ( __ VERSION ) __ SHA256 = \"10abd21aeb5003d87c01f033fd7c170360e362be397f23b0b730324abbd92612\" # # Supported Versions that can be queried with vswhere # Use lower case for key as all comparisons will be lower case # supported_vs_versions = { \"vs2017\" : \"15.0,16.0\" , \"vs2019\" : \"16.0,17.0\" } # Downloads VSWhere def _ DownloadVsWhere ( unpack_folder: os . PathLike = None ) : if unpack_folder is None : unpack_folder = os . path . dirname ( __ VsWherePath ()) out_file_name = os . path . join ( unpack_folder , \"vswhere.exe\" ) logging . info ( \"Attempting to download vswhere to: {}. This may take a second.\" . format ( unpack_folder )) # check if we have the vswhere file already downloaded if not os . path . isfile ( out_file_name ) : try : # Download the file and save it locally under ` temp_file_name ` with urllib . request . urlopen ( __ URL ) as response , open ( out_file_name , 'wb' ) as out_file: out_file . write ( response . read ()) except urllib . error . HTTPError as e : logging . error ( f \"We ran into an issue when getting VsWhere\" ) raise e # do the hash to make sure the file is good with open ( out_file_name , \"rb\" ) as file : import hashlib temp_file_sha256 = hashlib . sha256 ( file . read ()). hexdigest () if temp_file_sha256 ! = __ SHA256 : # delete the file since it's not what we're expecting os . remove ( out_file_name ) raise RuntimeError ( f \"VsWhere - sha256 does not match\\n\\tdownloaded:\\t{temp_file_sha256}\\n\\t\" ) def __ VsWherePath () : file = \"vswhere.exe\" requirement = pkg_resources . Requirement . parse ( \"edk2-pytool-library\" ) file_path = os . path . join ( \"edk2toollib\" , \"bin\" , file ) vswhere_path = pkg_resources . resource_filename ( requirement , file_path ) return vswhere_path #### # # https : // docs . microsoft . com / en - us / vswhere / install - vswhere - client - tools # # @return string \"/PATH/TO/vswhere.exe\" or None #### def GetVsWherePath ( fail_on_not_found: bool = True ) : vswhere_path = __ VsWherePath () # check if we can't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can't find it , download it if not os . path . isfile ( vswhere_path ) : vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _ DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren't able to find vswhere ! \") return None return vswhere_path #### # Finds a product with VS Where # # product: is defined by vswhere tool # vs_version: helper to find version of supported VS version (example vs2019). #### def FindWithVsWhere(products: str = \" * \", vs_version: str = None): cmd = \" - latest - nologo - all - property installationPath \" vs_where_path = GetVsWherePath() if vs_where_path is None: logging.warning(\" We weren't able to find VSWhere\") return (1, None) if(products is not None): cmd += \" -products \" + products if(vs_version is not None): vs_version = vs_version.lower() if vs_version in supported_vs_versions.keys(): cmd += \" -version \" + supported_vs_versions[vs_version] else: logging.warning(\"Invalid or unsupported vs_version \" + vs_version) return (2, None) a = StringIO() ret = RunCmd(vs_where_path, cmd, outstream=a) if(ret != 0): a.close() return (ret, None) p1 = a.getvalue().strip() a.close() if(len(p1.strip()) > 0): return (0, p1) return (ret, None) # Run visual studio batch file and collect the # interesting environment values # # Inspiration taken from cpython for this method of env collection # # keys: enumerable list with names of env variables to collect after bat run # arch: arch to run. amd64, x86, ?? # product: value defined by vswhere.exe # vs_version: helper to find version of supported VS version (example vs2019). # returns a dictionary of the interesting environment variables def QueryVcVariables(keys: list, arch: str = None, product: str = None, vs_version: str = None): \"\"\"Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys\"\"\" if product is None: product = \"*\" if arch is None: # TODO: look up host architecture? arch = \"amd64\" interesting = set(x.upper() for x in keys) result = {} ret, vs_path = FindWithVsWhere(product, vs_version) if ret != 0 or vs_path is None: logging.warning(\"We didn't find VS path or otherwise failed to invoke vsWhere \") raise ValueError(\" Bad VC \") vcvarsall_path = os.path.join(vs_path, \" VC \", \" Auxiliary \", \" Build \", \" vcvarsall . bat \") logging.debug(\" Calling '%s %s' \", vcvarsall_path, arch) popen = subprocess.Popen('\" %s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key . upper () in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) result_set = set ( list ( result . keys ())) difference = list ( interesting . difference ( result_set )) logging . error ( \"We were not able to find on the keys requested from vcvarsall.\" ) logging . error ( \"We didn't find: %s\" % str(difference)) raise ValueError ( \"Missing keys when querying vcvarsall: \" + str ( difference )) return result # return 1 if a > b # return 0 if b == a # return - 1 if a < b def _ CompareWindowVersions ( a , b ) : a_periods = str ( a ). count ( \".\" ) b_periods = str ( b ). count ( \".\" ) if a_periods == 3 and b_periods ! = 3 : return 1 if b_periods == 3 and a_periods ! = 3 : return - 1 if a_periods ! = 3 and b_periods ! = 3 : return 0 a_parts = str ( a ). split ( \".\" ) b_parts = str ( b ). split ( \".\" ) for i in range ( 3 ) : a_p = int ( a_parts [ i ]) b_p = int ( b_parts [ i ]) if a_p > b_p: return 1 if a_p < b_p: return - 1 return 0 def _ CheckArchOfMatch ( match ) : ''' Returns if this binary matches our host returns true or false if no arch is in the match, then we return true ''' match = str ( match ). lower () isx86 = \"x86\" in match isx64 = \"x64\" in match or \"amd64\" in match isArm64 = \"aarch\" in match or \"aarch64\" in match or \"arm64\" in match isi386 = \"i386\" in match isArm = not isArm64 and ( \"arm\" in match ) count = 0 count += 1 if isx64 else 0 count += 1 if isx86 else 0 count += 1 if isArm else 0 count += 1 if isArm64 else 0 count += 1 if isi386 else 0 if count == 0 : # we don't know what arch this is? return True if count > 1: # there are more than one arch for this binary logging.warning(\"We found more than one architecture for {}. Results maybe inconsistent\".format(match)) return True _, arch, bits = GetHostInfo() bits = int(bits) if isx86 and (bits < 32 or arch != \"x86\"): return False if isx64 and (bits < 64 or arch != \"x86\"): return False if isi386: # TODO add i386 to GetHostInfo return False if isArm64 and (bits < 64 or arch != \"ARM\"): return False if isArm and (bits < 32 or arch != \"ARM\"): return False return True # does a glob in the folder that your sdk is # uses the environmental variable WindowsSdkDir and tries to use WindowsSDKVersion def FindToolInWinSdk(tool: str, product=None, arch=None): variables = [\"WindowsSdkDir\", \"WindowsSDKVersion\"] # get the value with QueryVcVariables try: results = QueryVcVariables(variables, product, arch) # Get the variables we care about sdk_dir = results[\"WindowsSdkDir\"] sdk_ver = results[\"WindowsSDKVersion\"] except ValueError: sdk_dir = os.path.join(os.getenv(\"ProgramFiles(x86)\"), \"Windows Kits\", \"10\", \"bin\") sdk_ver = \"0.0.0.0\" sdk_dir = os.path.realpath(sdk_dir) search_pattern = os.path.join(sdk_dir, \"**\", tool) match_offset = len(sdk_dir) # look for something like 10.0.12323.0123 windows_ver_regex = re.compile(r'\\d+\\.\\d+\\.\\d+\\.\\d+') top_version_so_far = -1 top_match = None # Look at in match in the tree for match in glob.iglob(search_pattern, recursive=True): match_file = match[match_offset:] # strip off the root match_front, match_end = os.path.split(match_file) # split off the filename versions = windows_ver_regex.findall(match_front) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch(match_front): # make sure it's a good arch for us continue if len ( versions ) == 0 : top_ver_match = \"0.0.0.0\" # if we have a bad version , we should fall to a bad version for version in versions : # find the highest version if there are multiple in this? is_current_sdk_version = _ CompareWindowVersions ( version , sdk_ver ) == 0 if _ CompareWindowVersions ( version , top_ver_match ) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _ CompareWindowVersions ( top_ver_match , sdk_ver ) == 0 if _ CompareWindowVersions ( top_ver_match , top_version_so_far ) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None : logging . critical ( \"We weren't able to find {}\" . format ( tool )) return top_match","title":"Module edk2toollib.windows.locate_tools"},{"location":"edk2toollib/windows/locate_tools/#variables","text":"supported_vs_versions","title":"Variables"},{"location":"edk2toollib/windows/locate_tools/#functions","text":"","title":"Functions"},{"location":"edk2toollib/windows/locate_tools/#findtoolinwinsdk","text":"def FindToolInWinSdk ( tool : str , product = None , arch = None ) View Source def FindToolInWinSdk ( tool : str , product = None , arch = None ): variables = [ \"WindowsSdkDir\" , \"WindowsSDKVersion\" ] # get the value with QueryVcVariables try : results = QueryVcVariables ( variables , product , arch ) # Get the variables we care about sdk_dir = results [ \"WindowsSdkDir\" ] sdk_ver = results [ \"WindowsSDKVersion\" ] except ValueError : sdk_dir = os . path . join ( os . getenv ( \"ProgramFiles(x86)\" ), \"Windows Kits\" , \"10\" , \"bin\" ) sdk_ver = \"0.0.0.0\" sdk_dir = os . path . realpath ( sdk_dir ) search_pattern = os . path . join ( sdk_dir , \"**\" , tool ) match_offset = len ( sdk_dir ) # look for something like 10 . 0 . 12323 . 0123 windows_ver_regex = re . compile ( r '\\d+\\.\\d+\\.\\d+\\.\\d+' ) top_version_so_far = - 1 top_match = None # Look at in match in the tree for match in glob . iglob ( search_pattern , recursive = True ): match_file = match [ match_offset :] # strip off the root match_front , match_end = os . path . split ( match_file ) # split off the filename versions = windows_ver_regex . findall ( match_front ) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch ( match_front ): # make sure it 's a good arch for us continue if len(versions) == 0: top_ver_match = \"0.0.0.0\" # if we have a bad version, we should fall to a bad version for version in versions: # find the highest version if there are multiple in this? is_current_sdk_version = _CompareWindowVersions(version, sdk_ver) == 0 if _CompareWindowVersions(version, top_ver_match) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _CompareWindowVersions(top_ver_match, sdk_ver) == 0 if _CompareWindowVersions(top_ver_match, top_version_so_far) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None: logging.critical(\"We weren' t able to find {}\" . format ( tool )) return top_match","title":"FindToolInWinSdk"},{"location":"edk2toollib/windows/locate_tools/#findwithvswhere","text":"def FindWithVsWhere ( products : str = '*' , vs_version : str = None ) View Source def FindWithVsWhere ( products : str = \"*\" , vs_version : str = None ) : cmd = \"-latest -nologo -all -property installationPath\" vs_where_path = GetVsWherePath () if vs_where_path is None : logging . warning ( \"We weren't able to find VSWhere\" ) return ( 1 , None ) if ( products is not None ) : cmd += \" -products \" + products if ( vs_version is not None ) : vs_version = vs_version . lower () if vs_version in supported_vs_versions . keys () : cmd += \" -version \" + supported_vs_versions [ vs_version ] else : logging . warning ( \"Invalid or unsupported vs_version \" + vs_version ) return ( 2 , None ) a = StringIO () ret = RunCmd ( vs_where_path , cmd , outstream = a ) if ( ret != 0 ) : a . close () return ( ret , None ) p1 = a . getvalue (). strip () a . close () if ( len ( p1 . strip ()) > 0 ) : return ( 0 , p1 ) return ( ret , None )","title":"FindWithVsWhere"},{"location":"edk2toollib/windows/locate_tools/#getvswherepath","text":"def GetVsWherePath ( fail_on_not_found : bool = True ) View Source def GetVsWherePath ( fail_on_not_found : bool = True ): vswhere_path = __VsWherePath () # check if we can 't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can' t find it , download it if not os . path . isfile ( vswhere_path ): vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we 're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren' t able to find vswhere ! \" ) return None return vswhere_path","title":"GetVsWherePath"},{"location":"edk2toollib/windows/locate_tools/#queryvcvariables","text":"def QueryVcVariables ( keys : list , arch : str = None , product : str = None , vs_version : str = None ) Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys View Source def QueryVcVariables ( keys : list , arch : str = None , product : str = None , vs_version: str = None ) : \"\"\"Launch vcvarsall.bat and read the settings from its environment. This is a windows only function and Windows is case insensitive for the keys\"\"\" if product is None : product = \"*\" if arch is None : # TODO : look up host architecture? arch = \"amd64\" interesting = set ( x . upper () for x in keys ) result = {} ret , vs_path = FindWithVsWhere ( product , vs_version ) if ret ! = 0 or vs_path is None : logging . warning ( \"We didn't find VS path or otherwise failed to invoke vsWhere\" ) raise ValueError ( \"Bad VC\" ) vcvarsall_path = os . path . join ( vs_path , \"VC\" , \"Auxiliary\" , \"Build\" , \"vcvarsall.bat\" ) logging . debug ( \"Calling '%s %s'\" , vcvarsall_path , arch ) popen = subprocess . Popen ( '\"%s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key . upper () in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) result_set = set ( list ( result . keys ())) difference = list ( interesting . difference ( result_set )) logging . error ( \"We were not able to find on the keys requested from vcvarsall.\" ) logging . error ( \"We didn't find: %s\" % str(difference)) raise ValueError ( \"Missing keys when querying vcvarsall: \" + str ( difference )) return result","title":"QueryVcVariables"},{"location":"edk2toollib/windows/capsule/","text":"Module edk2toollib.windows.capsule View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.windows.capsule.cat_generator edk2toollib.windows.capsule.cat_generator_test edk2toollib.windows.capsule.inf_generator edk2toollib.windows.capsule.inf_generator_test","title":"Index"},{"location":"edk2toollib/windows/capsule/#module-edk2toollibwindowscapsule","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.windows.capsule"},{"location":"edk2toollib/windows/capsule/#sub-modules","text":"edk2toollib.windows.capsule.cat_generator edk2toollib.windows.capsule.cat_generator_test edk2toollib.windows.capsule.inf_generator edk2toollib.windows.capsule.inf_generator_test","title":"Sub-modules"},{"location":"edk2toollib/windows/capsule/cat_generator/","text":"Module edk2toollib.windows.capsule.cat_generator View Source ## @file # Script to generate Cat files for capsule update based on supplied inf file. # This uses the winsdk and the command line tool Inf2Cat.exe # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging from edk2toollib.utility_functions import RunCmd from edk2toollib.windows.locate_tools import FindToolInWinSdk class CatGenerator ( object ): SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ): self . Arch = arch self . OperatingSystem = os @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ): # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ): self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ): # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s \" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ): return self . _operatingsystem @OperatingSystem.setter def OperatingSystem ( self , value ): key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()): logging . critical ( \"Unsupported Operating System: %s \" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d \" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file ( %s ) not created\" % OutputCatFile ) return 0 Classes CatGenerator class CatGenerator ( arch , os ) View Source class CatGenerator ( object ) : SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ) : self . Arch = arch self . OperatingSystem = os @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ) : # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ) : self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ) : # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s\" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ) : return self . _operatingsystem @OperatingSystem . setter def OperatingSystem ( self , value ) : key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()) : logging . critical ( \"Unsupported Operating System: %s\" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) : # Find Inf2Cat tool if ( PathToInf2CatTool is None ) : PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ) : raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ) : raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )) : raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0 Class variables SUPPORTED_OS Instance variables Arch OperatingSystem Methods MakeCat def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) View Source def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"Cat generator"},{"location":"edk2toollib/windows/capsule/cat_generator/#module-edk2toollibwindowscapsulecat_generator","text":"View Source ## @file # Script to generate Cat files for capsule update based on supplied inf file. # This uses the winsdk and the command line tool Inf2Cat.exe # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging from edk2toollib.utility_functions import RunCmd from edk2toollib.windows.locate_tools import FindToolInWinSdk class CatGenerator ( object ): SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ): self . Arch = arch self . OperatingSystem = os @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ): # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ): self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ): # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s \" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ): return self . _operatingsystem @OperatingSystem.setter def OperatingSystem ( self , value ): key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()): logging . critical ( \"Unsupported Operating System: %s \" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d \" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file ( %s ) not created\" % OutputCatFile ) return 0","title":"Module edk2toollib.windows.capsule.cat_generator"},{"location":"edk2toollib/windows/capsule/cat_generator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/windows/capsule/cat_generator/#catgenerator","text":"class CatGenerator ( arch , os ) View Source class CatGenerator ( object ) : SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ) : self . Arch = arch self . OperatingSystem = os @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ) : # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ) : self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ) : # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s\" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ) : return self . _operatingsystem @OperatingSystem . setter def OperatingSystem ( self , value ) : key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()) : logging . critical ( \"Unsupported Operating System: %s\" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) : # Find Inf2Cat tool if ( PathToInf2CatTool is None ) : PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ) : raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ) : raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )) : raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"CatGenerator"},{"location":"edk2toollib/windows/capsule/cat_generator/#class-variables","text":"SUPPORTED_OS","title":"Class variables"},{"location":"edk2toollib/windows/capsule/cat_generator/#instance-variables","text":"Arch OperatingSystem","title":"Instance variables"},{"location":"edk2toollib/windows/capsule/cat_generator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/windows/capsule/cat_generator/#makecat","text":"def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) View Source def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose /uselocaltime\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"MakeCat"},{"location":"edk2toollib/windows/capsule/inf_generator/","text":"Module edk2toollib.windows.capsule.inf_generator View Source ## # Module to generate inf files for capsule update based on INF TEMPLATE and # supplied information (Name, Version, ESRT Guid, Rollback, etc.) # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import datetime import re import uuid class InfGenerator ( object ): ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\"$WINDOWS NT$\" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %F irmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \"{Provider}\" MfgName = \"{MfgName}\" FirmwareDesc = \"{Description}\" DiskName = \"Firmware Update\" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ): self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ): return self . _name @Name.setter def Name ( self , value ): # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )) . match ( value ): logging . critical ( \"Name invalid: ' %s '\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ): return self . _provider @Provider.setter def Provider ( self , value ): self . _provider = value @property def Manufacturer ( self ): if ( self . _manufacturer is None ): return self . Provider return self . _manufacturer @Manufacturer.setter def Manufacturer ( self , value ): self . _manufacturer = value @property def Description ( self ): return self . _description @Description.setter def Description ( self , value ): self . _description = value @property def EsrtGuid ( self ): return self . _esrt_guid @EsrtGuid.setter def EsrtGuid ( self , value ): uuid . UUID ( value ) # if this works it is valid...otherwise throws exception # todo - make sure it is formatted exactly right self . _esrt_guid = value @property def VersionString ( self ): return self . _versionstring @VersionString.setter def VersionString ( self , value ): c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ): logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ): return \"0x %X \" % self . _versionhex @VersionHex.setter def VersionHex ( self , value ): a = int ( value , 0 ) if ( a > 0xFFFFFFFF ): logging . critical ( \"VersionHex invalid: ' %s '\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()): logging . critical ( \"Arch invalid: ' %s '\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ): return self . _date . strftime ( \"%m/ %d /%Y\" ) @Date.setter def Date ( self , value ): if ( not isinstance ( value , datetime . date )): raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0 Classes InfGenerator class InfGenerator ( name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) View Source class InfGenerator ( object ) : ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\" $ WINDOWS NT $ \" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %FirmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \" { Provider } \" MfgName = \" { MfgName } \" FirmwareDesc = \" { Description } \" DiskName = \" Firmware Update \" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) : self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ) : return self . _name @Name . setter def Name ( self , value ) : # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )). match ( value ) : logging . critical ( \"Name invalid: '%s'\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ) : return self . _provider @Provider . setter def Provider ( self , value ) : self . _provider = value @property def Manufacturer ( self ) : if ( self . _manufacturer is None ) : return self . Provider return self . _manufacturer @Manufacturer . setter def Manufacturer ( self , value ) : self . _manufacturer = value @property def Description ( self ) : return self . _description @Description . setter def Description ( self , value ) : self . _description = value @property def EsrtGuid ( self ) : return self . _esrt_guid @EsrtGuid . setter def EsrtGuid ( self , value ) : uuid . UUID ( value ) # if this works it is valid ... otherwise throws exception # todo - make sure it is formatted exactly right self . _esrt_guid = value @property def VersionString ( self ) : return self . _versionstring @VersionString . setter def VersionString ( self , value ) : c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ) : logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ) : return \"0x%X\" % self . _versionhex @VersionHex . setter def VersionHex ( self , value ) : a = int ( value , 0 ) if ( a > 0xFFFFFFFF ) : logging . critical ( \"VersionHex invalid: '%s'\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()) : logging . critical ( \"Arch invalid: '%s'\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ) : return self . _date . strftime ( \"%m/%d/%Y\" ) @Date . setter def Date ( self , value ) : if ( not isinstance ( value , datetime . date )) : raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) : RollbackString = \"\" if ( Rollback ) : RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0 Class variables ROLLBACKTEMPLATE SUPPORTED_ARCH TEMPLATE Instance variables Arch Date Description EsrtGuid Manufacturer Name Provider VersionHex VersionString Methods MakeInf def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) View Source def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"Inf generator"},{"location":"edk2toollib/windows/capsule/inf_generator/#module-edk2toollibwindowscapsuleinf_generator","text":"View Source ## # Module to generate inf files for capsule update based on INF TEMPLATE and # supplied information (Name, Version, ESRT Guid, Rollback, etc.) # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import datetime import re import uuid class InfGenerator ( object ): ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\"$WINDOWS NT$\" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %F irmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \"{Provider}\" MfgName = \"{MfgName}\" FirmwareDesc = \"{Description}\" DiskName = \"Firmware Update\" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ): self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ): return self . _name @Name.setter def Name ( self , value ): # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )) . match ( value ): logging . critical ( \"Name invalid: ' %s '\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ): return self . _provider @Provider.setter def Provider ( self , value ): self . _provider = value @property def Manufacturer ( self ): if ( self . _manufacturer is None ): return self . Provider return self . _manufacturer @Manufacturer.setter def Manufacturer ( self , value ): self . _manufacturer = value @property def Description ( self ): return self . _description @Description.setter def Description ( self , value ): self . _description = value @property def EsrtGuid ( self ): return self . _esrt_guid @EsrtGuid.setter def EsrtGuid ( self , value ): uuid . UUID ( value ) # if this works it is valid...otherwise throws exception # todo - make sure it is formatted exactly right self . _esrt_guid = value @property def VersionString ( self ): return self . _versionstring @VersionString.setter def VersionString ( self , value ): c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ): logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ): return \"0x %X \" % self . _versionhex @VersionHex.setter def VersionHex ( self , value ): a = int ( value , 0 ) if ( a > 0xFFFFFFFF ): logging . critical ( \"VersionHex invalid: ' %s '\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()): logging . critical ( \"Arch invalid: ' %s '\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ): return self . _date . strftime ( \"%m/ %d /%Y\" ) @Date.setter def Date ( self , value ): if ( not isinstance ( value , datetime . date )): raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"Module edk2toollib.windows.capsule.inf_generator"},{"location":"edk2toollib/windows/capsule/inf_generator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/windows/capsule/inf_generator/#infgenerator","text":"class InfGenerator ( name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) View Source class InfGenerator ( object ) : ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\" $ WINDOWS NT $ \" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %FirmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \" { Provider } \" MfgName = \" { MfgName } \" FirmwareDesc = \" { Description } \" DiskName = \" Firmware Update \" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) : self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ) : return self . _name @Name . setter def Name ( self , value ) : # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )). match ( value ) : logging . critical ( \"Name invalid: '%s'\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ) : return self . _provider @Provider . setter def Provider ( self , value ) : self . _provider = value @property def Manufacturer ( self ) : if ( self . _manufacturer is None ) : return self . Provider return self . _manufacturer @Manufacturer . setter def Manufacturer ( self , value ) : self . _manufacturer = value @property def Description ( self ) : return self . _description @Description . setter def Description ( self , value ) : self . _description = value @property def EsrtGuid ( self ) : return self . _esrt_guid @EsrtGuid . setter def EsrtGuid ( self , value ) : uuid . UUID ( value ) # if this works it is valid ... otherwise throws exception # todo - make sure it is formatted exactly right self . _esrt_guid = value @property def VersionString ( self ) : return self . _versionstring @VersionString . setter def VersionString ( self , value ) : c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ) : logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ) : return \"0x%X\" % self . _versionhex @VersionHex . setter def VersionHex ( self , value ) : a = int ( value , 0 ) if ( a > 0xFFFFFFFF ) : logging . critical ( \"VersionHex invalid: '%s'\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()) : logging . critical ( \"Arch invalid: '%s'\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ) : return self . _date . strftime ( \"%m/%d/%Y\" ) @Date . setter def Date ( self , value ) : if ( not isinstance ( value , datetime . date )) : raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) : RollbackString = \"\" if ( Rollback ) : RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"InfGenerator"},{"location":"edk2toollib/windows/capsule/inf_generator/#class-variables","text":"ROLLBACKTEMPLATE SUPPORTED_ARCH TEMPLATE","title":"Class variables"},{"location":"edk2toollib/windows/capsule/inf_generator/#instance-variables","text":"Arch Date Description EsrtGuid Manufacturer Name Provider VersionHex VersionString","title":"Instance variables"},{"location":"edk2toollib/windows/capsule/inf_generator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/windows/capsule/inf_generator/#makeinf","text":"def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) View Source def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"MakeInf"},{"location":"edk2toollib/windows/policy/","text":"Module edk2toollib.windows.policy View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.windows.policy.firmware_policy edk2toollib.windows.policy.firmware_policy_test","title":"Index"},{"location":"edk2toollib/windows/policy/#module-edk2toollibwindowspolicy","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.windows.policy"},{"location":"edk2toollib/windows/policy/#sub-modules","text":"edk2toollib.windows.policy.firmware_policy edk2toollib.windows.policy.firmware_policy_test","title":"Sub-modules"},{"location":"edk2toollib/windows/policy/firmware_policy/","text":"Module edk2toollib.windows.policy.firmware_policy Summary: A firmware policy is conceptually a set of key value pair \u201crules\u201d. Rules can be 1-time actions, states persistent while the policy is in effect, or targeting information describing the machine where the policy is applicable Each key is composed of a UINT32 RootKey followed by String SubKeyName & ValueName For example: RootKey = 0xEF100000 SubKeyName = \u201cPolicyGroupFoo\u201d ValueName = \u201cTpmClear\u201d MyExampleKey = EF100000_PolicyGroupFoo_TpmClear Each value has a type that can be primitive or a variable-length structure. The firmware policy binary, pack(1), little endian, is as follows: UINT16 FormatVersion UINT32 PolicyVersion GUID PolicyPublisher UINT16 Reserved1Count # 0 Reserved1[Reserved1Count] # not present, not supported by this library UINT32 OptionFlags # 0 UINT16 Reserved2Count # 0 UINT16 RulesCount Reserved2[Reserved2Count] # not present for FW policies, partial support by this library RULE Rules[RulesCount] # inline, not a pointer, see class Rule below BYTE ValueTable[] #inline, not a pointer A RULE structure is as follows UINT32 RootKey UINT32 OffsetToSubKeyName # ValueTable offset UINT32 OffsetToValueName # ValueTable offset UINT32 OffsetToValue # ValueTable offset to a PolicyValueType + PolicyValue Each Rule corresponds to 3 entries in the ValueTable Rules may, however, re-use identical ValueTable entries to save space For example, multiple Rules with the same SubKeyName may report the same SubKeyNameOffset PolicyString SubKeyName # may or may not be NULL terminated, usually not PolicyString Valuename # may or may not be NULL terminated, usually not PolicyValue # Begins with a UINT16 PolicyValueType, followed by the actual value, may be NULL terminated Conventions _init__ constructors are to be used when creating new objects from desired values. When the number of parameters is small, __init__ may also take a stream parameter which will be deserialized to initialize the object in lieu of the other parameters. When the number of parameters is large, initialization from stream is factored out into a separate class method FromFileStream(). This overhead did not seem merited when the number of overall parameters was small. View Source # @file # # Library to parse / manage / build unsigned firmware policy blobs # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## # spell - checker : ignore QWORD \"\"\" Summary: A firmware policy is conceptually a set of key value pair \" rules \". Rules can be 1-time actions, states persistent while the policy is in effect, or targeting information describing the machine where the policy is applicable Each key is composed of a UINT32 RootKey followed by String SubKeyName & ValueName For example: RootKey = 0xEF100000 SubKeyName = \" PolicyGroupFoo \" ValueName = \" TpmClear \" MyExampleKey = EF100000_PolicyGroupFoo_TpmClear Each value has a type that can be primitive or a variable-length structure. ## The firmware policy binary, pack(1), little endian, is as follows: UINT16 FormatVersion UINT32 PolicyVersion GUID PolicyPublisher UINT16 Reserved1Count # 0 Reserved1[Reserved1Count] # not present, not supported by this library UINT32 OptionFlags # 0 UINT16 Reserved2Count # 0 UINT16 RulesCount Reserved2[Reserved2Count] # not present for FW policies, partial support by this library RULE Rules[RulesCount] # inline, not a pointer, see class Rule below BYTE ValueTable[] #inline, not a pointer ## ## A RULE structure is as follows UINT32 RootKey UINT32 OffsetToSubKeyName # ValueTable offset UINT32 OffsetToValueName # ValueTable offset UINT32 OffsetToValue # ValueTable offset to a PolicyValueType + PolicyValue ## ## Each Rule corresponds to 3 entries in the ValueTable Rules may, however, re-use identical ValueTable entries to save space For example, multiple Rules with the same SubKeyName may report the same SubKeyNameOffset PolicyString SubKeyName # may or may not be NULL terminated, usually not PolicyString Valuename # may or may not be NULL terminated, usually not PolicyValue # Begins with a UINT16 PolicyValueType, followed by the actual value, may be NULL terminated ## ## Conventions _init__ constructors are to be used when creating new objects from desired values. When the number of parameters is small, __init__ may also take a stream parameter which will be deserialized to initialize the object in lieu of the other parameters. When the number of parameters is large, initialization from stream is factored out into a separate class method FromFileStream(). This overhead did not seem merited when the number of overall parameters was small. ## \"\"\" import io import struct import uuid from typing import BinaryIO STRICT = False class Rule ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing RULE elements \"\"\" StructFormat = '<IIII' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) -> None : \"\"\" The parameter \" Value \" should be of type class PolicyValue() \"\"\" self . RootKey = RootKey self . OffsetToSubKeyName = OffsetToSubKeyName self . OffsetToValueName = OffsetToValueName self . OffsetToValue = OffsetToValue self . SubKeyName = SubKeyName self . ValueName = ValueName self . Value = PolicyValue ( Value . valueType , Value . value ) def __eq__ ( self , other ) -> bool : \"\"\"Rule table offsets are not considered for equivalency, only the actual key/value.\"\"\" if ( self . RootKey == other . RootKey and self . SubKeyName == other . SubKeyName and self . ValueName == other . ValueName and self . Value == other . Value ) : return True else : return False \"\"\" Construct a Rule initialized from a deserialized stream fs fs passed in should be pointing to Rule structure vtOffset is the offset in fs to the ValueTable \"\"\" @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) def Print ( self , prefix : str = '' ) : print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' ) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) : self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue ) class PolicyValueType () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyValue Types\"\"\" StructFormat = '<H' StructSize = struct . calcsize ( StructFormat ) POLICY_VALUE_TYPE_STRING = 0 POLICY_VALUE_TYPE_BOOL = 1 POLICY_VALUE_TYPE_DWORD = 2 POLICY_VALUE_TYPE_DWORD_RANGE = 3 POLICY_VALUE_TYPE_DWORD_CHOICE = 4 POLICY_VALUE_TYPE_QWORD = 5 POLICY_VALUE_TYPE_QWORD_RANGE = 6 POLICY_VALUE_TYPE_QWORD_CHOICE = 7 POLICY_VALUE_TYPE_OPTION = 8 POLICY_VALUE_TYPE_MULTI_STRING = 9 POLICY_VALUE_TYPE_BINARY = 10 SupportedValueTypes = { POLICY_VALUE_TYPE_DWORD , POLICY_VALUE_TYPE_QWORD , POLICY_VALUE_TYPE_STRING } def __init__ ( self , Type ) : if Type not in self . SupportedValueTypes : ErrorMessage = ( 'Unsupported ValueType: %x' % Type ) print ( ErrorMessage ) if STRICT : raise Exception ( ErrorMessage ) self . vt = Type \"\"\"if offset is not specified, stream fs position is at beginning PolicyValueType struct\"\"\" @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt )) def Serialize ( self , valueOut : bytearray ) : valueOut += struct . pack ( self . StructFormat , self . vt ) def Get ( self ) : return self . vt class PolicyString () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in _bytes_ followed by a UTF-16LE string, no NULL terminator Example of \" PlatformID \" \\x14\\x00P\\x00l\\x00a\\x00t\\x00f\\x00o\\x00r\\x00m\\x00I\\x00D\\x00 The trailing \\x00 is not a NULL, it is UTF-16LE encoding of \" D \" \"\"\" StringLengthFormat = '<H' StringLengthSize = struct . calcsize ( StringLengthFormat ) def __init__ ( self , String : str = None ) : if String : self . String = String else : self . String = '' return @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'String: ' , self . String )) def Serialize ( self , valueOut : bytearray ) : b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b class PolicyValue () : \"\"\" Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString \"\"\" def __init__ ( self , valueType , value ) : self . valueType = valueType self . value = value @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) def GetValueType ( self ) : return self . valueType def Print ( self , prefix : str = '' ) : self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ) : print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ) : self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value ))) def Serialize ( self , valueOut : bytearray ) : self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' ) class Reserved2 ( object ) : \"\"\" For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only \"\"\" StructFormat = '<III' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , fs : BinaryIO = None , vtOffset : int = 0 ) : if fs is None : self . ObjectType = 0 self . Element = 0 self . OffsetToValue = vtOffset else : self . PopulateFromFileStream ( fs , vtOffset ) errorMessage = 'Reserved2 not fully supported' if ( STRICT is True ) : raise Exception ( errorMessage ) def PopulateFromFileStream ( self , fs : BinaryIO , vtOffset : int = 0 ) : if fs is None : raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ) : raise Exception ( errorMessage ) def Print ( self , prefix : str = '' ) : print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ) : ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ) : raise Exception ( errorMessage ) class FirmwarePolicy ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString \"\"\" FixedStructFormat = '<HI16sHIHH' # omits completely unsupported Reserved1 array FixedStructSize = struct . calcsize ( FixedStructFormat ) POLICY_BLOB_MIN_SIZE = 32 # bytes POLICY_FORMAT_VERSION = 2 POLICY_VERSION = 1 POLICY_PUBLISHER = uuid . UUID ( '5AE6F808-8384-4EB9-A23A-0CCC1093E3DD' ) # Do NOT change FW_POLICY_ROOT_KEY = 0xEF100000 FW_POLICY_SUB_KEY_NAME_TARGET = 'Target' FW_POLICY_SUB_KEY_NAME = 'UEFI' FW_POLICY_VALUE_NAME = 'Policy' FW_POLICY_TYPE = PolicyValueType . POLICY_VALUE_TYPE_QWORD FW_POLICY_VALUE_DEFINED_MASK = 0x00000000FFFFFFFF FW_POLICY_VALUE_OEM_MASK = 0xFFFFFFFF00000000 FW_POLICY_VALUE_ACTIONS_MASK = 0x0000FFFF0000FFFF FW_POLICY_VALUE_STATES_MASK = 0xFFFF0000FFFF0000 \"\"\"Defined Policy Actions\"\"\" FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR = 0x0000000000000001 FW_POLICY_VALUE_ACTION_TPM_CLEAR = 0x0000000000000002 FW_POLICY_VALUE_ACTION_STRINGS = { FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR : \"Clear UEFI Secure Boot Keys\" , FW_POLICY_VALUE_ACTION_TPM_CLEAR : \"Clear the Trusted Platform Module (TPM)\" } \"\"\"Defined Policy States\"\"\" FW_POLICY_VALUE_STATE_TBD = 0x0000000000010000 FW_POLICY_VALUE_STATE_STRINGS = { FW_POLICY_VALUE_STATE_TBD : \"To Be Defined Placeholder\" } def __init__ ( self , fs = None ) : if fs is None : self . FormatVersion = self . POLICY_FORMAT_VERSION self . PolicyVersion = self . POLICY_VERSION self . PolicyPublisher = self . POLICY_PUBLISHER self . Reserved1Count = 0 self . Reserved1 = [] self . OptionFlags = 0 self . Reserved2Count = 0 self . RulesCount = 0 self . Reserved2 = [] self . Rules = [] self . ValueTableSize = 0 self . ValueTableOffset = 0 self . ValueTable = [] self . ValueTableFromFile = None self . parseValueTableViaBytes = True else : self . FromFileStream ( fs ) def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ) : return False self . Rules . append ( regRule ) self . RulesCount += 1 return True def SetDevicePolicy ( self , policy : int ) : \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SetDeviceTarget ( self , target : dict ) : \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items () : ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SerializeToStream ( self , stream : BinaryIO ) : ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba ) def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ) : if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ) : raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ) : print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )) : raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ) : Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ) : raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ) : raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ) : self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ) : if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule ) def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] ) def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ) : print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return Variables STRICT Classes FirmwarePolicy class FirmwarePolicy ( fs = None ) Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString View Source class FirmwarePolicy ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString \"\"\" FixedStructFormat = '<HI16sHIHH' # omits completely unsupported Reserved1 array FixedStructSize = struct . calcsize ( FixedStructFormat ) POLICY_BLOB_MIN_SIZE = 32 # bytes POLICY_FORMAT_VERSION = 2 POLICY_VERSION = 1 POLICY_PUBLISHER = uuid . UUID ( '5AE6F808-8384-4EB9-A23A-0CCC1093E3DD' ) # Do NOT change FW_POLICY_ROOT_KEY = 0xEF100000 FW_POLICY_SUB_KEY_NAME_TARGET = 'Target' FW_POLICY_SUB_KEY_NAME = 'UEFI' FW_POLICY_VALUE_NAME = 'Policy' FW_POLICY_TYPE = PolicyValueType . POLICY_VALUE_TYPE_QWORD FW_POLICY_VALUE_DEFINED_MASK = 0x00000000FFFFFFFF FW_POLICY_VALUE_OEM_MASK = 0xFFFFFFFF00000000 FW_POLICY_VALUE_ACTIONS_MASK = 0x0000FFFF0000FFFF FW_POLICY_VALUE_STATES_MASK = 0xFFFF0000FFFF0000 \"\"\"Defined Policy Actions\"\"\" FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR = 0x0000000000000001 FW_POLICY_VALUE_ACTION_TPM_CLEAR = 0x0000000000000002 FW_POLICY_VALUE_ACTION_STRINGS = { FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR : \"Clear UEFI Secure Boot Keys\" , FW_POLICY_VALUE_ACTION_TPM_CLEAR : \"Clear the Trusted Platform Module (TPM)\" } \"\"\"Defined Policy States\"\"\" FW_POLICY_VALUE_STATE_TBD = 0x0000000000010000 FW_POLICY_VALUE_STATE_STRINGS = { FW_POLICY_VALUE_STATE_TBD : \"To Be Defined Placeholder\" } def __init__ ( self , fs = None ) : if fs is None : self . FormatVersion = self . POLICY_FORMAT_VERSION self . PolicyVersion = self . POLICY_VERSION self . PolicyPublisher = self . POLICY_PUBLISHER self . Reserved1Count = 0 self . Reserved1 = [] self . OptionFlags = 0 self . Reserved2Count = 0 self . RulesCount = 0 self . Reserved2 = [] self . Rules = [] self . ValueTableSize = 0 self . ValueTableOffset = 0 self . ValueTable = [] self . ValueTableFromFile = None self . parseValueTableViaBytes = True else : self . FromFileStream ( fs ) def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ) : return False self . Rules . append ( regRule ) self . RulesCount += 1 return True def SetDevicePolicy ( self , policy : int ) : \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SetDeviceTarget ( self , target : dict ) : \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items () : ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SerializeToStream ( self , stream : BinaryIO ) : ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba ) def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ) : if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ) : raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ) : print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )) : raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ) : Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ) : raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ) : raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ) : self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ) : if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule ) def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] ) def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ) : print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return Class variables FW_POLICY_ROOT_KEY FW_POLICY_SUB_KEY_NAME FW_POLICY_SUB_KEY_NAME_TARGET FW_POLICY_TYPE FW_POLICY_VALUE_ACTIONS_MASK FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR FW_POLICY_VALUE_ACTION_STRINGS Defined Policy States FW_POLICY_VALUE_ACTION_TPM_CLEAR FW_POLICY_VALUE_DEFINED_MASK FW_POLICY_VALUE_NAME FW_POLICY_VALUE_OEM_MASK FW_POLICY_VALUE_STATES_MASK Defined Policy Actions FW_POLICY_VALUE_STATE_STRINGS FW_POLICY_VALUE_STATE_TBD FixedStructFormat FixedStructSize POLICY_BLOB_MIN_SIZE POLICY_FORMAT_VERSION POLICY_PUBLISHER POLICY_VERSION Methods AddRule def AddRule ( self , regRule ) -> bool AddRule does not update the valuetable, use Serialize to do that after all rules are added View Source def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ): return False self . Rules . append ( regRule ) self . RulesCount += 1 return True FromFileStream def FromFileStream ( self , fs : < class ' BinaryIO '>, parseByBytes : bool = True ) View Source def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ): if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ): raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ): print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 ))[ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' )))[ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )): raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ): Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' )))[ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 ))[ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ): raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ): raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ): self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ): if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule ) Print def Print ( self ) -> None View Source def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ): print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return PrintDevicePolicy def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) View Source def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] ) Serialize def Serialize ( self , output : bytearray ) View Source def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False SerializeToStream def SerializeToStream ( self , stream : < class ' BinaryIO '> ) View Source def SerializeToStream ( self , stream : BinaryIO ): ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba ) SetDevicePolicy def SetDevicePolicy ( self , policy : int ) Adds a Rule for the 64-bit policy value bitfield. The \u201ckey\u201d is a well-known constant assigned in the body of this method The \u201cvalue\u201d of the 64-bit bitfield is passed via the \u201cpolicy\u201d parameter View Source def SetDevicePolicy ( self , policy : int ): \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule ) SetDeviceTarget def SetDeviceTarget ( self , target : dict ) target should be a dictionary of ValueName/Value pairs View Source def SetDeviceTarget ( self , target : dict ): \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items (): ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule ) PolicyString class PolicyString ( String : str = None ) Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in bytes followed by a UTF-16LE string, no NULL terminator Example of \u201cPlatformID\u201d \u0014\u0000P\u0000l\u0000a\u0000t\u0000f\u0000o\u0000r\u0000m\u0000I\u0000D\u0000 The trailing \u0000 is not a NULL, it is UTF-16LE encoding of \u201cD\u201d View Source class PolicyString () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in _bytes_ followed by a UTF-16LE string, no NULL terminator Example of \" PlatformID \" \\x14\\x00P\\x00l\\x00a\\x00t\\x00f\\x00o\\x00r\\x00m\\x00I\\x00D\\x00 The trailing \\x00 is not a NULL, it is UTF-16LE encoding of \" D \" \"\"\" StringLengthFormat = '<H' StringLengthSize = struct . calcsize ( StringLengthFormat ) def __init__ ( self , String : str = None ) : if String : self . String = String else : self . String = '' return @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'String: ' , self . String )) def Serialize ( self , valueOut : bytearray ) : b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b Class variables StringLengthFormat StringLengthSize Static methods FromBytes def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) FromFileStream def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) Methods Print def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%s%s%s' % ( prefix , 'String: ' , self . String )) Serialize def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b PolicyValue class PolicyValue ( valueType , value ) Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString View Source class PolicyValue () : \"\"\" Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString \"\"\" def __init__ ( self , valueType , value ) : self . valueType = valueType self . value = value @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) def GetValueType ( self ) : return self . valueType def Print ( self , prefix : str = '' ) : self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ) : print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ) : self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value ))) def Serialize ( self , valueOut : bytearray ) : self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' ) Static methods FromBytes def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) FromFileStream def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) if fsOffset is not specified, stream fs position is at beginning of struct View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) Methods GetValueType def GetValueType ( self ) View Source def GetValueType ( self ): return self . valueType Print def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ): print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ): self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value ))) Serialize def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0 x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' ) PolicyValueType class PolicyValueType ( Type ) Class for storing, serializing, deserializing, & printing PolicyValue Types View Source class PolicyValueType () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyValue Types\"\"\" StructFormat = '<H' StructSize = struct . calcsize ( StructFormat ) POLICY_VALUE_TYPE_STRING = 0 POLICY_VALUE_TYPE_BOOL = 1 POLICY_VALUE_TYPE_DWORD = 2 POLICY_VALUE_TYPE_DWORD_RANGE = 3 POLICY_VALUE_TYPE_DWORD_CHOICE = 4 POLICY_VALUE_TYPE_QWORD = 5 POLICY_VALUE_TYPE_QWORD_RANGE = 6 POLICY_VALUE_TYPE_QWORD_CHOICE = 7 POLICY_VALUE_TYPE_OPTION = 8 POLICY_VALUE_TYPE_MULTI_STRING = 9 POLICY_VALUE_TYPE_BINARY = 10 SupportedValueTypes = { POLICY_VALUE_TYPE_DWORD , POLICY_VALUE_TYPE_QWORD , POLICY_VALUE_TYPE_STRING } def __init__ ( self , Type ) : if Type not in self . SupportedValueTypes : ErrorMessage = ( 'Unsupported ValueType: %x' % Type ) print ( ErrorMessage ) if STRICT : raise Exception ( ErrorMessage ) self . vt = Type \"\"\"if offset is not specified, stream fs position is at beginning PolicyValueType struct\"\"\" @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt )) def Serialize ( self , valueOut : bytearray ) : valueOut += struct . pack ( self . StructFormat , self . vt ) def Get ( self ) : return self . vt Class variables POLICY_VALUE_TYPE_BINARY POLICY_VALUE_TYPE_BOOL POLICY_VALUE_TYPE_DWORD POLICY_VALUE_TYPE_DWORD_CHOICE POLICY_VALUE_TYPE_DWORD_RANGE POLICY_VALUE_TYPE_MULTI_STRING POLICY_VALUE_TYPE_OPTION POLICY_VALUE_TYPE_QWORD POLICY_VALUE_TYPE_QWORD_CHOICE POLICY_VALUE_TYPE_QWORD_RANGE POLICY_VALUE_TYPE_STRING StructFormat StructSize SupportedValueTypes Static methods FromBytes def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType ) FromFileStream def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType ) Methods Get def Get ( self ) View Source def Get ( self ): return self . vt Print def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt )) Serialize def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): valueOut += struct . pack ( self . StructFormat , self . vt ) Reserved2 class Reserved2 ( fs : < class ' BinaryIO '> = None, vtOffset : int = 0 ) For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only View Source class Reserved2 ( object ): \"\"\" For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only \"\"\" StructFormat = '<III' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , fs: BinaryIO = None , vtOffset: int = 0 ): if fs is None: self . ObjectType = 0 self . Element = 0 self . OffsetToValue = vtOffset else: self . PopulateFromFileStream ( fs , vtOffset ) errorMessage = 'Reserved2 not fully supported' if ( STRICT is True ): raise Exception ( errorMessage ) def PopulateFromFileStream ( self , fs: BinaryIO , vtOffset: int = 0 ): if fs is None: raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage ) def Print ( self , prefix: str = '' ): print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) def Serialize ( self , ruleOut: bytearray , valueOut: bytearray = None , offsetInVT: int = 0 ): ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage ) Class variables StructFormat StructSize Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs : < class ' BinaryIO '>, vtOffset : int = 0 ) View Source def PopulateFromFileStream ( self , fs : BinaryIO , vtOffset : int = 0 ): if fs is None : raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage ) Print def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) Serialize def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ) View Source def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ): ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage ) Rule class Rule ( RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) Class for storing, serializing, deserializing, & printing RULE elements View Source class Rule ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing RULE elements \"\"\" StructFormat = '<IIII' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) -> None : \"\"\" The parameter \" Value \" should be of type class PolicyValue() \"\"\" self . RootKey = RootKey self . OffsetToSubKeyName = OffsetToSubKeyName self . OffsetToValueName = OffsetToValueName self . OffsetToValue = OffsetToValue self . SubKeyName = SubKeyName self . ValueName = ValueName self . Value = PolicyValue ( Value . valueType , Value . value ) def __eq__ ( self , other ) -> bool : \"\"\"Rule table offsets are not considered for equivalency, only the actual key/value.\"\"\" if ( self . RootKey == other . RootKey and self . SubKeyName == other . SubKeyName and self . ValueName == other . ValueName and self . Value == other . Value ) : return True else : return False \"\"\" Construct a Rule initialized from a deserialized stream fs fs passed in should be pointing to Rule structure vtOffset is the offset in fs to the ValueTable \"\"\" @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) def Print ( self , prefix : str = '' ) : print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' ) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) : self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue ) Class variables StructFormat StructSize Static methods FromFsAndVtBytes def FromFsAndVtBytes ( fs : < class ' BinaryIO '>, vt : bytes ) View Source @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) FromFsAndVtOffset def FromFsAndVtOffset ( fs : < class ' BinaryIO '>, vtOffset : int ) View Source @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) Methods Print def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' ) Serialize def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) View Source def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ): self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue )","title":"Firmware policy"},{"location":"edk2toollib/windows/policy/firmware_policy/#module-edk2toollibwindowspolicyfirmware_policy","text":"Summary: A firmware policy is conceptually a set of key value pair \u201crules\u201d. Rules can be 1-time actions, states persistent while the policy is in effect, or targeting information describing the machine where the policy is applicable Each key is composed of a UINT32 RootKey followed by String SubKeyName & ValueName For example: RootKey = 0xEF100000 SubKeyName = \u201cPolicyGroupFoo\u201d ValueName = \u201cTpmClear\u201d MyExampleKey = EF100000_PolicyGroupFoo_TpmClear Each value has a type that can be primitive or a variable-length structure.","title":"Module edk2toollib.windows.policy.firmware_policy"},{"location":"edk2toollib/windows/policy/firmware_policy/#_1","text":"The firmware policy binary, pack(1), little endian, is as follows: UINT16 FormatVersion UINT32 PolicyVersion GUID PolicyPublisher UINT16 Reserved1Count # 0 Reserved1[Reserved1Count] # not present, not supported by this library UINT32 OptionFlags # 0 UINT16 Reserved2Count # 0 UINT16 RulesCount Reserved2[Reserved2Count] # not present for FW policies, partial support by this library RULE Rules[RulesCount] # inline, not a pointer, see class Rule below BYTE ValueTable[] #inline, not a pointer","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_2","text":"","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_3","text":"A RULE structure is as follows UINT32 RootKey UINT32 OffsetToSubKeyName # ValueTable offset UINT32 OffsetToValueName # ValueTable offset UINT32 OffsetToValue # ValueTable offset to a PolicyValueType + PolicyValue","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_4","text":"","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_5","text":"Each Rule corresponds to 3 entries in the ValueTable Rules may, however, re-use identical ValueTable entries to save space For example, multiple Rules with the same SubKeyName may report the same SubKeyNameOffset PolicyString SubKeyName # may or may not be NULL terminated, usually not PolicyString Valuename # may or may not be NULL terminated, usually not PolicyValue # Begins with a UINT16 PolicyValueType, followed by the actual value, may be NULL terminated","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_6","text":"","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_7","text":"Conventions _init__ constructors are to be used when creating new objects from desired values. When the number of parameters is small, __init__ may also take a stream parameter which will be deserialized to initialize the object in lieu of the other parameters. When the number of parameters is large, initialization from stream is factored out into a separate class method FromFileStream(). This overhead did not seem merited when the number of overall parameters was small.","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#_8","text":"View Source # @file # # Library to parse / manage / build unsigned firmware policy blobs # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## # spell - checker : ignore QWORD \"\"\" Summary: A firmware policy is conceptually a set of key value pair \" rules \". Rules can be 1-time actions, states persistent while the policy is in effect, or targeting information describing the machine where the policy is applicable Each key is composed of a UINT32 RootKey followed by String SubKeyName & ValueName For example: RootKey = 0xEF100000 SubKeyName = \" PolicyGroupFoo \" ValueName = \" TpmClear \" MyExampleKey = EF100000_PolicyGroupFoo_TpmClear Each value has a type that can be primitive or a variable-length structure. ## The firmware policy binary, pack(1), little endian, is as follows: UINT16 FormatVersion UINT32 PolicyVersion GUID PolicyPublisher UINT16 Reserved1Count # 0 Reserved1[Reserved1Count] # not present, not supported by this library UINT32 OptionFlags # 0 UINT16 Reserved2Count # 0 UINT16 RulesCount Reserved2[Reserved2Count] # not present for FW policies, partial support by this library RULE Rules[RulesCount] # inline, not a pointer, see class Rule below BYTE ValueTable[] #inline, not a pointer ## ## A RULE structure is as follows UINT32 RootKey UINT32 OffsetToSubKeyName # ValueTable offset UINT32 OffsetToValueName # ValueTable offset UINT32 OffsetToValue # ValueTable offset to a PolicyValueType + PolicyValue ## ## Each Rule corresponds to 3 entries in the ValueTable Rules may, however, re-use identical ValueTable entries to save space For example, multiple Rules with the same SubKeyName may report the same SubKeyNameOffset PolicyString SubKeyName # may or may not be NULL terminated, usually not PolicyString Valuename # may or may not be NULL terminated, usually not PolicyValue # Begins with a UINT16 PolicyValueType, followed by the actual value, may be NULL terminated ## ## Conventions _init__ constructors are to be used when creating new objects from desired values. When the number of parameters is small, __init__ may also take a stream parameter which will be deserialized to initialize the object in lieu of the other parameters. When the number of parameters is large, initialization from stream is factored out into a separate class method FromFileStream(). This overhead did not seem merited when the number of overall parameters was small. ## \"\"\" import io import struct import uuid from typing import BinaryIO STRICT = False class Rule ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing RULE elements \"\"\" StructFormat = '<IIII' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) -> None : \"\"\" The parameter \" Value \" should be of type class PolicyValue() \"\"\" self . RootKey = RootKey self . OffsetToSubKeyName = OffsetToSubKeyName self . OffsetToValueName = OffsetToValueName self . OffsetToValue = OffsetToValue self . SubKeyName = SubKeyName self . ValueName = ValueName self . Value = PolicyValue ( Value . valueType , Value . value ) def __eq__ ( self , other ) -> bool : \"\"\"Rule table offsets are not considered for equivalency, only the actual key/value.\"\"\" if ( self . RootKey == other . RootKey and self . SubKeyName == other . SubKeyName and self . ValueName == other . ValueName and self . Value == other . Value ) : return True else : return False \"\"\" Construct a Rule initialized from a deserialized stream fs fs passed in should be pointing to Rule structure vtOffset is the offset in fs to the ValueTable \"\"\" @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) def Print ( self , prefix : str = '' ) : print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' ) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) : self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue ) class PolicyValueType () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyValue Types\"\"\" StructFormat = '<H' StructSize = struct . calcsize ( StructFormat ) POLICY_VALUE_TYPE_STRING = 0 POLICY_VALUE_TYPE_BOOL = 1 POLICY_VALUE_TYPE_DWORD = 2 POLICY_VALUE_TYPE_DWORD_RANGE = 3 POLICY_VALUE_TYPE_DWORD_CHOICE = 4 POLICY_VALUE_TYPE_QWORD = 5 POLICY_VALUE_TYPE_QWORD_RANGE = 6 POLICY_VALUE_TYPE_QWORD_CHOICE = 7 POLICY_VALUE_TYPE_OPTION = 8 POLICY_VALUE_TYPE_MULTI_STRING = 9 POLICY_VALUE_TYPE_BINARY = 10 SupportedValueTypes = { POLICY_VALUE_TYPE_DWORD , POLICY_VALUE_TYPE_QWORD , POLICY_VALUE_TYPE_STRING } def __init__ ( self , Type ) : if Type not in self . SupportedValueTypes : ErrorMessage = ( 'Unsupported ValueType: %x' % Type ) print ( ErrorMessage ) if STRICT : raise Exception ( ErrorMessage ) self . vt = Type \"\"\"if offset is not specified, stream fs position is at beginning PolicyValueType struct\"\"\" @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt )) def Serialize ( self , valueOut : bytearray ) : valueOut += struct . pack ( self . StructFormat , self . vt ) def Get ( self ) : return self . vt class PolicyString () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in _bytes_ followed by a UTF-16LE string, no NULL terminator Example of \" PlatformID \" \\x14\\x00P\\x00l\\x00a\\x00t\\x00f\\x00o\\x00r\\x00m\\x00I\\x00D\\x00 The trailing \\x00 is not a NULL, it is UTF-16LE encoding of \" D \" \"\"\" StringLengthFormat = '<H' StringLengthSize = struct . calcsize ( StringLengthFormat ) def __init__ ( self , String : str = None ) : if String : self . String = String else : self . String = '' return @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'String: ' , self . String )) def Serialize ( self , valueOut : bytearray ) : b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b class PolicyValue () : \"\"\" Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString \"\"\" def __init__ ( self , valueType , value ) : self . valueType = valueType self . value = value @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) def GetValueType ( self ) : return self . valueType def Print ( self , prefix : str = '' ) : self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ) : print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ) : self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value ))) def Serialize ( self , valueOut : bytearray ) : self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' ) class Reserved2 ( object ) : \"\"\" For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only \"\"\" StructFormat = '<III' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , fs : BinaryIO = None , vtOffset : int = 0 ) : if fs is None : self . ObjectType = 0 self . Element = 0 self . OffsetToValue = vtOffset else : self . PopulateFromFileStream ( fs , vtOffset ) errorMessage = 'Reserved2 not fully supported' if ( STRICT is True ) : raise Exception ( errorMessage ) def PopulateFromFileStream ( self , fs : BinaryIO , vtOffset : int = 0 ) : if fs is None : raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ) : raise Exception ( errorMessage ) def Print ( self , prefix : str = '' ) : print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ) : ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ) : raise Exception ( errorMessage ) class FirmwarePolicy ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString \"\"\" FixedStructFormat = '<HI16sHIHH' # omits completely unsupported Reserved1 array FixedStructSize = struct . calcsize ( FixedStructFormat ) POLICY_BLOB_MIN_SIZE = 32 # bytes POLICY_FORMAT_VERSION = 2 POLICY_VERSION = 1 POLICY_PUBLISHER = uuid . UUID ( '5AE6F808-8384-4EB9-A23A-0CCC1093E3DD' ) # Do NOT change FW_POLICY_ROOT_KEY = 0xEF100000 FW_POLICY_SUB_KEY_NAME_TARGET = 'Target' FW_POLICY_SUB_KEY_NAME = 'UEFI' FW_POLICY_VALUE_NAME = 'Policy' FW_POLICY_TYPE = PolicyValueType . POLICY_VALUE_TYPE_QWORD FW_POLICY_VALUE_DEFINED_MASK = 0x00000000FFFFFFFF FW_POLICY_VALUE_OEM_MASK = 0xFFFFFFFF00000000 FW_POLICY_VALUE_ACTIONS_MASK = 0x0000FFFF0000FFFF FW_POLICY_VALUE_STATES_MASK = 0xFFFF0000FFFF0000 \"\"\"Defined Policy Actions\"\"\" FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR = 0x0000000000000001 FW_POLICY_VALUE_ACTION_TPM_CLEAR = 0x0000000000000002 FW_POLICY_VALUE_ACTION_STRINGS = { FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR : \"Clear UEFI Secure Boot Keys\" , FW_POLICY_VALUE_ACTION_TPM_CLEAR : \"Clear the Trusted Platform Module (TPM)\" } \"\"\"Defined Policy States\"\"\" FW_POLICY_VALUE_STATE_TBD = 0x0000000000010000 FW_POLICY_VALUE_STATE_STRINGS = { FW_POLICY_VALUE_STATE_TBD : \"To Be Defined Placeholder\" } def __init__ ( self , fs = None ) : if fs is None : self . FormatVersion = self . POLICY_FORMAT_VERSION self . PolicyVersion = self . POLICY_VERSION self . PolicyPublisher = self . POLICY_PUBLISHER self . Reserved1Count = 0 self . Reserved1 = [] self . OptionFlags = 0 self . Reserved2Count = 0 self . RulesCount = 0 self . Reserved2 = [] self . Rules = [] self . ValueTableSize = 0 self . ValueTableOffset = 0 self . ValueTable = [] self . ValueTableFromFile = None self . parseValueTableViaBytes = True else : self . FromFileStream ( fs ) def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ) : return False self . Rules . append ( regRule ) self . RulesCount += 1 return True def SetDevicePolicy ( self , policy : int ) : \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SetDeviceTarget ( self , target : dict ) : \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items () : ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SerializeToStream ( self , stream : BinaryIO ) : ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba ) def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ) : if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ) : raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ) : print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )) : raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ) : Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ) : raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ) : raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ) : self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ) : if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule ) def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] ) def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ) : print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return","title":""},{"location":"edk2toollib/windows/policy/firmware_policy/#variables","text":"STRICT","title":"Variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#classes","text":"","title":"Classes"},{"location":"edk2toollib/windows/policy/firmware_policy/#firmwarepolicy","text":"class FirmwarePolicy ( fs = None ) Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString View Source class FirmwarePolicy ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing Firmware Policy structures Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. Rule, PolicyValue, PolicyString \"\"\" FixedStructFormat = '<HI16sHIHH' # omits completely unsupported Reserved1 array FixedStructSize = struct . calcsize ( FixedStructFormat ) POLICY_BLOB_MIN_SIZE = 32 # bytes POLICY_FORMAT_VERSION = 2 POLICY_VERSION = 1 POLICY_PUBLISHER = uuid . UUID ( '5AE6F808-8384-4EB9-A23A-0CCC1093E3DD' ) # Do NOT change FW_POLICY_ROOT_KEY = 0xEF100000 FW_POLICY_SUB_KEY_NAME_TARGET = 'Target' FW_POLICY_SUB_KEY_NAME = 'UEFI' FW_POLICY_VALUE_NAME = 'Policy' FW_POLICY_TYPE = PolicyValueType . POLICY_VALUE_TYPE_QWORD FW_POLICY_VALUE_DEFINED_MASK = 0x00000000FFFFFFFF FW_POLICY_VALUE_OEM_MASK = 0xFFFFFFFF00000000 FW_POLICY_VALUE_ACTIONS_MASK = 0x0000FFFF0000FFFF FW_POLICY_VALUE_STATES_MASK = 0xFFFF0000FFFF0000 \"\"\"Defined Policy Actions\"\"\" FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR = 0x0000000000000001 FW_POLICY_VALUE_ACTION_TPM_CLEAR = 0x0000000000000002 FW_POLICY_VALUE_ACTION_STRINGS = { FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR : \"Clear UEFI Secure Boot Keys\" , FW_POLICY_VALUE_ACTION_TPM_CLEAR : \"Clear the Trusted Platform Module (TPM)\" } \"\"\"Defined Policy States\"\"\" FW_POLICY_VALUE_STATE_TBD = 0x0000000000010000 FW_POLICY_VALUE_STATE_STRINGS = { FW_POLICY_VALUE_STATE_TBD : \"To Be Defined Placeholder\" } def __init__ ( self , fs = None ) : if fs is None : self . FormatVersion = self . POLICY_FORMAT_VERSION self . PolicyVersion = self . POLICY_VERSION self . PolicyPublisher = self . POLICY_PUBLISHER self . Reserved1Count = 0 self . Reserved1 = [] self . OptionFlags = 0 self . Reserved2Count = 0 self . RulesCount = 0 self . Reserved2 = [] self . Rules = [] self . ValueTableSize = 0 self . ValueTableOffset = 0 self . ValueTable = [] self . ValueTableFromFile = None self . parseValueTableViaBytes = True else : self . FromFileStream ( fs ) def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ) : return False self . Rules . append ( regRule ) self . RulesCount += 1 return True def SetDevicePolicy ( self , policy : int ) : \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SetDeviceTarget ( self , target : dict ) : \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items () : ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule ) def SerializeToStream ( self , stream : BinaryIO ) : ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba ) def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ) : if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ) : raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ) : print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )) : raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ) : Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' ))) [ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 )) [ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ) : raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ) : raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ) : self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ) : if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule ) def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] ) def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ) : print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return","title":"FirmwarePolicy"},{"location":"edk2toollib/windows/policy/firmware_policy/#class-variables","text":"FW_POLICY_ROOT_KEY FW_POLICY_SUB_KEY_NAME FW_POLICY_SUB_KEY_NAME_TARGET FW_POLICY_TYPE FW_POLICY_VALUE_ACTIONS_MASK FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR FW_POLICY_VALUE_ACTION_STRINGS Defined Policy States FW_POLICY_VALUE_ACTION_TPM_CLEAR FW_POLICY_VALUE_DEFINED_MASK FW_POLICY_VALUE_NAME FW_POLICY_VALUE_OEM_MASK FW_POLICY_VALUE_STATES_MASK Defined Policy Actions FW_POLICY_VALUE_STATE_STRINGS FW_POLICY_VALUE_STATE_TBD FixedStructFormat FixedStructSize POLICY_BLOB_MIN_SIZE POLICY_FORMAT_VERSION POLICY_PUBLISHER POLICY_VERSION","title":"Class variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#addrule","text":"def AddRule ( self , regRule ) -> bool AddRule does not update the valuetable, use Serialize to do that after all rules are added View Source def AddRule ( self , regRule ) -> bool : \"\"\" AddRule does not update the valuetable, use Serialize to do that after all rules are added \"\"\" for rule in self . Rules : if ( rule == regRule ): return False self . Rules . append ( regRule ) self . RulesCount += 1 return True","title":"AddRule"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfilestream","text":"def FromFileStream ( self , fs : < class ' BinaryIO '>, parseByBytes : bool = True ) View Source def FromFileStream ( self , fs : BinaryIO , parseByBytes : bool = True ): if fs is None : raise Exception ( 'Invalid File stream' ) self . parseValueTableViaBytes = parseByBytes begin = fs . tell () fs . seek ( 0 , io . SEEK_END ) end = fs . tell () # end is offset after last byte fs . seek ( begin ) size = end - begin if ( size < self . POLICY_BLOB_MIN_SIZE ): raise Exception ( 'Policy is too small' ) self . FormatVersion = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] if ( self . FormatVersion > self . POLICY_FORMAT_VERSION ): print ( \"Policy Format Version %x is not supported\" % self . FormatVersion ) raise Exception ( 'Policy Format Version is newer than supported' ) self . PolicyVersion = struct . unpack ( '<I' , fs . read ( 4 ))[ 0 ] PolicyPublisher = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' )))[ 0 ] self . PolicyPublisher = uuid . UUID ( bytes_le = PolicyPublisher ) self . Reserved1Count = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] if ( STRICT and ( self . Reserved1Count > 0 )): raise Exception ( 'Reserved1 not supported' ) self . Reserved1 = [] for i in range ( self . Reserved1Count ): Reserved1 = struct . unpack ( '<16s' , fs . read ( struct . calcsize ( '<16s' )))[ 0 ] self . Reserved1 . append ( uuid . UUID ( bytes_le = Reserved1 )) self . OptionFlags = struct . unpack ( '<I' , fs . read ( 4 ))[ 0 ] self . Reserved2Count = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] self . RulesCount = struct . unpack ( '<H' , fs . read ( 2 ))[ 0 ] # now we pause our parsing to bounds check the variable size structures Reserved2Offset = fs . tell () Reserved2Size = self . Reserved2Count * Reserved2 . StructSize if (( Reserved2Offset + Reserved2Size ) > end ): raise Exception ( 'Reserved2 larger than buffer' ) RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize if (( RulesOffset + RulesSize ) > end ): raise Exception ( 'Rules larger than buffer' ) self . ValueTableOffset = RulesOffset + RulesSize self . ValueTableSize = end - self . ValueTableOffset saved_fs = fs . tell () fs . seek ( self . ValueTableOffset ) self . ValueTable = bytes ( fs . read ( self . ValueTableSize )) self . ValueTableFromFile = True fs . seek ( saved_fs ) # resume parsing the variable length structures using table offset self . Reserved2 = [] for i in range ( self . Reserved2Count ): self . Reserved2 . append ( Reserved2 ( fs = fs , vtOffset = self . ValueTableOffset )) self . Rules = [] for i in range ( self . RulesCount ): if self . parseValueTableViaBytes is True : RegRule = Rule . FromFsAndVtBytes ( fs = fs , vt = self . ValueTable ) else : RegRule = Rule . FromFsAndVtOffset ( fs = fs , vtOffset = self . ValueTableOffset ) self . Rules . append ( RegRule )","title":"FromFileStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#print","text":"def Print ( self ) -> None View Source def Print ( self ) -> None : prefix = ' ' print ( 'Firmware Policy' ) print ( ' FormatVersion: %x' % self . FormatVersion ) print ( ' PolicyVersion: %x' % self . PolicyVersion ) print ( ' PolicyPublisher: %s' % self . PolicyPublisher ) print ( ' Reserved1Count: %x' % self . Reserved1Count ) for item in self . Reserved1 : print ( ' Reserved1: %s' % item ) print ( ' OptionFlags: %x' % self . OptionFlags ) print ( ' Reserved2Count: %x' % self . Reserved2Count ) print ( ' RulesCount: %x' % self . RulesCount ) print ( ' ValueTableSize: %x' % self . ValueTableSize ) print ( ' ValueTableOffset: %x' % self . ValueTableOffset ) for rule in self . Reserved2 : rule . Print ( prefix = prefix ) for rule in self . Rules : rule . Print ( prefix = prefix ) if ( rule . RootKey == self . FW_POLICY_ROOT_KEY and rule . SubKeyName . String == self . FW_POLICY_SUB_KEY_NAME and rule . ValueName . String == self . FW_POLICY_VALUE_NAME ): print ( prefix + ' Device Policy:' ) self . PrintDevicePolicy ( devicePolicy = rule . Value . value , prefix = prefix ) print ( ' Valuetable' ) print ( self . ValueTable ) return","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#printdevicepolicy","text":"def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) View Source def PrintDevicePolicy ( self , devicePolicy : int , prefix : str = '' ) : prefix = prefix + ' ' for bit in self . FW_POLICY_VALUE_ACTION_STRINGS . keys () : if ( devicePolicy & bit ) != 0 : print ( prefix + self . FW_POLICY_VALUE_ACTION_STRINGS [ bit ] )","title":"PrintDevicePolicy"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize","text":"def Serialize ( self , output : bytearray ) View Source def Serialize ( self , output : bytearray ) : if ( self . Reserved1Count > 0 ) : ErrorMessage = 'Reserved1 not supported' if ( STRICT is True ) : raise Exception ( ErrorMessage ) print ( ErrorMessage ) fixedSizeHeader = struct . pack ( self . FixedStructFormat , self . FormatVersion , self . PolicyVersion , self . PolicyPublisher . bytes_le , self . Reserved1Count , self . OptionFlags , self . Reserved2Count , self . RulesCount ) Reserved2Offset = len ( fixedSizeHeader ) Reserved2Size = self . Reserved2Count * Reserved2 . StructSize RulesOffset = Reserved2Offset + Reserved2Size RulesSize = self . RulesCount * Rule . StructSize self . ValueTableOffset = RulesOffset + RulesSize offsetInVT = 0 ruleArray = bytearray () valueArray = bytearray () for i in range ( self . Reserved2Count ) : rule = bytearray () value = bytearray () self . Reserved2 [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) for i in range ( self . RulesCount ) : rule = bytearray () value = bytearray () self . Rules [ i ] . Serialize ( ruleOut = rule , valueOut = value , offsetInVT = offsetInVT ) ruleArray += rule valueArray += value offsetInVT += len ( value ) serial = bytearray ( fixedSizeHeader ) serial += ruleArray self . ValueTableOffset = len ( serial ) self . ValueTableSize = len ( valueArray ) self . ValueTable = valueArray serial += valueArray output += serial self . ValueTableFromFile = False","title":"Serialize"},{"location":"edk2toollib/windows/policy/firmware_policy/#serializetostream","text":"def SerializeToStream ( self , stream : < class ' BinaryIO '> ) View Source def SerializeToStream ( self , stream : BinaryIO ): ba = bytearray () self . Serialize ( output = ba ) stream . write ( ba )","title":"SerializeToStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#setdevicepolicy","text":"def SetDevicePolicy ( self , policy : int ) Adds a Rule for the 64-bit policy value bitfield. The \u201ckey\u201d is a well-known constant assigned in the body of this method The \u201cvalue\u201d of the 64-bit bitfield is passed via the \u201cpolicy\u201d parameter View Source def SetDevicePolicy ( self , policy : int ): \"\"\"Adds a Rule for the 64-bit policy value bitfield. The \" key \" is a well-known constant assigned in the body of this method The \" value \" of the 64-bit bitfield is passed via the \" policy \" parameter \"\"\" policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME ) ValueName = PolicyString ( String = self . FW_POLICY_VALUE_NAME ) Value = PolicyValue ( valueType = policyVT , value = policy ) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) self . AddRule ( rule )","title":"SetDevicePolicy"},{"location":"edk2toollib/windows/policy/firmware_policy/#setdevicetarget","text":"def SetDeviceTarget ( self , target : dict ) target should be a dictionary of ValueName/Value pairs View Source def SetDeviceTarget ( self , target : dict ): \"\"\" target should be a dictionary of ValueName/Value pairs \"\"\" for k , v in target . items (): ValueName = PolicyString ( String = k ) if k == \"Nonce\" : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_QWORD ) Value = PolicyValue ( valueType = policyVT , value = v ) else : policyVT = PolicyValueType ( Type = PolicyValueType . POLICY_VALUE_TYPE_STRING ) Value = PolicyValue ( valueType = policyVT , value = PolicyString ( String = v )) rule = Rule ( RootKey = self . FW_POLICY_ROOT_KEY , SubKeyName = PolicyString ( String = self . FW_POLICY_SUB_KEY_NAME_TARGET ), ValueName = ValueName , Value = Value ) self . AddRule ( rule )","title":"SetDeviceTarget"},{"location":"edk2toollib/windows/policy/firmware_policy/#policystring","text":"class PolicyString ( String : str = None ) Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in bytes followed by a UTF-16LE string, no NULL terminator Example of \u201cPlatformID\u201d \u0014\u0000P\u0000l\u0000a\u0000t\u0000f\u0000o\u0000r\u0000m\u0000I\u0000D\u0000 The trailing \u0000 is not a NULL, it is UTF-16LE encoding of \u201cD\u201d View Source class PolicyString () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyString Types NOTE: This type is used both in the keys as SubKeyName and ValueName and it can be a value. When used as a value, a NULL may follow the string, but the NULL will not be included in the string size 16-bit, little endian, size of the string in _bytes_ followed by a UTF-16LE string, no NULL terminator Example of \" PlatformID \" \\x14\\x00P\\x00l\\x00a\\x00t\\x00f\\x00o\\x00r\\x00m\\x00I\\x00D\\x00 The trailing \\x00 is not a NULL, it is UTF-16LE encoding of \" D \" \"\"\" StringLengthFormat = '<H' StringLengthSize = struct . calcsize ( StringLengthFormat ) def __init__ ( self , String : str = None ) : if String : self . String = String else : self . String = '' return @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'String: ' , self . String )) def Serialize ( self , valueOut : bytearray ) : b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b","title":"PolicyString"},{"location":"edk2toollib/windows/policy/firmware_policy/#class-variables_1","text":"StringLengthFormat StringLengthSize","title":"Class variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#frombytes","text":"def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : StringLength = struct . unpack_from ( cls . StringLengthFormat , b , bOffset ) [ 0 ] bOffset += struct . calcsize ( cls . StringLengthFormat ) LocalString = bytes . decode ( b [ bOffset: bOffset + StringLength ] , encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString )","title":"FromBytes"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfilestream_1","text":"def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) StringLength = struct . unpack ( cls . StringLengthFormat , fs . read ( cls . StringLengthSize )) [ 0 ] LocalString = bytes . decode ( fs . read ( StringLength ), encoding = 'utf_16_le' ) if ( len ( LocalString ) != ( StringLength / 2 )) : raise Exception ( 'String length mismatch' ) return cls ( String = LocalString )","title":"FromFileStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#print_1","text":"def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%s%s%s' % ( prefix , 'String: ' , self . String ))","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize_1","text":"def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): b = str . encode ( self . String , encoding = 'utf_16_le' ) size = struct . pack ( self . StringLengthFormat , len ( b )) valueOut += size + b","title":"Serialize"},{"location":"edk2toollib/windows/policy/firmware_policy/#policyvalue","text":"class PolicyValue ( valueType , value ) Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString View Source class PolicyValue () : \"\"\" Class for storing, serializing, deserializing, & printing policy values Typically handles primitive types itself, or delegates to other classes for non-primitive structures, e.g. PolicyString \"\"\" def __init__ ( self , valueType , value ) : self . valueType = valueType self . value = value @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value ) def GetValueType ( self ) : return self . valueType def Print ( self , prefix : str = '' ) : self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ) : print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ) : self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value ))) def Serialize ( self , valueOut : bytearray ) : self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' )","title":"PolicyValue"},{"location":"edk2toollib/windows/policy/firmware_policy/#static-methods_1","text":"","title":"Static methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#frombytes_1","text":"def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = PolicyValueType . FromBytes ( b , bOffset ) bOffset += PolicyValueType . StructSize if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromBytes ( b , bOffset ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack_from ( '<I' , b , bOffset ) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack_from ( '<Q' , b , bOffset ) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value )","title":"FromBytes"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfilestream_2","text":"def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) if fsOffset is not specified, stream fs position is at beginning of struct View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : \"\"\"if fsOffset is not specified, stream fs position is at beginning of struct\"\"\" if fsOffset : fs . seek ( fsOffset ) else : fsOffset = fs . tell () valueType = PolicyValueType . FromFileStream ( fs = fs , fsOffset = fsOffset ) if valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_STRING : value = PolicyString . FromFileStream ( fs = fs ) elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_DWORD : value = struct . unpack ( '<I' , fs . read ( 4 )) [ 0 ] elif valueType . Get () is PolicyValueType . POLICY_VALUE_TYPE_QWORD : value = struct . unpack ( '<Q' , fs . read ( 8 )) [ 0 ] else : value = 'Value Type not supported' if STRICT : raise Exception ( value ) return cls ( valueType = valueType , value = value )","title":"FromFileStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#getvaluetype","text":"def GetValueType ( self ) View Source def GetValueType ( self ): return self . valueType","title":"GetValueType"},{"location":"edk2toollib/windows/policy/firmware_policy/#print_2","text":"def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): self . valueType . Print ( prefix = prefix ) if isinstance ( self . value , int ): print ( '%s%s0x%x' % ( prefix , 'Value: ' , self . value )) elif ( self . valueType . vt == PolicyValueType . POLICY_VALUE_TYPE_STRING ): self . value . Print ( prefix + 'Value: ' ) else : print ( '%s%s\"%s\"' % ( prefix , 'Value: ' , str ( self . value )))","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize_2","text":"def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): self . valueType . Serialize ( valueOut ) vt = self . valueType . Get () if vt is PolicyValueType . POLICY_VALUE_TYPE_STRING : self . value . Serialize ( valueOut ) \"\"\" NOTE: add a NULL here for consistency with server-side code \"\"\" valueOut += struct . pack ( '<H' , 0 x0000 ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_DWORD : valueOut += struct . pack ( '<I' , self . value ) elif vt is PolicyValueType . POLICY_VALUE_TYPE_QWORD : valueOut += struct . pack ( '<Q' , self . value ) else : print ( 'Type not supported' ) if STRICT : raise Exception ( 'Value Type not supported' )","title":"Serialize"},{"location":"edk2toollib/windows/policy/firmware_policy/#policyvaluetype","text":"class PolicyValueType ( Type ) Class for storing, serializing, deserializing, & printing PolicyValue Types View Source class PolicyValueType () : \"\"\" Class for storing, serializing, deserializing, & printing PolicyValue Types\"\"\" StructFormat = '<H' StructSize = struct . calcsize ( StructFormat ) POLICY_VALUE_TYPE_STRING = 0 POLICY_VALUE_TYPE_BOOL = 1 POLICY_VALUE_TYPE_DWORD = 2 POLICY_VALUE_TYPE_DWORD_RANGE = 3 POLICY_VALUE_TYPE_DWORD_CHOICE = 4 POLICY_VALUE_TYPE_QWORD = 5 POLICY_VALUE_TYPE_QWORD_RANGE = 6 POLICY_VALUE_TYPE_QWORD_CHOICE = 7 POLICY_VALUE_TYPE_OPTION = 8 POLICY_VALUE_TYPE_MULTI_STRING = 9 POLICY_VALUE_TYPE_BINARY = 10 SupportedValueTypes = { POLICY_VALUE_TYPE_DWORD , POLICY_VALUE_TYPE_QWORD , POLICY_VALUE_TYPE_STRING } def __init__ ( self , Type ) : if Type not in self . SupportedValueTypes : ErrorMessage = ( 'Unsupported ValueType: %x' % Type ) print ( ErrorMessage ) if STRICT : raise Exception ( ErrorMessage ) self . vt = Type \"\"\"if offset is not specified, stream fs position is at beginning PolicyValueType struct\"\"\" @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType ) @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType ) def Print ( self , prefix : str = '' ) : print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt )) def Serialize ( self , valueOut : bytearray ) : valueOut += struct . pack ( self . StructFormat , self . vt ) def Get ( self ) : return self . vt","title":"PolicyValueType"},{"location":"edk2toollib/windows/policy/firmware_policy/#class-variables_2","text":"POLICY_VALUE_TYPE_BINARY POLICY_VALUE_TYPE_BOOL POLICY_VALUE_TYPE_DWORD POLICY_VALUE_TYPE_DWORD_CHOICE POLICY_VALUE_TYPE_DWORD_RANGE POLICY_VALUE_TYPE_MULTI_STRING POLICY_VALUE_TYPE_OPTION POLICY_VALUE_TYPE_QWORD POLICY_VALUE_TYPE_QWORD_CHOICE POLICY_VALUE_TYPE_QWORD_RANGE POLICY_VALUE_TYPE_STRING StructFormat StructSize SupportedValueTypes","title":"Class variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#static-methods_2","text":"","title":"Static methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#frombytes_2","text":"def FromBytes ( b : bytes , bOffset : int = 0 ) View Source @classmethod def FromBytes ( cls , b : bytes , bOffset : int = 0 ) : valueType = struct . unpack_from ( cls . StructFormat , b , bOffset ) [ 0 ] return cls ( valueType )","title":"FromBytes"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfilestream_3","text":"def FromFileStream ( fs : < class ' BinaryIO '>, fsOffset : int = None ) View Source @classmethod def FromFileStream ( cls , fs : BinaryIO , fsOffset : int = None ) : if fsOffset : fs . seek ( fsOffset ) valueType = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) [ 0 ] return cls ( valueType )","title":"FromFileStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#get","text":"def Get ( self ) View Source def Get ( self ): return self . vt","title":"Get"},{"location":"edk2toollib/windows/policy/firmware_policy/#print_3","text":"def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%s%s%s' % ( prefix , 'ValueType: ' , self . vt ))","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize_3","text":"def Serialize ( self , valueOut : bytearray ) View Source def Serialize ( self , valueOut : bytearray ): valueOut += struct . pack ( self . StructFormat , self . vt )","title":"Serialize"},{"location":"edk2toollib/windows/policy/firmware_policy/#reserved2","text":"class Reserved2 ( fs : < class ' BinaryIO '> = None, vtOffset : int = 0 ) For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only View Source class Reserved2 ( object ): \"\"\" For testing non-firmware, legacy policies Implementation can do basic parsing of rules but not values For test purposes only \"\"\" StructFormat = '<III' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , fs: BinaryIO = None , vtOffset: int = 0 ): if fs is None: self . ObjectType = 0 self . Element = 0 self . OffsetToValue = vtOffset else: self . PopulateFromFileStream ( fs , vtOffset ) errorMessage = 'Reserved2 not fully supported' if ( STRICT is True ): raise Exception ( errorMessage ) def PopulateFromFileStream ( self , fs: BinaryIO , vtOffset: int = 0 ): if fs is None: raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage ) def Print ( self , prefix: str = '' ): print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) def Serialize ( self , ruleOut: bytearray , valueOut: bytearray = None , offsetInVT: int = 0 ): ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage )","title":"Reserved2"},{"location":"edk2toollib/windows/policy/firmware_policy/#class-variables_3","text":"StructFormat StructSize","title":"Class variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs : < class ' BinaryIO '>, vtOffset : int = 0 ) View Source def PopulateFromFileStream ( self , fs : BinaryIO , vtOffset : int = 0 ): if fs is None : raise Exception ( 'Invalid File stream' ) ( self . ObjectType , self . Element , self . OffsetToValue ) = struct . unpack ( self . StructFormat , fs . read ( self . StructSize )) errorMessage = 'Reserved2 PopulateFromFileStream does not deserialize Reserved2 values' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage )","title":"PopulateFromFileStream"},{"location":"edk2toollib/windows/policy/firmware_policy/#print_4","text":"def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%sReserved2' % prefix ) print ( '%s ObjectType: %x' % ( prefix , self . ObjectType )) print ( '%s Element: %x' % ( prefix , self . Element )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue ))","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize_4","text":"def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ) View Source def Serialize ( self , ruleOut : bytearray , valueOut : bytearray = None , offsetInVT : int = 0 ): ruleOut += struct . pack ( self . StructFormat , self . ObjectType , self . Element , self . OffsetToValue ) errorMessage = 'Reserved2 value serialization not supported' print ( errorMessage ) if ( STRICT is True ): raise Exception ( errorMessage )","title":"Serialize"},{"location":"edk2toollib/windows/policy/firmware_policy/#rule","text":"class Rule ( RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) Class for storing, serializing, deserializing, & printing RULE elements View Source class Rule ( object ) : \"\"\" Class for storing, serializing, deserializing, & printing RULE elements \"\"\" StructFormat = '<IIII' StructSize = struct . calcsize ( StructFormat ) def __init__ ( self , RootKey : int , SubKeyName : str , ValueName : str , Value , OffsetToSubKeyName : int = 0 , OffsetToValueName : int = 0 , OffsetToValue : int = 0 ) -> None : \"\"\" The parameter \" Value \" should be of type class PolicyValue() \"\"\" self . RootKey = RootKey self . OffsetToSubKeyName = OffsetToSubKeyName self . OffsetToValueName = OffsetToValueName self . OffsetToValue = OffsetToValue self . SubKeyName = SubKeyName self . ValueName = ValueName self . Value = PolicyValue ( Value . valueType , Value . value ) def __eq__ ( self , other ) -> bool : \"\"\"Rule table offsets are not considered for equivalency, only the actual key/value.\"\"\" if ( self . RootKey == other . RootKey and self . SubKeyName == other . SubKeyName and self . ValueName == other . ValueName and self . Value == other . Value ) : return True else : return False \"\"\" Construct a Rule initialized from a deserialized stream fs fs passed in should be pointing to Rule structure vtOffset is the offset in fs to the ValueTable \"\"\" @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value ) def Print ( self , prefix : str = '' ) : print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' ) def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) : self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue )","title":"Rule"},{"location":"edk2toollib/windows/policy/firmware_policy/#class-variables_4","text":"StructFormat StructSize","title":"Class variables"},{"location":"edk2toollib/windows/policy/firmware_policy/#static-methods_3","text":"","title":"Static methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfsandvtbytes","text":"def FromFsAndVtBytes ( fs : < class ' BinaryIO '>, vt : bytes ) View Source @classmethod def FromFsAndVtBytes ( cls , fs : BinaryIO , vt : bytes ) : if fs is None or vt is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) SubKeyName = PolicyString . FromBytes ( vt , OffsetToSubKeyName ) ValueName = PolicyString . FromBytes ( vt , OffsetToValueName ) Value = PolicyValue . FromBytes ( vt , OffsetToValue ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value )","title":"FromFsAndVtBytes"},{"location":"edk2toollib/windows/policy/firmware_policy/#fromfsandvtoffset","text":"def FromFsAndVtOffset ( fs : < class ' BinaryIO '>, vtOffset : int ) View Source @classmethod def FromFsAndVtOffset ( cls , fs : BinaryIO , vtOffset : int ) : if fs is None or vtOffset is None : raise Exception ( 'Invalid File stream or Value Table offset' ) ( RootKey , OffsetToSubKeyName , OffsetToValueName , OffsetToValue ) = struct . unpack ( cls . StructFormat , fs . read ( cls . StructSize )) orig_offset = fs . tell () SubKeyName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToSubKeyName ) ValueName = PolicyString . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValueName ) Value = PolicyValue . FromFileStream ( fs = fs , fsOffset = vtOffset + OffsetToValue ) fs . seek ( orig_offset ) return cls ( RootKey = RootKey , OffsetToSubKeyName = OffsetToSubKeyName , OffsetToValueName = OffsetToValueName , OffsetToValue = OffsetToValue , SubKeyName = SubKeyName , ValueName = ValueName , Value = Value )","title":"FromFsAndVtOffset"},{"location":"edk2toollib/windows/policy/firmware_policy/#methods_5","text":"","title":"Methods"},{"location":"edk2toollib/windows/policy/firmware_policy/#print_5","text":"def Print ( self , prefix : str = '' ) View Source def Print ( self , prefix : str = '' ): print ( '%sRule' % ( prefix ,)) print ( '%s RootKey: %x' % ( prefix , self . RootKey )) print ( '%s SubKeyNameOffset: %x' % ( prefix , self . OffsetToSubKeyName )) print ( '%s ValueNameOffset: %x' % ( prefix , self . OffsetToValueName )) print ( '%s ValueOffset: %x' % ( prefix , self . OffsetToValue )) self . SubKeyName . Print ( prefix = prefix + ' SubKeyName ' ) self . ValueName . Print ( prefix = prefix + ' ValueName ' ) self . Value . Print ( prefix = prefix + ' ' )","title":"Print"},{"location":"edk2toollib/windows/policy/firmware_policy/#serialize_5","text":"def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ) View Source def Serialize ( self , ruleOut : bytearray , valueOut : bytearray , offsetInVT : int ): self . OffsetToSubKeyName = offsetInVT localArray = bytearray () self . SubKeyName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValueName = self . OffsetToSubKeyName + len ( localArray ) localArray = bytearray () self . ValueName . Serialize ( valueOut = localArray ) valueOut += localArray self . OffsetToValue = self . OffsetToValueName + len ( localArray ) localArray = bytearray () self . Value . Serialize ( valueOut = localArray ) valueOut += localArray ruleOut += struct . pack ( self . StructFormat , self . RootKey , self . OffsetToSubKeyName , self . OffsetToValueName , self . OffsetToValue )","title":"Serialize"},{"location":"features/logging.ansi_handler/","text":"Logging ANSI Handler This document details the Ansi Handler How to Use from edk2toollib.logging.ansi_handler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter () Usage info ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formatter from the logging package that will insert ANSI codes according to the logging level into the output stream. ColoredStreamHandler Arguments 1. strip Strip will strip ANSI codes if the terminal does not support them (such as windows). 2. convert Convert will convert ANSI codes on windows platforms into windows platform calls. ColoredFormatter Arguments 1. msg The best documentation for this is from Python itself. It\u2019s the same message that\u2019s passed into the formatted base class. 2. use_azure Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI. Purpose To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don\u2019t support ANSI natively.","title":"Logging.ansi handler"},{"location":"features/logging.ansi_handler/#logging-ansi-handler","text":"This document details the Ansi Handler","title":"Logging ANSI Handler"},{"location":"features/logging.ansi_handler/#how-to-use","text":"from edk2toollib.logging.ansi_handler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter ()","title":"How to Use"},{"location":"features/logging.ansi_handler/#usage-info","text":"ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formatter from the logging package that will insert ANSI codes according to the logging level into the output stream.","title":"Usage info"},{"location":"features/logging.ansi_handler/#coloredstreamhandler-arguments","text":"","title":"ColoredStreamHandler Arguments"},{"location":"features/logging.ansi_handler/#1-strip","text":"Strip will strip ANSI codes if the terminal does not support them (such as windows).","title":"1. strip"},{"location":"features/logging.ansi_handler/#2-convert","text":"Convert will convert ANSI codes on windows platforms into windows platform calls.","title":"2. convert"},{"location":"features/logging.ansi_handler/#coloredformatter-arguments","text":"","title":"ColoredFormatter Arguments"},{"location":"features/logging.ansi_handler/#1-msg","text":"The best documentation for this is from Python itself. It\u2019s the same message that\u2019s passed into the formatted base class.","title":"1. msg"},{"location":"features/logging.ansi_handler/#2-use_azure","text":"Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI.","title":"2. use_azure"},{"location":"features/logging.ansi_handler/#purpose","text":"To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don\u2019t support ANSI natively.","title":"Purpose"},{"location":"features/utility_functions.GetHostInfo/","text":"Utility Functions GetHostInfo() This document details the utility function called GetHostInfo. This function was written because tools needed a consistent way to determine attributes about the host system. Purpose Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform. How to Use from edk2toollib.utility_functions import GetHostInfo host_info = GetHostInfo () Usage info GetHostInfo() will return a named tuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein. 1. os - OS Name Windows, Linux, or Java 2. arch - Processor architecture ARM or x86 3. bit - Highest order bit 32 or 64","title":"Utility functions.get host info"},{"location":"features/utility_functions.GetHostInfo/#utility-functions-gethostinfo","text":"This document details the utility function called GetHostInfo. This function was written because tools needed a consistent way to determine attributes about the host system.","title":"Utility Functions GetHostInfo()"},{"location":"features/utility_functions.GetHostInfo/#purpose","text":"Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform.","title":"Purpose"},{"location":"features/utility_functions.GetHostInfo/#how-to-use","text":"from edk2toollib.utility_functions import GetHostInfo host_info = GetHostInfo ()","title":"How to Use"},{"location":"features/utility_functions.GetHostInfo/#usage-info","text":"GetHostInfo() will return a named tuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein.","title":"Usage info"},{"location":"features/utility_functions.GetHostInfo/#1-os-os-name","text":"Windows, Linux, or Java","title":"1. os - OS Name"},{"location":"features/utility_functions.GetHostInfo/#2-arch-processor-architecture","text":"ARM or x86","title":"2. arch - Processor architecture"},{"location":"features/utility_functions.GetHostInfo/#3-bit-highest-order-bit","text":"32 or 64","title":"3. bit - Highest order bit"},{"location":"features/windows_firmware_policy/","text":"Windows Firmware Policy Library This library supports creation and analysis of Windows Firmware Policy binaries (unsigned) Usage info To deserialize an unsigned firmware policy binary file and print its contents Construct a FirmwarePolicy() using a binary file stream as a parameter Inspect data members Invoke the Print() method on it To create a firmware policy binary file Device targeting information must first be read from the target device (not covered here). Construct a Dictionary with keys \u2018Manufacturer\u2019, \u2018Product\u2019, \u2018SerialNumber\u2019, \u2018OEM_01\u2019, \u2018OEM_02\u2019, & \u2018Nonce\u2019 populated with the targeting values read from the device. Construct an default FirmwarePolicy() object, then call SetDeviceTarget(target_dictionary) to populate it with the targeting information Bitwise OR the desired FirmwarePolicy.FW_POLICY_VALUE_foo values into an integer and pass to SetDevicePolicy(64_bit_device_policy) The FirmwarePolicy object is now ready, serialize it to a file stream using SerializeToStream(your_file_stream) For consumption by a secure device, sign the policy using instructions found elsewhere How to Use from edk2toollib.windows.policy.firmware_policy import FirmwarePolicy # to create an object from file and print its contents policy = FirmwarePolicy ( fs = policy_file_stream ) # construct from file stream policy . Print () # or to create a policy and save to file policy = FirmwarePolicy () deviceTarget = { 'Manufacturer' : manufacturer_read_from_device , 'Product' : product_make_read_from_device , 'SerialNumber' : sn_read_from_device , 'OEM_01' : '' , # Yours to define, or not use (NULL string) 'OEM_02' : '' , 'Nonce' : nonce_read_from_device } policy . SetDeviceTarget ( TargetInfo ) devicePolicy = \\ FirmwarePolicy . FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR \\ + FirmwarePolicy . FW_POLICY_VALUE_ACTION_TPM_CLEAR policy . SetDevicePolicy ( devicePolicy ) policy . SerializeToStream ( stream = your_file_stream )","title":"Windows firmware policy"},{"location":"features/windows_firmware_policy/#windows-firmware-policy-library","text":"This library supports creation and analysis of Windows Firmware Policy binaries (unsigned)","title":"Windows Firmware Policy Library"},{"location":"features/windows_firmware_policy/#usage-info","text":"","title":"Usage info"},{"location":"features/windows_firmware_policy/#to-deserialize-an-unsigned-firmware-policy-binary-file-and-print-its-contents","text":"Construct a FirmwarePolicy() using a binary file stream as a parameter Inspect data members Invoke the Print() method on it","title":"To deserialize an unsigned firmware policy binary file and print its contents"},{"location":"features/windows_firmware_policy/#to-create-a-firmware-policy-binary-file","text":"Device targeting information must first be read from the target device (not covered here). Construct a Dictionary with keys \u2018Manufacturer\u2019, \u2018Product\u2019, \u2018SerialNumber\u2019, \u2018OEM_01\u2019, \u2018OEM_02\u2019, & \u2018Nonce\u2019 populated with the targeting values read from the device. Construct an default FirmwarePolicy() object, then call SetDeviceTarget(target_dictionary) to populate it with the targeting information Bitwise OR the desired FirmwarePolicy.FW_POLICY_VALUE_foo values into an integer and pass to SetDevicePolicy(64_bit_device_policy) The FirmwarePolicy object is now ready, serialize it to a file stream using SerializeToStream(your_file_stream) For consumption by a secure device, sign the policy using instructions found elsewhere","title":"To create a firmware policy binary file"},{"location":"features/windows_firmware_policy/#how-to-use","text":"from edk2toollib.windows.policy.firmware_policy import FirmwarePolicy # to create an object from file and print its contents policy = FirmwarePolicy ( fs = policy_file_stream ) # construct from file stream policy . Print () # or to create a policy and save to file policy = FirmwarePolicy () deviceTarget = { 'Manufacturer' : manufacturer_read_from_device , 'Product' : product_make_read_from_device , 'SerialNumber' : sn_read_from_device , 'OEM_01' : '' , # Yours to define, or not use (NULL string) 'OEM_02' : '' , 'Nonce' : nonce_read_from_device } policy . SetDeviceTarget ( TargetInfo ) devicePolicy = \\ FirmwarePolicy . FW_POLICY_VALUE_ACTION_SECUREBOOT_CLEAR \\ + FirmwarePolicy . FW_POLICY_VALUE_ACTION_TPM_CLEAR policy . SetDevicePolicy ( devicePolicy ) policy . SerializeToStream ( stream = your_file_stream )","title":"How to Use"}]}