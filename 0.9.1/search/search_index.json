{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tianocore Edk2 PyTool Library (edk2toollib) This is a Tianocore maintained project consisting of a python library supporting UEFI firmware development. This package\u2019s intent is to provide an easy way to organize and share python code to facilitate reuse across environments, tools, and scripts. Inclusion of this package and dependency management is best managed using Pip/Pypi. This is a supplemental package and is not required to be used for edk2 builds. Content The package contains classes and modules that can be used as the building blocks of tools that are relevant to UEFI firmware developers. These modules should attempt to provide generic support and avoid tightly coupling with specific use cases. It is expected these modules do not provide direct interaction with the user (through command line interfaces) but instead are intended to be wrapped in other scripts/tools which contains the specific usage and interface. Examples: File parsers for edk2 specific file types. These parse the file and provide an object for interacting with the content. UEFI specific services for encoding/decoding binary structures. UEFI defined values and interfaces for usage in python Python wrappers for other system cli tools ( signtool, catalog file generation, inf file generation, etc) Python utilities to provide consistent logging, command invocation, path resolution, etc License All content in this repository is licensed under BSD-2-Clause Plus Patent License . Usage NOTE: It is strongly recommended that you use python virtual environments. Virtual environments avoid changing the global python workspace and causing conflicting dependencies. Virtual environments are lightweight and easy to use. Learn more To install run pip install --upgrade edk2-pytool-library To use in your python code python from edk2toollib. < module > import < class > Release Version History Version 0.9.1 Features: Add support for getting WinSdk tools on platforms without VS2017 or newer FindToolInWinSdk in locate_tools.py throws a FileNotFoundException when it cannot find the tool requested, previouly it returned None Add support for limiting vswhere to certain versions of visual studio (VS2017 and VS2019 supported) Version 0.9.00 Initial release of library with functionality ported from Project Mu. For history and documentation prior to this see the original Project Mu project https://github.com/microsoft/mu_pip_python_library Current Status Host Type Toolchain Branch Build Status Test Status Code Coverage Linux Ubuntu 1604 Python 3.7.x master Windows Server 2019 Python 3.7.x master Contribution Process This project welcomes all types of contributions. For issues, bugs, and questions it is best to open a github issue . Code Contributions For code contributions this project leverages github pull requests. See github tutorials, help, and documentation for complete descriptions. For best success please follow the below process. Contributor opens an issue describing problem or new desired functionality Contributor forks repository in github Contributor creates branch for work in their fork Contributor makes code changes, writes relevant unit tests, authors documentation and release notes as necessary. Contributor runs tests locally Contributor submits PR to master branch of tianocore/edk2-pytool-library PR reviewers will provide feedback on change. If any modifications are required, contributor will make changes and push updates. PR automation will run and validate tests pass If all comments resolved, maintainers approved, and tests pass the PR will be squash merged and closed by the maintainers. Maintainers See the github team for more details. Documentation See the github repo docs folder","title":"Home"},{"location":"#tianocore-edk2-pytool-library-edk2toollib","text":"This is a Tianocore maintained project consisting of a python library supporting UEFI firmware development. This package\u2019s intent is to provide an easy way to organize and share python code to facilitate reuse across environments, tools, and scripts. Inclusion of this package and dependency management is best managed using Pip/Pypi. This is a supplemental package and is not required to be used for edk2 builds.","title":"Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"#content","text":"The package contains classes and modules that can be used as the building blocks of tools that are relevant to UEFI firmware developers. These modules should attempt to provide generic support and avoid tightly coupling with specific use cases. It is expected these modules do not provide direct interaction with the user (through command line interfaces) but instead are intended to be wrapped in other scripts/tools which contains the specific usage and interface. Examples: File parsers for edk2 specific file types. These parse the file and provide an object for interacting with the content. UEFI specific services for encoding/decoding binary structures. UEFI defined values and interfaces for usage in python Python wrappers for other system cli tools ( signtool, catalog file generation, inf file generation, etc) Python utilities to provide consistent logging, command invocation, path resolution, etc","title":"Content"},{"location":"#license","text":"All content in this repository is licensed under BSD-2-Clause Plus Patent License .","title":"License"},{"location":"#usage","text":"NOTE: It is strongly recommended that you use python virtual environments. Virtual environments avoid changing the global python workspace and causing conflicting dependencies. Virtual environments are lightweight and easy to use. Learn more To install run pip install --upgrade edk2-pytool-library To use in your python code python from edk2toollib. < module > import < class >","title":"Usage"},{"location":"#release-version-history","text":"","title":"Release Version History"},{"location":"#version-091","text":"Features: Add support for getting WinSdk tools on platforms without VS2017 or newer FindToolInWinSdk in locate_tools.py throws a FileNotFoundException when it cannot find the tool requested, previouly it returned None Add support for limiting vswhere to certain versions of visual studio (VS2017 and VS2019 supported)","title":"Version 0.9.1"},{"location":"#version-0900","text":"Initial release of library with functionality ported from Project Mu. For history and documentation prior to this see the original Project Mu project https://github.com/microsoft/mu_pip_python_library","title":"Version 0.9.00"},{"location":"#current-status","text":"Host Type Toolchain Branch Build Status Test Status Code Coverage Linux Ubuntu 1604 Python 3.7.x master Windows Server 2019 Python 3.7.x master","title":"Current Status"},{"location":"#contribution-process","text":"This project welcomes all types of contributions. For issues, bugs, and questions it is best to open a github issue .","title":"Contribution Process"},{"location":"#code-contributions","text":"For code contributions this project leverages github pull requests. See github tutorials, help, and documentation for complete descriptions. For best success please follow the below process. Contributor opens an issue describing problem or new desired functionality Contributor forks repository in github Contributor creates branch for work in their fork Contributor makes code changes, writes relevant unit tests, authors documentation and release notes as necessary. Contributor runs tests locally Contributor submits PR to master branch of tianocore/edk2-pytool-library PR reviewers will provide feedback on change. If any modifications are required, contributor will make changes and push updates. PR automation will run and validate tests pass If all comments resolved, maintainers approved, and tests pass the PR will be squash merged and closed by the maintainers.","title":"Code Contributions"},{"location":"#maintainers","text":"See the github team for more details.","title":"Maintainers"},{"location":"#documentation","text":"See the github repo docs folder","title":"Documentation"},{"location":"developing/","text":"Developing Tianocore Edk2 PyTool Library (edk2toollib) Pre-Requisites Get the code cmd git clone https://github.com/tianocore/edk2-pytool-library.git Install development dependencies cmd pip install --upgrade -r requirements.txt Uninstall any copy of edk2-pytool-library cmd pip uninstall edk2-pytool-library Install from local source (run command from root of repo) cmd pip install -e . Testing Run a Basic Syntax/Lint Check (using flake8) and resolve any issues cmd flake8 edk2toollib INFO: Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run the BasicDevTests.py script to check file encoding, file naming, etc cmd BasicDevTests.py Run pytest with coverage data collected cmd pytest -v --junitxml=test.junit.xml --html=pytest_report.html --self-contained-html --cov=edk2toollib --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_report.html cov_html/index.html Conventions Shortlist File and folder names Use python defined Pep conventions. For example package, module, and class naming should follow PEP8 ( https://www.python.org/dev/peps/pep-0008/ ) Comments Docstring style comments should be added to each public function and class. *Existing code should be updated to be compliant as it is modified. New Module or Class When creating a new module or class it should be clearly defined for a single purpose and provide general purpose support. The module should be added to the package in which the interface is defined. For example for modules supporting interfaces defined in the UEFI specification it would be in the uefi package. If it is defined by EDK2 then it should be in the uefi.edk2 package. Documentation of the feature should be added to the docs/features folder in markdown format. The filename should be the package import path. For example for edk2toollib.logging.ansi_handler.py module the filename for documentation would be logging.ansi_handler.md . The content of this documentation should be focused on why. Docstrings within the module should describe functional parameters and usage info. Unit tests should be written in python unittest or pytest format. A test module should be added in the same folder or package as the module and the filename should be same as the module plus \u201c_test\u201d.","title":"Developing"},{"location":"developing/#developing-tianocore-edk2-pytool-library-edk2toollib","text":"","title":"Developing Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"developing/#pre-requisites","text":"Get the code cmd git clone https://github.com/tianocore/edk2-pytool-library.git Install development dependencies cmd pip install --upgrade -r requirements.txt Uninstall any copy of edk2-pytool-library cmd pip uninstall edk2-pytool-library Install from local source (run command from root of repo) cmd pip install -e .","title":"Pre-Requisites"},{"location":"developing/#testing","text":"Run a Basic Syntax/Lint Check (using flake8) and resolve any issues cmd flake8 edk2toollib INFO: Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run the BasicDevTests.py script to check file encoding, file naming, etc cmd BasicDevTests.py Run pytest with coverage data collected cmd pytest -v --junitxml=test.junit.xml --html=pytest_report.html --self-contained-html --cov=edk2toollib --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_report.html cov_html/index.html","title":"Testing"},{"location":"developing/#conventions-shortlist","text":"","title":"Conventions Shortlist"},{"location":"developing/#file-and-folder-names","text":"Use python defined Pep conventions. For example package, module, and class naming should follow PEP8 ( https://www.python.org/dev/peps/pep-0008/ )","title":"File and folder names"},{"location":"developing/#comments","text":"Docstring style comments should be added to each public function and class. *Existing code should be updated to be compliant as it is modified.","title":"Comments"},{"location":"developing/#new-module-or-class","text":"When creating a new module or class it should be clearly defined for a single purpose and provide general purpose support. The module should be added to the package in which the interface is defined. For example for modules supporting interfaces defined in the UEFI specification it would be in the uefi package. If it is defined by EDK2 then it should be in the uefi.edk2 package. Documentation of the feature should be added to the docs/features folder in markdown format. The filename should be the package import path. For example for edk2toollib.logging.ansi_handler.py module the filename for documentation would be logging.ansi_handler.md . The content of this documentation should be focused on why. Docstrings within the module should describe functional parameters and usage info. Unit tests should be written in python unittest or pytest format. A test module should be added in the same folder or package as the module and the filename should be same as the module plus \u201c_test\u201d.","title":"New Module or Class"},{"location":"publishing/","text":"Publishing Tianocore Edk2 PyTool Library (edk2toollib) The edk2toollib is published as a pypi (pip) module. The pip module is named edk2-pytool-library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here. Version Scheme Versioning follows: aa.bb.cc and is based on tags in git aa == Major version. Changes don\u2019t need to be backward compatible bb == Minor version. Significant new features. Backward compatibility generally maintained except when new feature is used. cc == Patch version. Bug fix or small optional feature. Backward compatibility maintained. Publishing Process NOTE: These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and checks. Update the readme.md Release Version History section with info on all important changes for this version. Remove the \u201c-dev\u201d tag from the version about to be released. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released and push tag. Tag format is v\\ .\\ .\\ Do the release process Install tools cmd pip install --upgrade -r requirements.publisher.txt Build a wheel cmd python setup.py sdist bdist_wheel Confirm wheel version is aligned with git tag cmd ConfirmVersionAndTag.py Publish the wheel/distribution to pypi cmd twine upload dist/*","title":"Publishing"},{"location":"publishing/#publishing-tianocore-edk2-pytool-library-edk2toollib","text":"The edk2toollib is published as a pypi (pip) module. The pip module is named edk2-pytool-library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here.","title":"Publishing Tianocore Edk2 PyTool Library (edk2toollib)"},{"location":"publishing/#version-scheme","text":"Versioning follows: aa.bb.cc and is based on tags in git aa == Major version. Changes don\u2019t need to be backward compatible bb == Minor version. Significant new features. Backward compatibility generally maintained except when new feature is used. cc == Patch version. Bug fix or small optional feature. Backward compatibility maintained.","title":"Version Scheme"},{"location":"publishing/#publishing-process","text":"NOTE: These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and checks. Update the readme.md Release Version History section with info on all important changes for this version. Remove the \u201c-dev\u201d tag from the version about to be released. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released and push tag. Tag format is v\\ .\\ .\\ Do the release process Install tools cmd pip install --upgrade -r requirements.publisher.txt Build a wheel cmd python setup.py sdist bdist_wheel Confirm wheel version is aligned with git tag cmd ConfirmVersionAndTag.py Publish the wheel/distribution to pypi cmd twine upload dist/*","title":"Publishing Process"},{"location":"using/","text":"Using Tianocore edk2 pytool library (edk2toollib) Installing NOTE: It is suggested to use python virtual environments to avoid dependency pollution and conflicts. Read More Install from pip pip install --upgrade edk2-pytool-library Using in python code from edk2toollib. < module > import < class >","title":"Using"},{"location":"using/#using-tianocore-edk2-pytool-library-edk2toollib","text":"","title":"Using Tianocore edk2 pytool library (edk2toollib)"},{"location":"using/#installing","text":"NOTE: It is suggested to use python virtual environments to avoid dependency pollution and conflicts. Read More Install from pip pip install --upgrade edk2-pytool-library","title":"Installing"},{"location":"using/#using-in-python-code","text":"from edk2toollib. < module > import < class >","title":"Using in python code"},{"location":"edk2toollib/","text":"Module edk2toollib View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.acpi edk2toollib.bin edk2toollib.log edk2toollib.tpm edk2toollib.uefi edk2toollib.utility_functions edk2toollib.windows","title":"Index"},{"location":"edk2toollib/#module-edk2toollib","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib"},{"location":"edk2toollib/#sub-modules","text":"edk2toollib.acpi edk2toollib.bin edk2toollib.log edk2toollib.tpm edk2toollib.uefi edk2toollib.utility_functions edk2toollib.windows","title":"Sub-modules"},{"location":"edk2toollib/bin/","text":"Module edk2toollib.bin View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Bin"},{"location":"edk2toollib/bin/#module-edk2toollibbin","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.bin"},{"location":"edk2toollib/utility_functions/","text":"Module edk2toollib.utility_functions View Source ## # Utility Functions to support re-use in python scripts. # Includes functions for running external commands, etc # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import re import os import logging import datetime import time import shutil import threading import subprocess import sys import inspect import platform import importlib from collections import namedtuple #### # Helper to allow Enum type to be used which allows better code readability # # ref: http://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python #### class Enum ( tuple ): __getattr__ = tuple . index #### # Class to support running commands from the shell in a python environment. # Don't use directly. # # PropagatingThread copied from sample here: # https://stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python #### class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ) . join () if self . exc : raise self . exc return self . ret #### # Helper functions for running commands from the shell in python environment # Don't use directly # # process output stream and write to log. # part of the threading pattern. # # http://stackoverflow.com/questions/19423008/logged-subprocess-communicate #### def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline () . decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () #### # Returns a namedtuple containing information about host machine. # # @return namedtuple Host(os=OS Type, arch=System Architecture, bit=Highest Order Bit) #### def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine logging . debug ( \"Getting host info for host: {0}\" . format ( str ( host_info ))) arch = None bit = None if ( \"x86\" in processor_info ) or ( \"AMD\" in processor_info ) or ( \"Intel\" in processor_info ): arch = \"x86\" elif ( \"ARM\" in processor_info ) or ( \"AARCH\" in processor_info ): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) #### # This is a mixing to do timing on a function. Use it like this: # # @timing # def function_i_want_to_time(): # ... #### def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000.0 )) return ret return wrap #### # Run a shell commmand and print the output to the log file # This is the public function that should be used to run commands from the shell in python environment # @param cmd - command being run, either quoted or not quoted # @param parameters - parameters string taken as is # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # @param logging_level - log level to log output at. Default is INFO # @param raise_exception_on_nonzero - Setting to true causes exception to be raised if the cmd # return code is not zero. # # @return returncode of called cmd #### def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\" \\' ' ) if \" \" in cmd : cmd = '\"' + cmd + '\"' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): outr = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) outr . start () c . wait () outr . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with error code: {1}\" . format ( cmd , c . returncode )) return c . returncode #### # Run a python script and print the output to the log file # This is the public function that should be used to execute python scripts from the shell in python environment. # The python script will be located using the path as if it was an executable. # # @param cmd - cmd string to run including parameters # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # # @return returncode of called cmd #### def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ): # locate python file on path pythonfile . strip ( '\" \\' ' ) if \" \" in pythonfile : pythonfile = '\"' + pythonfile + '\"' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s \" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s \" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ) . split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s \" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ ) #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow stronger # security practices (HSM / smart cards / etc) # # Signing is in format specified by UEFI authentacted variables #### def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # Signtool parameters from # https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/secure-boot-key-generation-and-signing-using-hsm--example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't eixst %s \" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow # stronger security practices (HSM / smart cards / etc) # # Signing is catalog format which is an attached signature #### def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # todo: link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret ### # Function to print a byte list as hex and optionally output ascii as well as # offset within the buffer ### def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ): Ascii = \"\" for index in range ( len ( ByteList )): # Start of New Line if ( index % 16 == 0 ): if ( IncludeOffset ): print ( \"0x %04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ): if ( IncludeHexSep ): print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x %02X \" % ByteList [ index ], end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ): Ascii += \".\" else : Ascii += ( \" %c \" % ByteList [ index ]) # End of Line if ( index % 16 == 15 ): if ( IncludeAscii ): print ( \" %s \" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ): # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ): # Pad out to the correct spot while ( index % 16 != 15 ): print ( \" \" , end = '' ) if ( index % 16 == 7 ): # acount for the - symbol in the hex dump if ( IncludeOffset ): print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s \" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) # Simplified Comparison Function borrowed from StackOverflow... # https://stackoverflow.com/questions/1714027/version-number-comparison # With Python 3.0 help from: # https://docs.python.org/3.0/whatsnew/3.0.html#ordering-comparisons def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ) . split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if DesiredClassInstance is not None : raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) DesiredClassInstance = _class return DesiredClassInstance if __name__ == '__main__' : pass # Test code for printing a byte buffer # a = [0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3a, 0x3b, 0x3c, 0x3d] # index = 0x55 # while(index < 0x65): # a.append(index) # PrintByteList(a) # index += 1 Functions CatalogSignWithSignTool def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ) View Source def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # todo : link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret DetachedSignWithSignTool def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = '1.2.840.113549.1.7.2' , Eku = None ) View Source def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # Signtool parameters from # https : // docs . microsoft . com / en - us / windows - hardware / manufacture / desktop / secure - boot - key - generation - and - signing - using - hsm --example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't eixst %s\" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret GetHostInfo def GetHostInfo ( ) View Source def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine logging . debug ( \"Getting host info for host: {0}\" . format ( str ( host_info ))) arch = None bit = None if ( \"x86\" in processor_info ) or ( \"AMD\" in processor_info ) or ( \"Intel\" in processor_info ): arch = \"x86\" elif ( \"ARM\" in processor_info ) or ( \"AARCH\" in processor_info ): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) PrintByteList def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) View Source def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) : Ascii = \"\" for index in range ( len ( ByteList )) : # Start of New Line if ( index % 16 == 0 ) : if ( IncludeOffset ) : print ( \"0x%04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ) : if ( IncludeHexSep ) : print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x%02X\" % ByteList [ index ] , end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ) : Ascii += \".\" else : Ascii += ( \"%c\" % ByteList [ index ] ) # End of Line if ( index % 16 == 15 ) : if ( IncludeAscii ) : print ( \" %s\" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ) : # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ) : # Pad out to the correct spot while ( index % 16 != 15 ) : print ( \" \" , end = '' ) if ( index % 16 == 7 ) : # acount for the - symbol in the hex dump if ( IncludeOffset ) : print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s\" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) RunCmd def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\"\\'') if \" \" in cmd: cmd = ' \"' + cmd + '\" ' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): outr = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) outr . start () c . wait () outr . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with error code: {1}\" . format ( cmd , c . returncode )) return c . returncode RunPythonScript def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ) View Source def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ): # locate python file on path pythonfile . strip ( '\"\\'') if \" \" in pythonfile: pythonfile = ' \"' + pythonfile + '\" ' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s\" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s\" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ). split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s\" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ ) import_module_by_file_name def import_module_by_file_name ( module_file_path ) Standard method of importing a Python file. Expecting absolute path. View Source def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule locate_class_in_module def locate_class_in_module ( Module , DesiredClass ) Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. View Source def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if DesiredClassInstance is not None : raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) DesiredClassInstance = _class return DesiredClassInstance reader def reader ( filepath , outstream , stream , logging_level = 20 ) View Source def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline (). decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () timing def timing ( f ) View Source def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000 . 0 )) return ret return wrap version_compare def version_compare ( version1 , version2 ) View Source def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ). split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) Classes Enum class Enum ( / , * args , ** kwargs ) Built-in immutable sequence. If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable\u2019s items. If the argument is a tuple, the return value is the same object. View Source class Enum ( tuple ): __getattr__ = tuple . index Ancestors (in MRO) builtins.tuple Methods count def count ( self , value , / ) Return number of occurrences of value. index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. PropagatingThread class PropagatingThread ( group = None , target = None , name = None , args = (), kwargs = None , * , daemon = None ) A class that represents a thread of control. This class can be safely subclassed in a limited fashion. There are two ways to specify the activity: by passing a callable object to the constructor, or by overriding the run() method in a subclass. View Source class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try: if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target (* self . _Thread__args , ** self . _Thread__kwargs ) else: self . ret = self . _target (* self . _args , ** self . _kwargs ) except BaseException as e: self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc: raise self . exc return self . ret Ancestors (in MRO) threading.Thread Instance variables daemon A boolean value indicating whether this thread is a daemon thread. This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. The entire Python program exits when only daemon threads are left. ident Thread identifier of this thread or None if it has not been started. This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. name A string used for identification purposes only. It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor. Methods getName def getName ( self ) View Source def getName ( self ): return self . name isAlive def isAlive ( self ) Return whether the thread is alive. This method is deprecated, use is_alive() instead. View Source def isAlive ( self ): \"\"\"Return whether the thread is alive. This method is deprecated, use is_alive() instead. \"\"\" import warnings warnings . warn ( 'isAlive() is deprecated, use is_alive() instead' , PendingDeprecationWarning , stacklevel = 2 ) return self . is_alive () isDaemon def isDaemon ( self ) View Source def isDaemon ( self ): return self . daemon is_alive def is_alive ( self ) Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. View Source def is_alive ( self ): \"\"\"Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. \"\"\" assert self . _initialized , \"Thread.__init__() not called\" if self . _is_stopped or not self . _started . is_set (): return False self . _wait_for_tstate_lock ( False ) return not self . _is_stopped join def join ( self , timeout = None ) Wait until the thread terminates. This blocks the calling thread until the thread whose join() method is called terminates \u2013 either normally or through an unhandled exception or until the optional timeout occurs. When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened \u2013 if the thread is still alive, the join() call timed out. When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception. View Source def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc : raise self . exc return self . ret run def run ( self ) Method representing the thread\u2019s activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object\u2019s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. View Source def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3 . self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e setDaemon def setDaemon ( self , daemonic ) View Source def setDaemon ( self , daemonic ): self . daemon = daemonic setName def setName ( self , name ) View Source def setName ( self , name ): self . name = name start def start ( self ) Start the thread\u2019s activity. It must be called at most once per thread object. It arranges for the object\u2019s run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. View Source def start ( self ) : \"\"\"Start the thread's activity. It must be called at most once per thread object. It arranges for the object's run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. \"\"\" if not self . _initialized : raise RuntimeError ( \"thread.__init__() not called\" ) if self . _started . is_set () : raise RuntimeError ( \"threads can only be started once\" ) with _active_limbo_lock : _limbo [ self ] = self try : _start_new_thread ( self . _bootstrap , ()) except Exception : with _active_limbo_lock : del _limbo [ self ] raise self . _started . wait ()","title":"Utility functions"},{"location":"edk2toollib/utility_functions/#module-edk2toollibutility_functions","text":"View Source ## # Utility Functions to support re-use in python scripts. # Includes functions for running external commands, etc # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import re import os import logging import datetime import time import shutil import threading import subprocess import sys import inspect import platform import importlib from collections import namedtuple #### # Helper to allow Enum type to be used which allows better code readability # # ref: http://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python #### class Enum ( tuple ): __getattr__ = tuple . index #### # Class to support running commands from the shell in a python environment. # Don't use directly. # # PropagatingThread copied from sample here: # https://stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python #### class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ) . join () if self . exc : raise self . exc return self . ret #### # Helper functions for running commands from the shell in python environment # Don't use directly # # process output stream and write to log. # part of the threading pattern. # # http://stackoverflow.com/questions/19423008/logged-subprocess-communicate #### def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline () . decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close () #### # Returns a namedtuple containing information about host machine. # # @return namedtuple Host(os=OS Type, arch=System Architecture, bit=Highest Order Bit) #### def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine logging . debug ( \"Getting host info for host: {0}\" . format ( str ( host_info ))) arch = None bit = None if ( \"x86\" in processor_info ) or ( \"AMD\" in processor_info ) or ( \"Intel\" in processor_info ): arch = \"x86\" elif ( \"ARM\" in processor_info ) or ( \"AARCH\" in processor_info ): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit ) #### # This is a mixing to do timing on a function. Use it like this: # # @timing # def function_i_want_to_time(): # ... #### def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000.0 )) return ret return wrap #### # Run a shell commmand and print the output to the log file # This is the public function that should be used to run commands from the shell in python environment # @param cmd - command being run, either quoted or not quoted # @param parameters - parameters string taken as is # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # @param logging_level - log level to log output at. Default is INFO # @param raise_exception_on_nonzero - Setting to true causes exception to be raised if the cmd # return code is not zero. # # @return returncode of called cmd #### def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\" \\' ' ) if \" \" in cmd : cmd = '\"' + cmd + '\"' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): outr = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) outr . start () c . wait () outr . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with error code: {1}\" . format ( cmd , c . returncode )) return c . returncode #### # Run a python script and print the output to the log file # This is the public function that should be used to execute python scripts from the shell in python environment. # The python script will be located using the path as if it was an executable. # # @param cmd - cmd string to run including parameters # @param capture - boolean to determine if caller wants the output captured in any format. # @param workingdir - path to set to the working directory before running the command. # @param outfile - capture output to file of given path. # @param outstream - capture output to a stream. # @param environ - shell environment variables dictionary that replaces the one inherited from the # current process. # # @return returncode of called cmd #### def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ): # locate python file on path pythonfile . strip ( '\" \\' ' ) if \" \" in pythonfile : pythonfile = '\"' + pythonfile + '\"' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s \" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s \" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ) . split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s \" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ ) #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow stronger # security practices (HSM / smart cards / etc) # # Signing is in format specified by UEFI authentacted variables #### def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # Signtool parameters from # https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/secure-boot-key-generation-and-signing-using-hsm--example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't eixst %s \" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret #### # Locally Sign input file using Windows SDK signtool. This will use a local Pfx file. # WARNING!!! : This should not be used for production signing as that process should follow # stronger security practices (HSM / smart cards / etc) # # Signing is catalog format which is an attached signature #### def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s \" % SignToolPath ) return - 1 # Adjust for spaces in the path (when calling the command). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https://docs.microsoft.com/en-us/dotnet/framework/tools/signtool-exe # todo: link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d \" % ret ) return ret ### # Function to print a byte list as hex and optionally output ascii as well as # offset within the buffer ### def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ): Ascii = \"\" for index in range ( len ( ByteList )): # Start of New Line if ( index % 16 == 0 ): if ( IncludeOffset ): print ( \"0x %04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ): if ( IncludeHexSep ): print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x %02X \" % ByteList [ index ], end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ): Ascii += \".\" else : Ascii += ( \" %c \" % ByteList [ index ]) # End of Line if ( index % 16 == 15 ): if ( IncludeAscii ): print ( \" %s \" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ): # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ): # Pad out to the correct spot while ( index % 16 != 15 ): print ( \" \" , end = '' ) if ( index % 16 == 7 ): # acount for the - symbol in the hex dump if ( IncludeOffset ): print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s \" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" ) # Simplified Comparison Function borrowed from StackOverflow... # https://stackoverflow.com/questions/1714027/version-number-comparison # With Python 3.0 help from: # https://docs.python.org/3.0/whatsnew/3.0.html#ordering-comparisons def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ) . split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b ) def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if DesiredClassInstance is not None : raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) DesiredClassInstance = _class return DesiredClassInstance if __name__ == '__main__' : pass # Test code for printing a byte buffer # a = [0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3a, 0x3b, 0x3c, 0x3d] # index = 0x55 # while(index < 0x65): # a.append(index) # PrintByteList(a) # index += 1","title":"Module edk2toollib.utility_functions"},{"location":"edk2toollib/utility_functions/#functions","text":"","title":"Functions"},{"location":"edk2toollib/utility_functions/#catalogsignwithsigntool","text":"def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ) View Source def CatalogSignWithSignTool ( SignToolPath , ToSignFilePath , PfxFilePath , PfxPass = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( ToSignFilePath ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # todo : link to catalog signing documentation params = \"sign /a /fd SHA256 /f \" + PfxFilePath if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params , workingdir = OutputDir ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret","title":"CatalogSignWithSignTool"},{"location":"edk2toollib/utility_functions/#detachedsignwithsigntool","text":"def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = '1.2.840.113549.1.7.2' , Eku = None ) View Source def DetachedSignWithSignTool ( SignToolPath , ToSignFilePath , SignatureOutputFile , PfxFilePath , PfxPass = None , Oid = \"1.2.840.113549.1.7.2\" , Eku = None ): # check signtool path if not os . path . exists ( SignToolPath ): logging . error ( \"Path to signtool invalid. %s\" % SignToolPath ) return - 1 # Adjust for spaces in the path ( when calling the command ). if \" \" in SignToolPath : SignToolPath = '\"' + SignToolPath + '\"' OutputDir = os . path . dirname ( SignatureOutputFile ) # Signtool docs https : // docs . microsoft . com / en - us / dotnet / framework / tools / signtool - exe # Signtool parameters from # https : // docs . microsoft . com / en - us / windows - hardware / manufacture / desktop / secure - boot - key - generation - and - signing - using - hsm --example # noqa: E501 # Search for \"Secure Boot Key Generation and Signing Using HSM\" params = 'sign /fd sha256 /p7ce DetachedSignedData /p7co ' + Oid + ' /p7 \"' + \\ OutputDir + '\" /f \"' + PfxFilePath + '\"' if Eku is not None : params += ' /u ' + Eku if PfxPass is not None : # add password if set params = params + ' /p ' + PfxPass params = params + ' /debug /v \"' + ToSignFilePath + '\" ' ret = RunCmd ( SignToolPath , params ) if ( ret != 0 ): logging . error ( \"Signtool failed %d\" % ret ) return ret signedfile = os . path . join ( OutputDir , os . path . basename ( ToSignFilePath ) + \".p7\" ) if ( not os . path . isfile ( signedfile )): raise Exception ( \"Output file doesn't eixst %s\" % signedfile ) shutil . move ( signedfile , SignatureOutputFile ) return ret","title":"DetachedSignWithSignTool"},{"location":"edk2toollib/utility_functions/#gethostinfo","text":"def GetHostInfo ( ) View Source def GetHostInfo (): Host = namedtuple ( 'Host' , 'os arch bit' ) host_info = platform . uname () os = host_info . system processor_info = host_info . machine logging . debug ( \"Getting host info for host: {0}\" . format ( str ( host_info ))) arch = None bit = None if ( \"x86\" in processor_info ) or ( \"AMD\" in processor_info ) or ( \"Intel\" in processor_info ): arch = \"x86\" elif ( \"ARM\" in processor_info ) or ( \"AARCH\" in processor_info ): arch = \"ARM\" if \"32\" in processor_info : bit = \"32\" elif \"64\" in processor_info : bit = \"64\" if ( arch is None ) or ( bit is None ): raise EnvironmentError ( \"Host info could not be parsed: {0}\" . format ( str ( host_info ))) return Host ( os = os , arch = arch , bit = bit )","title":"GetHostInfo"},{"location":"edk2toollib/utility_functions/#printbytelist","text":"def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) View Source def PrintByteList ( ByteList , IncludeAscii = True , IncludeOffset = True , IncludeHexSep = True , OffsetStart = 0 ) : Ascii = \"\" for index in range ( len ( ByteList )) : # Start of New Line if ( index % 16 == 0 ) : if ( IncludeOffset ) : print ( \"0x%04X -\" % ( index + OffsetStart ), end = '' ) # Midpoint of a Line if ( index % 16 == 8 ) : if ( IncludeHexSep ) : print ( \" -\" , end = '' ) # Print As Hex Byte print ( \" 0x%02X\" % ByteList [ index ] , end = '' ) # Prepare to Print As Ascii if ( ByteList [ index ] < 0x20 ) or ( ByteList [ index ] > 0x7E ) : Ascii += \".\" else : Ascii += ( \"%c\" % ByteList [ index ] ) # End of Line if ( index % 16 == 15 ) : if ( IncludeAscii ) : print ( \" %s\" % Ascii , end = '' ) Ascii = \"\" print ( \"\" ) # Done - Lets check if we have partial if ( index % 16 != 15 ) : # Lets print any partial line of ascii if ( IncludeAscii ) and ( Ascii != \"\" ) : # Pad out to the correct spot while ( index % 16 != 15 ) : print ( \" \" , end = '' ) if ( index % 16 == 7 ) : # acount for the - symbol in the hex dump if ( IncludeOffset ) : print ( \" \" , end = '' ) index += 1 # print the ascii partial line print ( \" %s\" % Ascii , end = '' ) # print a single newline so that next print will be on new line print ( \"\" )","title":"PrintByteList"},{"location":"edk2toollib/utility_functions/#runcmd","text":"def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = 20 , raise_exception_on_nonzero = False ) View Source def RunCmd ( cmd , parameters , capture = True , workingdir = None , outfile = None , outstream = None , environ = None , logging_level = logging . INFO , raise_exception_on_nonzero = False ): cmd = cmd . strip ( '\"\\'') if \" \" in cmd: cmd = ' \"' + cmd + '\" ' if parameters is not None : parameters = parameters . strip () cmd += \" \" + parameters starttime = datetime . datetime . now () logging . log ( logging_level , \"Cmd to run is: \" + cmd ) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Starting---------------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) c = subprocess . Popen ( cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = workingdir , shell = True , env = environ ) if ( capture ): outr = PropagatingThread ( target = reader , args = ( outfile , outstream , c . stdout , logging_level )) outr . start () c . wait () outr . join () else : c . wait () endtime = datetime . datetime . now () delta = endtime - starttime endtime_str = \"{0[0]:02}:{0[1]:02}\" . format ( divmod ( delta . seconds , 60 )) logging . log ( logging_level , \"------------------------------------------------\" ) logging . log ( logging_level , \"--------------Cmd Output Finished---------------\" ) logging . log ( logging_level , \"--------- Running Time (mm:ss): \" + endtime_str + \" ----------\" ) logging . log ( logging_level , \"------------------------------------------------\" ) if raise_exception_on_nonzero and c . returncode != 0 : raise Exception ( \"{0} failed with error code: {1}\" . format ( cmd , c . returncode )) return c . returncode","title":"RunCmd"},{"location":"edk2toollib/utility_functions/#runpythonscript","text":"def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ) View Source def RunPythonScript ( pythonfile , params , capture = True , workingdir = None , outfile = None , outstream = None , environ = None ): # locate python file on path pythonfile . strip ( '\"\\'') if \" \" in pythonfile: pythonfile = ' \"' + pythonfile + '\" ' params . strip () logging . debug ( \"RunPythonScript: {0} {1}\" . format ( pythonfile , params )) if ( os . path . isabs ( pythonfile )): logging . debug ( \"Python Script was given as absolute path: %s\" % pythonfile ) elif ( os . path . isfile ( os . path . join ( os . getcwd (), pythonfile ))): pythonfile = os . path . join ( os . getcwd (), pythonfile ) logging . debug ( \"Python Script was given as relative path: %s\" % pythonfile ) else : # loop thru path environment variable for a in os . getenv ( \"PATH\" ). split ( os . pathsep ): a = os . path . normpath ( a ) if os . path . isfile ( os . path . join ( a , pythonfile )): pythonfile = os . path . join ( a , pythonfile ) logging . debug ( \"Python Script was found on the path: %s\" % pythonfile ) break params = pythonfile + \" \" + params return RunCmd ( sys . executable , params , capture = capture , workingdir = workingdir , outfile = outfile , outstream = outstream , environ = environ )","title":"RunPythonScript"},{"location":"edk2toollib/utility_functions/#import_module_by_file_name","text":"def import_module_by_file_name ( module_file_path ) Standard method of importing a Python file. Expecting absolute path. View Source def import_module_by_file_name ( module_file_path ): ''' Standard method of importing a Python file. Expecting absolute path. ''' module_name = os . path . basename ( module_file_path ) spec = importlib . util . spec_from_file_location ( module_name , module_file_path ) if spec is None : raise RuntimeError ( f \"Expected module file named {module_file_path}\" ) ImportedModule = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( ImportedModule ) return ImportedModule","title":"import_module_by_file_name"},{"location":"edk2toollib/utility_functions/#locate_class_in_module","text":"def locate_class_in_module ( Module , DesiredClass ) Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. View Source def locate_class_in_module ( Module , DesiredClass ): ''' Given a module and a class, this function will return the subclass of DesiredClass in Module. Throws exception if two classes are found that fit the same criterea. ''' DesiredClassInstance = None # Pull out the contents of the module that was provided module_contents = dir ( Module ) # Filter through the Module, we're only looking for classes. classList = [ getattr ( Module , obj ) for obj in module_contents if inspect . isclass ( getattr ( Module , obj ))] for _class in classList : # Classes that the module import show up in this list too so we need # to make sure it's an INSTANCE of DesiredClass, not DesiredClass itself! if _class is not DesiredClass and issubclass ( _class , DesiredClass ): if DesiredClassInstance is not None : raise RuntimeError ( f \"Multiple instances were found: \\n\\t {DesiredClassInstance} \\n\\t {_class}\" ) DesiredClassInstance = _class return DesiredClassInstance","title":"locate_class_in_module"},{"location":"edk2toollib/utility_functions/#reader","text":"def reader ( filepath , outstream , stream , logging_level = 20 ) View Source def reader ( filepath , outstream , stream , logging_level = logging . INFO ): f = None # open file if caller provided path if ( filepath ): f = open ( filepath , \"w\" ) while True : s = stream . readline (). decode () if not s : break if ( f is not None ): # write to file if caller provided file f . write ( s ) if ( outstream is not None ): # write to stream object if caller provided object outstream . write ( s ) logging . log ( logging_level , s . rstrip ()) stream . close () if ( f is not None ): f . close ()","title":"reader"},{"location":"edk2toollib/utility_functions/#timing","text":"def timing ( f ) View Source def timing ( f ): def wrap ( * args ): time1 = time . time () ret = f ( * args ) time2 = time . time () logging . debug ( '{:s} function took {:.3f} ms' . format ( f . __name__ , ( time2 - time1 ) * 1000 . 0 )) return ret return wrap","title":"timing"},{"location":"edk2toollib/utility_functions/#version_compare","text":"def version_compare ( version1 , version2 ) View Source def version_compare ( version1 , version2 ): def normalize ( v ): return [ int ( x ) for x in re . sub ( r '(\\.0+)*$' , '' , v ). split ( \".\" )] ( a , b ) = ( normalize ( version1 ), normalize ( version2 )) return ( a > b ) - ( a < b )","title":"version_compare"},{"location":"edk2toollib/utility_functions/#classes","text":"","title":"Classes"},{"location":"edk2toollib/utility_functions/#enum","text":"class Enum ( / , * args , ** kwargs ) Built-in immutable sequence. If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable\u2019s items. If the argument is a tuple, the return value is the same object. View Source class Enum ( tuple ): __getattr__ = tuple . index","title":"Enum"},{"location":"edk2toollib/utility_functions/#ancestors-in-mro","text":"builtins.tuple","title":"Ancestors (in MRO)"},{"location":"edk2toollib/utility_functions/#methods","text":"","title":"Methods"},{"location":"edk2toollib/utility_functions/#count","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"edk2toollib/utility_functions/#index","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"edk2toollib/utility_functions/#propagatingthread","text":"class PropagatingThread ( group = None , target = None , name = None , args = (), kwargs = None , * , daemon = None ) A class that represents a thread of control. This class can be safely subclassed in a limited fashion. There are two ways to specify the activity: by passing a callable object to the constructor, or by overriding the run() method in a subclass. View Source class PropagatingThread ( threading . Thread ): def run ( self ): self . exc = None try: if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3. self . ret = self . _Thread__target (* self . _Thread__args , ** self . _Thread__kwargs ) else: self . ret = self . _target (* self . _args , ** self . _kwargs ) except BaseException as e: self . exc = e def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc: raise self . exc return self . ret","title":"PropagatingThread"},{"location":"edk2toollib/utility_functions/#ancestors-in-mro_1","text":"threading.Thread","title":"Ancestors (in MRO)"},{"location":"edk2toollib/utility_functions/#instance-variables","text":"daemon A boolean value indicating whether this thread is a daemon thread. This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. The entire Python program exits when only daemon threads are left. ident Thread identifier of this thread or None if it has not been started. This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. name A string used for identification purposes only. It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor.","title":"Instance variables"},{"location":"edk2toollib/utility_functions/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/utility_functions/#getname","text":"def getName ( self ) View Source def getName ( self ): return self . name","title":"getName"},{"location":"edk2toollib/utility_functions/#isalive","text":"def isAlive ( self ) Return whether the thread is alive. This method is deprecated, use is_alive() instead. View Source def isAlive ( self ): \"\"\"Return whether the thread is alive. This method is deprecated, use is_alive() instead. \"\"\" import warnings warnings . warn ( 'isAlive() is deprecated, use is_alive() instead' , PendingDeprecationWarning , stacklevel = 2 ) return self . is_alive ()","title":"isAlive"},{"location":"edk2toollib/utility_functions/#isdaemon","text":"def isDaemon ( self ) View Source def isDaemon ( self ): return self . daemon","title":"isDaemon"},{"location":"edk2toollib/utility_functions/#is_alive","text":"def is_alive ( self ) Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. View Source def is_alive ( self ): \"\"\"Return whether the thread is alive. This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads. \"\"\" assert self . _initialized , \"Thread.__init__() not called\" if self . _is_stopped or not self . _started . is_set (): return False self . _wait_for_tstate_lock ( False ) return not self . _is_stopped","title":"is_alive"},{"location":"edk2toollib/utility_functions/#join","text":"def join ( self , timeout = None ) Wait until the thread terminates. This blocks the calling thread until the thread whose join() method is called terminates \u2013 either normally or through an unhandled exception or until the optional timeout occurs. When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened \u2013 if the thread is still alive, the join() call timed out. When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception. View Source def join ( self , timeout = None ): super ( PropagatingThread , self ). join () if self . exc : raise self . exc return self . ret","title":"join"},{"location":"edk2toollib/utility_functions/#run","text":"def run ( self ) Method representing the thread\u2019s activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object\u2019s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. View Source def run ( self ): self . exc = None try : if hasattr ( self , '_Thread__target' ): # Thread uses name mangling prior to Python 3 . self . ret = self . _Thread__target ( * self . _Thread__args , ** self . _Thread__kwargs ) else : self . ret = self . _target ( * self . _args , ** self . _kwargs ) except BaseException as e : self . exc = e","title":"run"},{"location":"edk2toollib/utility_functions/#setdaemon","text":"def setDaemon ( self , daemonic ) View Source def setDaemon ( self , daemonic ): self . daemon = daemonic","title":"setDaemon"},{"location":"edk2toollib/utility_functions/#setname","text":"def setName ( self , name ) View Source def setName ( self , name ): self . name = name","title":"setName"},{"location":"edk2toollib/utility_functions/#start","text":"def start ( self ) Start the thread\u2019s activity. It must be called at most once per thread object. It arranges for the object\u2019s run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. View Source def start ( self ) : \"\"\"Start the thread's activity. It must be called at most once per thread object. It arranges for the object's run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. \"\"\" if not self . _initialized : raise RuntimeError ( \"thread.__init__() not called\" ) if self . _started . is_set () : raise RuntimeError ( \"threads can only be started once\" ) with _active_limbo_lock : _limbo [ self ] = self try : _start_new_thread ( self . _bootstrap , ()) except Exception : with _active_limbo_lock : del _limbo [ self ] raise self . _started . wait ()","title":"start"},{"location":"edk2toollib/acpi/","text":"Module edk2toollib.acpi View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.acpi.dmar_parser","title":"Index"},{"location":"edk2toollib/acpi/#module-edk2toollibacpi","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.acpi"},{"location":"edk2toollib/acpi/#sub-modules","text":"edk2toollib.acpi.dmar_parser","title":"Sub-modules"},{"location":"edk2toollib/acpi/dmar_parser/","text":"Module edk2toollib.acpi.dmar_parser View Source ## # Python script that converts a raw DMAR table into a struct # More details see https://software.intel.com/sites/default/files/managed/c5/15/vt-directed-io-spec.pdf # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import sys import struct import xml.etree.ElementTree as ET DMARParserVersion = '1.01' class DMARTable ( object ): # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ): self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable . DMARHeaderLength :] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header . Length :] self . xml = self . toXml () def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ): retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ): return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ) . text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ): STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ): return \"\"\" \\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x %08X Revision : 0x %02X Checksum : 0x %02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x %08X Creator ID : %s Creator Revision : 0x %08X Host Address Width : 0x %02X Flags : 0x %02X \\n \"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x %X ' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) return xml_repr class RemappingStructHeader ( object ): STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ): ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ): return \"\"\" \\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBHQ' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . DRDHHeaderLength :] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n DRHD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x Register Base Address : 0x %016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHHHQQ' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . RMRRHeaderLength :] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ): retString = \"\" for index , item in enumerate ( self . DeviceScope ): retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ): xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x %X ' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x %X ' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n RMRR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %04X Segment Number : 0x %04x Reserved Memory Base Address : 0x %016x Reserved Memory Region Limit Address : 0x %016x \\n \"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBH' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . ASTRHeaderLength :] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n ASTR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHIQI' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x %X ' % self . ProximityDomain ) return xml_repr def __str__ ( self ): return \"\"\" \\n RHSA ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %08X Register Base Address : 0x %016X Proximity Domain : 0x %08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ): header_format = '=HH' def __init__ ( self , header_byte_array , length ): self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ): self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i : i + 1 ])[ 0 ] header_byte_array = header_byte_array [ 7 :] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x %X ' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , ' %s ' % self . ACPIObjectName ) return xml_repr def __str__ ( self ): return \"\"\" \\n ANDD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %06X ACPI Device Number : 0x %02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ): STRUCT_FORMAT = '=BBHBB' def __init__ ( self , header_byte_array ): ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset : offset + 1 ]), struct . unpack ( \"<B\" , header_byte_array [ offset + 1 : offset + 2 ]))) offset += 2 number_path_entries -= 1 def getPath ( self ): retstring = \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ): retstring = \"\"\" \\n\\t\\t %s \\t\\t -------------------------------------------------- \\t\\t Type : 0x %02X \\t\\t Length : 0x %02X \\t\\t Reserved : 0x %04X \\t\\t Enumeration ID : 0x %02x \\t\\t Start Bus Number : 0x %02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \" \\n \" return retstring Variables DMARParserVersion Classes DMARTable class DMARTable ( data ) View Source class DMARTable ( object ) : # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ) : self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable.DMARHeaderLength: ] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header.Length: ] self . xml = self . toXml () def toXml ( self ) : root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ) : retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ) : return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ) : return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ) : goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ) : print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ) : STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ) : return \"\"\"\\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x%08X Revision : 0x%02X Checksum : 0x%02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x%08X Creator ID : %s Creator Revision : 0x%08X Host Address Width : 0x%02X Flags : 0x%02X\\n\"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x%X' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) return xml_repr class RemappingStructHeader ( object ) : STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ) : return \"\"\"\\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBHQ' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.DRDHHeaderLength: ] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n DRHD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x Register Base Address : 0x%016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHHHQQ' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.RMRRHeaderLength: ] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ) : retString = \"\" for index , item in enumerate ( self . DeviceScope ) : retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ) : xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x%X' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x%X' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n RMRR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%04X Segment Number : 0x%04x Reserved Memory Base Address : 0x%016x Reserved Memory Region Limit Address : 0x%016x\\n\"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBH' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.ASTRHeaderLength: ] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n ASTR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHIQI' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x%X' % self . ProximityDomain ) return xml_repr def __str__ ( self ) : return \"\"\"\\n RHSA ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%08X Register Base Address : 0x%016X Proximity Domain : 0x%08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ) : header_format = '=HH' def __init__ ( self , header_byte_array , length ) : self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ) : self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i:i + 1 ] ) [ 0 ] header_byte_array = header_byte_array [ 7: ] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x%X' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , '%s' % self . ACPIObjectName ) return xml_repr def __str__ ( self ) : return \"\"\"\\n ANDD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%06X ACPI Device Number : 0x%02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ) : STRUCT_FORMAT = '=BBHBB' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset:offset + 1 ] ), struct . unpack ( \"<B\" , header_byte_array [ offset + 1:offset + 2 ] ))) offset += 2 number_path_entries -= 1 def getPath ( self ) : retstring = \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ) : retstring = \"\"\"\\n\\t\\t %s \\t\\t-------------------------------------------------- \\t\\t Type : 0x%02X \\t\\t Length : 0x%02X \\t\\t Reserved : 0x%04X \\t\\t Enumeration ID : 0x%02x \\t\\t Start Bus Number : 0x%02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \"\\n\" return retstring Class variables ANDDHeaderLength ANDDStruct ASTRHeaderLength ATSRStruct AcpiTableHeader DMARHeaderLength DRDHHeaderLength DRHDStruct DeviceScopeHeaderLength DeviceScopeStruct RHSAStruct RMRRHeaderLength RMRRStruct RemappingStructHeader Methods ANDDCount def ANDDCount ( self ) View Source def ANDDCount ( self ): return self . dmar_table . ANDDCount CheckRMRRCount def CheckRMRRCount ( self , goldenxml = None ) View Source def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True DMARBitEnabled def DMARBitEnabled ( self ) View Source def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) toXml def toXml ( self ) View Source def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root","title":"Dmar parser"},{"location":"edk2toollib/acpi/dmar_parser/#module-edk2toollibacpidmar_parser","text":"View Source ## # Python script that converts a raw DMAR table into a struct # More details see https://software.intel.com/sites/default/files/managed/c5/15/vt-directed-io-spec.pdf # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import sys import struct import xml.etree.ElementTree as ET DMARParserVersion = '1.01' class DMARTable ( object ): # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ): self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable . DMARHeaderLength :] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header . Length :] self . xml = self . toXml () def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ): retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ): return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ) . text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ): STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ): ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ): return \"\"\" \\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x %08X Revision : 0x %02X Checksum : 0x %02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x %08X Creator ID : %s Creator Revision : 0x %08X Host Address Width : 0x %02X Flags : 0x %02X \\n \"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ): xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , ' %s ' % self . Signature ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Revision' , '0x %X ' % self . Revision ) xml_repr . set ( 'Checksum' , '0x %X ' % self . Checksum ) xml_repr . set ( 'OEMID' , ' %s ' % self . OEMID ) xml_repr . set ( 'OEMTableID' , ' %s ' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x %X ' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , ' %s ' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x %X ' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x %X ' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) return xml_repr class RemappingStructHeader ( object ): STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ): ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ): return \"\"\" \\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBHQ' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . DRDHHeaderLength :] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n DRHD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x Register Base Address : 0x %016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHHHQQ' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . RMRRHeaderLength :] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ): retString = \"\" for index , item in enumerate ( self . DeviceScope ): retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ): xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x %X ' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x %X ' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n RMRR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %04X Segment Number : 0x %04x Reserved Memory Base Address : 0x %016x Reserved Memory Region Limit Address : 0x %016x \\n \"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHBBH' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable . ASTRHeaderLength :] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope . Length :] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ): xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Flags' , '0x %X ' % self . Flags ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x %X ' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x %X ' % item . Type ) xml_subitem . set ( 'Length' , '0x %X ' % item . Length ) xml_subitem . set ( 'Reserved' , '0x %X ' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x %X ' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x %X ' % item . StartBusNumber ) return xml_repr def __str__ ( self ): retstring = \"\"\" \\n ASTR ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Flags : 0x %02X Reserved : 0x %02X Segment Number : 0x %04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ): STRUCT_FORMAT = '=HHIQI' def __init__ ( self , header_byte_array , length ): ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x %X ' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x %X ' % self . ProximityDomain ) return xml_repr def __str__ ( self ): return \"\"\" \\n RHSA ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %08X Register Base Address : 0x %016X Proximity Domain : 0x %08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ): header_format = '=HH' def __init__ ( self , header_byte_array , length ): self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ): self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i : i + 1 ])[ 0 ] header_byte_array = header_byte_array [ 7 :] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ): xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x %X ' % self . Type ) xml_repr . set ( 'Length' , '0x %X ' % self . Length ) xml_repr . set ( 'Reserved' , '0x %X ' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x %X ' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , ' %s ' % self . ACPIObjectName ) return xml_repr def __str__ ( self ): return \"\"\" \\n ANDD ------------------------------------------------------------------ Type : 0x %04X Length : 0x %04X Reserved : 0x %06X ACPI Device Number : 0x %02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ): STRUCT_FORMAT = '=BBHBB' def __init__ ( self , header_byte_array ): ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset : offset + 1 ]), struct . unpack ( \"<B\" , header_byte_array [ offset + 1 : offset + 2 ]))) offset += 2 number_path_entries -= 1 def getPath ( self ): retstring = \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ): retstring = \"\"\" \\n\\t\\t %s \\t\\t -------------------------------------------------- \\t\\t Type : 0x %02X \\t\\t Length : 0x %02X \\t\\t Reserved : 0x %04X \\t\\t Enumeration ID : 0x %02x \\t\\t Start Bus Number : 0x %02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \" %02d \" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ): retstring += \" %02d \" % item [ 0 ] + \".\" + \" %01d \" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \" \\n \" return retstring","title":"Module edk2toollib.acpi.dmar_parser"},{"location":"edk2toollib/acpi/dmar_parser/#variables","text":"DMARParserVersion","title":"Variables"},{"location":"edk2toollib/acpi/dmar_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/acpi/dmar_parser/#dmartable","text":"class DMARTable ( data ) View Source class DMARTable ( object ) : # Header Lengths DMARHeaderLength = 48 DRDHHeaderLength = 16 RMRRHeaderLength = 24 ASTRHeaderLength = 8 ANDDHeaderLength = 8 DeviceScopeHeaderLength = 6 def __init__ ( self , data ) : self . dmar_table = self . ACPITableHeader ( data ) self . data = data [ DMARTable.DMARHeaderLength: ] while len ( self . data ) > 0 : # Get type and length of remapping struct remapping_header = self . Remp ( self . data ) assert remapping_header . Type < 5 , \"Reserved remapping struct found in DMAR table\" # Parse remapping struct if remapping_header . Type == 0 : remapping_header = self . DRHDStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 1 : remapping_header = self . RMRRStruct ( self . data , remapping_header . Length ) self . dmar_table . RMRRlist . append ( remapping_header ) elif remapping_header . Type == 2 : remapping_header = self . ATSRStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 3 : remapping_header = self . RHSAStruct ( self . data , remapping_header . Length ) elif remapping_header . Type == 4 : remapping_header = self . ANDDStruct ( self . data , remapping_header . Length ) self . dmar_table . ANDDCount += 1 else : print ( 'Reserved remapping struct found in DMAR table' ) sys . exit ( - 1 ) self . dmar_table . SubStructs . append ( remapping_header ) # Add to XML self . data = self . data [ remapping_header.Length: ] self . xml = self . toXml () def toXml ( self ) : root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root def __str__ ( self ) : retval = str ( self . dmar_table ) for sub in self . dmar_table . SubStructs : retval += str ( sub ) return retval def DMARBitEnabled ( self ) : return bool ( self . dmar_table . DMARBit ) def ANDDCount ( self ) : return self . dmar_table . ANDDCount def CheckRMRRCount ( self , goldenxml = None ) : goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ) : print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True class AcpiTableHeader ( object ) : STRUCT_FORMAT = '=4sIBB6s8sI4sIBB' size = struct . calcsize ( STRUCT_FORMAT ) def __init__ ( self , header_byte_array ) : ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) = struct . unpack_from ( DMARTable . AcpiTableHeader . STRUCT_FORMAT , header_byte_array ) self . DMARBit = self . Flags & 0x4 self . ANDDCount = 0 self . RMRRlist = list () self . SubStructs = list () def __str__ ( self ) : return \"\"\"\\n ACPI Table Header ------------------------------------------------------------------ Signature : %s Length : 0x%08X Revision : 0x%02X Checksum : 0x%02X OEM ID : %s OEM Table ID : %s OEM Revision : 0x%08X Creator ID : %s Creator Revision : 0x%08X Host Address Width : 0x%02X Flags : 0x%02X\\n\"\"\" % ( self . Signature , self . Length , self . Revision , self . Checksum , self . OEMID , self . OEMTableID , self . OEMRevision , self . CreatorID , self . CreatorRevision , self . HostAddressWidth , self . Flags ) def toXml ( self ) : xml_repr = ET . Element ( 'AcpiTableHeader' ) xml_repr . set ( 'Signature' , '%s' % self . Signature ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Revision' , '0x%X' % self . Revision ) xml_repr . set ( 'Checksum' , '0x%X' % self . Checksum ) xml_repr . set ( 'OEMID' , '%s' % self . OEMID ) xml_repr . set ( 'OEMTableID' , '%s' % self . OEMTableID ) xml_repr . set ( 'OEMRevision' , '0x%X' % self . OEMRevision ) xml_repr . set ( 'CreatorID' , '%s' % self . CreatorID ) xml_repr . set ( 'CreatorRevision' , '0x%X' % self . CreatorRevision ) xml_repr . set ( 'HostAddressWidth' , '0x%X' % self . HostAddressWidth ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) return xml_repr class RemappingStructHeader ( object ) : STRUCT_FORMAT = '=HH' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . RemappingStructHeader . STRUCT_FORMAT , header_byte_array ) def __str__ ( self ) : return \"\"\"\\n Remapping Struct Header ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X \"\"\" % ( self . Type , self . Length ) class DRHDStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBHQ' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) = struct . unpack_from ( DMARTable . DRHDStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.DRDHHeaderLength: ] bytes_left = self . Length - DMARTable . DRDHHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'DRHD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n DRHD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x Register Base Address : 0x%016x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber , self . RegisterBaseAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RMRRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHHHQQ' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) = struct . unpack_from ( DMARTable . RMRRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.RMRRHeaderLength: ] bytes_left = self . Length - DMARTable . RMRRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def getPath ( self ) : retString = \"\" for index , item in enumerate ( self . DeviceScope ) : retString += self . DeviceScope [ index ] . getPath () if index != len ( self . DeviceScope ) - 1 : retString += \", \" return retString def toXml ( self ) : xml_repr = ET . Element ( 'RMRR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) xml_repr . set ( 'ReservedMemoryBaseAddress' , '0x%X' % self . ReservedMemoryBaseAddress ) xml_repr . set ( 'ReservedMemoryRegionLimitAddress' , '0x%X' % self . ReservedMemoryRegionLimitAddress ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n RMRR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%04X Segment Number : 0x%04x Reserved Memory Base Address : 0x%016x Reserved Memory Region Limit Address : 0x%016x\\n\"\"\" % ( self . Type , self . Length , self . Reserved , self . SegmentNumber , self . ReservedMemoryBaseAddress , self . ReservedMemoryRegionLimitAddress ) for item in self . DeviceScope : retstring += str ( item ) return retstring class ATSRStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHBBH' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) = struct . unpack_from ( DMARTable . ATSRStruct . STRUCT_FORMAT , header_byte_array ) # Get Sub Structs self . DeviceScope = list () header_byte_array = header_byte_array [ DMARTable.ASTRHeaderLength: ] bytes_left = self . Length - DMARTable . ASTRHeaderLength while bytes_left > 0 : device_scope = DMARTable . DeviceScopeStruct ( header_byte_array ) header_byte_array = header_byte_array [ device_scope.Length: ] bytes_left -= device_scope . Length self . DeviceScope . append ( device_scope ) def toXml ( self ) : xml_repr = ET . Element ( 'ASTR' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Flags' , '0x%X' % self . Flags ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'SegmentNumber' , '0x%X' % self . SegmentNumber ) # Add SubStructs for item in self . DeviceScope : xml_subitem = ET . SubElement ( xml_repr , item . TypeString ) xml_subitem . set ( 'Type' , '0x%X' % item . Type ) xml_subitem . set ( 'Length' , '0x%X' % item . Length ) xml_subitem . set ( 'Reserved' , '0x%X' % item . Reserved ) xml_subitem . set ( 'EnumerationID' , '0x%X' % item . EnumerationID ) xml_subitem . set ( 'StartBusNumber' , '0x%X' % item . StartBusNumber ) return xml_repr def __str__ ( self ) : retstring = \"\"\"\\n ASTR ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Flags : 0x%02X Reserved : 0x%02X Segment Number : 0x%04x \"\"\" % ( self . Type , self . Length , self . Flags , self . Reserved , self . SegmentNumber ) for item in self . DeviceScope : retstring += str ( item ) return retstring class RHSAStruct ( RemappingStructHeader ) : STRUCT_FORMAT = '=HHIQI' def __init__ ( self , header_byte_array , length ) : ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) = struct . unpack_from ( DMARTable . RHSAStruct . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'RHSA' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'RegisterBaseAddress' , '0x%X' % self . RegisterBaseAddress ) xml_repr . set ( 'ProximityDomain' , '0x%X' % self . ProximityDomain ) return xml_repr def __str__ ( self ) : return \"\"\"\\n RHSA ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%08X Register Base Address : 0x%016X Proximity Domain : 0x%08x \"\"\" % ( self . Type , self . Length , self . Reserved , self . RegisterBaseAddress , self . ProximityDomain ) class ANDDStruct ( RemappingStructHeader ) : header_format = '=HH' def __init__ ( self , header_byte_array , length ) : self . STRUCT_FORMAT = '=B' ( self . Type , self . Length ) = struct . unpack_from ( DMARTable . ANDDStruct . header_format , header_byte_array ) # Since there is no variable of size 3 we need to manually pull into reserved self . Reserved = 0 for i in range ( 6 , 3 , - 1 ) : self . Reserved = self . Reserved << 8 self . Reserved |= struct . unpack ( \"<B\" , header_byte_array [ i:i + 1 ] ) [ 0 ] header_byte_array = header_byte_array [ 7: ] # Unpack remaining values self . STRUCT_FORMAT = self . STRUCT_FORMAT + str ( self . Length - DMARTable . ANDDHeaderLength ) + 's' ( self . ACPIDeviceNumber , self . ACPIObjectName ) = struct . unpack_from ( self . STRUCT_FORMAT , header_byte_array ) def toXml ( self ) : xml_repr = ET . Element ( 'ANDD' ) xml_repr . set ( 'Type' , '0x%X' % self . Type ) xml_repr . set ( 'Length' , '0x%X' % self . Length ) xml_repr . set ( 'Reserved' , '0x%X' % self . Reserved ) xml_repr . set ( 'ACPIDeviceNumber' , '0x%X' % self . ACPIDeviceNumber ) xml_repr . set ( 'ACPIObjectName' , '%s' % self . ACPIObjectName ) return xml_repr def __str__ ( self ) : return \"\"\"\\n ANDD ------------------------------------------------------------------ Type : 0x%04X Length : 0x%04X Reserved : 0x%06X ACPI Device Number : 0x%02X ACPI Object Name : %s \"\"\" % ( self . Type , self . Length , self . Reserved , self . ACPIDeviceNumber , self . ACPIObjectName ) class DeviceScopeStruct ( object ) : STRUCT_FORMAT = '=BBHBB' def __init__ ( self , header_byte_array ) : ( self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) = struct . unpack_from ( DMARTable . DeviceScopeStruct . STRUCT_FORMAT , header_byte_array ) assert self . Type < 6 , \"Reserved Device Scope Type Found\" if self . Type == 1 : self . TypeString = \"PCI Endpoint Device\" elif self . Type == 2 : self . TypeString = \"PCI Sub-hierarchy\" elif self . Type == 3 : self . TypeString = \"IOAPIC\" elif self . Type == 4 : self . TypeString = \"MSI_CAPABLE_HPET\" elif self . Type == 5 : self . TypeString = \"ACPI_NAMESPACE_DEVICE\" else : print ( \"Reserved Device Scope Type Found\" ) sys . exit ( - 1 ) number_path_entries = ( self . Length - DMARTable . DeviceScopeHeaderLength ) / 2 offset = 6 self . Path = list () while number_path_entries > 0 : self . Path . append (( struct . unpack ( \"<B\" , header_byte_array [ offset:offset + 1 ] ), struct . unpack ( \"<B\" , header_byte_array [ offset + 1:offset + 2 ] ))) offset += 2 number_path_entries -= 1 def getPath ( self ) : retstring = \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" return retstring def __str__ ( self ) : retstring = \"\"\"\\n\\t\\t %s \\t\\t-------------------------------------------------- \\t\\t Type : 0x%02X \\t\\t Length : 0x%02X \\t\\t Reserved : 0x%04X \\t\\t Enumeration ID : 0x%02x \\t\\t Start Bus Number : 0x%02x \\t\\t Path : \"\"\" % ( self . TypeString , self . Type , self . Length , self . Reserved , self . EnumerationID , self . StartBusNumber ) retstring += \"%02d\" % self . StartBusNumber + \":\" for ( index , item ) in enumerate ( self . Path ) : retstring += \"%02d\" % item [ 0 ] + \".\" + \"%01d\" % item [ 1 ] if index != len ( self . Path ) - 1 : retstring += \":\" retstring += \"\\n\" return retstring","title":"DMARTable"},{"location":"edk2toollib/acpi/dmar_parser/#class-variables","text":"ANDDHeaderLength ANDDStruct ASTRHeaderLength ATSRStruct AcpiTableHeader DMARHeaderLength DRDHHeaderLength DRHDStruct DeviceScopeHeaderLength DeviceScopeStruct RHSAStruct RMRRHeaderLength RMRRStruct RemappingStructHeader","title":"Class variables"},{"location":"edk2toollib/acpi/dmar_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/acpi/dmar_parser/#anddcount","text":"def ANDDCount ( self ) View Source def ANDDCount ( self ): return self . dmar_table . ANDDCount","title":"ANDDCount"},{"location":"edk2toollib/acpi/dmar_parser/#checkrmrrcount","text":"def CheckRMRRCount ( self , goldenxml = None ) View Source def CheckRMRRCount ( self , goldenxml = None ): goldenignores = set () if goldenxml is None or not os . path . isfile ( goldenxml ): print ( \"XML File not found\" ) else : goldenfile = ET . parse ( goldenxml ) goldenroot = goldenfile . getroot () for RMRR in goldenroot : goldenignores . add ( RMRR . find ( 'Path' ). text . lower ()) for RMRR in self . dmar_table . RMRRlist : if RMRR . getPath () not in goldenignores : print ( \"RMRR PCIe Endpoint \" + RMRR . getPath () + \" found but not in golden XML\" ) return False return True","title":"CheckRMRRCount"},{"location":"edk2toollib/acpi/dmar_parser/#dmarbitenabled","text":"def DMARBitEnabled ( self ) View Source def DMARBitEnabled ( self ): return bool ( self . dmar_table . DMARBit )","title":"DMARBitEnabled"},{"location":"edk2toollib/acpi/dmar_parser/#toxml","text":"def toXml ( self ) View Source def toXml ( self ): root = ET . Element ( 'DMAR Table' ) root . append ( self . dmar_table . toXml ()) for sub in self . dmar_table . SubStructs : root . append ( sub . toXml ()) return root","title":"toXml"},{"location":"edk2toollib/log/","text":"Module edk2toollib.log View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.log.ansi_handler edk2toollib.log.ansi_handler_test edk2toollib.log.file_handler edk2toollib.log.junit_report_format edk2toollib.log.markdown_handler edk2toollib.log.string_handler","title":"Index"},{"location":"edk2toollib/log/#module-edk2toolliblog","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.log"},{"location":"edk2toollib/log/#sub-modules","text":"edk2toollib.log.ansi_handler edk2toollib.log.ansi_handler_test edk2toollib.log.file_handler edk2toollib.log.junit_report_format edk2toollib.log.markdown_handler edk2toollib.log.string_handler","title":"Sub-modules"},{"location":"edk2toollib/log/ansi_handler/","text":"Module edk2toollib.log.ansi_handler View Source ## # Handle basic logging with color via ANSI comamnds # Will call into win32 commands as needed when needed # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import re from edk2toollib.utility_functions import GetHostInfo try : # try to import windows types from winDLL import ctypes from ctypes import LibraryLoader windll = LibraryLoader ( ctypes . WinDLL ) from ctypes import wintypes except ( AttributeError , ImportError ): # if we run into an exception (ie on unix or linux) windll = None # create blank lambda def SetConsoleTextAttribute (): None # create blank lambda def winapi_test (): None else : # if we don't raise an exception when we import windows types # then execute this but don't catch an exception if raised from ctypes import byref , Structure # inspired by https://github.com/tartley/colorama/ class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '( %d , %d , %d , %d , %d , %d , %d , %d , %d , %d , %d )' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) # a simple wrapper around the few methods calls to windows class Win32Console ( object ): _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes . HANDLE , wintypes . WORD , ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes . DWORD , ] _GetStdHandle . restype = wintypes . HANDLE # from winbase.h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ): csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test (): return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ): handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ): handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) # from wincon.h class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background # defines the different codes for the ansi colors class AnsiColor ( object ): BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported, but not part of the standard. BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ): if type ( item ) is str and hasattr ( self , item ): return True # check if we contain the color number for attr_name in dir ( self ): if getattr ( self , attr_name ) is item : return True return False # the formatter that ouputs ANSI codes as needed class ColoredFormatter ( logging . Formatter ): AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ): logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ): levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result # returns the string formatted ANSI command for the specific color def get_ansi_string ( color = AnsiColor . RESET ): CSI = ' \\033 [' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' class ColoredStreamHandler ( logging . StreamHandler ): # Control Sequence Introducer ANSI_CSI_RE = re . compile ( ' \\001 ? \\033\\\\ [((?: \\\\ d|;)*)([a-zA-Z]) \\002 ?' ) def __init__ ( self , stream = None , strip = None , convert = None ): logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo () . os == \"Windows\" # We test if the WinAPI works, because even if we are on Windows # we may be using a terminal that doesn't support the WinAPI # (e.g. Cygwin Terminal). In this case it's up to the terminal # to support the ANSI codes. self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ) . wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream, stripping ANSI if specified def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ): if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1 :] kwargs = dict () func ( * args , ** kwargs ) # logging.handler method we are overriding to emit a record def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) Functions get_ansi_string def get_ansi_string ( color = 39 ) View Source def get_ansi_string ( color = AnsiColor . RESET ): CSI = '\\033[' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' Classes AnsiColor class AnsiColor ( / , * args , ** kwargs ) View Source class AnsiColor ( object ) : BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported , but not part of the standard . BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ) : if type ( item ) is str and hasattr ( self , item ) : return True # check if we contain the color number for attr_name in dir ( self ) : if getattr ( self , attr_name ) is item : return True return False Class variables BG_BLACK BG_BLUE BG_CYAN BG_GREEN BG_LIGHTBLACK_EX BG_LIGHTBLUE_EX BG_LIGHTCYAN_EX BG_LIGHTGREEN_EX BG_LIGHTMAGENTA_EX BG_LIGHTRED_EX BG_LIGHTWHITE_EX BG_LIGHTYELLOW_EX BG_MAGENTA BG_RED BG_RESET BG_WHITE BG_YELLOW BLACK BLUE CYAN GREEN LIGHTBLACK_EX LIGHTBLUE_EX LIGHTCYAN_EX LIGHTGREEN_EX LIGHTMAGENTA_EX LIGHTRED_EX LIGHTWHITE_EX LIGHTYELLOW_EX MAGENTA RED RESET WHITE YELLOW CONSOLE_SCREEN_BUFFER_INFO class CONSOLE_SCREEN_BUFFER_INFO ( / , * args , ** kwargs ) Structure base class View Source class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) Ancestors (in MRO) _ctypes.Structure _ctypes._CData Class variables COORD dwCursorPosition dwMaximumWindowSize dwSize srWindow wAttributes ColoredFormatter class ColoredFormatter ( msg = '' , use_azure = False ) Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the the style-dependent default value, \u201c%(message)s\u201d, \u201c{message}\u201d, or \u201c${message}\u201d, is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user\u2019s message and arguments are pre- formatted into a LogRecord\u2019s message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\u201cDEBUG\u201d, \u201cINFO\u201d, \u201cWARNING\u201d, \u201cERROR\u201d, \u201cCRITICAL\u201d) %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted View Source class ColoredFormatter ( logging . Formatter ) : AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ) : logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result Ancestors (in MRO) logging.Formatter Class variables AZURE_COLORS COLORS default_msec_format default_time_format Methods converter def converter ( ... ) localtime([seconds]) -> (tm_year,tm_mon,tm_mday,tm_hour,tm_min, tm_sec,tm_wday,tm_yday,tm_isdst) Convert seconds since the Epoch to a time tuple expressing local time. When \u2018seconds\u2019 is not passed in, convert the current time instead. format def format ( self , record ) Format the specified record as text. The record\u2019s attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. View Source def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result formatException def formatException ( self , ei ) Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() View Source def formatException ( self , ei ) : \"\"\" Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() \"\"\" sio = io . StringIO () tb = ei [ 2 ] # See issues # 9427 , # 1553375. Commented out for now . #if getattr ( self , 'fullstack' , False ) : # traceback . print_stack ( tb . tb_frame . f_back , file = sio ) traceback . print_exception ( ei [ 0 ], ei [ 1 ], tb , None , sio ) s = sio . getvalue () sio . close () if s [ - 1 : ] == \"\\n\" : s = s [:- 1 ] return s formatMessage def formatMessage ( self , record ) View Source def formatMessage ( self , record ): return self . _style . format ( record ) formatStack def formatStack ( self , stack_info ) This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func: traceback.print_stack , but with the last trailing newline removed. The base implementation just returns the value passed in. View Source def formatStack ( self , stack_info ): \"\"\" This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func:`traceback.print_stack`, but with the last trailing newline removed. The base implementation just returns the value passed in. \"\"\" return stack_info formatTime def formatTime ( self , record , datefmt = None ) Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the \u2018converter\u2019 attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the \u2018converter\u2019 attribute in the Formatter class. View Source def formatTime ( self , record , datefmt = None ): \"\"\" Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the 'converter' attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the 'converter' attribute in the Formatter class. \"\"\" ct = self . converter ( record . created ) if datefmt : s = time . strftime ( datefmt , ct ) else : t = time . strftime ( self . default_time_format , ct ) s = self . default_msec_format % ( t , record . msecs ) return s usesTime def usesTime ( self ) Check if the format uses the creation time of the record. View Source def usesTime ( self ): \"\"\" Check if the format uses the creation time of the record. \"\"\" return self . _style . usesTime () ColoredStreamHandler class ColoredStreamHandler ( stream = None , strip = None , convert = None ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class ColoredStreamHandler ( logging . StreamHandler ) : # Control Sequence Introducer ANSI_CSI_RE = re . compile ( '\\001?\\033\\\\[((?:\\\\d|;)*)([a-zA-Z])\\002?' ) def __init__ ( self , stream = None , strip = None , convert = None ) : logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo (). os == \"Windows\" # We test if the WinAPI works , because even if we are on Windows # we may be using a terminal that doesn 't support the WinAPI # (e.g. Cygwin Terminal). In this case it' s up to the terminal # to support the ANSI codes . self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output ? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls ? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ). wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ) : if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) : if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ) : if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ) : if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ) : return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ) : self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream , stripping ANSI if specified def write ( self , text ) : if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ) : cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ) : start , end = match . span () if ( cursor < start ) : self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ) : if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start:end ] ) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ) : if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ) : params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) # logging . handler method we are overriding to emit a record def emit ( self , record ) : try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) Ancestors (in MRO) logging.StreamHandler logging.Handler logging.Filterer Class variables ANSI_CSI_RE terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) call_win32 def call_win32 ( self , command , params ) View Source def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) close def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock () convert_ansi def convert_ansi ( self , paramstring , command ) View Source def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record ) extract_params def extract_params ( self , command , paramstring ) View Source def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_attrs def get_attrs ( self ) View Source def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name get_win32_calls def get_win32_calls ( self ) View Source def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_attrs def set_attrs ( self , value ) View Source def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) set_background def set_background ( self , back = None , light = False , on_stderr = False ) View Source def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) set_console def set_console ( self , attrs = None , on_stderr = False ) View Source def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) set_foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) View Source def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock () write def write ( self , text ) View Source def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) write_and_convert def write_and_convert ( self , text ) View Source def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) write_plain_text def write_plain_text ( self , text , start = None , end = None ) View Source def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () Win32Console class Win32Console ( / , * args , ** kwargs ) View Source class Win32Console ( object ) : _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes.HANDLE, wintypes.WORD, ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes.DWORD, ] _GetStdHandle . restype = wintypes . HANDLE # from winbase . h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ) : csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) Class variables STDERR STDOUT Static methods GetConsoleScreenBufferInfo def GetConsoleScreenBufferInfo ( stream_id =- 11 ) View Source @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi SetConsoleTextAttribute def SetConsoleTextAttribute ( stream_id , attrs ) View Source @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) winapi_test def winapi_test ( ) View Source @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) WinColor class WinColor ( / , * args , ** kwargs ) View Source class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background Class variables BLACK BLUE BRIGHT BRIGHT_BACKGROUND CYAN GREEN GREY MAGENTA NORMAL RED YELLOW","title":"Ansi handler"},{"location":"edk2toollib/log/ansi_handler/#module-edk2toolliblogansi_handler","text":"View Source ## # Handle basic logging with color via ANSI comamnds # Will call into win32 commands as needed when needed # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import re from edk2toollib.utility_functions import GetHostInfo try : # try to import windows types from winDLL import ctypes from ctypes import LibraryLoader windll = LibraryLoader ( ctypes . WinDLL ) from ctypes import wintypes except ( AttributeError , ImportError ): # if we run into an exception (ie on unix or linux) windll = None # create blank lambda def SetConsoleTextAttribute (): None # create blank lambda def winapi_test (): None else : # if we don't raise an exception when we import windows types # then execute this but don't catch an exception if raised from ctypes import byref , Structure # inspired by https://github.com/tartley/colorama/ class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '( %d , %d , %d , %d , %d , %d , %d , %d , %d , %d , %d )' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X ) # a simple wrapper around the few methods calls to windows class Win32Console ( object ): _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes . HANDLE , wintypes . WORD , ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes . DWORD , ] _GetStdHandle . restype = wintypes . HANDLE # from winbase.h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ): csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test (): return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ): handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ): handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs ) # from wincon.h class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background # defines the different codes for the ansi colors class AnsiColor ( object ): BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported, but not part of the standard. BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ): if type ( item ) is str and hasattr ( self , item ): return True # check if we contain the color number for attr_name in dir ( self ): if getattr ( self , attr_name ) is item : return True return False # the formatter that ouputs ANSI codes as needed class ColoredFormatter ( logging . Formatter ): AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ): logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ): levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ]) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result # returns the string formatted ANSI command for the specific color def get_ansi_string ( color = AnsiColor . RESET ): CSI = ' \\033 [' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm' class ColoredStreamHandler ( logging . StreamHandler ): # Control Sequence Introducer ANSI_CSI_RE = re . compile ( ' \\001 ? \\033\\\\ [((?: \\\\ d|;)*)([a-zA-Z]) \\002 ?' ) def __init__ ( self , stream = None , strip = None , convert = None ): logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo () . os == \"Windows\" # We test if the WinAPI works, because even if we are on Windows # we may be using a terminal that doesn't support the WinAPI # (e.g. Cygwin Terminal). In this case it's up to the terminal # to support the ANSI codes. self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ) . wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream, stripping ANSI if specified def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ): if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1 :] kwargs = dict () func ( * args , ** kwargs ) # logging.handler method we are overriding to emit a record def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"Module edk2toollib.log.ansi_handler"},{"location":"edk2toollib/log/ansi_handler/#functions","text":"","title":"Functions"},{"location":"edk2toollib/log/ansi_handler/#get_ansi_string","text":"def get_ansi_string ( color = 39 ) View Source def get_ansi_string ( color = AnsiColor . RESET ): CSI = '\\033[' colors = AnsiColor () if color not in colors : color = AnsiColor . RESET return CSI + str ( color ) + 'm'","title":"get_ansi_string"},{"location":"edk2toollib/log/ansi_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/ansi_handler/#ansicolor","text":"class AnsiColor ( / , * args , ** kwargs ) View Source class AnsiColor ( object ) : BLACK = 30 RED = 31 GREEN = 32 YELLOW = 33 BLUE = 34 MAGENTA = 35 CYAN = 36 WHITE = 37 RESET = 39 LIGHTBLACK_EX = 90 LIGHTRED_EX = 91 LIGHTGREEN_EX = 92 LIGHTYELLOW_EX = 93 LIGHTBLUE_EX = 94 LIGHTMAGENTA_EX = 95 LIGHTCYAN_EX = 96 LIGHTWHITE_EX = 97 BG_BLACK = 40 BG_RED = 41 BG_GREEN = 42 BG_YELLOW = 43 BG_BLUE = 44 BG_MAGENTA = 45 BG_CYAN = 46 BG_WHITE = 47 BG_RESET = 49 # These are fairly well supported , but not part of the standard . BG_LIGHTBLACK_EX = 100 BG_LIGHTRED_EX = 101 BG_LIGHTGREEN_EX = 102 BG_LIGHTYELLOW_EX = 103 BG_LIGHTBLUE_EX = 104 BG_LIGHTMAGENTA_EX = 105 BG_LIGHTCYAN_EX = 106 BG_LIGHTWHITE_EX = 107 @classmethod def __contains__ ( self , item ) : if type ( item ) is str and hasattr ( self , item ) : return True # check if we contain the color number for attr_name in dir ( self ) : if getattr ( self , attr_name ) is item : return True return False","title":"AnsiColor"},{"location":"edk2toollib/log/ansi_handler/#class-variables","text":"BG_BLACK BG_BLUE BG_CYAN BG_GREEN BG_LIGHTBLACK_EX BG_LIGHTBLUE_EX BG_LIGHTCYAN_EX BG_LIGHTGREEN_EX BG_LIGHTMAGENTA_EX BG_LIGHTRED_EX BG_LIGHTWHITE_EX BG_LIGHTYELLOW_EX BG_MAGENTA BG_RED BG_RESET BG_WHITE BG_YELLOW BLACK BLUE CYAN GREEN LIGHTBLACK_EX LIGHTBLUE_EX LIGHTCYAN_EX LIGHTGREEN_EX LIGHTMAGENTA_EX LIGHTRED_EX LIGHTWHITE_EX LIGHTYELLOW_EX MAGENTA RED RESET WHITE YELLOW","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#console_screen_buffer_info","text":"class CONSOLE_SCREEN_BUFFER_INFO ( / , * args , ** kwargs ) Structure base class View Source class CONSOLE_SCREEN_BUFFER_INFO ( Structure ): COORD = wintypes . _COORD \"\"\"struct in wincon.h.\"\"\" _fields_ = [ ( \"dwSize\" , COORD ), ( \"dwCursorPosition\" , COORD ), ( \"wAttributes\" , wintypes . WORD ), ( \"srWindow\" , wintypes . SMALL_RECT ), ( \"dwMaximumWindowSize\" , COORD ), ] def __str__ ( self ): return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % ( self . dwSize . Y , self . dwSize . X , self . dwCursorPosition . Y , self . dwCursorPosition . X , self . wAttributes , self . srWindow . Top , self . srWindow . Left , self . srWindow . Bottom , self . srWindow . Right , self . dwMaximumWindowSize . Y , self . dwMaximumWindowSize . X )","title":"CONSOLE_SCREEN_BUFFER_INFO"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro","text":"_ctypes.Structure _ctypes._CData","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_1","text":"COORD dwCursorPosition dwMaximumWindowSize dwSize srWindow wAttributes","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#coloredformatter","text":"class ColoredFormatter ( msg = '' , use_azure = False ) Formatter instances are used to convert a LogRecord to text. Formatters need to know how a LogRecord is constructed. They are responsible for converting a LogRecord to (usually) a string which can be interpreted by either a human or an external system. The base Formatter allows a formatting string to be specified. If none is supplied, the the style-dependent default value, \u201c%(message)s\u201d, \u201c{message}\u201d, or \u201c${message}\u201d, is used. The Formatter can be initialized with a format string which makes use of knowledge of the LogRecord attributes - e.g. the default value mentioned above makes use of the fact that the user\u2019s message and arguments are pre- formatted into a LogRecord\u2019s message attribute. Currently, the useful attributes in a LogRecord are described by: %(name)s Name of the logger (logging channel) %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) %(levelname)s Text logging level for the message (\u201cDEBUG\u201d, \u201cINFO\u201d, \u201cWARNING\u201d, \u201cERROR\u201d, \u201cCRITICAL\u201d) %(pathname)s Full pathname of the source file where the logging call was issued (if available) %(filename)s Filename portion of pathname %(module)s Module (name portion of filename) %(lineno)d Source line number where the logging call was issued (if available) %(funcName)s Function name %(created)f Time when the LogRecord was created (time.time() return value) %(asctime)s Textual time when the LogRecord was created %(msecs)d Millisecond portion of the creation time %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) %(thread)d Thread ID (if available) %(threadName)s Thread name (if available) %(process)d Process ID (if available) %(message)s The result of record.getMessage(), computed just as the record is emitted View Source class ColoredFormatter ( logging . Formatter ) : AZURE_COLORS = { 'CRITICAL' : \"section\" , 'ERROR' : \"error\" } COLORS = { 'WARNING' : AnsiColor . YELLOW , 'INFO' : AnsiColor . CYAN , 'DEBUG' : AnsiColor . BLUE , 'CRITICAL' : AnsiColor . LIGHTWHITE_EX , 'ERROR' : AnsiColor . RED , \"STATUS\" : AnsiColor . GREEN , \"PROGRESS\" : AnsiColor . GREEN , \"SECTION\" : AnsiColor . CYAN } def __init__ ( self , msg = \"\" , use_azure = False ) : logging . Formatter . __init__ ( self , msg ) self . use_azure = use_azure def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result","title":"ColoredFormatter"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro_1","text":"logging.Formatter","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_2","text":"AZURE_COLORS COLORS default_msec_format default_time_format","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/ansi_handler/#converter","text":"def converter ( ... ) localtime([seconds]) -> (tm_year,tm_mon,tm_mday,tm_hour,tm_min, tm_sec,tm_wday,tm_yday,tm_isdst) Convert seconds since the Epoch to a time tuple expressing local time. When \u2018seconds\u2019 is not passed in, convert the current time instead.","title":"converter"},{"location":"edk2toollib/log/ansi_handler/#format","text":"def format ( self , record ) Format the specified record as text. The record\u2019s attribute dictionary is used as the operand to a string formatting operation which yields the returned string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using LogRecord.getMessage(). If the formatting string uses the time (as determined by a call to usesTime(), formatTime() is called to format the event time. If there is exception information, it is formatted using formatException() and appended to the message. View Source def format ( self , record ) : levelname = record . levelname org_message = record . msg if not self . use_azure and levelname in ColoredFormatter . COLORS : # just color the level name if record . levelno < logging . WARNING : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname + get_ansi_string () # otherwise color the wholes message else : levelname_color = get_ansi_string ( ColoredFormatter . COLORS [ levelname ] ) + levelname record . msg += get_ansi_string () record . levelname = levelname_color if self . use_azure and levelname in ColoredFormatter . AZURE_COLORS : levelname_color = \"##[\" + \\ ColoredFormatter . AZURE_COLORS [ levelname ] + \"]\" record . levelname = levelname_color result = logging . Formatter . format ( self , record ) record . levelname = levelname record . msg = org_message return result","title":"format"},{"location":"edk2toollib/log/ansi_handler/#formatexception","text":"def formatException ( self , ei ) Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() View Source def formatException ( self , ei ) : \"\"\" Format and return the specified exception information as a string. This default implementation just uses traceback.print_exception() \"\"\" sio = io . StringIO () tb = ei [ 2 ] # See issues # 9427 , # 1553375. Commented out for now . #if getattr ( self , 'fullstack' , False ) : # traceback . print_stack ( tb . tb_frame . f_back , file = sio ) traceback . print_exception ( ei [ 0 ], ei [ 1 ], tb , None , sio ) s = sio . getvalue () sio . close () if s [ - 1 : ] == \"\\n\" : s = s [:- 1 ] return s","title":"formatException"},{"location":"edk2toollib/log/ansi_handler/#formatmessage","text":"def formatMessage ( self , record ) View Source def formatMessage ( self , record ): return self . _style . format ( record )","title":"formatMessage"},{"location":"edk2toollib/log/ansi_handler/#formatstack","text":"def formatStack ( self , stack_info ) This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func: traceback.print_stack , but with the last trailing newline removed. The base implementation just returns the value passed in. View Source def formatStack ( self , stack_info ): \"\"\" This method is provided as an extension point for specialized formatting of stack information. The input data is a string as returned from a call to :func:`traceback.print_stack`, but with the last trailing newline removed. The base implementation just returns the value passed in. \"\"\" return stack_info","title":"formatStack"},{"location":"edk2toollib/log/ansi_handler/#formattime","text":"def formatTime ( self , record , datefmt = None ) Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the \u2018converter\u2019 attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the \u2018converter\u2019 attribute in the Formatter class. View Source def formatTime ( self , record , datefmt = None ): \"\"\" Return the creation time of the specified LogRecord as formatted text. This method should be called from format() by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic behaviour is as follows: if datefmt (a string) is specified, it is used with time.strftime() to format the creation time of the record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used. The resulting string is returned. This function uses a user-configurable function to convert the creation time to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the 'converter' attribute to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the 'converter' attribute in the Formatter class. \"\"\" ct = self . converter ( record . created ) if datefmt : s = time . strftime ( datefmt , ct ) else : t = time . strftime ( self . default_time_format , ct ) s = self . default_msec_format % ( t , record . msecs ) return s","title":"formatTime"},{"location":"edk2toollib/log/ansi_handler/#usestime","text":"def usesTime ( self ) Check if the format uses the creation time of the record. View Source def usesTime ( self ): \"\"\" Check if the format uses the creation time of the record. \"\"\" return self . _style . usesTime ()","title":"usesTime"},{"location":"edk2toollib/log/ansi_handler/#coloredstreamhandler","text":"class ColoredStreamHandler ( stream = None , strip = None , convert = None ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class ColoredStreamHandler ( logging . StreamHandler ) : # Control Sequence Introducer ANSI_CSI_RE = re . compile ( '\\001?\\033\\\\[((?:\\\\d|;)*)([a-zA-Z])\\002?' ) def __init__ ( self , stream = None , strip = None , convert = None ) : logging . StreamHandler . __init__ ( self , stream ) self . on_windows = GetHostInfo (). os == \"Windows\" # We test if the WinAPI works , because even if we are on Windows # we may be using a terminal that doesn 't support the WinAPI # (e.g. Cygwin Terminal). In this case it' s up to the terminal # to support the ANSI codes . self . conversion_supported = ( self . on_windows and Win32Console . winapi_test ()) self . strip = False # should we strip ANSI sequences from our output ? if strip is None : strip = self . conversion_supported or ( not self . stream . closed and not self . stream . isatty ()) self . strip = strip # should we should convert ANSI sequences into win32 calls ? if convert is None : convert = ( self . conversion_supported and not self . stream . closed and self . stream . isatty ()) self . convert = convert self . win32_calls = None if stream is not None : self . stream = stream if self . on_windows : self . win32_calls = self . get_win32_calls () self . _light = 0 self . _default = Win32Console . GetConsoleScreenBufferInfo ( Win32Console . STDOUT ). wAttributes self . set_attrs ( self . _default ) self . _default_fore = self . _fore self . _default_back = self . _back self . _default_style = self . _style def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def get_win32_calls ( self ) : if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict () # does the win32 call to set the foreground def set_foreground ( self , fore = None , light = False , on_stderr = False ) : if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr ) # does the win32 call to see the background def set_background ( self , back = None , light = False , on_stderr = False ) : if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr ) # the win32 call to set the console text attribute def set_console ( self , attrs = None , on_stderr = False ) : if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs ) # gets the current settings for the style and colors selected def get_attrs ( self ) : return self . _fore + self . _back * 16 + ( self . _style | self . _light ) # sets the attributes for the style and colors selected def set_attrs ( self , value ) : self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND ) # writes to stream , stripping ANSI if specified def write ( self , text ) : if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text ) # write the given text to the strip stripping and converting ANSI def write_and_convert ( self , text ) : cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ) : start , end = match . span () if ( cursor < start ) : self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text )) # writes plain text to our stream def write_plain_text ( self , text , start = None , end = None ) : if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start:end ] ) self . flush () # converts an ANSI command to a win32 command def convert_ansi ( self , paramstring , command ) : if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params ) # extracts the parameters in the ANSI command def extract_params ( self , command , paramstring ) : params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params # calls the win32 apis set_foreground and set_background def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs ) # logging . handler method we are overriding to emit a record def emit ( self , record ) : try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"ColoredStreamHandler"},{"location":"edk2toollib/log/ansi_handler/#ancestors-in-mro_2","text":"logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/ansi_handler/#class-variables_3","text":"ANSI_CSI_RE terminator","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/ansi_handler/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/log/ansi_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/ansi_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/ansi_handler/#call_win32","text":"def call_win32 ( self , command , params ) View Source def call_win32 ( self , command , params ) : if command == 'm' : for param in params : if param in self . win32_calls : func_args = self . win32_calls [ param ] func = func_args [ 0 ] args = func_args [ 1: ] kwargs = dict () func ( * args , ** kwargs )","title":"call_win32"},{"location":"edk2toollib/log/ansi_handler/#close","text":"def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock ()","title":"close"},{"location":"edk2toollib/log/ansi_handler/#convert_ansi","text":"def convert_ansi ( self , paramstring , command ) View Source def convert_ansi ( self , paramstring , command ): if self . convert : params = self . extract_params ( command , paramstring ) self . call_win32 ( command , params )","title":"convert_ansi"},{"location":"edk2toollib/log/ansi_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/ansi_handler/#emit","text":"def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): try : if record is None : return msg = self . format ( record ) if msg is None : return self . write ( str ( msg )) self . write ( self . terminator ) self . flush () except Exception : self . handleError ( record )","title":"emit"},{"location":"edk2toollib/log/ansi_handler/#extract_params","text":"def extract_params ( self , command , paramstring ) View Source def extract_params ( self , command , paramstring ): params = tuple ( int ( p ) for p in paramstring . split ( ';' ) if len ( p ) != 0 ) if len ( params ) == 0 : params = ( 0 ,) return params","title":"extract_params"},{"location":"edk2toollib/log/ansi_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/ansi_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/ansi_handler/#format_1","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/ansi_handler/#get_attrs","text":"def get_attrs ( self ) View Source def get_attrs ( self ): return self . _fore + self . _back * 16 + ( self . _style | self . _light )","title":"get_attrs"},{"location":"edk2toollib/log/ansi_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/ansi_handler/#get_win32_calls","text":"def get_win32_calls ( self ) View Source def get_win32_calls ( self ): if self . convert : return { AnsiColor . BLACK : ( self . set_foreground , WinColor . BLACK ), AnsiColor . RED : ( self . set_foreground , WinColor . RED ), AnsiColor . GREEN : ( self . set_foreground , WinColor . GREEN ), AnsiColor . YELLOW : ( self . set_foreground , WinColor . YELLOW ), AnsiColor . BLUE : ( self . set_foreground , WinColor . BLUE ), AnsiColor . MAGENTA : ( self . set_foreground , WinColor . MAGENTA ), AnsiColor . CYAN : ( self . set_foreground , WinColor . CYAN ), AnsiColor . WHITE : ( self . set_foreground , WinColor . GREY ), AnsiColor . RESET : ( self . set_foreground , None ), AnsiColor . LIGHTBLACK_EX : ( self . set_foreground , WinColor . BLACK , True ), AnsiColor . LIGHTRED_EX : ( self . set_foreground , WinColor . RED , True ), AnsiColor . LIGHTGREEN_EX : ( self . set_foreground , WinColor . GREEN , True ), AnsiColor . LIGHTYELLOW_EX : ( self . set_foreground , WinColor . YELLOW , True ), AnsiColor . LIGHTBLUE_EX : ( self . set_foreground , WinColor . BLUE , True ), AnsiColor . LIGHTMAGENTA_EX : ( self . set_foreground , WinColor . MAGENTA , True ), AnsiColor . LIGHTCYAN_EX : ( self . set_foreground , WinColor . CYAN , True ), AnsiColor . LIGHTWHITE_EX : ( self . set_foreground , WinColor . GREY , True ), AnsiColor . BG_BLACK : ( self . set_background , WinColor . BLACK ), AnsiColor . BG_RED : ( self . set_background , WinColor . RED ), AnsiColor . BG_GREEN : ( self . set_background , WinColor . GREEN ), AnsiColor . BG_YELLOW : ( self . set_background , WinColor . YELLOW ), AnsiColor . BG_BLUE : ( self . set_background , WinColor . BLUE ), AnsiColor . BG_MAGENTA : ( self . set_background , WinColor . MAGENTA ), AnsiColor . BG_CYAN : ( self . set_background , WinColor . CYAN ), AnsiColor . BG_WHITE : ( self . set_background , WinColor . GREY ), AnsiColor . BG_RESET : ( self . set_background , None ), AnsiColor . BG_LIGHTBLACK_EX : ( self . set_background , WinColor . BLACK , True ), AnsiColor . BG_LIGHTRED_EX : ( self . set_background , WinColor . RED , True ), AnsiColor . BG_LIGHTGREEN_EX : ( self . set_background , WinColor . GREEN , True ), AnsiColor . BG_LIGHTYELLOW_EX : ( self . set_background , WinColor . YELLOW , True ), AnsiColor . BG_LIGHTBLUE_EX : ( self . set_background , WinColor . BLUE , True ), AnsiColor . BG_LIGHTMAGENTA_EX : ( self . set_background , WinColor . MAGENTA , True ), AnsiColor . BG_LIGHTCYAN_EX : ( self . set_background , WinColor . CYAN , True ), AnsiColor . BG_LIGHTWHITE_EX : ( self . set_background , WinColor . GREY , True ), } return dict ()","title":"get_win32_calls"},{"location":"edk2toollib/log/ansi_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/ansi_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/ansi_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/ansi_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/ansi_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/ansi_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/ansi_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/ansi_handler/#set_attrs","text":"def set_attrs ( self , value ) View Source def set_attrs ( self , value ): self . _fore = value & 7 self . _back = ( value >> 4 ) & 7 self . _style = value & ( WinColor . BRIGHT | WinColor . BRIGHT_BACKGROUND )","title":"set_attrs"},{"location":"edk2toollib/log/ansi_handler/#set_background","text":"def set_background ( self , back = None , light = False , on_stderr = False ) View Source def set_background ( self , back = None , light = False , on_stderr = False ): if back is None : back = self . _default_back self . _back = back # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style if light : self . _light |= WinColor . BRIGHT_BACKGROUND else : self . _light &= ~ WinColor . BRIGHT_BACKGROUND self . set_console ( on_stderr = on_stderr )","title":"set_background"},{"location":"edk2toollib/log/ansi_handler/#set_console","text":"def set_console ( self , attrs = None , on_stderr = False ) View Source def set_console ( self , attrs = None , on_stderr = False ): if attrs is None : attrs = self . get_attrs () handle = Win32Console . STDOUT if on_stderr : handle = Win32Console . STDERR Win32Console . SetConsoleTextAttribute ( handle , attrs )","title":"set_console"},{"location":"edk2toollib/log/ansi_handler/#set_foreground","text":"def set_foreground ( self , fore = None , light = False , on_stderr = False ) View Source def set_foreground ( self , fore = None , light = False , on_stderr = False ): if fore is None : fore = self . _default_fore self . _fore = fore # Emulate LIGHT_EX with BRIGHT Style if light : self . _light |= WinColor . BRIGHT else : self . _light &= ~ WinColor . BRIGHT self . set_console ( on_stderr = on_stderr )","title":"set_foreground"},{"location":"edk2toollib/log/ansi_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/ansi_handler/#write","text":"def write ( self , text ) View Source def write ( self , text ): if self . strip or self . convert : self . write_and_convert ( text ) else : self . write_plain_text ( text )","title":"write"},{"location":"edk2toollib/log/ansi_handler/#write_and_convert","text":"def write_and_convert ( self , text ) View Source def write_and_convert ( self , text ): cursor = 0 for match in self . ANSI_CSI_RE . finditer ( text ): start , end = match . span () if ( cursor < start ): self . write_plain_text ( text , cursor , start ) self . convert_ansi ( * match . groups ()) cursor = end self . write_plain_text ( text , cursor , len ( text ))","title":"write_and_convert"},{"location":"edk2toollib/log/ansi_handler/#write_plain_text","text":"def write_plain_text ( self , text , start = None , end = None ) View Source def write_plain_text ( self , text , start = None , end = None ): if start is None : self . stream . write ( text ) elif start < end : self . stream . write ( text [ start : end ]) self . flush ()","title":"write_plain_text"},{"location":"edk2toollib/log/ansi_handler/#win32console","text":"class Win32Console ( / , * args , ** kwargs ) View Source class Win32Console ( object ) : _GetConsoleScreenBufferInfo = windll . kernel32 . GetConsoleScreenBufferInfo _SetConsoleTextAttribute = windll . kernel32 . SetConsoleTextAttribute _SetConsoleTextAttribute . argtypes = [ wintypes.HANDLE, wintypes.WORD, ] _SetConsoleTextAttribute . restype = wintypes . BOOL _GetStdHandle = windll . kernel32 . GetStdHandle _GetStdHandle . argtypes = [ wintypes.DWORD, ] _GetStdHandle . restype = wintypes . HANDLE # from winbase . h STDOUT = - 11 STDERR = - 12 @staticmethod def _winapi_test ( handle ) : csbi = CONSOLE_SCREEN_BUFFER_INFO () success = Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return bool ( success ) @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR ))) @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs )","title":"Win32Console"},{"location":"edk2toollib/log/ansi_handler/#class-variables_4","text":"STDERR STDOUT","title":"Class variables"},{"location":"edk2toollib/log/ansi_handler/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/log/ansi_handler/#getconsolescreenbufferinfo","text":"def GetConsoleScreenBufferInfo ( stream_id =- 11 ) View Source @staticmethod def GetConsoleScreenBufferInfo ( stream_id = STDOUT ) : handle = Win32Console . _GetStdHandle ( stream_id ) csbi = CONSOLE_SCREEN_BUFFER_INFO () Win32Console . _GetConsoleScreenBufferInfo ( handle , byref ( csbi )) return csbi","title":"GetConsoleScreenBufferInfo"},{"location":"edk2toollib/log/ansi_handler/#setconsoletextattribute","text":"def SetConsoleTextAttribute ( stream_id , attrs ) View Source @staticmethod def SetConsoleTextAttribute ( stream_id , attrs ) : handle = Win32Console . _GetStdHandle ( stream_id ) return Win32Console . _SetConsoleTextAttribute ( handle , attrs )","title":"SetConsoleTextAttribute"},{"location":"edk2toollib/log/ansi_handler/#winapi_test","text":"def winapi_test ( ) View Source @staticmethod def winapi_test () : return any ( Win32Console . _winapi_test ( h ) for h in ( Win32Console . _GetStdHandle ( Win32Console . STDOUT ), Win32Console . _GetStdHandle ( Win32Console . STDERR )))","title":"winapi_test"},{"location":"edk2toollib/log/ansi_handler/#wincolor","text":"class WinColor ( / , * args , ** kwargs ) View Source class WinColor ( object ): BLACK = 0 BLUE = 1 GREEN = 2 CYAN = 3 RED = 4 MAGENTA = 5 YELLOW = 6 GREY = 7 NORMAL = 0x00 # dim text, dim background BRIGHT = 0x08 # bright text, dim background BRIGHT_BACKGROUND = 0x80 # dim text, bright background","title":"WinColor"},{"location":"edk2toollib/log/ansi_handler/#class-variables_5","text":"BLACK BLUE BRIGHT BRIGHT_BACKGROUND CYAN GREEN GREY MAGENTA NORMAL RED YELLOW","title":"Class variables"},{"location":"edk2toollib/log/file_handler/","text":"Module edk2toollib.log.file_handler View Source ## # Handle basic logging outputting to files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv Classes FileHandler class FileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv Ancestors (in MRO) logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Closes the stream. View Source def close ( self ): \"\"\" Closes the stream. \"\"\" self . acquire () try : try : if self . stream : try : self . flush () finally : stream = self . stream self . stream = None if hasattr ( stream , \"close\" ): stream . close () finally : # Issue # 19523 : call unconditionally to # prevent a handler leak when delay is set StreamHandler . close ( self ) finally : self . release () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ): \"\"\" Emit a record. If the stream was not opened because 'delay' was specified in the constructor, open it before calling the superclass's emit. \"\"\" if self . stream is None : self . stream = self . _open () StreamHandler . emit ( self , record ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"File handler"},{"location":"edk2toollib/log/file_handler/#module-edk2toolliblogfile_handler","text":"View Source ## # Handle basic logging outputting to files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"Module edk2toollib.log.file_handler"},{"location":"edk2toollib/log/file_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/file_handler/#filehandler","text":"class FileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class FileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv","title":"FileHandler"},{"location":"edk2toollib/log/file_handler/#ancestors-in-mro","text":"logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/file_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/file_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/file_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/file_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/file_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/file_handler/#close","text":"def close ( self ) Closes the stream. View Source def close ( self ): \"\"\" Closes the stream. \"\"\" self . acquire () try : try : if self . stream : try : self . flush () finally : stream = self . stream self . stream = None if hasattr ( stream , \"close\" ): stream . close () finally : # Issue # 19523 : call unconditionally to # prevent a handler leak when delay is set StreamHandler . close ( self ) finally : self . release ()","title":"close"},{"location":"edk2toollib/log/file_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/file_handler/#emit","text":"def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ): \"\"\" Emit a record. If the stream was not opened because 'delay' was specified in the constructor, open it before calling the superclass's emit. \"\"\" if self . stream is None : self . stream = self . _open () StreamHandler . emit ( self , record )","title":"emit"},{"location":"edk2toollib/log/file_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/file_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/file_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/file_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/file_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/file_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/file_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/file_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/file_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/file_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/file_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/file_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/junit_report_format/","text":"Module edk2toollib.log.junit_report_format View Source ## # junit_report_format # This module contains support for Outputting Junit test results xml. # # Used to support CI/CD and exporting test results for other tools. # This does test report generation without being a test runner. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import time class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type ## # Test Case class # ## class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = Name self . ClassName = ClassName self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \" \\n \" def LogStdError ( self , msg ): self . StdErr += msg . strip () + \" \\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) ## # Test Suite class. Create new suites by using the JunitTestReport Object # # ## class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = Name self . Package = Package self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases : if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases : a . Output ( outstream ) outstream . write ( '</testsuite>' ) ## # Test Report. Top level object test reporting. # # ## class JunitTestReport ( object ): def __init__ ( self ): self . TestSuites = [] def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts def Output ( self , filepath ): f = open ( filepath , \"w\" ) f . write ( '' ) f . write ( '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' ) f . write ( '<testsuites>' ) for a in self . TestSuites : a . Output ( f ) f . write ( '</testsuites>' ) f . close () Classes JunitReportError class JunitReportError ( type , msg ) View Source class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type JunitReportFailure class JunitReportFailure ( type , msg ) View Source class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type JunitReportTestCase class JunitReportTestCase ( Name , ClassName ) View Source class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = Name self . ClassName = ClassName self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \"\\n \" def LogStdError ( self , msg ): self . StdErr += msg . strip () + \"\\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED: outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED: outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR: outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS: raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) Class variables ERROR FAILED NEW SKIPPED SUCCESS Methods LogStdError def LogStdError ( self , msg ) View Source def LogStdError ( self , msg ): self . StdErr += msg . strip () + \"\\n \" LogStdOut def LogStdOut ( self , msg ) View Source def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \"\\n \" Output def Output ( self , outstream ) View Source def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) SetError def SetError ( self , Msg , Type ) View Source def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) SetFailed def SetFailed ( self , Msg , Type ) View Source def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) SetSkipped def SetSkipped ( self ) View Source def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime SetSuccess def SetSuccess ( self ) View Source def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime JunitReportTestSuite class JunitReportTestSuite ( Name , Package , Id ) View Source class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = Name self . Package = Package self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases: if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases: a . Output ( outstream ) outstream . write ( '</testsuite>' ) Methods Output def Output ( self , outstream ) View Source def Output(self, outstream): Errors = 0 Failures = 0 Skipped = 0 Tests = len(self.TestCases) for a in self.TestCases: if(a.Status == JunitReportTestCase.FAILED): Failures += 1 elif(a.Status == JunitReportTestCase.ERROR): Errors += 1 elif(a.Status == JunitReportTestCase.SKIPPED): Skipped += 1 outstream.write(' <testsuite id= \"{0}\" name= \"{1}\" package= \"{2}\" errors= \"{3}\" tests= \"{4}\" ' ' failures= \"{5}\" skipped= \"{6}\" > '.format(self.TestId, self.Name, self.Package, Errors, Tests, Failures, Skipped)) for a in self.TestCases: a.Output(outstream) outstream.write(' </testsuite> ') create_new_testcase def create_new_testcase ( self , name , classname ) View Source def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc JunitTestReport class JunitTestReport ( ) View Source class JunitTestReport(object): def __init__(self): self.TestSuites = [] def create_new_testsuite(self, name, package): id = len(self.TestSuites) ts = JunitReportTestSuite(name, package, id) self.TestSuites.append(ts) return ts def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close() Methods Output def Output ( self , filepath ) View Source def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close() create_new_testsuite def create_new_testsuite ( self , name , package ) View Source def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts","title":"Junit report format"},{"location":"edk2toollib/log/junit_report_format/#module-edk2toolliblogjunit_report_format","text":"View Source ## # junit_report_format # This module contains support for Outputting Junit test results xml. # # Used to support CI/CD and exporting test results for other tools. # This does test report generation without being a test runner. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import time class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type ## # Test Case class # ## class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = Name self . ClassName = ClassName self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \" \\n \" def LogStdError ( self , msg ): self . StdErr += msg . strip () + \" \\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' ) ## # Test Suite class. Create new suites by using the JunitTestReport Object # # ## class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = Name self . Package = Package self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases : if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases : a . Output ( outstream ) outstream . write ( '</testsuite>' ) ## # Test Report. Top level object test reporting. # # ## class JunitTestReport ( object ): def __init__ ( self ): self . TestSuites = [] def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts def Output ( self , filepath ): f = open ( filepath , \"w\" ) f . write ( '' ) f . write ( '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' ) f . write ( '<testsuites>' ) for a in self . TestSuites : a . Output ( f ) f . write ( '</testsuites>' ) f . close ()","title":"Module edk2toollib.log.junit_report_format"},{"location":"edk2toollib/log/junit_report_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/junit_report_format/#junitreporterror","text":"class JunitReportError ( type , msg ) View Source class JunitReportError ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type","title":"JunitReportError"},{"location":"edk2toollib/log/junit_report_format/#junitreportfailure","text":"class JunitReportFailure ( type , msg ) View Source class JunitReportFailure ( object ): def __init__ ( self , type , msg ): self . Message = msg self . Type = type","title":"JunitReportFailure"},{"location":"edk2toollib/log/junit_report_format/#junitreporttestcase","text":"class JunitReportTestCase ( Name , ClassName ) View Source class JunitReportTestCase ( object ): NEW = 1 SKIPPED = 2 FAILED = 3 ERROR = 4 SUCCESS = 5 def __init__ ( self , Name , ClassName ): self . Name = Name self . ClassName = ClassName self . Time = 0 self . Status = JunitReportTestCase . NEW self . FailureMsg = None self . ErrorMsg = None self . _TestSuite = None self . StdErr = \"\" self . StdOut = \"\" self . _StartTime = time . time () def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg ) def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg ) def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \"\\n \" def LogStdError ( self , msg ): self . StdErr += msg . strip () + \"\\n \" def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED: outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED: outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR: outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS: raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' )","title":"JunitReportTestCase"},{"location":"edk2toollib/log/junit_report_format/#class-variables","text":"ERROR FAILED NEW SKIPPED SUCCESS","title":"Class variables"},{"location":"edk2toollib/log/junit_report_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#logstderror","text":"def LogStdError ( self , msg ) View Source def LogStdError ( self , msg ): self . StdErr += msg . strip () + \"\\n \"","title":"LogStdError"},{"location":"edk2toollib/log/junit_report_format/#logstdout","text":"def LogStdOut ( self , msg ) View Source def LogStdOut ( self , msg ): self . StdOut += msg . strip () + \"\\n \"","title":"LogStdOut"},{"location":"edk2toollib/log/junit_report_format/#output","text":"def Output ( self , outstream ) View Source def Output ( self , outstream ): outstream . write ( '<testcase classname=\"{0}\" name=\"{1}\" time=\"{2}\">' . format ( self . ClassName , self . Name , self . Time )) if self . Status == JunitReportTestCase . SKIPPED : outstream . write ( '<skipped />' ) elif self . Status == JunitReportTestCase . FAILED : outstream . write ( '<failure message=\"{0}\" type=\"{1}\" />' . format ( self . FailureMsg . Message , self . FailureMsg . Type )) elif self . Status == JunitReportTestCase . ERROR : outstream . write ( '<error message=\"{0}\" type=\"{1}\" />' . format ( self . ErrorMsg . Message , self . ErrorMsg . Type )) elif self . Status != JunitReportTestCase . SUCCESS : raise Exception ( \"Can't output a testcase {0}.{1} in invalid state {2}\" . format ( self . ClassName , self . Name , self . Status )) outstream . write ( '<system-out>' + self . StdOut + '</system-out>' ) outstream . write ( '<system-err>' + self . StdErr + '</system-err>' ) outstream . write ( '</testcase>' )","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#seterror","text":"def SetError ( self , Msg , Type ) View Source def SetError ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to error. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . ERROR self . ErrorMsg = JunitReportError ( Type , Msg )","title":"SetError"},{"location":"edk2toollib/log/junit_report_format/#setfailed","text":"def SetFailed ( self , Msg , Type ) View Source def SetFailed ( self , Msg , Type ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to failed. State must be in NEW\" ) self . Time = time . time () - self . _StartTime self . Status = JunitReportTestCase . FAILED self . FailureMsg = JunitReportFailure ( Type , Msg )","title":"SetFailed"},{"location":"edk2toollib/log/junit_report_format/#setskipped","text":"def SetSkipped ( self ) View Source def SetSkipped ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to skipped. State must be in NEW\" ) self . Status = JunitReportTestCase . SKIPPED self . Time = time . time () - self . _StartTime","title":"SetSkipped"},{"location":"edk2toollib/log/junit_report_format/#setsuccess","text":"def SetSuccess ( self ) View Source def SetSuccess ( self ): if ( self . Status != JunitReportTestCase . NEW ): raise Exception ( \"Can't Set to success. State must be in NEW\" ) self . Status = JunitReportTestCase . SUCCESS self . Time = time . time () - self . _StartTime","title":"SetSuccess"},{"location":"edk2toollib/log/junit_report_format/#junitreporttestsuite","text":"class JunitReportTestSuite ( Name , Package , Id ) View Source class JunitReportTestSuite ( object ): def __init__ ( self , Name , Package , Id ): self . Name = Name self . Package = Package self . TestId = Id self . TestCases = [] def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc def Output ( self , outstream ): Errors = 0 Failures = 0 Skipped = 0 Tests = len ( self . TestCases ) for a in self . TestCases: if ( a . Status == JunitReportTestCase . FAILED ): Failures += 1 elif ( a . Status == JunitReportTestCase . ERROR ): Errors += 1 elif ( a . Status == JunitReportTestCase . SKIPPED ): Skipped += 1 outstream . write ( '<testsuite id=\"{0}\" name=\"{1}\" package=\"{2}\" errors=\"{3}\" tests=\"{4}\" ' 'failures=\"{5}\" skipped=\"{6}\">' . format ( self . TestId , self . Name , self . Package , Errors , Tests , Failures , Skipped )) for a in self . TestCases: a . Output ( outstream ) outstream . write ( '</testsuite>' )","title":"JunitReportTestSuite"},{"location":"edk2toollib/log/junit_report_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#output_1","text":"def Output ( self , outstream ) View Source def Output(self, outstream): Errors = 0 Failures = 0 Skipped = 0 Tests = len(self.TestCases) for a in self.TestCases: if(a.Status == JunitReportTestCase.FAILED): Failures += 1 elif(a.Status == JunitReportTestCase.ERROR): Errors += 1 elif(a.Status == JunitReportTestCase.SKIPPED): Skipped += 1 outstream.write(' <testsuite id= \"{0}\" name= \"{1}\" package= \"{2}\" errors= \"{3}\" tests= \"{4}\" ' ' failures= \"{5}\" skipped= \"{6}\" > '.format(self.TestId, self.Name, self.Package, Errors, Tests, Failures, Skipped)) for a in self.TestCases: a.Output(outstream) outstream.write(' </testsuite> ')","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#create_new_testcase","text":"def create_new_testcase ( self , name , classname ) View Source def create_new_testcase ( self , name , classname ): tc = JunitReportTestCase ( name , classname ) self . TestCases . append ( tc ) tc . _TestSuite = self return tc","title":"create_new_testcase"},{"location":"edk2toollib/log/junit_report_format/#junittestreport","text":"class JunitTestReport ( ) View Source class JunitTestReport(object): def __init__(self): self.TestSuites = [] def create_new_testsuite(self, name, package): id = len(self.TestSuites) ts = JunitReportTestSuite(name, package, id) self.TestSuites.append(ts) return ts def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close()","title":"JunitTestReport"},{"location":"edk2toollib/log/junit_report_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/log/junit_report_format/#output_2","text":"def Output ( self , filepath ) View Source def Output(self, filepath): f = open(filepath, \"w\") f.write('') f.write(' <?xml version=\"1.0\" encoding=\"UTF-8\"?> ') f.write(' <testsuites> ') for a in self.TestSuites: a.Output(f) f.write(' </testsuites> ') f.close()","title":"Output"},{"location":"edk2toollib/log/junit_report_format/#create_new_testsuite","text":"def create_new_testsuite ( self , name , package ) View Source def create_new_testsuite ( self , name , package ): id = len ( self . TestSuites ) ts = JunitReportTestSuite ( name , package , id ) self . TestSuites . append ( ts ) return ts","title":"create_new_testsuite"},{"location":"edk2toollib/log/markdown_handler/","text":"Module edk2toollib.log.markdown_handler View Source ## # Handle basic logging outputting to markdown # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class MarkdownFileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report \\n \" ) self . stream . write ( \"[Go to table of contents](#table-of-contents) \\n \" ) self . stream . write ( \"===== \\n \" ) self . stream . write ( \" [Go to Error List](#error-list) \\n \" ) self . stream . write ( \"===== \\n \" ) self . contents = [] self . error_records = [] def emit ( self , record ): if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [])) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046: merged two stream.writes into one. stream . write ( msg + self . terminator ) # self.flush() def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ): # Using info from here https://stackoverflow.com/a/38507669 # get rid of uppercase characters text = text . lower () . strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ) . replace ( \",\" , \"\" ) . replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ): output = \" + \\\" {0} \\\" from {1}:{2} \\n \" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ): self . stream . write ( \"## Table of Contents \\n \" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1}) \\n \" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1}) \\n \" . format ( section , section_link )) self . stream . write ( \"## Error List \\n \" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () Classes MarkdownFileHandler class MarkdownFileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class MarkdownFileHandler ( logging . FileHandler ) : def __init__ ( self , filename , mode = 'w+' ) : logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report\\n\" ) self . stream . write ( \"[Go to table of contents](#table-of-contents)\\n\" ) self . stream . write ( \"=====\\n\" ) self . stream . write ( \" [Go to Error List](#error-list)\\n\" ) self . stream . write ( \"=====\\n\" ) self . contents = [] self . error_records = [] def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) # self . flush () def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ) : # Using info from here https : // stackoverflow . com / a / 38507669 # get rid of uppercase characters text = text . lower (). strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ). replace ( \",\" , \"\" ). replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ) : output = \" + \\\" { 0 }\\ \" from {1}:{2}\\n\" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ) : self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () Ancestors (in MRO) logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Closes the stream. View Source def close ( self ): self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"Markdown handler"},{"location":"edk2toollib/log/markdown_handler/#module-edk2toolliblogmarkdown_handler","text":"View Source ## # Handle basic logging outputting to markdown # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging class MarkdownFileHandler ( logging . FileHandler ): def __init__ ( self , filename , mode = 'w+' ): logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report \\n \" ) self . stream . write ( \"[Go to table of contents](#table-of-contents) \\n \" ) self . stream . write ( \"===== \\n \" ) self . stream . write ( \" [Go to Error List](#error-list) \\n \" ) self . stream . write ( \"===== \\n \" ) self . contents = [] self . error_records = [] def emit ( self , record ): if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [])) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046: merged two stream.writes into one. stream . write ( msg + self . terminator ) # self.flush() def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ): # Using info from here https://stackoverflow.com/a/38507669 # get rid of uppercase characters text = text . lower () . strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ) . replace ( \",\" , \"\" ) . replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ): output = \" + \\\" {0} \\\" from {1}:{2} \\n \" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ): self . stream . write ( \"## Table of Contents \\n \" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1}) \\n \" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1}) \\n \" . format ( section , section_link )) self . stream . write ( \"## Error List \\n \" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"Module edk2toollib.log.markdown_handler"},{"location":"edk2toollib/log/markdown_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/markdown_handler/#markdownfilehandler","text":"class MarkdownFileHandler ( filename , mode = 'w+' ) A handler class which writes formatted logging records to disk files. View Source class MarkdownFileHandler ( logging . FileHandler ) : def __init__ ( self , filename , mode = 'w+' ) : logging . FileHandler . __init__ ( self , filename , mode = mode ) if self . stream . writable : self . stream . write ( \" # Build Report\\n\" ) self . stream . write ( \"[Go to table of contents](#table-of-contents)\\n\" ) self . stream . write ( \"=====\\n\" ) self . stream . write ( \" [Go to Error List](#error-list)\\n\" ) self . stream . write ( \"=====\\n\" ) self . contents = [] self . error_records = [] def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) # self . flush () def handle ( self , record ) : \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv @staticmethod def __convert_to_markdownlink ( text ) : # Using info from here https : // stackoverflow . com / a / 38507669 # get rid of uppercase characters text = text . lower (). strip () # get rid of punctuation text = text . replace ( \".\" , \"\" ). replace ( \",\" , \"\" ). replace ( \"-\" , \"\" ) # replace spaces text = text . replace ( \" \" , \"-\" ) return text def _output_error ( self , record ) : output = \" + \\\" { 0 }\\ \" from {1}:{2}\\n\" . format ( record . msg , record . pathname , record . lineno ) self . stream . write ( output ) def close ( self ) : self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"MarkdownFileHandler"},{"location":"edk2toollib/log/markdown_handler/#ancestors-in-mro","text":"logging.FileHandler logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/markdown_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/markdown_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/markdown_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/markdown_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/markdown_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/markdown_handler/#close","text":"def close ( self ) Closes the stream. View Source def close ( self ): self . stream . write ( \"## Table of Contents\\n\" ) for item , subsections in self . contents : link = MarkdownFileHandler . __convert_to_markdownlink ( item ) self . stream . write ( \"+ [{0}](#{1})\\n\" . format ( item , link )) for section in subsections : section_link = MarkdownFileHandler . __convert_to_markdownlink ( section ) self . stream . write ( \" + [{0}](#{1})\\n\" . format ( section , section_link )) self . stream . write ( \"## Error List\\n\" ) if len ( self . error_records ) == 0 : self . stream . write ( \" No errors found\" ) for record in self . error_records : self . _output_error ( record ) self . flush () self . stream . close ()","title":"close"},{"location":"edk2toollib/log/markdown_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/markdown_handler/#emit","text":"def emit ( self , record ) Emit a record. If the stream was not opened because \u2018delay\u2019 was specified in the constructor, open it before calling the superclass\u2019s emit. View Source def emit ( self , record ) : if self . stream is None : self . stream = self . _open () msg = record . message . strip ( \"#- \" ) if len ( msg ) > 0 : if logging . getLevelName ( record . levelno ) == \"SECTION\" : self . contents . append (( msg , [] )) msg = \"## \" + msg elif record . levelno == logging . CRITICAL : section_index = len ( self . contents ) - 1 if section_index >= 0 : self . contents [ section_index ][ 1 ] . append ( msg ) msg = \"### \" + msg elif record . levelno == logging . ERROR : self . error_records . append ( record ) msg = \"#### ERROR: \" + msg elif record . levelno == logging . WARNING : msg = \" _ WARNING: \" + msg + \"_\" else : msg = \" \" + msg stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator )","title":"emit"},{"location":"edk2toollib/log/markdown_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/markdown_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/markdown_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/markdown_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/markdown_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/markdown_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/markdown_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/markdown_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/markdown_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/markdown_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/markdown_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/markdown_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/log/string_handler/","text":"Module edk2toollib.log.string_handler View Source ## # Handle basic logging by streaming into stringIO # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging try : from StringIO import StringIO except ImportError : from io import StringIO class StringStreamHandler ( logging . StreamHandler ): terminator = ' \\n ' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 2 , 0 ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) Classes StringStreamHandler class StringStreamHandler ( ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class StringStreamHandler ( logging . StreamHandler ): terminator = '\\n' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 2 , 0 ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) Ancestors (in MRO) logging.StreamHandler logging.Handler logging.Filterer Class variables terminator Instance variables name Methods acquire def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire () addFilter def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter ) close def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock () createLock def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self ) emit def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): \"\"\" Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an 'encoding' attribute, it is used to determine how to do the output to the stream. \"\"\" try : msg = self . format ( record ) stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) self . flush () except RecursionError : # See issue 36272 raise except Exception : self . handleError ( record ) filter def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv flush def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release () format def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record ) get_name def get_name ( self ) View Source def get_name ( self ): return self . _name handle def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv handleError def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb readlines def readlines ( self , hint =- 1 ) View Source def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) release def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release () removeFilter def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter ) seek def seek ( self , offset , whence ) View Source def seek ( self , offset , whence ): return self . stream . seek ( offset , whence ) seek_end def seek_end ( self ) View Source def seek_end ( self ): self . stream . seek ( 2 , 0 ) seek_start def seek_start ( self ) View Source def seek_start ( self ): self . stream . seek ( 0 , 0 ) setFormatter def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt setLevel def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level ) setStream def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result set_name def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"String handler"},{"location":"edk2toollib/log/string_handler/#module-edk2toolliblogstring_handler","text":"View Source ## # Handle basic logging by streaming into stringIO # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging try : from StringIO import StringIO except ImportError : from io import StringIO class StringStreamHandler ( logging . StreamHandler ): terminator = ' \\n ' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 2 , 0 ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"Module edk2toollib.log.string_handler"},{"location":"edk2toollib/log/string_handler/#classes","text":"","title":"Classes"},{"location":"edk2toollib/log/string_handler/#stringstreamhandler","text":"class StringStreamHandler ( ) A handler class which writes logging records, appropriately formatted, to a stream. Note that this class does not close the stream, as sys.stdout or sys.stderr may be used. View Source class StringStreamHandler ( logging . StreamHandler ): terminator = '\\n' def __init__ ( self ): logging . Handler . __init__ ( self ) self . stream = StringIO () def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level: self . acquire () try: self . emit ( record ) finally: self . release () return rv def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint ) def seek_start ( self ): self . stream . seek ( 0 , 0 ) def seek_end ( self ): self . stream . seek ( 2 , 0 ) def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"StringStreamHandler"},{"location":"edk2toollib/log/string_handler/#ancestors-in-mro","text":"logging.StreamHandler logging.Handler logging.Filterer","title":"Ancestors (in MRO)"},{"location":"edk2toollib/log/string_handler/#class-variables","text":"terminator","title":"Class variables"},{"location":"edk2toollib/log/string_handler/#instance-variables","text":"name","title":"Instance variables"},{"location":"edk2toollib/log/string_handler/#methods","text":"","title":"Methods"},{"location":"edk2toollib/log/string_handler/#acquire","text":"def acquire ( self ) Acquire the I/O thread lock. View Source def acquire ( self ): \"\"\" Acquire the I/O thread lock. \"\"\" if self . lock : self . lock . acquire ()","title":"acquire"},{"location":"edk2toollib/log/string_handler/#addfilter","text":"def addFilter ( self , filter ) Add the specified filter to this handler. View Source def addFilter ( self , filter ): \"\"\" Add the specified filter to this handler. \"\"\" if not ( filter in self . filters ): self . filters . append ( filter )","title":"addFilter"},{"location":"edk2toollib/log/string_handler/#close","text":"def close ( self ) Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. View Source def close ( self ): \"\"\" Tidy up any resources used by the handler. This version removes the handler from an internal map of handlers, _handlers, which is used for handler lookup by name. Subclasses should ensure that this gets called from overridden close() methods. \"\"\" # get the module data lock , as we ' re updating a shared structure . _acquireLock () try : # unlikely to raise an exception , but you never know ... if self . _name and self . _name in _handlers : del _handlers [ self . _name ] finally : _releaseLock ()","title":"close"},{"location":"edk2toollib/log/string_handler/#createlock","text":"def createLock ( self ) Acquire a thread lock for serializing access to the underlying I/O. View Source def createLock ( self ): \"\"\" Acquire a thread lock for serializing access to the underlying I/O. \"\"\" self . lock = threading . RLock () _register_at_fork_reinit_lock ( self )","title":"createLock"},{"location":"edk2toollib/log/string_handler/#emit","text":"def emit ( self , record ) Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an \u2018encoding\u2019 attribute, it is used to determine how to do the output to the stream. View Source def emit ( self , record ): \"\"\" Emit a record. If a formatter is specified, it is used to format the record. The record is then written to the stream with a trailing newline. If exception information is present, it is formatted using traceback.print_exception and appended to the stream. If the stream has an 'encoding' attribute, it is used to determine how to do the output to the stream. \"\"\" try : msg = self . format ( record ) stream = self . stream # issue 35046 : merged two stream . writes into one . stream . write ( msg + self . terminator ) self . flush () except RecursionError : # See issue 36272 raise except Exception : self . handleError ( record )","title":"emit"},{"location":"edk2toollib/log/string_handler/#filter","text":"def filter ( self , record ) Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. View Source def filter ( self , record ): \"\"\" Determine if a record is loggable by consulting all the filters. The default is to allow the record to be logged; any filter can veto this and the record is then dropped. Returns a zero value if a record is to be dropped, else non-zero. .. versionchanged:: 3.2 Allow filters to be just callables. \"\"\" rv = True for f in self . filters : if hasattr ( f , 'filter' ): result = f . filter ( record ) else : result = f ( record ) # assume callable - will raise if not if not result : rv = False break return rv","title":"filter"},{"location":"edk2toollib/log/string_handler/#flush","text":"def flush ( self ) Flushes the stream. View Source def flush ( self ): \"\"\" Flushes the stream. \"\"\" self . acquire () try : if self . stream and hasattr ( self . stream , \"flush\" ): self . stream . flush () finally : self . release ()","title":"flush"},{"location":"edk2toollib/log/string_handler/#format","text":"def format ( self , record ) Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. View Source def format ( self , record ): \"\"\" Format the specified record. If a formatter is set, use it. Otherwise, use the default formatter for the module. \"\"\" if self . formatter : fmt = self . formatter else : fmt = _defaultFormatter return fmt . format ( record )","title":"format"},{"location":"edk2toollib/log/string_handler/#get_name","text":"def get_name ( self ) View Source def get_name ( self ): return self . _name","title":"get_name"},{"location":"edk2toollib/log/string_handler/#handle","text":"def handle ( self , record ) Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. View Source def handle ( self , record ): \"\"\" Conditionally emit the specified logging record. Emission depends on filters which may have been added to the handler. Wrap the actual emission of the record with acquisition/release of the I/O thread lock. Returns whether the filter passed the record for emission. \"\"\" rv = self . filter ( record ) if rv and record . levelno >= self . level : self . acquire () try : self . emit ( record ) finally : self . release () return rv","title":"handle"},{"location":"edk2toollib/log/string_handler/#handleerror","text":"def handleError ( self , record ) Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. View Source def handleError ( self , record ): \"\"\" Handle errors which occur during an emit() call. This method should be called from handlers when an exception is encountered during an emit() call. If raiseExceptions is false, exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The record which was being processed is passed in to this method. \"\"\" if raiseExceptions and sys . stderr : # see issue 13807 t , v , tb = sys . exc_info () try : sys . stderr . write ( '--- Logging error ---\\n' ) traceback . print_exception ( t , v , tb , None , sys . stderr ) sys . stderr . write ( 'Call stack:\\n' ) # Walk the stack frame up until we 're out of logging, # so as to print the calling context. frame = tb.tb_frame while (frame and os.path.dirname(frame.f_code.co_filename) == __path__[0]): frame = frame.f_back if frame: traceback.print_stack(frame, file=sys.stderr) else: # couldn' t find the right stack frame , for some reason sys . stderr . write ( 'Logged from file %s, line %s\\n' % ( record . filename , record . lineno )) # Issue 18671 : output logging message and arguments try : sys . stderr . write ( 'Message: %r\\n' 'Arguments: %s\\n' % ( record . msg , record . args )) except RecursionError : # See issue 36272 raise except Exception : sys . stderr . write ( 'Unable to print the message and arguments' ' - possible formatting error.\\nUse the' ' traceback above to help find the error.\\n' ) except OSError : # pragma : no cover pass # see issue 5971 finally : del t , v , tb","title":"handleError"},{"location":"edk2toollib/log/string_handler/#readlines","text":"def readlines ( self , hint =- 1 ) View Source def readlines ( self , hint =- 1 ): return self . stream . readlines ( hint )","title":"readlines"},{"location":"edk2toollib/log/string_handler/#release","text":"def release ( self ) Release the I/O thread lock. View Source def release ( self ): \"\"\" Release the I/O thread lock. \"\"\" if self . lock : self . lock . release ()","title":"release"},{"location":"edk2toollib/log/string_handler/#removefilter","text":"def removeFilter ( self , filter ) Remove the specified filter from this handler. View Source def removeFilter ( self , filter ): \"\"\" Remove the specified filter from this handler. \"\"\" if filter in self . filters : self . filters . remove ( filter )","title":"removeFilter"},{"location":"edk2toollib/log/string_handler/#seek","text":"def seek ( self , offset , whence ) View Source def seek ( self , offset , whence ): return self . stream . seek ( offset , whence )","title":"seek"},{"location":"edk2toollib/log/string_handler/#seek_end","text":"def seek_end ( self ) View Source def seek_end ( self ): self . stream . seek ( 2 , 0 )","title":"seek_end"},{"location":"edk2toollib/log/string_handler/#seek_start","text":"def seek_start ( self ) View Source def seek_start ( self ): self . stream . seek ( 0 , 0 )","title":"seek_start"},{"location":"edk2toollib/log/string_handler/#setformatter","text":"def setFormatter ( self , fmt ) Set the formatter for this handler. View Source def setFormatter ( self , fmt ): \"\"\" Set the formatter for this handler. \"\"\" self . formatter = fmt","title":"setFormatter"},{"location":"edk2toollib/log/string_handler/#setlevel","text":"def setLevel ( self , level ) Set the logging level of this handler. level must be an int or a str. View Source def setLevel ( self , level ): \"\"\" Set the logging level of this handler. level must be an int or a str. \"\"\" self . level = _checkLevel ( level )","title":"setLevel"},{"location":"edk2toollib/log/string_handler/#setstream","text":"def setStream ( self , stream ) Sets the StreamHandler\u2019s stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn\u2019t. View Source def setStream ( self , stream ): \"\"\" Sets the StreamHandler's stream to the specified value, if it is different. Returns the old stream, if the stream was changed, or None if it wasn't. \"\"\" if stream is self . stream : result = None else : result = self . stream self . acquire () try : self . flush () self . stream = stream finally : self . release () return result","title":"setStream"},{"location":"edk2toollib/log/string_handler/#set_name","text":"def set_name ( self , name ) View Source def set_name ( self , name ) : _acquireLock () try : if self . _name in _handlers : del _handlers [ self._name ] self . _name = name if name : _handlers [ name ] = self finally : _releaseLock ()","title":"set_name"},{"location":"edk2toollib/tpm/","text":"Module edk2toollib.tpm View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.tpm.tpm2_defs edk2toollib.tpm.tpm2_defs_test edk2toollib.tpm.tpm2_policy_calc edk2toollib.tpm.tpm2_policy_calc_test edk2toollib.tpm.tpm2_simulator edk2toollib.tpm.tpm2_stream edk2toollib.tpm.tpm2_stream_test","title":"Index"},{"location":"edk2toollib/tpm/#module-edk2toollibtpm","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.tpm"},{"location":"edk2toollib/tpm/#sub-modules","text":"edk2toollib.tpm.tpm2_defs edk2toollib.tpm.tpm2_defs_test edk2toollib.tpm.tpm2_policy_calc edk2toollib.tpm.tpm2_policy_calc_test edk2toollib.tpm.tpm2_simulator edk2toollib.tpm.tpm2_stream edk2toollib.tpm.tpm2_stream_test","title":"Sub-modules"},{"location":"edk2toollib/tpm/tpm2_defs/","text":"Module edk2toollib.tpm.tpm2_defs View Source # @file tpm2_defs . py # This file contains utility classes to help interpret definitions from the # Tpm20 . h header file in TianoCore . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## ## # INCLUDES CONTENTS FROM TianoCore Tpm20 . h HEADER FILE !! # # TPM2 .0 Specification data structures # ( Trusted Platform Module Library Specification , Family \"2.0\" , Level 00 , Revision 00.96 , # @http : // www . trustedcomputinggroup . org / resources / tpm_library_specification ) # # Check http : // trustedcomputinggroup . org for latest specification updates . # # Copyright ( c ) 2013 - 2015 , Intel Corporation . All rights reserved . < BR > ## # Table 7 - TPM_ALG_ID Constants TPM_ALG_Size = 2 TPM_ALG_Pack = \"H\" TPM_ALG_ERROR = 0x0000 TPM_ALG_FIRST = 0x0001 TPM_ALG_RSA = 0x0001 TPM_ALG_SHA = 0x0004 TPM_ALG_SHA1 = 0x0004 TPM_ALG_HMAC = 0x0005 TPM_ALG_AES = 0x0006 TPM_ALG_MGF1 = 0x0007 TPM_ALG_KEYEDHASH = 0x0008 TPM_ALG_XOR = 0x000A TPM_ALG_SHA256 = 0x000B TPM_ALG_SHA384 = 0x000C TPM_ALG_SHA512 = 0x000D TPM_ALG_NULL = 0x0010 TPM_ALG_SM3_256 = 0x0012 TPM_ALG_SM4 = 0x0013 TPM_ALG_RSASSA = 0x0014 TPM_ALG_RSAES = 0x0015 TPM_ALG_RSAPSS = 0x0016 TPM_ALG_OAEP = 0x0017 TPM_ALG_ECDSA = 0x0018 TPM_ALG_ECDH = 0x0019 TPM_ALG_ECDAA = 0x001A TPM_ALG_SM2 = 0x001B TPM_ALG_ECSCHNORR = 0x001C TPM_ALG_ECMQV = 0x001D TPM_ALG_KDF1_SP800_56a = 0x0020 TPM_ALG_KDF2 = 0x0021 TPM_ALG_KDF1_SP800_108 = 0x0022 TPM_ALG_ECC = 0x0023 TPM_ALG_SYMCIPHER = 0x0025 TPM_ALG_CTR = 0x0040 TPM_ALG_OFB = 0x0041 TPM_ALG_CBC = 0x0042 TPM_ALG_CFB = 0x0043 TPM_ALG_ECB = 0x0044 TPM_ALG_LAST = 0x0044 # Table 11 - TPM_CC Constants ( Numeric Order ) TPM_CC_Size = 4 TPM_CC_Pack = \"L\" TPM_CC_FIRST = 0x0000011F TPM_CC_PP_FIRST = 0x0000011F TPM_CC_NV_UndefineSpaceSpecial = 0x0000011F TPM_CC_EvictControl = 0x00000120 TPM_CC_HierarchyControl = 0x00000121 TPM_CC_NV_UndefineSpace = 0x00000122 TPM_CC_ChangeEPS = 0x00000124 TPM_CC_ChangePPS = 0x00000125 TPM_CC_Clear = 0x00000126 TPM_CC_ClearControl = 0x00000127 TPM_CC_ClockSet = 0x00000128 TPM_CC_HierarchyChangeAuth = 0x00000129 TPM_CC_NV_DefineSpace = 0x0000012A TPM_CC_PCR_Allocate = 0x0000012B TPM_CC_PCR_SetAuthPolicy = 0x0000012C TPM_CC_PP_Commands = 0x0000012D TPM_CC_SetPrimaryPolicy = 0x0000012E TPM_CC_FieldUpgradeStart = 0x0000012F TPM_CC_ClockRateAdjust = 0x00000130 TPM_CC_CreatePrimary = 0x00000131 TPM_CC_NV_GlobalWriteLock = 0x00000132 TPM_CC_PP_LAST = 0x00000132 TPM_CC_GetCommandAuditDigest = 0x00000133 TPM_CC_NV_Increment = 0x00000134 TPM_CC_NV_SetBits = 0x00000135 TPM_CC_NV_Extend = 0x00000136 TPM_CC_NV_Write = 0x00000137 TPM_CC_NV_WriteLock = 0x00000138 TPM_CC_DictionaryAttackLockReset = 0x00000139 TPM_CC_DictionaryAttackParameters = 0x0000013A TPM_CC_NV_ChangeAuth = 0x0000013B TPM_CC_PCR_Event = 0x0000013C TPM_CC_PCR_Reset = 0x0000013D TPM_CC_SequenceComplete = 0x0000013E TPM_CC_SetAlgorithmSet = 0x0000013F TPM_CC_SetCommandCodeAuditStatus = 0x00000140 TPM_CC_FieldUpgradeData = 0x00000141 TPM_CC_IncrementalSelfTest = 0x00000142 TPM_CC_SelfTest = 0x00000143 TPM_CC_Startup = 0x00000144 TPM_CC_Shutdown = 0x00000145 TPM_CC_StirRandom = 0x00000146 TPM_CC_ActivateCredential = 0x00000147 TPM_CC_Certify = 0x00000148 TPM_CC_PolicyNV = 0x00000149 TPM_CC_CertifyCreation = 0x0000014A TPM_CC_Duplicate = 0x0000014B TPM_CC_GetTime = 0x0000014C TPM_CC_GetSessionAuditDigest = 0x0000014D TPM_CC_NV_Read = 0x0000014E TPM_CC_NV_ReadLock = 0x0000014F TPM_CC_ObjectChangeAuth = 0x00000150 TPM_CC_PolicySecret = 0x00000151 TPM_CC_Rewrap = 0x00000152 TPM_CC_Create = 0x00000153 TPM_CC_ECDH_ZGen = 0x00000154 TPM_CC_HMAC = 0x00000155 TPM_CC_Import = 0x00000156 TPM_CC_Load = 0x00000157 TPM_CC_Quote = 0x00000158 TPM_CC_RSA_Decrypt = 0x00000159 TPM_CC_HMAC_Start = 0x0000015B TPM_CC_SequenceUpdate = 0x0000015C TPM_CC_Sign = 0x0000015D TPM_CC_Unseal = 0x0000015E TPM_CC_PolicySigned = 0x00000160 TPM_CC_ContextLoad = 0x00000161 TPM_CC_ContextSave = 0x00000162 TPM_CC_ECDH_KeyGen = 0x00000163 TPM_CC_EncryptDecrypt = 0x00000164 TPM_CC_FlushContext = 0x00000165 TPM_CC_LoadExternal = 0x00000167 TPM_CC_MakeCredential = 0x00000168 TPM_CC_NV_ReadPublic = 0x00000169 TPM_CC_PolicyAuthorize = 0x0000016A TPM_CC_PolicyAuthValue = 0x0000016B TPM_CC_PolicyCommandCode = 0x0000016C TPM_CC_PolicyCounterTimer = 0x0000016D TPM_CC_PolicyCpHash = 0x0000016E TPM_CC_PolicyLocality = 0x0000016F TPM_CC_PolicyNameHash = 0x00000170 TPM_CC_PolicyOR = 0x00000171 TPM_CC_PolicyTicket = 0x00000172 TPM_CC_ReadPublic = 0x00000173 TPM_CC_RSA_Encrypt = 0x00000174 TPM_CC_StartAuthSession = 0x00000176 TPM_CC_VerifySignature = 0x00000177 TPM_CC_ECC_Parameters = 0x00000178 TPM_CC_FirmwareRead = 0x00000179 TPM_CC_GetCapability = 0x0000017A TPM_CC_GetRandom = 0x0000017B TPM_CC_GetTestResult = 0x0000017C TPM_CC_Hash = 0x0000017D TPM_CC_PCR_Read = 0x0000017E TPM_CC_PolicyPCR = 0x0000017F TPM_CC_PolicyRestart = 0x00000180 TPM_CC_ReadClock = 0x00000181 TPM_CC_PCR_Extend = 0x00000182 TPM_CC_PCR_SetAuthValue = 0x00000183 TPM_CC_NV_Certify = 0x00000184 TPM_CC_EventSequenceComplete = 0x00000185 TPM_CC_HashSequenceStart = 0x00000186 TPM_CC_PolicyPhysicalPresence = 0x00000187 TPM_CC_PolicyDuplicationSelect = 0x00000188 TPM_CC_PolicyGetDigest = 0x00000189 TPM_CC_TestParms = 0x0000018A TPM_CC_Commit = 0x0000018B TPM_CC_PolicyPassword = 0x0000018C TPM_CC_ZGen_2Phase = 0x0000018D TPM_CC_EC_Ephemeral = 0x0000018E TPM_CC_LAST = 0x0000018E # Table 18 - TPM_ST Constants TPM_ST_Size = 2 TPM_ST_Pack = \"H\" TPM_ST_RSP_COMMAND = 0x00C4 TPM_ST_NULL = 0X8000 TPM_ST_NO_SESSIONS = 0x8001 TPM_ST_SESSIONS = 0x8002 TPM_ST_ATTEST_NV = 0x8014 TPM_ST_ATTEST_COMMAND_AUDIT = 0x8015 TPM_ST_ATTEST_SESSION_AUDIT = 0x8016 TPM_ST_ATTEST_CERTIFY = 0x8017 TPM_ST_ATTEST_QUOTE = 0x8018 TPM_ST_ATTEST_TIME = 0x8019 TPM_ST_ATTEST_CREATION = 0x801A TPM_ST_CREATION = 0x8021 TPM_ST_VERIFIED = 0x8022 TPM_ST_AUTH_SECRET = 0x8023 TPM_ST_HASHCHECK = 0x8024 TPM_ST_AUTH_SIGNED = 0x8025 TPM_ST_FU_MANIFEST = 0x8029 # Table 19 - TPM_SU Constants TPM_SU_Size = 2 TPM_SU_Pack = \"H\" TPM_SU_CLEAR = 0x0000 TPM_SU_STATE = 0x0001 # Table 20 - TPM_SE Constants TPM_SE_Size = 1 TPM_SE_Pack = \"B\" TPM_SE_HMAC = 0x00 TPM_SE_POLICY = 0x01 TPM_SE_TRIAL = 0x03 # Table 27 - TPM_RH Constants TPM_RH_Size = 4 TPM_RH_Pack = \"L\" TPM_RH_FIRST = 0x40000000 TPM_RH_SRK = 0x40000000 TPM_RH_OWNER = 0x40000001 TPM_RH_REVOKE = 0x40000002 TPM_RH_TRANSPORT = 0x40000003 TPM_RH_OPERATOR = 0x40000004 TPM_RH_ADMIN = 0x40000005 TPM_RH_EK = 0x40000006 TPM_RH_NULL = 0x40000007 TPM_RH_UNASSIGNED = 0x40000008 TPM_RS_PW = 0x40000009 TPM_RH_LOCKOUT = 0x4000000A TPM_RH_ENDORSEMENT = 0x4000000B TPM_RH_PLATFORM = 0x4000000C TPM_RH_PLATFORM_NV = 0x4000000D TPM_RH_AUTH_00 = 0x40000010 TPM_RH_AUTH_FF = 0x4000010F TPM_RH_LAST = 0x4000010F class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None Variables TPM_ALG_AES TPM_ALG_CBC TPM_ALG_CFB TPM_ALG_CTR TPM_ALG_ECB TPM_ALG_ECC TPM_ALG_ECDAA TPM_ALG_ECDH TPM_ALG_ECDSA TPM_ALG_ECMQV TPM_ALG_ECSCHNORR TPM_ALG_ERROR TPM_ALG_FIRST TPM_ALG_HMAC TPM_ALG_KDF1_SP800_108 TPM_ALG_KDF1_SP800_56a TPM_ALG_KDF2 TPM_ALG_KEYEDHASH TPM_ALG_LAST TPM_ALG_MGF1 TPM_ALG_NULL TPM_ALG_OAEP TPM_ALG_OFB TPM_ALG_Pack TPM_ALG_RSA TPM_ALG_RSAES TPM_ALG_RSAPSS TPM_ALG_RSASSA TPM_ALG_SHA TPM_ALG_SHA1 TPM_ALG_SHA256 TPM_ALG_SHA384 TPM_ALG_SHA512 TPM_ALG_SM2 TPM_ALG_SM3_256 TPM_ALG_SM4 TPM_ALG_SYMCIPHER TPM_ALG_Size TPM_ALG_XOR TPM_CC_ActivateCredential TPM_CC_Certify TPM_CC_CertifyCreation TPM_CC_ChangeEPS TPM_CC_ChangePPS TPM_CC_Clear TPM_CC_ClearControl TPM_CC_ClockRateAdjust TPM_CC_ClockSet TPM_CC_Commit TPM_CC_ContextLoad TPM_CC_ContextSave TPM_CC_Create TPM_CC_CreatePrimary TPM_CC_DictionaryAttackLockReset TPM_CC_DictionaryAttackParameters TPM_CC_Duplicate TPM_CC_ECC_Parameters TPM_CC_ECDH_KeyGen TPM_CC_ECDH_ZGen TPM_CC_EC_Ephemeral TPM_CC_EncryptDecrypt TPM_CC_EventSequenceComplete TPM_CC_EvictControl TPM_CC_FIRST TPM_CC_FieldUpgradeData TPM_CC_FieldUpgradeStart TPM_CC_FirmwareRead TPM_CC_FlushContext TPM_CC_GetCapability TPM_CC_GetCommandAuditDigest TPM_CC_GetRandom TPM_CC_GetSessionAuditDigest TPM_CC_GetTestResult TPM_CC_GetTime TPM_CC_HMAC TPM_CC_HMAC_Start TPM_CC_Hash TPM_CC_HashSequenceStart TPM_CC_HierarchyChangeAuth TPM_CC_HierarchyControl TPM_CC_Import TPM_CC_IncrementalSelfTest TPM_CC_LAST TPM_CC_Load TPM_CC_LoadExternal TPM_CC_MakeCredential TPM_CC_NV_Certify TPM_CC_NV_ChangeAuth TPM_CC_NV_DefineSpace TPM_CC_NV_Extend TPM_CC_NV_GlobalWriteLock TPM_CC_NV_Increment TPM_CC_NV_Read TPM_CC_NV_ReadLock TPM_CC_NV_ReadPublic TPM_CC_NV_SetBits TPM_CC_NV_UndefineSpace TPM_CC_NV_UndefineSpaceSpecial TPM_CC_NV_Write TPM_CC_NV_WriteLock TPM_CC_ObjectChangeAuth TPM_CC_PCR_Allocate TPM_CC_PCR_Event TPM_CC_PCR_Extend TPM_CC_PCR_Read TPM_CC_PCR_Reset TPM_CC_PCR_SetAuthPolicy TPM_CC_PCR_SetAuthValue TPM_CC_PP_Commands TPM_CC_PP_FIRST TPM_CC_PP_LAST TPM_CC_Pack TPM_CC_PolicyAuthValue TPM_CC_PolicyAuthorize TPM_CC_PolicyCommandCode TPM_CC_PolicyCounterTimer TPM_CC_PolicyCpHash TPM_CC_PolicyDuplicationSelect TPM_CC_PolicyGetDigest TPM_CC_PolicyLocality TPM_CC_PolicyNV TPM_CC_PolicyNameHash TPM_CC_PolicyOR TPM_CC_PolicyPCR TPM_CC_PolicyPassword TPM_CC_PolicyPhysicalPresence TPM_CC_PolicyRestart TPM_CC_PolicySecret TPM_CC_PolicySigned TPM_CC_PolicyTicket TPM_CC_Quote TPM_CC_RSA_Decrypt TPM_CC_RSA_Encrypt TPM_CC_ReadClock TPM_CC_ReadPublic TPM_CC_Rewrap TPM_CC_SelfTest TPM_CC_SequenceComplete TPM_CC_SequenceUpdate TPM_CC_SetAlgorithmSet TPM_CC_SetCommandCodeAuditStatus TPM_CC_SetPrimaryPolicy TPM_CC_Shutdown TPM_CC_Sign TPM_CC_Size TPM_CC_StartAuthSession TPM_CC_Startup TPM_CC_StirRandom TPM_CC_TestParms TPM_CC_Unseal TPM_CC_VerifySignature TPM_CC_ZGen_2Phase TPM_RH_ADMIN TPM_RH_AUTH_00 TPM_RH_AUTH_FF TPM_RH_EK TPM_RH_ENDORSEMENT TPM_RH_FIRST TPM_RH_LAST TPM_RH_LOCKOUT TPM_RH_NULL TPM_RH_OPERATOR TPM_RH_OWNER TPM_RH_PLATFORM TPM_RH_PLATFORM_NV TPM_RH_Pack TPM_RH_REVOKE TPM_RH_SRK TPM_RH_Size TPM_RH_TRANSPORT TPM_RH_UNASSIGNED TPM_RS_PW TPM_SE_HMAC TPM_SE_POLICY TPM_SE_Pack TPM_SE_Size TPM_SE_TRIAL TPM_ST_ATTEST_CERTIFY TPM_ST_ATTEST_COMMAND_AUDIT TPM_ST_ATTEST_CREATION TPM_ST_ATTEST_NV TPM_ST_ATTEST_QUOTE TPM_ST_ATTEST_SESSION_AUDIT TPM_ST_ATTEST_TIME TPM_ST_AUTH_SECRET TPM_ST_AUTH_SIGNED TPM_ST_CREATION TPM_ST_FU_MANIFEST TPM_ST_HASHCHECK TPM_ST_NO_SESSIONS TPM_ST_NULL TPM_ST_Pack TPM_ST_RSP_COMMAND TPM_ST_SESSIONS TPM_ST_Size TPM_ST_VERIFIED TPM_SU_CLEAR TPM_SU_Pack TPM_SU_STATE TPM_SU_Size Classes CommandCode class CommandCode ( / , * args , ** kwargs ) View Source class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) Static methods get_code def get_code ( cc_string ) View Source @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) get_string def get_string ( cc_code ) View Source @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) ResponseCode class ResponseCode ( / , * args , ** kwargs ) View Source class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None Static methods get_simple_string def get_simple_string ( rc_code ) View Source @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) parse_code def parse_code ( rc_code ) View Source @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"Tpm2 defs"},{"location":"edk2toollib/tpm/tpm2_defs/#module-edk2toollibtpmtpm2_defs","text":"View Source # @file tpm2_defs . py # This file contains utility classes to help interpret definitions from the # Tpm20 . h header file in TianoCore . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## ## # INCLUDES CONTENTS FROM TianoCore Tpm20 . h HEADER FILE !! # # TPM2 .0 Specification data structures # ( Trusted Platform Module Library Specification , Family \"2.0\" , Level 00 , Revision 00.96 , # @http : // www . trustedcomputinggroup . org / resources / tpm_library_specification ) # # Check http : // trustedcomputinggroup . org for latest specification updates . # # Copyright ( c ) 2013 - 2015 , Intel Corporation . All rights reserved . < BR > ## # Table 7 - TPM_ALG_ID Constants TPM_ALG_Size = 2 TPM_ALG_Pack = \"H\" TPM_ALG_ERROR = 0x0000 TPM_ALG_FIRST = 0x0001 TPM_ALG_RSA = 0x0001 TPM_ALG_SHA = 0x0004 TPM_ALG_SHA1 = 0x0004 TPM_ALG_HMAC = 0x0005 TPM_ALG_AES = 0x0006 TPM_ALG_MGF1 = 0x0007 TPM_ALG_KEYEDHASH = 0x0008 TPM_ALG_XOR = 0x000A TPM_ALG_SHA256 = 0x000B TPM_ALG_SHA384 = 0x000C TPM_ALG_SHA512 = 0x000D TPM_ALG_NULL = 0x0010 TPM_ALG_SM3_256 = 0x0012 TPM_ALG_SM4 = 0x0013 TPM_ALG_RSASSA = 0x0014 TPM_ALG_RSAES = 0x0015 TPM_ALG_RSAPSS = 0x0016 TPM_ALG_OAEP = 0x0017 TPM_ALG_ECDSA = 0x0018 TPM_ALG_ECDH = 0x0019 TPM_ALG_ECDAA = 0x001A TPM_ALG_SM2 = 0x001B TPM_ALG_ECSCHNORR = 0x001C TPM_ALG_ECMQV = 0x001D TPM_ALG_KDF1_SP800_56a = 0x0020 TPM_ALG_KDF2 = 0x0021 TPM_ALG_KDF1_SP800_108 = 0x0022 TPM_ALG_ECC = 0x0023 TPM_ALG_SYMCIPHER = 0x0025 TPM_ALG_CTR = 0x0040 TPM_ALG_OFB = 0x0041 TPM_ALG_CBC = 0x0042 TPM_ALG_CFB = 0x0043 TPM_ALG_ECB = 0x0044 TPM_ALG_LAST = 0x0044 # Table 11 - TPM_CC Constants ( Numeric Order ) TPM_CC_Size = 4 TPM_CC_Pack = \"L\" TPM_CC_FIRST = 0x0000011F TPM_CC_PP_FIRST = 0x0000011F TPM_CC_NV_UndefineSpaceSpecial = 0x0000011F TPM_CC_EvictControl = 0x00000120 TPM_CC_HierarchyControl = 0x00000121 TPM_CC_NV_UndefineSpace = 0x00000122 TPM_CC_ChangeEPS = 0x00000124 TPM_CC_ChangePPS = 0x00000125 TPM_CC_Clear = 0x00000126 TPM_CC_ClearControl = 0x00000127 TPM_CC_ClockSet = 0x00000128 TPM_CC_HierarchyChangeAuth = 0x00000129 TPM_CC_NV_DefineSpace = 0x0000012A TPM_CC_PCR_Allocate = 0x0000012B TPM_CC_PCR_SetAuthPolicy = 0x0000012C TPM_CC_PP_Commands = 0x0000012D TPM_CC_SetPrimaryPolicy = 0x0000012E TPM_CC_FieldUpgradeStart = 0x0000012F TPM_CC_ClockRateAdjust = 0x00000130 TPM_CC_CreatePrimary = 0x00000131 TPM_CC_NV_GlobalWriteLock = 0x00000132 TPM_CC_PP_LAST = 0x00000132 TPM_CC_GetCommandAuditDigest = 0x00000133 TPM_CC_NV_Increment = 0x00000134 TPM_CC_NV_SetBits = 0x00000135 TPM_CC_NV_Extend = 0x00000136 TPM_CC_NV_Write = 0x00000137 TPM_CC_NV_WriteLock = 0x00000138 TPM_CC_DictionaryAttackLockReset = 0x00000139 TPM_CC_DictionaryAttackParameters = 0x0000013A TPM_CC_NV_ChangeAuth = 0x0000013B TPM_CC_PCR_Event = 0x0000013C TPM_CC_PCR_Reset = 0x0000013D TPM_CC_SequenceComplete = 0x0000013E TPM_CC_SetAlgorithmSet = 0x0000013F TPM_CC_SetCommandCodeAuditStatus = 0x00000140 TPM_CC_FieldUpgradeData = 0x00000141 TPM_CC_IncrementalSelfTest = 0x00000142 TPM_CC_SelfTest = 0x00000143 TPM_CC_Startup = 0x00000144 TPM_CC_Shutdown = 0x00000145 TPM_CC_StirRandom = 0x00000146 TPM_CC_ActivateCredential = 0x00000147 TPM_CC_Certify = 0x00000148 TPM_CC_PolicyNV = 0x00000149 TPM_CC_CertifyCreation = 0x0000014A TPM_CC_Duplicate = 0x0000014B TPM_CC_GetTime = 0x0000014C TPM_CC_GetSessionAuditDigest = 0x0000014D TPM_CC_NV_Read = 0x0000014E TPM_CC_NV_ReadLock = 0x0000014F TPM_CC_ObjectChangeAuth = 0x00000150 TPM_CC_PolicySecret = 0x00000151 TPM_CC_Rewrap = 0x00000152 TPM_CC_Create = 0x00000153 TPM_CC_ECDH_ZGen = 0x00000154 TPM_CC_HMAC = 0x00000155 TPM_CC_Import = 0x00000156 TPM_CC_Load = 0x00000157 TPM_CC_Quote = 0x00000158 TPM_CC_RSA_Decrypt = 0x00000159 TPM_CC_HMAC_Start = 0x0000015B TPM_CC_SequenceUpdate = 0x0000015C TPM_CC_Sign = 0x0000015D TPM_CC_Unseal = 0x0000015E TPM_CC_PolicySigned = 0x00000160 TPM_CC_ContextLoad = 0x00000161 TPM_CC_ContextSave = 0x00000162 TPM_CC_ECDH_KeyGen = 0x00000163 TPM_CC_EncryptDecrypt = 0x00000164 TPM_CC_FlushContext = 0x00000165 TPM_CC_LoadExternal = 0x00000167 TPM_CC_MakeCredential = 0x00000168 TPM_CC_NV_ReadPublic = 0x00000169 TPM_CC_PolicyAuthorize = 0x0000016A TPM_CC_PolicyAuthValue = 0x0000016B TPM_CC_PolicyCommandCode = 0x0000016C TPM_CC_PolicyCounterTimer = 0x0000016D TPM_CC_PolicyCpHash = 0x0000016E TPM_CC_PolicyLocality = 0x0000016F TPM_CC_PolicyNameHash = 0x00000170 TPM_CC_PolicyOR = 0x00000171 TPM_CC_PolicyTicket = 0x00000172 TPM_CC_ReadPublic = 0x00000173 TPM_CC_RSA_Encrypt = 0x00000174 TPM_CC_StartAuthSession = 0x00000176 TPM_CC_VerifySignature = 0x00000177 TPM_CC_ECC_Parameters = 0x00000178 TPM_CC_FirmwareRead = 0x00000179 TPM_CC_GetCapability = 0x0000017A TPM_CC_GetRandom = 0x0000017B TPM_CC_GetTestResult = 0x0000017C TPM_CC_Hash = 0x0000017D TPM_CC_PCR_Read = 0x0000017E TPM_CC_PolicyPCR = 0x0000017F TPM_CC_PolicyRestart = 0x00000180 TPM_CC_ReadClock = 0x00000181 TPM_CC_PCR_Extend = 0x00000182 TPM_CC_PCR_SetAuthValue = 0x00000183 TPM_CC_NV_Certify = 0x00000184 TPM_CC_EventSequenceComplete = 0x00000185 TPM_CC_HashSequenceStart = 0x00000186 TPM_CC_PolicyPhysicalPresence = 0x00000187 TPM_CC_PolicyDuplicationSelect = 0x00000188 TPM_CC_PolicyGetDigest = 0x00000189 TPM_CC_TestParms = 0x0000018A TPM_CC_Commit = 0x0000018B TPM_CC_PolicyPassword = 0x0000018C TPM_CC_ZGen_2Phase = 0x0000018D TPM_CC_EC_Ephemeral = 0x0000018E TPM_CC_LAST = 0x0000018E # Table 18 - TPM_ST Constants TPM_ST_Size = 2 TPM_ST_Pack = \"H\" TPM_ST_RSP_COMMAND = 0x00C4 TPM_ST_NULL = 0X8000 TPM_ST_NO_SESSIONS = 0x8001 TPM_ST_SESSIONS = 0x8002 TPM_ST_ATTEST_NV = 0x8014 TPM_ST_ATTEST_COMMAND_AUDIT = 0x8015 TPM_ST_ATTEST_SESSION_AUDIT = 0x8016 TPM_ST_ATTEST_CERTIFY = 0x8017 TPM_ST_ATTEST_QUOTE = 0x8018 TPM_ST_ATTEST_TIME = 0x8019 TPM_ST_ATTEST_CREATION = 0x801A TPM_ST_CREATION = 0x8021 TPM_ST_VERIFIED = 0x8022 TPM_ST_AUTH_SECRET = 0x8023 TPM_ST_HASHCHECK = 0x8024 TPM_ST_AUTH_SIGNED = 0x8025 TPM_ST_FU_MANIFEST = 0x8029 # Table 19 - TPM_SU Constants TPM_SU_Size = 2 TPM_SU_Pack = \"H\" TPM_SU_CLEAR = 0x0000 TPM_SU_STATE = 0x0001 # Table 20 - TPM_SE Constants TPM_SE_Size = 1 TPM_SE_Pack = \"B\" TPM_SE_HMAC = 0x00 TPM_SE_POLICY = 0x01 TPM_SE_TRIAL = 0x03 # Table 27 - TPM_RH Constants TPM_RH_Size = 4 TPM_RH_Pack = \"L\" TPM_RH_FIRST = 0x40000000 TPM_RH_SRK = 0x40000000 TPM_RH_OWNER = 0x40000001 TPM_RH_REVOKE = 0x40000002 TPM_RH_TRANSPORT = 0x40000003 TPM_RH_OPERATOR = 0x40000004 TPM_RH_ADMIN = 0x40000005 TPM_RH_EK = 0x40000006 TPM_RH_NULL = 0x40000007 TPM_RH_UNASSIGNED = 0x40000008 TPM_RS_PW = 0x40000009 TPM_RH_LOCKOUT = 0x4000000A TPM_RH_ENDORSEMENT = 0x4000000B TPM_RH_PLATFORM = 0x4000000C TPM_RH_PLATFORM_NV = 0x4000000D TPM_RH_AUTH_00 = 0x40000010 TPM_RH_AUTH_FF = 0x4000010F TPM_RH_LAST = 0x4000010F class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None ) class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"Module edk2toollib.tpm.tpm2_defs"},{"location":"edk2toollib/tpm/tpm2_defs/#variables","text":"TPM_ALG_AES TPM_ALG_CBC TPM_ALG_CFB TPM_ALG_CTR TPM_ALG_ECB TPM_ALG_ECC TPM_ALG_ECDAA TPM_ALG_ECDH TPM_ALG_ECDSA TPM_ALG_ECMQV TPM_ALG_ECSCHNORR TPM_ALG_ERROR TPM_ALG_FIRST TPM_ALG_HMAC TPM_ALG_KDF1_SP800_108 TPM_ALG_KDF1_SP800_56a TPM_ALG_KDF2 TPM_ALG_KEYEDHASH TPM_ALG_LAST TPM_ALG_MGF1 TPM_ALG_NULL TPM_ALG_OAEP TPM_ALG_OFB TPM_ALG_Pack TPM_ALG_RSA TPM_ALG_RSAES TPM_ALG_RSAPSS TPM_ALG_RSASSA TPM_ALG_SHA TPM_ALG_SHA1 TPM_ALG_SHA256 TPM_ALG_SHA384 TPM_ALG_SHA512 TPM_ALG_SM2 TPM_ALG_SM3_256 TPM_ALG_SM4 TPM_ALG_SYMCIPHER TPM_ALG_Size TPM_ALG_XOR TPM_CC_ActivateCredential TPM_CC_Certify TPM_CC_CertifyCreation TPM_CC_ChangeEPS TPM_CC_ChangePPS TPM_CC_Clear TPM_CC_ClearControl TPM_CC_ClockRateAdjust TPM_CC_ClockSet TPM_CC_Commit TPM_CC_ContextLoad TPM_CC_ContextSave TPM_CC_Create TPM_CC_CreatePrimary TPM_CC_DictionaryAttackLockReset TPM_CC_DictionaryAttackParameters TPM_CC_Duplicate TPM_CC_ECC_Parameters TPM_CC_ECDH_KeyGen TPM_CC_ECDH_ZGen TPM_CC_EC_Ephemeral TPM_CC_EncryptDecrypt TPM_CC_EventSequenceComplete TPM_CC_EvictControl TPM_CC_FIRST TPM_CC_FieldUpgradeData TPM_CC_FieldUpgradeStart TPM_CC_FirmwareRead TPM_CC_FlushContext TPM_CC_GetCapability TPM_CC_GetCommandAuditDigest TPM_CC_GetRandom TPM_CC_GetSessionAuditDigest TPM_CC_GetTestResult TPM_CC_GetTime TPM_CC_HMAC TPM_CC_HMAC_Start TPM_CC_Hash TPM_CC_HashSequenceStart TPM_CC_HierarchyChangeAuth TPM_CC_HierarchyControl TPM_CC_Import TPM_CC_IncrementalSelfTest TPM_CC_LAST TPM_CC_Load TPM_CC_LoadExternal TPM_CC_MakeCredential TPM_CC_NV_Certify TPM_CC_NV_ChangeAuth TPM_CC_NV_DefineSpace TPM_CC_NV_Extend TPM_CC_NV_GlobalWriteLock TPM_CC_NV_Increment TPM_CC_NV_Read TPM_CC_NV_ReadLock TPM_CC_NV_ReadPublic TPM_CC_NV_SetBits TPM_CC_NV_UndefineSpace TPM_CC_NV_UndefineSpaceSpecial TPM_CC_NV_Write TPM_CC_NV_WriteLock TPM_CC_ObjectChangeAuth TPM_CC_PCR_Allocate TPM_CC_PCR_Event TPM_CC_PCR_Extend TPM_CC_PCR_Read TPM_CC_PCR_Reset TPM_CC_PCR_SetAuthPolicy TPM_CC_PCR_SetAuthValue TPM_CC_PP_Commands TPM_CC_PP_FIRST TPM_CC_PP_LAST TPM_CC_Pack TPM_CC_PolicyAuthValue TPM_CC_PolicyAuthorize TPM_CC_PolicyCommandCode TPM_CC_PolicyCounterTimer TPM_CC_PolicyCpHash TPM_CC_PolicyDuplicationSelect TPM_CC_PolicyGetDigest TPM_CC_PolicyLocality TPM_CC_PolicyNV TPM_CC_PolicyNameHash TPM_CC_PolicyOR TPM_CC_PolicyPCR TPM_CC_PolicyPassword TPM_CC_PolicyPhysicalPresence TPM_CC_PolicyRestart TPM_CC_PolicySecret TPM_CC_PolicySigned TPM_CC_PolicyTicket TPM_CC_Quote TPM_CC_RSA_Decrypt TPM_CC_RSA_Encrypt TPM_CC_ReadClock TPM_CC_ReadPublic TPM_CC_Rewrap TPM_CC_SelfTest TPM_CC_SequenceComplete TPM_CC_SequenceUpdate TPM_CC_SetAlgorithmSet TPM_CC_SetCommandCodeAuditStatus TPM_CC_SetPrimaryPolicy TPM_CC_Shutdown TPM_CC_Sign TPM_CC_Size TPM_CC_StartAuthSession TPM_CC_Startup TPM_CC_StirRandom TPM_CC_TestParms TPM_CC_Unseal TPM_CC_VerifySignature TPM_CC_ZGen_2Phase TPM_RH_ADMIN TPM_RH_AUTH_00 TPM_RH_AUTH_FF TPM_RH_EK TPM_RH_ENDORSEMENT TPM_RH_FIRST TPM_RH_LAST TPM_RH_LOCKOUT TPM_RH_NULL TPM_RH_OPERATOR TPM_RH_OWNER TPM_RH_PLATFORM TPM_RH_PLATFORM_NV TPM_RH_Pack TPM_RH_REVOKE TPM_RH_SRK TPM_RH_Size TPM_RH_TRANSPORT TPM_RH_UNASSIGNED TPM_RS_PW TPM_SE_HMAC TPM_SE_POLICY TPM_SE_Pack TPM_SE_Size TPM_SE_TRIAL TPM_ST_ATTEST_CERTIFY TPM_ST_ATTEST_COMMAND_AUDIT TPM_ST_ATTEST_CREATION TPM_ST_ATTEST_NV TPM_ST_ATTEST_QUOTE TPM_ST_ATTEST_SESSION_AUDIT TPM_ST_ATTEST_TIME TPM_ST_AUTH_SECRET TPM_ST_AUTH_SIGNED TPM_ST_CREATION TPM_ST_FU_MANIFEST TPM_ST_HASHCHECK TPM_ST_NO_SESSIONS TPM_ST_NULL TPM_ST_Pack TPM_ST_RSP_COMMAND TPM_ST_SESSIONS TPM_ST_Size TPM_ST_VERIFIED TPM_SU_CLEAR TPM_SU_Pack TPM_SU_STATE TPM_SU_Size","title":"Variables"},{"location":"edk2toollib/tpm/tpm2_defs/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_defs/#commandcode","text":"class CommandCode ( / , * args , ** kwargs ) View Source class CommandCode ( object ) : @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None ) @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None )","title":"CommandCode"},{"location":"edk2toollib/tpm/tpm2_defs/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/tpm/tpm2_defs/#get_code","text":"def get_code ( cc_string ) View Source @staticmethod def get_code ( cc_string ) : return { \"TPM_CC_NV_UndefineSpaceSpecial\" : 0x0000011F , \"TPM_CC_EvictControl\" : 0x00000120 , \"TPM_CC_HierarchyControl\" : 0x00000121 , \"TPM_CC_NV_UndefineSpace\" : 0x00000122 , \"TPM_CC_ChangeEPS\" : 0x00000124 , \"TPM_CC_ChangePPS\" : 0x00000125 , \"TPM_CC_Clear\" : 0x00000126 , \"TPM_CC_ClearControl\" : 0x00000127 , \"TPM_CC_ClockSet\" : 0x00000128 , \"TPM_CC_HierarchyChangeAuth\" : 0x00000129 , \"TPM_CC_NV_DefineSpace\" : 0x0000012A , \"TPM_CC_PCR_Allocate\" : 0x0000012B , \"TPM_CC_PCR_SetAuthPolicy\" : 0x0000012C , \"TPM_CC_PP_Commands\" : 0x0000012D , \"TPM_CC_SetPrimaryPolicy\" : 0x0000012E , \"TPM_CC_FieldUpgradeStart\" : 0x0000012F , \"TPM_CC_ClockRateAdjust\" : 0x00000130 , \"TPM_CC_CreatePrimary\" : 0x00000131 , \"TPM_CC_NV_GlobalWriteLock\" : 0x00000132 , \"TPM_CC_GetCommandAuditDigest\" : 0x00000133 , \"TPM_CC_NV_Increment\" : 0x00000134 , \"TPM_CC_NV_SetBits\" : 0x00000135 , \"TPM_CC_NV_Extend\" : 0x00000136 , \"TPM_CC_NV_Write\" : 0x00000137 , \"TPM_CC_NV_WriteLock\" : 0x00000138 , \"TPM_CC_DictionaryAttackLockReset\" : 0x00000139 , \"TPM_CC_DictionaryAttackParameters\" : 0x0000013A , \"TPM_CC_NV_ChangeAuth\" : 0x0000013B , \"TPM_CC_PCR_Event\" : 0x0000013C , \"TPM_CC_PCR_Reset\" : 0x0000013D , \"TPM_CC_SequenceComplete\" : 0x0000013E , \"TPM_CC_SetAlgorithmSet\" : 0x0000013F , \"TPM_CC_SetCommandCodeAuditStatus\" : 0x00000140 , \"TPM_CC_FieldUpgradeData\" : 0x00000141 , \"TPM_CC_IncrementalSelfTest\" : 0x00000142 , \"TPM_CC_SelfTest\" : 0x00000143 , \"TPM_CC_Startup\" : 0x00000144 , \"TPM_CC_Shutdown\" : 0x00000145 , \"TPM_CC_StirRandom\" : 0x00000146 , \"TPM_CC_ActivateCredential\" : 0x00000147 , \"TPM_CC_Certify\" : 0x00000148 , \"TPM_CC_PolicyNV\" : 0x00000149 , \"TPM_CC_CertifyCreation\" : 0x0000014A , \"TPM_CC_Duplicate\" : 0x0000014B , \"TPM_CC_GetTime\" : 0x0000014C , \"TPM_CC_GetSessionAuditDigest\" : 0x0000014D , \"TPM_CC_NV_Read\" : 0x0000014E , \"TPM_CC_NV_ReadLock\" : 0x0000014F , \"TPM_CC_ObjectChangeAuth\" : 0x00000150 , \"TPM_CC_PolicySecret\" : 0x00000151 , \"TPM_CC_Rewrap\" : 0x00000152 , \"TPM_CC_Create\" : 0x00000153 , \"TPM_CC_ECDH_ZGen\" : 0x00000154 , \"TPM_CC_HMAC\" : 0x00000155 , \"TPM_CC_Import\" : 0x00000156 , \"TPM_CC_Load\" : 0x00000157 , \"TPM_CC_Quote\" : 0x00000158 , \"TPM_CC_RSA_Decrypt\" : 0x00000159 , \"TPM_CC_HMAC_Start\" : 0x0000015B , \"TPM_CC_SequenceUpdate\" : 0x0000015C , \"TPM_CC_Sign\" : 0x0000015D , \"TPM_CC_Unseal\" : 0x0000015E , \"TPM_CC_PolicySigned\" : 0x00000160 , \"TPM_CC_ContextLoad\" : 0x00000161 , \"TPM_CC_ContextSave\" : 0x00000162 , \"TPM_CC_ECDH_KeyGen\" : 0x00000163 , \"TPM_CC_EncryptDecrypt\" : 0x00000164 , \"TPM_CC_FlushContext\" : 0x00000165 , \"TPM_CC_LoadExternal\" : 0x00000167 , \"TPM_CC_MakeCredential\" : 0x00000168 , \"TPM_CC_NV_ReadPublic\" : 0x00000169 , \"TPM_CC_PolicyAuthorize\" : 0x0000016A , \"TPM_CC_PolicyAuthValue\" : 0x0000016B , \"TPM_CC_PolicyCommandCode\" : 0x0000016C , \"TPM_CC_PolicyCounterTimer\" : 0x0000016D , \"TPM_CC_PolicyCpHash\" : 0x0000016E , \"TPM_CC_PolicyLocality\" : 0x0000016F , \"TPM_CC_PolicyNameHash\" : 0x00000170 , \"TPM_CC_PolicyOR\" : 0x00000171 , \"TPM_CC_PolicyTicket\" : 0x00000172 , \"TPM_CC_ReadPublic\" : 0x00000173 , \"TPM_CC_RSA_Encrypt\" : 0x00000174 , \"TPM_CC_StartAuthSession\" : 0x00000176 , \"TPM_CC_VerifySignature\" : 0x00000177 , \"TPM_CC_ECC_Parameters\" : 0x00000178 , \"TPM_CC_FirmwareRead\" : 0x00000179 , \"TPM_CC_GetCapability\" : 0x0000017A , \"TPM_CC_GetRandom\" : 0x0000017B , \"TPM_CC_GetTestResult\" : 0x0000017C , \"TPM_CC_Hash\" : 0x0000017D , \"TPM_CC_PCR_Read\" : 0x0000017E , \"TPM_CC_PolicyPCR\" : 0x0000017F , \"TPM_CC_PolicyRestart\" : 0x00000180 , \"TPM_CC_ReadClock\" : 0x00000181 , \"TPM_CC_PCR_Extend\" : 0x00000182 , \"TPM_CC_PCR_SetAuthValue\" : 0x00000183 , \"TPM_CC_NV_Certify\" : 0x00000184 , \"TPM_CC_EventSequenceComplete\" : 0x00000185 , \"TPM_CC_HashSequenceStart\" : 0x00000186 , \"TPM_CC_PolicyPhysicalPresence\" : 0x00000187 , \"TPM_CC_PolicyDuplicationSelect\" : 0x00000188 , \"TPM_CC_PolicyGetDigest\" : 0x00000189 , \"TPM_CC_TestParms\" : 0x0000018A , \"TPM_CC_Commit\" : 0x0000018B , \"TPM_CC_PolicyPassword\" : 0x0000018C , \"TPM_CC_ZGen_2Phase\" : 0x0000018D , \"TPM_CC_EC_Ephemeral\" : 0x0000018E , } . get ( cc_string , None )","title":"get_code"},{"location":"edk2toollib/tpm/tpm2_defs/#get_string","text":"def get_string ( cc_code ) View Source @staticmethod def get_string ( cc_code ) : return { 0x0000011F : \"TPM_CC_NV_UndefineSpaceSpecial\" , 0x00000120 : \"TPM_CC_EvictControl\" , 0x00000121 : \"TPM_CC_HierarchyControl\" , 0x00000122 : \"TPM_CC_NV_UndefineSpace\" , 0x00000124 : \"TPM_CC_ChangeEPS\" , 0x00000125 : \"TPM_CC_ChangePPS\" , 0x00000126 : \"TPM_CC_Clear\" , 0x00000127 : \"TPM_CC_ClearControl\" , 0x00000128 : \"TPM_CC_ClockSet\" , 0x00000129 : \"TPM_CC_HierarchyChangeAuth\" , 0x0000012A : \"TPM_CC_NV_DefineSpace\" , 0x0000012B : \"TPM_CC_PCR_Allocate\" , 0x0000012C : \"TPM_CC_PCR_SetAuthPolicy\" , 0x0000012D : \"TPM_CC_PP_Commands\" , 0x0000012E : \"TPM_CC_SetPrimaryPolicy\" , 0x0000012F : \"TPM_CC_FieldUpgradeStart\" , 0x00000130 : \"TPM_CC_ClockRateAdjust\" , 0x00000131 : \"TPM_CC_CreatePrimary\" , 0x00000132 : \"TPM_CC_NV_GlobalWriteLock\" , 0x00000133 : \"TPM_CC_GetCommandAuditDigest\" , 0x00000134 : \"TPM_CC_NV_Increment\" , 0x00000135 : \"TPM_CC_NV_SetBits\" , 0x00000136 : \"TPM_CC_NV_Extend\" , 0x00000137 : \"TPM_CC_NV_Write\" , 0x00000138 : \"TPM_CC_NV_WriteLock\" , 0x00000139 : \"TPM_CC_DictionaryAttackLockReset\" , 0x0000013A : \"TPM_CC_DictionaryAttackParameters\" , 0x0000013B : \"TPM_CC_NV_ChangeAuth\" , 0x0000013C : \"TPM_CC_PCR_Event\" , 0x0000013D : \"TPM_CC_PCR_Reset\" , 0x0000013E : \"TPM_CC_SequenceComplete\" , 0x0000013F : \"TPM_CC_SetAlgorithmSet\" , 0x00000140 : \"TPM_CC_SetCommandCodeAuditStatus\" , 0x00000141 : \"TPM_CC_FieldUpgradeData\" , 0x00000142 : \"TPM_CC_IncrementalSelfTest\" , 0x00000143 : \"TPM_CC_SelfTest\" , 0x00000144 : \"TPM_CC_Startup\" , 0x00000145 : \"TPM_CC_Shutdown\" , 0x00000146 : \"TPM_CC_StirRandom\" , 0x00000147 : \"TPM_CC_ActivateCredential\" , 0x00000148 : \"TPM_CC_Certify\" , 0x00000149 : \"TPM_CC_PolicyNV\" , 0x0000014A : \"TPM_CC_CertifyCreation\" , 0x0000014B : \"TPM_CC_Duplicate\" , 0x0000014C : \"TPM_CC_GetTime\" , 0x0000014D : \"TPM_CC_GetSessionAuditDigest\" , 0x0000014E : \"TPM_CC_NV_Read\" , 0x0000014F : \"TPM_CC_NV_ReadLock\" , 0x00000150 : \"TPM_CC_ObjectChangeAuth\" , 0x00000151 : \"TPM_CC_PolicySecret\" , 0x00000152 : \"TPM_CC_Rewrap\" , 0x00000153 : \"TPM_CC_Create\" , 0x00000154 : \"TPM_CC_ECDH_ZGen\" , 0x00000155 : \"TPM_CC_HMAC\" , 0x00000156 : \"TPM_CC_Import\" , 0x00000157 : \"TPM_CC_Load\" , 0x00000158 : \"TPM_CC_Quote\" , 0x00000159 : \"TPM_CC_RSA_Decrypt\" , 0x0000015B : \"TPM_CC_HMAC_Start\" , 0x0000015C : \"TPM_CC_SequenceUpdate\" , 0x0000015D : \"TPM_CC_Sign\" , 0x0000015E : \"TPM_CC_Unseal\" , 0x00000160 : \"TPM_CC_PolicySigned\" , 0x00000161 : \"TPM_CC_ContextLoad\" , 0x00000162 : \"TPM_CC_ContextSave\" , 0x00000163 : \"TPM_CC_ECDH_KeyGen\" , 0x00000164 : \"TPM_CC_EncryptDecrypt\" , 0x00000165 : \"TPM_CC_FlushContext\" , 0x00000167 : \"TPM_CC_LoadExternal\" , 0x00000168 : \"TPM_CC_MakeCredential\" , 0x00000169 : \"TPM_CC_NV_ReadPublic\" , 0x0000016A : \"TPM_CC_PolicyAuthorize\" , 0x0000016B : \"TPM_CC_PolicyAuthValue\" , 0x0000016C : \"TPM_CC_PolicyCommandCode\" , 0x0000016D : \"TPM_CC_PolicyCounterTimer\" , 0x0000016E : \"TPM_CC_PolicyCpHash\" , 0x0000016F : \"TPM_CC_PolicyLocality\" , 0x00000170 : \"TPM_CC_PolicyNameHash\" , 0x00000171 : \"TPM_CC_PolicyOR\" , 0x00000172 : \"TPM_CC_PolicyTicket\" , 0x00000173 : \"TPM_CC_ReadPublic\" , 0x00000174 : \"TPM_CC_RSA_Encrypt\" , 0x00000176 : \"TPM_CC_StartAuthSession\" , 0x00000177 : \"TPM_CC_VerifySignature\" , 0x00000178 : \"TPM_CC_ECC_Parameters\" , 0x00000179 : \"TPM_CC_FirmwareRead\" , 0x0000017A : \"TPM_CC_GetCapability\" , 0x0000017B : \"TPM_CC_GetRandom\" , 0x0000017C : \"TPM_CC_GetTestResult\" , 0x0000017D : \"TPM_CC_Hash\" , 0x0000017E : \"TPM_CC_PCR_Read\" , 0x0000017F : \"TPM_CC_PolicyPCR\" , 0x00000180 : \"TPM_CC_PolicyRestart\" , 0x00000181 : \"TPM_CC_ReadClock\" , 0x00000182 : \"TPM_CC_PCR_Extend\" , 0x00000183 : \"TPM_CC_PCR_SetAuthValue\" , 0x00000184 : \"TPM_CC_NV_Certify\" , 0x00000185 : \"TPM_CC_EventSequenceComplete\" , 0x00000186 : \"TPM_CC_HashSequenceStart\" , 0x00000187 : \"TPM_CC_PolicyPhysicalPresence\" , 0x00000188 : \"TPM_CC_PolicyDuplicationSelect\" , 0x00000189 : \"TPM_CC_PolicyGetDigest\" , 0x0000018A : \"TPM_CC_TestParms\" , 0x0000018B : \"TPM_CC_Commit\" , 0x0000018C : \"TPM_CC_PolicyPassword\" , 0x0000018D : \"TPM_CC_ZGen_2Phase\" , 0x0000018E : \"TPM_CC_EC_Ephemeral\" , } . get ( cc_code , None )","title":"get_string"},{"location":"edk2toollib/tpm/tpm2_defs/#responsecode","text":"class ResponseCode ( / , * args , ** kwargs ) View Source class ResponseCode ( object ) : @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None ) @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"ResponseCode"},{"location":"edk2toollib/tpm/tpm2_defs/#static-methods_1","text":"","title":"Static methods"},{"location":"edk2toollib/tpm/tpm2_defs/#get_simple_string","text":"def get_simple_string ( rc_code ) View Source @staticmethod def get_simple_string ( rc_code ) : return { 0x00000100 : \"TPM_RC_INITIALIZE\" , 0x00000101 : \"TPM_RC_FAILURE\" , 0x00000103 : \"TPM_RC_SEQUENCE\" , 0x0000010B : \"TPM_RC_PRIVATE\" , 0x00000119 : \"TPM_RC_HMAC\" , 0x00000120 : \"TPM_RC_DISABLED\" , 0x00000121 : \"TPM_RC_EXCLUSIVE\" , 0x00000124 : \"TPM_RC_AUTH_TYPE\" , 0x00000125 : \"TPM_RC_AUTH_MISSING\" , 0x00000126 : \"TPM_RC_POLICY\" , 0x00000127 : \"TPM_RC_PCR\" , 0x00000128 : \"TPM_RC_PCR_CHANGED\" , 0x0000012D : \"TPM_RC_UPGRADE\" , 0x0000012E : \"TPM_RC_TOO_MANY_CONTEXTS\" , 0x0000012F : \"TPM_RC_AUTH_UNAVAILABLE\" , 0x00000130 : \"TPM_RC_REBOOT\" , 0x00000131 : \"TPM_RC_UNBALANCED\" , 0x00000142 : \"TPM_RC_COMMAND_SIZE\" , 0x00000143 : \"TPM_RC_COMMAND_CODE\" , 0x00000144 : \"TPM_RC_AUTHSIZE\" , 0x00000145 : \"TPM_RC_AUTH_CONTEXT\" , 0x00000146 : \"TPM_RC_NV_RANGE\" , 0x00000147 : \"TPM_RC_NV_SIZE\" , 0x00000148 : \"TPM_RC_NV_LOCKED\" , 0x00000149 : \"TPM_RC_NV_AUTHORIZATION\" , 0x0000014A : \"TPM_RC_NV_UNINITIALIZED\" , 0x0000014B : \"TPM_RC_NV_SPACE\" , 0x0000014C : \"TPM_RC_NV_DEFINED\" , 0x00000150 : \"TPM_RC_BAD_CONTEXT\" , 0x00000151 : \"TPM_RC_CPHASH\" , 0x00000152 : \"TPM_RC_PARENT\" , 0x00000153 : \"TPM_RC_NEEDS_TEST\" , 0x00000154 : \"TPM_RC_NO_RESULT\" , 0x00000155 : \"TPM_RC_SENSITIVE\" , } . get ( rc_code , None )","title":"get_simple_string"},{"location":"edk2toollib/tpm/tpm2_defs/#parse_code","text":"def parse_code ( rc_code ) View Source @staticmethod def parse_code ( rc_code ) : generic_errors = { 0x000 : 'TPM_RC_INITIALIZE' , 0x001 : 'TPM_RC_FAILURE' , 0x003 : 'TPM_RC_SEQUENCE' , 0x00B : 'TPM_RC_PRIVATE' , 0x019 : 'TPM_RC_HMAC' , 0x020 : 'TPM_RC_DISABLED' , 0x021 : 'TPM_RC_EXCLUSIVE' , 0x024 : 'TPM_RC_AUTH_TYPE' , 0x025 : 'TPM_RC_AUTH_MISSING' , 0x026 : 'TPM_RC_POLICY' , 0x027 : 'TPM_RC_PCR' , 0x028 : 'TPM_RC_PCR_CHANGED' , 0x02D : 'TPM_RC_UPGRADE' , 0x02E : 'TPM_RC_TOO_MANY_CONTEXTS' , 0x02F : 'TPM_RC_AUTH_UNAVAILABLE' , 0x030 : 'TPM_RC_REBOOT' , 0x031 : 'TPM_RC_UNBALANCED' , 0x042 : 'TPM_RC_COMMAND_SIZE' , 0x043 : 'TPM_RC_COMMAND_CODE' , 0x044 : 'TPM_RC_AUTHSIZE' , 0x045 : 'TPM_RC_AUTH_CONTEXT' , 0x046 : 'TPM_RC_NV_RANGE' , 0x047 : 'TPM_RC_NV_SIZE' , 0x048 : 'TPM_RC_NV_LOCKED' , 0x049 : 'TPM_RC_NV_AUTHORIZATION' , 0x04A : 'TPM_RC_NV_UNINITIALIZED' , 0x04B : 'TPM_RC_NV_SPACE' , 0x04C : 'TPM_RC_NV_DEFINED' , 0x050 : 'TPM_RC_BAD_CONTEXT' , 0x051 : 'TPM_RC_CPHASH' , 0x052 : 'TPM_RC_PARENT' , 0x053 : 'TPM_RC_NEEDS_TEST' , 0x054 : 'TPM_RC_NO_RESULT' , 0x055 : 'TPM_RC_SENSITIVE' , } handle_errors = { 0x001 : 'TPM_RC_ASYMMETRIC' , 0x002 : 'TPM_RC_ATTRIBUTES' , 0x003 : 'TPM_RC_HASH' , 0x004 : 'TPM_RC_VALUE' , 0x005 : 'TPM_RC_HIERARCHY' , 0x007 : 'TPM_RC_KEY_SIZE' , 0x008 : 'TPM_RC_MGF' , 0x009 : 'TPM_RC_MODE' , 0x00A : 'TPM_RC_TYPE' , 0x00B : 'TPM_RC_HANDLE' , 0x00C : 'TPM_RC_KDF' , 0x00D : 'TPM_RC_RANGE' , 0x00E : 'TPM_RC_AUTH_FAIL' , 0x00F : 'TPM_RC_NONCE' , 0x010 : 'TPM_RC_PP' , 0x012 : 'TPM_RC_SCHEME' , 0x015 : 'TPM_RC_SIZE' , 0x016 : 'TPM_RC_SYMMETRIC' , 0x017 : 'TPM_RC_TAG' , 0x018 : 'TPM_RC_SELECTOR' , 0x01A : 'TPM_RC_INSUFFICIENT' , 0x01B : 'TPM_RC_SIGNATURE' , 0x01C : 'TPM_RC_KEY' , 0x01D : 'TPM_RC_POLICY_FAIL' , 0x01F : 'TPM_RC_INTEGRITY' , 0x020 : 'TPM_RC_TICKET' , 0x021 : 'TPM_RC_RESERVED_BITS' , 0x022 : 'TPM_RC_BAD_AUTH' , 0x023 : 'TPM_RC_EXPIRED' , 0x024 : 'TPM_RC_POLICY_CC' , 0x025 : 'TPM_RC_BINDING' , 0x026 : 'TPM_RC_CURVE' , 0x027 : 'TPM_RC_ECC_POINT' , } warnings = { 0x001 : \"TPM_RC_CONTEXT_GAP\" , 0x002 : \"TPM_RC_OBJECT_MEMORY\" , 0x003 : \"TPM_RC_SESSION_MEMORY\" , 0x004 : \"TPM_RC_MEMORY\" , 0x005 : \"TPM_RC_SESSION_HANDLES\" , 0x006 : \"TPM_RC_OBJECT_HANDLES\" , 0x007 : \"TPM_RC_LOCALITY\" , 0x008 : \"TPM_RC_YIELDED\" , 0x009 : \"TPM_RC_CANCELED\" , 0x00A : \"TPM_RC_TESTING\" , 0x010 : \"TPM_RC_REFERENCE_H0\" , 0x011 : \"TPM_RC_REFERENCE_H1\" , 0x012 : \"TPM_RC_REFERENCE_H2\" , 0x013 : \"TPM_RC_REFERENCE_H3\" , 0x014 : \"TPM_RC_REFERENCE_H4\" , 0x015 : \"TPM_RC_REFERENCE_H5\" , 0x016 : \"TPM_RC_REFERENCE_H6\" , 0x018 : \"TPM_RC_REFERENCE_S0\" , 0x019 : \"TPM_RC_REFERENCE_S1\" , 0x01A : \"TPM_RC_REFERENCE_S2\" , 0x01B : \"TPM_RC_REFERENCE_S3\" , 0x01C : \"TPM_RC_REFERENCE_S4\" , 0x01D : \"TPM_RC_REFERENCE_S5\" , 0x01E : \"TPM_RC_REFERENCE_S6\" , 0x020 : \"TPM_RC_NV_RATE\" , 0x021 : \"TPM_RC_LOCKOUT\" , 0x022 : \"TPM_RC_RETRY\" , 0x023 : \"TPM_RC_NV_UNAVAILABLE\" , } # Check for TPM_RC_SUCCESS . if rc_code == 0x00 : return ( 'Success' , 'None' , 0 , 'TPM_RC_SUCCESS' , 'NA' ) # Check for TPM 1.2 response . if not ( rc_code & ( 0 b11 << 7 )) : return ( 'Tpm1.2 Response' , 'None' , 0 , 0 , 'NA' ) # Check bit 7. if not ( rc_code & ( 1 << 7 )) : # Check bit 10. if ( rc_code & ( 1 << 10 )) : return ( 'Vendor Defined Code' , 'None' , 0 , 0 , 'NA' ) # At this point the code will be in [ 6:0 ] ... code = rc_code & 0 b1111111 # Check bit 11. if ( rc_code & ( 1 << 11 )) : return ( 'Warning' , 'None' , 0 , warnings [ code ] , 'NA' ) # TODO : Complete this . else : return ( 'Error' , 'None' , 0 , code , generic_errors [ code ] ) # At this point the code will always be in [ 5:0 ] ... code = rc_code & 0 b111111 # Check bit 6. if ( rc_code & ( 1 << 6 )) : number = ( rc_code >> 8 ) & 0 b1111 return ( 'Error' , 'Parameter' , number , code , 'NA' ) # TODO : Complete this . # At this point the nubmer will always be in [ 10:8 ] ... number = ( rc_code >> 8 ) & 0 b111 # Check bit 11. if not ( rc_code & ( 1 << 11 )) : return ( 'Error' , 'Handle' , number , code , handle_errors [ code ] ) # TODO : Complete this . else : return ( 'Error' , 'Session' , number , code , 'NA' ) # TODO : Complete this . raise ValueError ( \"Code '0x%x' could not be parsed!\" % rc_code ) return None","title":"parse_code"},{"location":"edk2toollib/tpm/tpm2_policy_calc/","text":"Module edk2toollib.tpm.tpm2_policy_calc View Source # @file tpm2_policy_calc.py # This file contains classes used to calculate TPM 2.0 policies # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.tpm.tpm2_defs as t2d import hashlib import struct # ======================================================================================== ## # POLICY TREE CLASSES # These are used to describe a final policy structure. # You can construct nodes to form complex policies from the policy primitive classes. ## # PolicyTreeOr <--- Tree Node # / \\ # PolicyTreeSolo PolicyTreeAnd <--- Tree Nodes # / / \\ # PolicyCommandCode PolicyLocality PolicyCommandCode <--- Primitives ## # ======================================================================================== class PolicyHasher ( object ): def __init__ ( self , hash_type ): if hash_type not in [ 'sha256' , 'sha384' ]: raise ValueError ( \"Invalid hash type ' %s '!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 }[ hash_type ] def get_size ( self ): return self . hash_size def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b ' \\x00 ' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components : if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b ' \\x00 ' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b ' \\x00 ' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) # ======================================================================================== ## # POLICY PRIMITIVES # These classes are used to describe a single assertion (eg. PolicyLocality) and # can be used with the PolicyTree classes to construct complex policies. ## # ======================================================================================== class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None : self . bitfield = self . calc_bitfield_from_list ( localities ) else : self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities : # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality ' %d '!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality ' %d ' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else : for value in localities : bitfield |= 1 << value return bitfield def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None : raise ValueError ( \"Command code ' %s ' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) Classes PolicyCalculator class PolicyCalculator ( primitive_dict , policy_tree ) View Source class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass Methods generate_digest def generate_digest ( self , digest_type ) View Source def generate_digest ( self , digest_type ): pass PolicyCommandCode class PolicyCommandCode ( command_code_string = None ) View Source class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None: raise ValueError ( \"Command code '%s' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) Methods get_buffer_for_digest def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string )) get_code def get_code ( self ) View Source def get_code ( self ): return self . command_code_string PolicyHasher class PolicyHasher ( hash_type ) View Source class PolicyHasher ( object ) : def __init__ ( self , hash_type ) : if hash_type not in [ 'sha256', 'sha384' ] : raise ValueError ( \"Invalid hash type '%s'!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 } [ hash_type ] def get_size ( self ) : return self . hash_size def hash ( self , data ) : hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () Methods get_size def get_size ( self ) View Source def get_size ( self ): return self . hash_size hash def hash ( self , data ) View Source def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () PolicyLocality class PolicyLocality ( localities ) View Source class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None: self . bitfield = self . calc_bitfield_from_list ( localities ) else: self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities: # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality '%d'!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality '%d' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else: for value in localities: bitfield |= 1 << value return bitfield def get_buffer_for_digest(self): # NOTE: We force big-endian to match the marshalling in the TPM. return struct.pack(\"> LB \", t2d . TPM_CC_PolicyLocality , self . bitfield ) Methods calc_bitfield_from_list def calc_bitfield_from_list ( self , localities ) View Source def calc_bitfield_from_list ( self , localities ): bitfield = 0 b00000000 # First , we need to validate all of the localities in the list . for value in localities : # If the value is in a bad range , we 're done here. if not (0 <= value < 5) and not (32 <= value < 256): raise ValueError(\"Invalid locality ' % d '!\" % value) # An \"upper\" locality must be individual. Cannot combine with 0-4. if (32 <= value < 256) and len(localities) > 1: raise ValueError(\"Cannot combine locality ' % d ' with others!\" % value) # If the list is empty... well, we' re done . if len ( localities ) == 0 : pass # Now , if we 're an \"upper\" locality, that' s a simple value . elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities . else : for value in localities : bitfield |= 1 << value return bitfield get_bitfield def get_bitfield ( self ) View Source def get_bitfield ( self ): return self . bitfield get_buffer_for_digest def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) PolicyTreeAnd class PolicyTreeAnd ( components ) View Source class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components: if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b' \\ x00' * hash_obj . get_size () for component in self . components: current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): current_digest = b '\\x00' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest get_type def get_type ( self ) View Source def get_type ( self ): return 'and' validate def validate ( self ) View Source def validate ( self ): return True PolicyTreeOr class PolicyTreeOr ( components ) View Source class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components: # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b' \\ x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b'' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) get_policy_buffer def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b '\\x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer get_type def get_type ( self ) View Source def get_type ( self ): return 'or' validate def validate ( self ) View Source def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy . if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid . if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result PolicyTreeSolo class PolicyTreeSolo ( policy_obj ) This object should only be used to put a single policy claim under an OR View Source class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b' \\ x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) Methods get_policy def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) get_policy_buffer def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): return ( b '\\x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () get_type def get_type ( self ) View Source def get_type ( self ): return 'solo' validate def validate ( self ) View Source def validate ( self ): return True","title":"Tpm2 policy calc"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#module-edk2toollibtpmtpm2_policy_calc","text":"View Source # @file tpm2_policy_calc.py # This file contains classes used to calculate TPM 2.0 policies # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.tpm.tpm2_defs as t2d import hashlib import struct # ======================================================================================== ## # POLICY TREE CLASSES # These are used to describe a final policy structure. # You can construct nodes to form complex policies from the policy primitive classes. ## # PolicyTreeOr <--- Tree Node # / \\ # PolicyTreeSolo PolicyTreeAnd <--- Tree Nodes # / / \\ # PolicyCommandCode PolicyLocality PolicyCommandCode <--- Primitives ## # ======================================================================================== class PolicyHasher ( object ): def __init__ ( self , hash_type ): if hash_type not in [ 'sha256' , 'sha384' ]: raise ValueError ( \"Invalid hash type ' %s '!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 }[ hash_type ] def get_size ( self ): return self . hash_size def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest () class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b ' \\x00 ' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components : if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b ' \\x00 ' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b ' \\x00 ' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj )) # ======================================================================================== ## # POLICY PRIMITIVES # These classes are used to describe a single assertion (eg. PolicyLocality) and # can be used with the PolicyTree classes to construct complex policies. ## # ======================================================================================== class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None : self . bitfield = self . calc_bitfield_from_list ( localities ) else : self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities : # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality ' %d '!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality ' %d ' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else : for value in localities : bitfield |= 1 << value return bitfield def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield ) class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None : raise ValueError ( \"Command code ' %s ' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"Module edk2toollib.tpm.tpm2_policy_calc"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policycalculator","text":"class PolicyCalculator ( primitive_dict , policy_tree ) View Source class PolicyCalculator ( object ): def __init__ ( self , primitive_dict , policy_tree ): # For now, we'll leave this pretty sparse. # We should have WAY more testing for this stuff. self . primitive_dict = primitive_dict self . policy_tree = policy_tree def generate_digest ( self , digest_type ): pass","title":"PolicyCalculator"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#generate_digest","text":"def generate_digest ( self , digest_type ) View Source def generate_digest ( self , digest_type ): pass","title":"generate_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policycommandcode","text":"class PolicyCommandCode ( command_code_string = None ) View Source class PolicyCommandCode ( object ): def __init__ ( self , command_code_string = None ): # Check to make sure that a command_code can be found. str_command_code_string = str ( command_code_string ) command_code = t2d . CommandCode . get_code ( str_command_code_string ) if command_code is None: raise ValueError ( \"Command code '%s' unknown!\" % str_command_code_string ) self . command_code_string = str_command_code_string def get_code ( self ): return self . command_code_string def get_buffer_for_digest ( self ): # NOTE: We force big-endian to match the marshalling in the TPM. return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"PolicyCommandCode"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_buffer_for_digest","text":"def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LL\" , t2d . CommandCode . get_code ( 'TPM_CC_PolicyCommandCode' ), t2d . CommandCode . get_code ( self . command_code_string ))","title":"get_buffer_for_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_code","text":"def get_code ( self ) View Source def get_code ( self ): return self . command_code_string","title":"get_code"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policyhasher","text":"class PolicyHasher ( hash_type ) View Source class PolicyHasher ( object ) : def __init__ ( self , hash_type ) : if hash_type not in [ 'sha256', 'sha384' ] : raise ValueError ( \"Invalid hash type '%s'!\" % hash_type ) self . hash_type = hash_type self . hash_size = { 'sha256' : 32 , 'sha384' : 48 } [ hash_type ] def get_size ( self ) : return self . hash_size def hash ( self , data ) : hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest ()","title":"PolicyHasher"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return self . hash_size","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#hash","text":"def hash ( self , data ) View Source def hash ( self , data ): hash_obj = None if self . hash_type == 'sha256' : hash_obj = hashlib . sha256 () else : hash_obj = hashlib . sha384 () hash_obj . update ( data ) return hash_obj . digest ()","title":"hash"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policylocality","text":"class PolicyLocality ( localities ) View Source class PolicyLocality ( object ): def __init__ ( self , localities ): # Update the bitfield with the requested localities. if localities is not None: self . bitfield = self . calc_bitfield_from_list ( localities ) else: self . bitfield = 0b00000000 def get_bitfield ( self ): return self . bitfield def calc_bitfield_from_list ( self , localities ): bitfield = 0b00000000 # First, we need to validate all of the localities in the list. for value in localities: # If the value is in a bad range, we're done here. if not ( 0 <= value < 5 ) and not ( 32 <= value < 256 ): raise ValueError ( \"Invalid locality '%d'!\" % value ) # An \"upper\" locality must be individual. Cannot combine with 0-4. if ( 32 <= value < 256 ) and len ( localities ) > 1 : raise ValueError ( \"Cannot combine locality '%d' with others!\" % value ) # If the list is empty... well, we're done. if len ( localities ) == 0 : pass # Now, if we're an \"upper\" locality, that's a simple value. elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities. else: for value in localities: bitfield |= 1 << value return bitfield def get_buffer_for_digest(self): # NOTE: We force big-endian to match the marshalling in the TPM. return struct.pack(\"> LB \", t2d . TPM_CC_PolicyLocality , self . bitfield )","title":"PolicyLocality"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#calc_bitfield_from_list","text":"def calc_bitfield_from_list ( self , localities ) View Source def calc_bitfield_from_list ( self , localities ): bitfield = 0 b00000000 # First , we need to validate all of the localities in the list . for value in localities : # If the value is in a bad range , we 're done here. if not (0 <= value < 5) and not (32 <= value < 256): raise ValueError(\"Invalid locality ' % d '!\" % value) # An \"upper\" locality must be individual. Cannot combine with 0-4. if (32 <= value < 256) and len(localities) > 1: raise ValueError(\"Cannot combine locality ' % d ' with others!\" % value) # If the list is empty... well, we' re done . if len ( localities ) == 0 : pass # Now , if we 're an \"upper\" locality, that' s a simple value . elif len ( localities ) == 1 and ( 32 <= localities [ 0 ] < 256 ): bitfield = localities [ 0 ] # We have to actually \"think\" to calculate the \"lower\" localities . else : for value in localities : bitfield |= 1 << value return bitfield","title":"calc_bitfield_from_list"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_bitfield","text":"def get_bitfield ( self ) View Source def get_bitfield ( self ): return self . bitfield","title":"get_bitfield"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_buffer_for_digest_1","text":"def get_buffer_for_digest ( self ) View Source def get_buffer_for_digest ( self ): # NOTE : We force big - endian to match the marshalling in the TPM . return struct . pack ( \">LB\" , t2d . TPM_CC_PolicyLocality , self . bitfield )","title":"get_buffer_for_digest"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreeand","text":"class PolicyTreeAnd ( components ) View Source class PolicyTreeAnd ( object ): def __init__ ( self , components ): # ANDs must only be composed of primitives. For simplicity, I guess. # Honestly, this has spiralled out of control, but something is better than nothing. for component in components: if not hasattr ( component , 'get_buffer_for_digest' ): raise ValueError ( \"AND junctions must consist of primitives!\" ) self . components = components def get_type ( self ): return 'and' def validate ( self ): return True def get_policy ( self , hash_obj ): current_digest = b' \\ x00' * hash_obj . get_size () for component in self . components: current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest","title":"PolicyTreeAnd"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): current_digest = b '\\x00' * hash_obj . get_size () for component in self . components : current_digest = hash_obj . hash ( current_digest + component . get_buffer_for_digest ()) return current_digest","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type","text":"def get_type ( self ) View Source def get_type ( self ): return 'and'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate","text":"def validate ( self ) View Source def validate ( self ): return True","title":"validate"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreeor","text":"class PolicyTreeOr ( components ) View Source class PolicyTreeOr ( object ): def __init__ ( self , components ): # OR connections can only be 8 digests long. # They CAN, however, be links of ORs. if len ( components ) > 8 : raise ValueError ( \"OR junctions cannot contain more than 8 sub-policies!\" ) self . components = components def get_type ( self ): return 'or' def validate ( self ): result = True for component in self . components: # All components must be convertible into a policy. if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid. if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b' \\ x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b'' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"PolicyTreeOr"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_5","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_1","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_buffer","text":"def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): concat_policy_buffer = b '\\x00' * hash_obj . get_size () concat_policy_buffer += struct . pack ( \">L\" , t2d . TPM_CC_PolicyOR ) concat_policy_buffer += b '' . join ([ component . get_policy ( hash_obj ) for component in self . components ]) return concat_policy_buffer","title":"get_policy_buffer"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type_1","text":"def get_type ( self ) View Source def get_type ( self ): return 'or'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate_1","text":"def validate ( self ) View Source def validate ( self ): result = True for component in self . components : # All components must be convertible into a policy . if not hasattr ( component , 'get_policy' ): result = False # All components must also be valid . if not hasattr ( component , 'validate' ) or not component . validate (): result = False return result","title":"validate"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#policytreesolo","text":"class PolicyTreeSolo ( policy_obj ) This object should only be used to put a single policy claim under an OR View Source class PolicyTreeSolo ( object ): \"\"\"This object should only be used to put a single policy claim under an OR\"\"\" def __init__ ( self , policy_obj ): if not hasattr ( policy_obj , 'get_buffer_for_digest' ): raise ValueError ( \"Supplied policy object is missing required functionality!\" ) self . policy_obj = policy_obj def get_type ( self ): return 'solo' def validate ( self ): return True def get_policy_buffer ( self , hash_obj ): return ( b' \\ x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest () def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"PolicyTreeSolo"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#methods_6","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_2","text":"def get_policy ( self , hash_obj ) View Source def get_policy ( self , hash_obj ): return hash_obj . hash ( self . get_policy_buffer ( hash_obj ))","title":"get_policy"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_policy_buffer_1","text":"def get_policy_buffer ( self , hash_obj ) View Source def get_policy_buffer ( self , hash_obj ): return ( b '\\x00' * hash_obj . get_size ()) + self . policy_obj . get_buffer_for_digest ()","title":"get_policy_buffer"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#get_type_2","text":"def get_type ( self ) View Source def get_type ( self ): return 'solo'","title":"get_type"},{"location":"edk2toollib/tpm/tpm2_policy_calc/#validate_2","text":"def validate ( self ) View Source def validate ( self ): return True","title":"validate"},{"location":"edk2toollib/tpm/tpm2_simulator/","text":"Module edk2toollib.tpm.tpm2_simulator View Source # @file tpm2_simulator.py # This file contains transportation layer classes for interacting with the TPM 2.0 simulator. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import socket import struct import edk2toollib.tpm.tpm2_stream as t2s import edk2toollib.tpm.tpm2_defs as t2d PLAT_COMMANDS = { 'TPM_SIGNAL_POWER_ON' : 1 , 'TPM_SIGNAL_POWER_OFF' : 2 , 'TPM_SIGNAL_PHYS_PRES_ON' : 3 , 'TPM_SIGNAL_PHYS_PRES_OFF' : 4 , 'TPM_SIGNAL_HASH_START' : 5 , 'TPM_SIGNAL_HASH_DATA' : 6 , # {UINT32 BufferSize, BYTE[BufferSize] Buffer} 'TPM_SIGNAL_HASH_END' : 7 , 'TPM_SEND_COMMAND' : 8 , # {BYTE Locality, UINT32 InBufferSize, BYTE[InBufferSize] InBuffer} -> # {UINT32 OutBufferSize, BYTE[OutBufferSize] OutBuffer} 'TPM_SIGNAL_CANCEL_ON' : 9 , 'TPM_SIGNAL_CANCEL_OFF' : 10 , 'TPM_SIGNAL_NV_ON' : 11 , 'TPM_SIGNAL_NV_OFF' : 12 , 'TPM_SIGNAL_KEY_CACHE_ON' : 13 , 'TPM_SIGNAL_KEY_CACHE_OFF' : 14 , 'TPM_REMOTE_HANDSHAKE' : 15 , 'TPM_SET_ALTERNATIVE_RESULT' : 16 , 'TPM_SIGNAL_RESET' : 17 , 'TPM_SESSION_END' : 20 , 'TPM_STOP' : 21 , 'TPM_GET_COMMAND_RESPONSE_SIZES' : 25 , 'TPM_TEST_FAILURE_MODE' : 30 , } class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ) . __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ) . encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ) . encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ()) Variables PLAT_COMMANDS Classes TpmSimulator class TpmSimulator ( host = 'localhost' , port = 2321 ) View Source class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ). __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True: result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ()) Methods read_raw_data def read_raw_data ( self , count ) View Source def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data send_data def send_data ( self , data ) View Source def send_data ( self , data ): # Send the \"I'm about to send data\" command . self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data . self . send_raw_data ( struct . pack ( \">b\" , 0 x03 )) # Send the size of the data . self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now , send the data itself . self . send_raw_data ( data ) # Poll until a result is available . # NOTE : This shouldn ' t be necessary and denotes a lack of understanding ... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) send_raw_data def send_raw_data ( self , data ) View Source def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) startup def startup ( self , type ) View Source def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0 x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"Tpm2 simulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#module-edk2toollibtpmtpm2_simulator","text":"View Source # @file tpm2_simulator.py # This file contains transportation layer classes for interacting with the TPM 2.0 simulator. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import socket import struct import edk2toollib.tpm.tpm2_stream as t2s import edk2toollib.tpm.tpm2_defs as t2d PLAT_COMMANDS = { 'TPM_SIGNAL_POWER_ON' : 1 , 'TPM_SIGNAL_POWER_OFF' : 2 , 'TPM_SIGNAL_PHYS_PRES_ON' : 3 , 'TPM_SIGNAL_PHYS_PRES_OFF' : 4 , 'TPM_SIGNAL_HASH_START' : 5 , 'TPM_SIGNAL_HASH_DATA' : 6 , # {UINT32 BufferSize, BYTE[BufferSize] Buffer} 'TPM_SIGNAL_HASH_END' : 7 , 'TPM_SEND_COMMAND' : 8 , # {BYTE Locality, UINT32 InBufferSize, BYTE[InBufferSize] InBuffer} -> # {UINT32 OutBufferSize, BYTE[OutBufferSize] OutBuffer} 'TPM_SIGNAL_CANCEL_ON' : 9 , 'TPM_SIGNAL_CANCEL_OFF' : 10 , 'TPM_SIGNAL_NV_ON' : 11 , 'TPM_SIGNAL_NV_OFF' : 12 , 'TPM_SIGNAL_KEY_CACHE_ON' : 13 , 'TPM_SIGNAL_KEY_CACHE_OFF' : 14 , 'TPM_REMOTE_HANDSHAKE' : 15 , 'TPM_SET_ALTERNATIVE_RESULT' : 16 , 'TPM_SIGNAL_RESET' : 17 , 'TPM_SESSION_END' : 20 , 'TPM_STOP' : 21 , 'TPM_GET_COMMAND_RESPONSE_SIZES' : 25 , 'TPM_TEST_FAILURE_MODE' : 30 , } class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ) . __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ) . encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ) . encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"Module edk2toollib.tpm.tpm2_simulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#variables","text":"PLAT_COMMANDS","title":"Variables"},{"location":"edk2toollib/tpm/tpm2_simulator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_simulator/#tpmsimulator","text":"class TpmSimulator ( host = 'localhost' , port = 2321 ) View Source class TpmSimulator ( object ): def __init__ ( self , host = 'localhost' , port = 2321 ): super ( TpmSimulator , self ). __init__ () # Connect to the control socket. self . platSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . platSock . connect (( host , port + 1 )) # Connect to the simulator socket. self . tpmSock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . tpmSock . connect (( host , port )) # Power cycle the TPM. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_OFF' ])) self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_POWER_ON' ])) # Enable the NV space. self . platSock . send ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SIGNAL_NV_ON' ])) def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data ) def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data def send_data ( self , data ): # Send the \"I'm about to send data\" command. self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data. self . send_raw_data ( struct . pack ( \">b\" , 0x03 )) # Send the size of the data. self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now, send the data itself. self . send_raw_data ( data ) # Poll until a result is available. # NOTE: This shouldn't be necessary and denotes a lack of understanding... while True: result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size ) def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"TpmSimulator"},{"location":"edk2toollib/tpm/tpm2_simulator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_simulator/#read_raw_data","text":"def read_raw_data ( self , count ) View Source def read_raw_data ( self , count ): data = self . tpmSock . recv ( count ) print ( \"RAW <--: \" + str ( data ). encode ( 'hex' )) return data","title":"read_raw_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#send_data","text":"def send_data ( self , data ) View Source def send_data ( self , data ): # Send the \"I'm about to send data\" command . self . send_raw_data ( struct . pack ( \">L\" , PLAT_COMMANDS [ 'TPM_SEND_COMMAND' ])) # Send the locality for the data . self . send_raw_data ( struct . pack ( \">b\" , 0 x03 )) # Send the size of the data . self . send_raw_data ( struct . pack ( \">L\" , len ( data ))) # Now , send the data itself . self . send_raw_data ( data ) # Poll until a result is available . # NOTE : This shouldn ' t be necessary and denotes a lack of understanding ... while True : result_size = self . read_raw_data ( 4 ) result_size = struct . unpack ( \">L\" , result_size )[ 0 ] if ( result_size > 0 ): break return self . read_raw_data ( result_size )","title":"send_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#send_raw_data","text":"def send_raw_data ( self , data ) View Source def send_raw_data ( self , data ): print ( \"RAW -->: \" + str ( data ). encode ( 'hex' )) self . tpmSock . send ( data )","title":"send_raw_data"},{"location":"edk2toollib/tpm/tpm2_simulator/#startup","text":"def startup ( self , type ) View Source def startup ( self , type ): stream = t2s . Tpm2CommandStream ( t2d . TPM_ST_NO_SESSIONS , 0 x00 , t2d . TPM_CC_Startup ) stream . add_element ( t2s . Tpm2StreamPrimitive ( t2d . TPM_SU_Size , type )) return self . send_data ( stream . get_stream ())","title":"startup"},{"location":"edk2toollib/tpm/tpm2_stream/","text":"Module edk2toollib.tpm.tpm2_stream View Source # @file tpm2_stream.py # This file contains utility classes to help marshal and unmarshal data to/from the TPM. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) class Tpm2StreamPrimitive ( Tpm2StreamElement ): def __init__ ( self , size , value ): super ( Tpm2StreamPrimitive , self ) . __init__ () if size not in ( 1 , 2 , 4 , 8 ): raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" }[ size ] self . value = value def marshal ( self ): return struct . pack ( self . pack_string , self . value ) class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ) . __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ) . __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ) . __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements ) Classes TPM2B class TPM2B ( data ) View Source class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ). __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) update_data def update_data ( self , data ) View Source def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size TPM2_COMMAND_HEADER class TPM2_COMMAND_HEADER ( tag , size , code ) View Source class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ). __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) update_size def update_size ( self , size ) View Source def update_size ( self , size ): self . size = size Tpm2CommandStream class Tpm2CommandStream ( tag , size , code ) View Source class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ). __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b'' . join ( element . marshal () for element in self . stream_elements ) Methods add_element def add_element ( self , element ) View Source def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) get_size def get_size ( self ) View Source def get_size ( self ): return self . stream_size get_stream def get_stream ( self ) View Source def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements ) Tpm2StreamElement class Tpm2StreamElement ( ) View Source class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) Descendants edk2toollib.tpm.tpm2_stream.Tpm2StreamPrimitive edk2toollib.tpm.tpm2_stream.TPM2_COMMAND_HEADER edk2toollib.tpm.tpm2_stream.TPM2B Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) Tpm2StreamPrimitive class Tpm2StreamPrimitive ( size , value ) View Source class Tpm2StreamPrimitive ( Tpm2StreamElement ) : def __init__ ( self , size , value ) : super ( Tpm2StreamPrimitive , self ). __init__ () if size not in ( 1 , 2 , 4 , 8 ) : raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" } [ size ] self . value = value def marshal ( self ) : return struct . pack ( self . pack_string , self . value ) Ancestors (in MRO) edk2toollib.tpm.tpm2_stream.Tpm2StreamElement Methods get_size def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string ) marshal def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . value )","title":"Tpm2 stream"},{"location":"edk2toollib/tpm/tpm2_stream/#module-edk2toollibtpmtpm2_stream","text":"View Source # @file tpm2_stream.py # This file contains utility classes to help marshal and unmarshal data to/from the TPM. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string ) class Tpm2StreamPrimitive ( Tpm2StreamElement ): def __init__ ( self , size , value ): super ( Tpm2StreamPrimitive , self ) . __init__ () if size not in ( 1 , 2 , 4 , 8 ): raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" }[ size ] self . value = value def marshal ( self ): return struct . pack ( self . pack_string , self . value ) class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ) . __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code ) class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ) . __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H %d s\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data ) class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ) . __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements )","title":"Module edk2toollib.tpm.tpm2_stream"},{"location":"edk2toollib/tpm/tpm2_stream/#classes","text":"","title":"Classes"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2b","text":"class TPM2B ( data ) View Source class TPM2B ( Tpm2StreamElement ): def __init__ ( self , data ): super ( TPM2B , self ). __init__ () self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data )","title":"TPM2B"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . size , self . data )","title":"marshal"},{"location":"edk2toollib/tpm/tpm2_stream/#update_data","text":"def update_data ( self , data ) View Source def update_data ( self , data ): self . data = data self . size = len ( data ) self . pack_string = \">H%ds\" % self . size","title":"update_data"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2_command_header","text":"class TPM2_COMMAND_HEADER ( tag , size , code ) View Source class TPM2_COMMAND_HEADER ( Tpm2StreamElement ): def __init__ ( self , tag , size , code ): super ( TPM2_COMMAND_HEADER , self ). __init__ () self . tag = tag self . code = code self . size = size self . pack_string = \">HLL\" \"\"\"This update_size refers to the size of the whole command\"\"\" def update_size ( self , size ): self . size = size def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code )","title":"TPM2_COMMAND_HEADER"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro_1","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_1","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal_1","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . tag , self . size , self . code )","title":"marshal"},{"location":"edk2toollib/tpm/tpm2_stream/#update_size","text":"def update_size ( self , size ) View Source def update_size ( self , size ): self . size = size","title":"update_size"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2commandstream","text":"class Tpm2CommandStream ( tag , size , code ) View Source class Tpm2CommandStream ( object ): def __init__ ( self , tag , size , code ): super ( Tpm2CommandStream , self ). __init__ () self . header = TPM2_COMMAND_HEADER ( tag , size , code ) self . stream_size = self . header . get_size () self . header . update_size ( self . stream_size ) self . stream_elements = [] def get_size ( self ): return self . stream_size def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size ) def get_stream ( self ): return self . header . marshal () + b'' . join ( element . marshal () for element in self . stream_elements )","title":"Tpm2CommandStream"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#add_element","text":"def add_element ( self , element ) View Source def add_element ( self , element ): self . stream_elements . append ( element ) self . stream_size += element . get_size () self . header . update_size ( self . stream_size )","title":"add_element"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_2","text":"def get_size ( self ) View Source def get_size ( self ): return self . stream_size","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#get_stream","text":"def get_stream ( self ) View Source def get_stream ( self ): return self . header . marshal () + b '' . join ( element . marshal () for element in self . stream_elements )","title":"get_stream"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2streamelement","text":"class Tpm2StreamElement ( ) View Source class Tpm2StreamElement ( object ): def __init__ ( self ): self . pack_string = \"\" \"\"\"This get_size refers to the size of this structure when marshalled\"\"\" def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"Tpm2StreamElement"},{"location":"edk2toollib/tpm/tpm2_stream/#descendants","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamPrimitive edk2toollib.tpm.tpm2_stream.TPM2_COMMAND_HEADER edk2toollib.tpm.tpm2_stream.TPM2B","title":"Descendants"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_3","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#tpm2streamprimitive","text":"class Tpm2StreamPrimitive ( size , value ) View Source class Tpm2StreamPrimitive ( Tpm2StreamElement ) : def __init__ ( self , size , value ) : super ( Tpm2StreamPrimitive , self ). __init__ () if size not in ( 1 , 2 , 4 , 8 ) : raise ValueError ( \"Size must be 1, 2, 4, or 8 bytes!\" ) self . pack_string = { 1 : \">B\" , 2 : \">H\" , 4 : \">L\" , 8 : \">Q\" } [ size ] self . value = value def marshal ( self ) : return struct . pack ( self . pack_string , self . value )","title":"Tpm2StreamPrimitive"},{"location":"edk2toollib/tpm/tpm2_stream/#ancestors-in-mro_2","text":"edk2toollib.tpm.tpm2_stream.Tpm2StreamElement","title":"Ancestors (in MRO)"},{"location":"edk2toollib/tpm/tpm2_stream/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/tpm/tpm2_stream/#get_size_4","text":"def get_size ( self ) View Source def get_size ( self ): return struct . calcsize ( self . pack_string )","title":"get_size"},{"location":"edk2toollib/tpm/tpm2_stream/#marshal_2","text":"def marshal ( self ) View Source def marshal ( self ): return struct . pack ( self . pack_string , self . value )","title":"marshal"},{"location":"edk2toollib/uefi/","text":"Module edk2toollib.uefi View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.authenticated_variables_structure_support edk2toollib.uefi.bmp_object edk2toollib.uefi.bmp_object_test edk2toollib.uefi.edk2 edk2toollib.uefi.pi_firmware_file edk2toollib.uefi.pi_firmware_volume edk2toollib.uefi.status_codes edk2toollib.uefi.uefi_multi_phase edk2toollib.uefi.wincert","title":"Index"},{"location":"edk2toollib/uefi/#module-edk2toollibuefi","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi"},{"location":"edk2toollib/uefi/#sub-modules","text":"edk2toollib.uefi.authenticated_variables_structure_support edk2toollib.uefi.bmp_object edk2toollib.uefi.bmp_object_test edk2toollib.uefi.edk2 edk2toollib.uefi.pi_firmware_file edk2toollib.uefi.pi_firmware_volume edk2toollib.uefi.status_codes edk2toollib.uefi.uefi_multi_phase edk2toollib.uefi.wincert","title":"Sub-modules"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/","text":"Module edk2toollib.uefi.authenticated_variables_structure_support View Source ## # UEFI Authenticated Variable Structure Support Library # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import datetime import struct import hashlib import uuid from edk2toollib.uefi.wincert import WinCert , WinCertUefiGuid from edk2toollib.utility_functions import PrintByteList ''' Structures definition based on UEFI specification (UEFI 2.7) Each object can be created and or populated from a file stream. Each object can be written to a filesteam as binary and printed to the console in text. ''' # UEFI global Variable Namespace EfiGlobalVarNamespaceUuid = uuid . UUID ( '8BE4DF61-93CA-11d2-AA0D-00E098032B8C' ) Sha256Oid = [ 0x60 , 0x86 , 0x48 , 0x01 , 0x65 , 0x03 , 0x04 , 0x02 , 0x01 ] # # EFI_SIGNATURE_DATA Structure for X509 Certs # class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize # # EFI_SIGNATURE_DATA Structure for Sha256 hash # class EfiSignatureDataEfiCertSha256 ( object ): STATIC_STRUCT_SIZE = 16 + hashlib . sha256 () . digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()) . digest ()) elif ( digest is not None ): self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 () . digest_size )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )): print ( \" %02X \" % sdl [ index ], end = '' ) print ( \"\" ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) class EfiSignatureDataFactory ( object ): EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid.UUID(\"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\") # EFI_CERT_RSA2048_SHA256_GUID = uuid.UUID(\"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\") # noqa: E501 # EFI_CERT_SHA1_GUID = uuid.UUID(\"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\") # EFI_CERT_RSA2048_SHA1_GUID = uuid.UUID(\"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\") # noqa: E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid.UUID(\"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\") # EFI_CERT_SHA384_GUID = uuid.UUID(\"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\") # EFI_CERT_SHA512_GUID = uuid.UUID(\"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\") EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid.UUID(\"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\") # noqa: E501 # EFI_CERT_X509_SHA512_GUID = uuid.UUID(\"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\") # noqa: E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid.UUID(\"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\") # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): raise Exception ( \"Invalid Size 0x %x \" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s \" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object. # Type will be baed on GUID # Value will be based on type and Content (content stream opened for reading) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ): if ( ContentFileStream is None ): raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) ## # EFI_SIGNATURE_LIST structure ## class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else : self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x %x \" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x %x \" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s \" % str ( self . SignatureType )) print ( \" Signature List Size: 0x %x \" % self . SignatureListSize ) print ( \" Signature Header Size: 0x %x \" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x %x \" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x %x \" % TimeZone ) logging . debug ( \"Daylight value is: 0x %X \" % Daylight ) def Print ( self ): print ( \"EfiTime: %s \" % datetime . datetime . strftime ( self . Time , \"%A, %B %d , %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n %s \" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) ''' THESE ARE NOT SUPPORTED IN THE TOOL typedef struct { /// /// The SHA256 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA256_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA256; typedef struct { /// /// The SHA384 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA384_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA384; typedef struct { /// /// The SHA512 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA512_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA512; ''' Variables EfiGlobalVarNamespaceUuid Sha256Oid Classes EFiVariableAuthentication2 class EFiVariableAuthentication2 ( Time = datetime . datetime ( 2020 , 6 , 1 , 11 , 47 , 16 , 879097 ), decodefs = None ) View Source class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try: self . SigListPayload = EfiSignatureList ( fs ) except Exception as e: logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) Print def Print ( self ) View Source def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) SetPayload def SetPayload ( self , fs ) View Source def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) EfiSignatureDataEfiCertSha256 class EfiSignatureDataEfiCertSha256 ( decodefs = None , createfs = None , digest = None , sigowner = None ) View Source class EfiSignatureDataEfiCertSha256 ( object ) : STATIC_STRUCT_SIZE = 16 + hashlib . sha256 (). digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ) : if ( decodefs is not None ) : self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ) : # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()). digest ()) elif ( digest is not None ) : self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) def Write ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ) : raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ) : return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE Class variables STATIC_STRUCT_SIZE Methods GetTotalSize def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) Print def Print ( self ) View Source def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) EfiSignatureDataEfiCertX509 class EfiSignatureDataEfiCertX509 ( decodefs = None , decodesize = 0 , createfs = None , sigowner = None ) View Source class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else: raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else: sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize Class variables STATIC_STRUCT_SIZE Methods GetTotalSize def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize PopulateFromFileStream def PopulateFromFileStream ( self , fs , decodesize ) View Source def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) EfiSignatureDataFactory class EfiSignatureDataFactory ( / , * args , ** kwargs ) View Source class EfiSignatureDataFactory ( object ) : EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid . UUID ( \"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\" ) # EFI_CERT_RSA2048_SHA256_GUID = uuid . UUID ( \"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\" ) # noqa : E501 # EFI_CERT_SHA1_GUID = uuid . UUID ( \"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\" ) # EFI_CERT_RSA2048_SHA1_GUID = uuid . UUID ( \"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\" ) # noqa : E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid . UUID ( \"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\" ) # EFI_CERT_SHA384_GUID = uuid . UUID ( \"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\" ) # EFI_CERT_SHA512_GUID = uuid . UUID ( \"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\" ) EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid . UUID ( \"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\" ) # noqa : E501 # EFI_CERT_X509_SHA512_GUID = uuid . UUID ( \"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\" ) # noqa : E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( \"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\" ) # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object . # Type will be baed on GUID # Value will be based on type and Content ( content stream opened for reading ) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) Class variables EFI_CERT_SHA256_GUID EFI_CERT_X509_GUID EFI_CERT_X509_SHA256_GUID Static methods Create def Create ( type , ContentFileStream , sigowner ) View Source @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) Factory def Factory ( fs , type , size ) View Source @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None EfiSignatureHeader class EfiSignatureHeader ( ) View Source class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) EfiSignatureList class EfiSignatureList ( filestream = None , typeguid = None ) View Source class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else: self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else: print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List: a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List: a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else: self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize Class variables STATIC_STRUCT_SIZE Methods AddSignatureData def AddSignatureData ( self , SigDataObject ) View Source def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize AddSignatureHeader def AddSignatureHeader ( self , SigHeader , SigSize = 0 ) View Source def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing ( size 0 ) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly . if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) EfiTime class EfiTime ( Time = datetime . datetime ( 2020 , 6 , 1 , 11 , 47 , 16 , 879097 ), decodefs = None ) View Source class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 Class variables STATIC_STRUCT_SIZE Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) Print def Print ( self ) View Source def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) Write def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"Authenticated variables structure support"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#module-edk2toollibuefiauthenticated_variables_structure_support","text":"View Source ## # UEFI Authenticated Variable Structure Support Library # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import datetime import struct import hashlib import uuid from edk2toollib.uefi.wincert import WinCert , WinCertUefiGuid from edk2toollib.utility_functions import PrintByteList ''' Structures definition based on UEFI specification (UEFI 2.7) Each object can be created and or populated from a file stream. Each object can be written to a filesteam as binary and printed to the console in text. ''' # UEFI global Variable Namespace EfiGlobalVarNamespaceUuid = uuid . UUID ( '8BE4DF61-93CA-11d2-AA0D-00E098032B8C' ) Sha256Oid = [ 0x60 , 0x86 , 0x48 , 0x01 , 0x65 , 0x03 , 0x04 , 0x02 , 0x01 ] # # EFI_SIGNATURE_DATA Structure for X509 Certs # class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize # # EFI_SIGNATURE_DATA Structure for Sha256 hash # class EfiSignatureDataEfiCertSha256 ( object ): STATIC_STRUCT_SIZE = 16 + hashlib . sha256 () . digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()) . digest ()) elif ( digest is not None ): self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 () . digest_size )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s \" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )): print ( \" %02X \" % sdl [ index ], end = '' ) print ( \"\" ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" ) class EfiSignatureDataFactory ( object ): EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid.UUID(\"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\") # EFI_CERT_RSA2048_SHA256_GUID = uuid.UUID(\"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\") # noqa: E501 # EFI_CERT_SHA1_GUID = uuid.UUID(\"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\") # EFI_CERT_RSA2048_SHA1_GUID = uuid.UUID(\"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\") # noqa: E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid.UUID(\"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\") # EFI_CERT_SHA384_GUID = uuid.UUID(\"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\") # EFI_CERT_SHA512_GUID = uuid.UUID(\"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\") EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid.UUID(\"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\") # noqa: E501 # EFI_CERT_X509_SHA512_GUID = uuid.UUID(\"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\") # noqa: E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid.UUID(\"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\") # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): raise Exception ( \"Invalid Size 0x %x \" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s \" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object. # Type will be baed on GUID # Value will be based on type and Content (content stream opened for reading) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ): if ( ContentFileStream is None ): raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ): return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ): return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" ) ## # EFI_SIGNATURE_LIST structure ## class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else : self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x %x \" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x %x \" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s \" % str ( self . SignatureType )) print ( \" Signature List Size: 0x %x \" % self . SignatureListSize ) print ( \" Signature Header Size: 0x %x \" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x %x \" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x %x \" % TimeZone ) logging . debug ( \"Daylight value is: 0x %X \" % Daylight ) def Print ( self ): print ( \"EfiTime: %s \" % datetime . datetime . strftime ( self . Time , \"%A, %B %d , %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2 class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else : self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n %s \" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize )) ''' THESE ARE NOT SUPPORTED IN THE TOOL typedef struct { /// /// The SHA256 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA256_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA256; typedef struct { /// /// The SHA384 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA384_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA384; typedef struct { /// /// The SHA512 hash of an X.509 certificate's To-Be-Signed contents. /// EFI_SHA512_HASH ToBeSignedHash; /// /// The time that the certificate shall be considered to be revoked. /// EFI_TIME TimeOfRevocation; } EFI_CERT_X509_SHA512; '''","title":"Module edk2toollib.uefi.authenticated_variables_structure_support"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#variables","text":"EfiGlobalVarNamespaceUuid Sha256Oid","title":"Variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efivariableauthentication2","text":"class EFiVariableAuthentication2 ( Time = datetime . datetime ( 2020 , 6 , 1 , 11 , 47 , 16 , 879097 ), decodefs = None ) View Source class EFiVariableAuthentication2 ( object ): def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . EfiTime = EfiTime ( Time = Time ) self . AuthInfo = WinCertUefiGuid () self . Payload = None self . PayloadSize = 0 self . SigListPayload = None else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs ) def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload ) def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try: self . SigListPayload = EfiSignatureList ( fs ) except Exception as e: logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize ))","title":"EFiVariableAuthentication2"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) self . EfiTime = EfiTime ( decodefs = fs ) self . AuthInfo = WinCert . Factory ( fs ) self . Payload = None self . SigListPayload = None self . SetPayload ( fs )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print","text":"def Print ( self ) View Source def Print ( self ): print ( \"EFiVariableAuthentication2\" ) self . EfiTime . Print () self . AuthInfo . Print () print ( \"-------------------- VARIABLE PAYLOAD --------------------\" ) if ( self . SigListPayload is not None ): self . SigListPayload . Print () elif ( self . Payload is not None ): print ( \"Raw Data: \" ) sdl = self . Payload . tolist () if ( self . PayloadSize != len ( sdl )): raise Exception ( \"Invalid Payload Data Size vs Length of data\" ) PrintByteList ( sdl )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#setpayload","text":"def SetPayload ( self , fs ) View Source def SetPayload ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Input Stream\" ) # Find the payload size start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) self . PayloadSize = end - start if ( self . PayloadSize == 0 ): logging . debug ( \"No Payload for this EfiVariableAuthenticated2 Object\" ) return # read as siglist try : self . SigListPayload = EfiSignatureList ( fs ) except Exception as e : logging . debug ( \"Exception Trying to parse SigList Payload. \\n%s\" % str ( e )) # reset the file pointer fs . seek ( start ) self . Payload = memoryview ( fs . read ( self . PayloadSize ))","title":"SetPayload"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) self . EfiTime . Write ( fs ) self . AuthInfo . Write ( fs ) if ( self . Payload is not None ): fs . write ( self . Payload )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedataeficertsha256","text":"class EfiSignatureDataEfiCertSha256 ( decodefs = None , createfs = None , digest = None , sigowner = None ) View Source class EfiSignatureDataEfiCertSha256 ( object ) : STATIC_STRUCT_SIZE = 16 + hashlib . sha256 (). digest_size # has guid and array # # decodefs is a filestream object of binary content that is the structure encoded # createfs is a filestream object of binary that is to be hashed to create the signature data # digest is a byte array that contains the hash value for new signature data # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , createfs = None , digest = None , sigowner = None ) : if ( decodefs is not None ) : self . PopulateFromFileStream ( decodefs ) elif ( createfs is not None ) : # create a new one self . SignatureOwner = sigowner self . SignatureData = memoryview ( hashlib . sha256 ( createfs . read ()). digest ()) elif ( digest is not None ) : self . SignatureOwner = uuid . UUID ( sigowner ) self . SignatureData = memoryview ( digest ) else : raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size )) def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" ) def Write ( self , fs ) : if ( fs is None ) : raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ) : raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ) : return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE","title":"EfiSignatureDataEfiCertSha256"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#gettotalsize","text":"def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE","title":"GetTotalSize"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ): # size of the data raise Exception ( \"Invalid file stream size\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureData = memoryview ( fs . read ( hashlib . sha256 (). digest_size ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_1","text":"def Print ( self ) View Source def Print ( self ) : print ( \"EfiSignatureData - EfiSignatureDataEfiCertSha256\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" , end = \"\" ) if ( self . SignatureData is None ) : print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () for index in range ( len ( sdl )) : print ( \"%02X\" % sdl [ index ] , end = '' ) print ( \"\" )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedataeficertx509","text":"class EfiSignatureDataEfiCertX509 ( decodefs = None , decodesize = 0 , createfs = None , sigowner = None ) View Source class EfiSignatureDataEfiCertX509 ( object ): STATIC_STRUCT_SIZE = 16 # # decodefs is a filestream object of binary content that is the structure encoded # decodesize is number of bytes to decode as the EFI_SIGNATURE_DATA object (guid + x509 data) # createfs is a filestream object that is the DER encoded x509 cert # sigowner is the uuid object of the signature owner guid def __init__ ( self , decodefs = None , decodesize = 0 , createfs = None , sigowner = None ): if ( decodefs is not None ): self . PopulateFromFileStream ( decodefs , decodesize ) elif ( createfs is not None ): # create a new one self . SignatureOwner = sigowner start = createfs . tell () # should be 0 but maybe this filestream has other things at the head createfs . seek ( 0 , 2 ) end = createfs . tell () createfs . seek ( start ) self . SignatureDataSize = end - start if ( self . SignatureDataSize < 0 ): raise Exception ( \"Create File Stream has invalid size\" ) self . SignatureData = memoryview ( createfs . read ( self . SignatureDataSize )) else: raise Exception ( \"Invalid Parameters - Not Supported\" ) def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize )) def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else: sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl ) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData ) def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize","title":"EfiSignatureDataEfiCertX509"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_1","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#gettotalsize_1","text":"def GetTotalSize ( self ) View Source def GetTotalSize ( self ): return EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE + self . SignatureDataSize","title":"GetTotalSize"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_2","text":"def PopulateFromFileStream ( self , fs , decodesize ) View Source def PopulateFromFileStream ( self , fs , decodesize ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) if ( decodesize == 0 ): raise Exception ( \"Invalid Decode Size\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE ): # size of the guid raise Exception ( \"Invalid file stream size\" ) if (( end - offset ) < decodesize ): # size requested is too big raise Exception ( \"Invalid file stream size vs decodesize\" ) self . SignatureOwner = uuid . UUID ( bytes_le = fs . read ( 16 )) # read remainling decode size for x509 data self . SignatureDataSize = decodesize - EfiSignatureDataEfiCertX509 . STATIC_STRUCT_SIZE self . SignatureData = memoryview ( fs . read ( self . SignatureDataSize ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_2","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureData - EfiSignatureDataEfiCertX509\" ) print ( \" Signature Owner: %s\" % str ( self . SignatureOwner )) print ( \" Signature Data: \" ) if ( self . SignatureData is None ): print ( \" NONE\" ) else : sdl = self . SignatureData . tolist () if ( self . SignatureDataSize != len ( sdl )): raise Exception ( \"Invalid Signature Data Size vs Length of data\" ) PrintByteList ( sdl )","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_2","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if ( self . SignatureData is None ): raise Exception ( \"Invalid object\" ) fs . write ( self . SignatureOwner . bytes_le ) fs . write ( self . SignatureData )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturedatafactory","text":"class EfiSignatureDataFactory ( / , * args , ** kwargs ) View Source class EfiSignatureDataFactory ( object ) : EFI_CERT_SHA256_GUID = uuid . UUID ( 'c1c41626-504c-4092-aca9-41f936934328' ) # EFI_CERT_RSA2048_GUID = uuid . UUID ( \"0x3c5766e8, 0x269c, 0x4e34, 0xaa, 0x14, 0xed, 0x77, 0x6e, 0x85, 0xb3, 0xb6\" ) # EFI_CERT_RSA2048_SHA256_GUID = uuid . UUID ( \"0xe2b36190, 0x879b, 0x4a3d, 0xad, 0x8d, 0xf2, 0xe7, 0xbb, 0xa3, 0x27, 0x84\" ) # noqa : E501 # EFI_CERT_SHA1_GUID = uuid . UUID ( \"0x826ca512, 0xcf10, 0x4ac9, 0xb1, 0x87, 0xbe, 0x1, 0x49, 0x66, 0x31, 0xbd\" ) # EFI_CERT_RSA2048_SHA1_GUID = uuid . UUID ( \"0x67f8444f, 0x8743, 0x48f1, 0xa3, 0x28, 0x1e, 0xaa, 0xb8, 0x73, 0x60, 0x80\" ) # noqa : E501 EFI_CERT_X509_GUID = uuid . UUID ( \"a5c059a1-94e4-4aa7-87b5-ab155c2bf072\" ) # EFI_CERT_SHA224_GUID = uuid . UUID ( \"0xb6e5233, 0xa65c, 0x44c9, 0x94, 0x7, 0xd9, 0xab, 0x83, 0xbf, 0xc8, 0xbd\" ) # EFI_CERT_SHA384_GUID = uuid . UUID ( \"0xff3e5307, 0x9fd0, 0x48c9, 0x85, 0xf1, 0x8a, 0xd5, 0x6c, 0x70, 0x1e, 0x1\" ) # EFI_CERT_SHA512_GUID = uuid . UUID ( \"0x93e0fae, 0xa6c4, 0x4f50, 0x9f, 0x1b, 0xd4, 0x1e, 0x2b, 0x89, 0xc1, 0x9a\" ) EFI_CERT_X509_SHA256_GUID = uuid . UUID ( \"3bd2a492-96c0-4079-b420-fcf98ef103ed\" ) # EFI_CERT_X509_SHA384_GUID = uuid . UUID ( \"0x7076876e, 0x80c2, 0x4ee6, 0xaa, 0xd2, 0x28, 0xb3, 0x49, 0xa6, 0x86, 0x5b\" ) # noqa : E501 # EFI_CERT_X509_SHA512_GUID = uuid . UUID ( \"0x446dbf63, 0x2502, 0x4cda, 0xbc, 0xfa, 0x24, 0x65, 0xd2, 0xb0, 0xfe, 0x9d\" ) # noqa : E501 # EFI_CERT_TYPE_PKCS7_GUID = uuid . UUID ( \"0x4aafd29d, 0x68df, 0x49ee, 0x8a, 0xa9, 0x34, 0x7d, 0x37, 0x56, 0x65, 0xa7\" ) # # This method is a factory for creating the correct Efi Signature Data object # from the filestream of an existing auth payload # @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None # # Create a new Efi Signature Data object . # Type will be baed on GUID # Value will be based on type and Content ( content stream opened for reading ) # sigowner is the UUID object for the signature owner guid @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" )","title":"EfiSignatureDataFactory"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_2","text":"EFI_CERT_SHA256_GUID EFI_CERT_X509_GUID EFI_CERT_X509_SHA256_GUID","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#create","text":"def Create ( type , ContentFileStream , sigowner ) View Source @staticmethod def Create ( type , ContentFileStream , sigowner ) : if ( ContentFileStream is None ) : raise Exception ( \"Invalid Content File Stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : return EfiSignatureDataEfiCertSha256 ( createfs = ContentFileStream , sigowner = sigowner ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( createfs = ContentFileStream , sigowner = sigowner ) else : raise Exception ( \"Not Supported\" )","title":"Create"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#factory","text":"def Factory ( fs , type , size ) View Source @staticmethod def Factory ( fs , type , size ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) if ( type == EfiSignatureDataFactory . EFI_CERT_SHA256_GUID ) : if ( size != EfiSignatureDataEfiCertSha256 . STATIC_STRUCT_SIZE ) : raise Exception ( \"Invalid Size 0x%x\" % size ) return EfiSignatureDataEfiCertSha256 ( decodefs = fs ) elif ( type == EfiSignatureDataFactory . EFI_CERT_X509_GUID ) : return EfiSignatureDataEfiCertX509 ( decodefs = fs , decodesize = size ) else : logging . error ( \"GuidType Value: %s\" % type ) raise Exception ( \"Not Supported\" ) return None","title":"Factory"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignatureheader","text":"class EfiSignatureHeader ( ) View Source class EfiSignatureHeader ( object ): def __init__ ( self ): raise Exception ( \"Not Implemented\" )","title":"EfiSignatureHeader"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efisignaturelist","text":"class EfiSignatureList ( filestream = None , typeguid = None ) View Source class EfiSignatureList ( object ): STATIC_STRUCT_SIZE = 16 + 4 + 4 + 4 def __init__ ( self , filestream = None , typeguid = None ): if ( filestream is None ): # Type of the signature. GUID signature types are defined in below. self . SignatureType = typeguid # Total size of the signature list, including this header. self . SignatureListSize = EfiSignatureList . STATIC_STRUCT_SIZE # Size of the signature header which precedes the array of signatures. self . SignatureHeaderSize = - 1 # Size of each signature. self . SignatureSize = 0 # Header before the array of signatures. The format of this header is specified by the SignatureType. self . SignatureHeader = None # An array of signatures. Each signature is SignatureSize bytes in length. self . SignatureData_List = None else: self . PopulateFromFileStream ( filestream ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing (size 0) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly. if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a ) def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else: print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List: a . Print () def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List: a . Write ( fs ) def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else: self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize","title":"EfiSignatureList"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_3","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_3","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#addsignaturedata","text":"def AddSignatureData ( self , SigDataObject ) View Source def AddSignatureData ( self , SigDataObject ): if ( self . SignatureSize == 0 ): raise Exception ( \"Before adding Signature Data you must have set the Signature Size\" ) if ( self . SignatureSize != SigDataObject . GetTotalSize ()): raise Exception ( \"Can't add Signature Data of different size\" ) if ( self . SignatureData_List is None ): self . SignatureData_List = [] self . SignatureData_List . append ( SigDataObject ) self . SignatureListSize += self . SignatureSize","title":"AddSignatureData"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#addsignatureheader","text":"def AddSignatureHeader ( self , SigHeader , SigSize = 0 ) View Source def AddSignatureHeader ( self , SigHeader , SigSize = 0 ): if ( self . SignatureHeader is not None ): raise Exception ( \"Signature Header already set\" ) if ( self . SignatureHeaderSize != - 1 ): raise Exception ( \"Signature Header already set (size)\" ) if ( self . SignatureSize != 0 ): raise Exception ( \"Signature Size already set\" ) if ( self . SignatureData_List is not None ): raise Exception ( \"Signature Data List is already initialized\" ) if ( SigHeader is None ) and ( SigSize == 0 ): raise Exception ( \"Invalid parameters. Can't have no header and 0 Signature Size\" ) self . SignatureHeader = SigHeader if ( SigHeader is None ): self . SignatureHeaderSize = 0 self . SignatureSize = SigSize else : self . SignatureHeaderSize = SigHeader . GetTotalSize () self . SignatureSize = SigHeader . GetSizeOfSignatureDataEntry () self . SignatureListSize += self . SignatureHeaderSize","title":"AddSignatureHeader"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_3","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiSignatureList . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . SignatureType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . SignatureListSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureHeaderSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] self . SignatureSize = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] # check the total size of this is within the File if (( end - start ) < self . SignatureListSize ): logging . debug ( \"SignatureListSize 0x%x\" % self . SignatureListSize ) logging . debug ( \"End - Start is 0x%x\" % ( end - start )) raise Exception ( \"Invalid File Stream. Not enough file content to cover the Sig List Size\" ) # check that structure is built correctly and there is room within the structure total size to read the header if (( self . SignatureListSize - ( fs . tell () - start )) < self . SignatureHeaderSize ): raise Exception ( \"Invalid Sig List. Sizes not correct. \" \"SignatureHeaderSize extends beyond end of structure\" ) # Signature Header is allowed to be nothing ( size 0 ) self . SignatureHeader = None if ( self . SignatureHeaderSize > 0 ): self . SignatureHeader = EfiSignatureHeader ( fs , self . SignatureHeaderSize ) if ((( self . SignatureListSize - ( fs . tell () - start )) % self . SignatureSize ) != 0 ): raise Exception ( \"Invalid Sig List. Signature Data Array is not a valid size\" ) self . SignatureData_List = [] while (( start + self . SignatureListSize ) > fs . tell ()): # double check that everything is adding up correctly . if (( start + self . SignatureListSize - fs . tell () - self . SignatureSize ) < 0 ): raise Exception ( \"Invalid Signature List Processing. Signature Data not correctly parsed!!\" ) a = EfiSignatureDataFactory . Factory ( fs , self . SignatureType , self . SignatureSize ) self . SignatureData_List . append ( a )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_3","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiSignatureList\" ) print ( \" Signature Type: %s\" % str ( self . SignatureType )) print ( \" Signature List Size: 0x%x\" % self . SignatureListSize ) print ( \" Signature Header Size: 0x%x\" % self . SignatureHeaderSize ) print ( \" Signature Size: 0x%x\" % self . SignatureSize ) if ( self . SignatureHeader is not None ): self . SignatureHeader . Print () else : print ( \" Signature Header: NONE\" ) for a in self . SignatureData_List : a . Print ()","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_3","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) if (( self . SignatureHeader is None ) and ( self . SignatureHeaderSize == - 1 )): raise Exception ( \"Invalid object. Uninitialized Sig Header\" ) if ( self . SignatureData_List is None ): raise Exception ( \"Invalid object. No Sig Data\" ) fs . write ( self . SignatureType . bytes_le ) fs . write ( struct . pack ( \"<I\" , self . SignatureListSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureHeaderSize )) fs . write ( struct . pack ( \"<I\" , self . SignatureSize )) if ( self . SignatureHeader is not None ): self . SignatureHeader . Write ( fs ) for a in self . SignatureData_List : a . Write ( fs )","title":"Write"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#efitime","text":"class EfiTime ( Time = datetime . datetime ( 2020 , 6 , 1 , 11 , 47 , 16 , 879097 ), decodefs = None ) View Source class EfiTime ( object ): STATIC_STRUCT_SIZE = 16 def __init__ ( self , Time = datetime . datetime . now (), decodefs = None ): if ( decodefs is None ): self . Time = Time else: self . PopulateFromFileStream ( decodefs ) def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight ) def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" )) def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"EfiTime"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#class-variables_4","text":"STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#methods_4","text":"","title":"Methods"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#populatefromfilestream_4","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Steam\" ) # only populate from file stream those parts that are complete in the file stream start = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( start ) if (( end - start ) < EfiTime . STATIC_STRUCT_SIZE ): # size of the static structure data raise Exception ( \"Invalid file stream size\" ) Year = struct . unpack ( \"<H\" , fs . read ( 2 ))[ 0 ] Month = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Day = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Hour = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Minute = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] Second = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad1 NanoSecond = struct . unpack ( \"<I\" , fs . read ( 4 ))[ 0 ] TimeZone = struct . unpack ( \"<h\" , fs . read ( 2 ))[ 0 ] Daylight = struct . unpack ( \"<B\" , fs . read ( 1 ))[ 0 ] fs . seek ( 1 , 1 ) # seek past pad2 self . Time = datetime . datetime ( Year , Month , Day , Hour , Minute , Second , NanoSecond / 1000 ) logging . debug ( \"I don't know how to deal with TimeZone or Daylight and I don't care at the moment\" ) logging . debug ( \"Timezone value is: 0x%x\" % TimeZone ) logging . debug ( \"Daylight value is: 0x%X\" % Daylight )","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#print_4","text":"def Print ( self ) View Source def Print ( self ): print ( \"EfiTime: %s\" % datetime . datetime . strftime ( self . Time , \"%A, %B %d, %Y %I:%M%p\" ))","title":"Print"},{"location":"edk2toollib/uefi/authenticated_variables_structure_support/#write_4","text":"def Write ( self , fs ) View Source def Write ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File Output Stream\" ) fs . write ( struct . pack ( \"<H\" , self . Time . year )) fs . write ( struct . pack ( \"<B\" , self . Time . month )) fs . write ( struct . pack ( \"<B\" , self . Time . day )) fs . write ( struct . pack ( \"<B\" , self . Time . hour )) fs . write ( struct . pack ( \"<B\" , self . Time . minute )) fs . write ( struct . pack ( \"<B\" , self . Time . second )) fs . write ( struct . pack ( \"<B\" , 0 )) # Pad1 fs . write ( struct . pack ( \"<I\" , 0 )) # Nano Seconds fs . write ( struct . pack ( \"<h\" , 0 )) # TimeZone fs . write ( struct . pack ( \"<B\" , 0 )) # Daylight fs . write ( struct . pack ( \"<B\" , 0 )) # Pad2","title":"Write"},{"location":"edk2toollib/uefi/bmp_object/","text":"Module edk2toollib.uefi.bmp_object View Source # @file # Helper lib to read and parse bitmap graphics files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import struct class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None : self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else : self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x %X \" % self . Blue ) logger . info ( \" Green: 0x %X \" % self . Green ) logger . info ( \" Red: 0x %X \" % self . Red ) logger . info ( \" Reserved: 0x %X \" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) class BmpObject ( object ): STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB; < -- Start of FileHeader # CHAR8 CharM; # UINT32 Size; # UINT16 Reserved[2]; # UINT32 ImageOffset; <-- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize; < -- Start of BmpHeader # UINT32 PixelWidth; # UINT32 PixelHeight; # UINT16 Planes; ///< Must be 1 # UINT16 BitPerPixel; ///< 1, 4, 8, or 24 # UINT32 CompressionType; # UINT32 ImageSize; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter; # UINT32 YPixelsPerMeter; # UINT32 NumberOfColors; # UINT32 ImportantColors; # } BMP_IMAGE_HEADER; def __init__ ( self , filestream = None ): self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x %X ( %d )\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x %X Less Than 0x %X \" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d \" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d \" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x %X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ): self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s \" % self . CharB ) self . logger . info ( \" CharM: %s \" % self . CharM ) self . logger . info ( \" Size: 0x %X ( %d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x %X \" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x %X \" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x %X ( %d )\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x %X \" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x %X ( %d )\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x %X ( %d )\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x %X \" % self . Planes ) self . logger . info ( \" BitPerPixel: %d \" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x %X \" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x %X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d \" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d \" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d \" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d \" % self . ImportantColors ) # print color maps if ( PrintColorMapData ): for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ): self . logger . info ( \" BMP Padding (0x %X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ): self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData ) Classes BmpColorMap class BmpColorMap ( filestream = None ) View Source class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None: self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else: self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None: raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE: # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) Class variables STATIC_SIZE Methods PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] Print def Print ( self ) View Source def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) BmpObject class BmpObject ( filestream = None ) View Source class BmpObject ( object ) : STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB ; < -- Start of FileHeader # CHAR8 CharM ; # UINT32 Size ; # UINT16 Reserved [ 2 ] ; # UINT32 ImageOffset ; < -- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize ; < -- Start of BmpHeader # UINT32 PixelWidth ; # UINT32 PixelHeight ; # UINT16 Planes ; ///< Must be 1 # UINT16 BitPerPixel ; ///< 1 , 4 , 8 , or 24 # UINT32 CompressionType ; # UINT32 ImageSize ; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter ; # UINT32 YPixelsPerMeter ; # UINT32 NumberOfColors ; # UINT32 ImportantColors ; # } BMP_IMAGE_HEADER ; def __init__ ( self , filestream = None ) : self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ) : if ( self . BitPerPixel == 1 ) : return 2 elif ( self . BitPerPixel == 4 ) : return 16 elif ( self . BitPerPixel == 8 ) : return 256 else : return 0 # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ) : # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ) : raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if ( self . Size < self . HeaderSize ) : raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )) : raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ) : # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ) : ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ) : self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )) : raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ) : self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ) : raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ) : # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ) : fs . write ( self . Padding ) # Pixel data if ( self . ImageData ) : fs . write ( self . ImageData ) Class variables STATIC_FILE_HEADER_SIZE STATIC_IMAGE_HEADER_SIZE Methods ExpectedColorMapEntires def ExpectedColorMapEntires ( self ) View Source def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) Print def Print ( self , PrintImageData = False , PrintColorMapData = False ) View Source def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) Write def Write ( self , fs ) View Source def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Bmp object"},{"location":"edk2toollib/uefi/bmp_object/#module-edk2toollibuefibmp_object","text":"View Source # @file # Helper lib to read and parse bitmap graphics files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import logging import struct class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None : self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else : self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x %X \" % self . Blue ) logger . info ( \" Green: 0x %X \" % self . Green ) logger . info ( \" Red: 0x %X \" % self . Red ) logger . info ( \" Reserved: 0x %X \" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved )) class BmpObject ( object ): STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB; < -- Start of FileHeader # CHAR8 CharM; # UINT32 Size; # UINT16 Reserved[2]; # UINT32 ImageOffset; <-- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize; < -- Start of BmpHeader # UINT32 PixelWidth; # UINT32 PixelHeight; # UINT16 Planes; ///< Must be 1 # UINT16 BitPerPixel; ///< 1, 4, 8, or 24 # UINT32 CompressionType; # UINT32 ImageSize; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter; # UINT32 YPixelsPerMeter; # UINT32 NumberOfColors; # UINT32 ImportantColors; # } BMP_IMAGE_HEADER; def __init__ ( self , filestream = None ): self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0 # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x %X ( %d )\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x %X Less Than 0x %X \" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d \" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d \" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x %X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ): self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s \" % self . CharB ) self . logger . info ( \" CharM: %s \" % self . CharM ) self . logger . info ( \" Size: 0x %X ( %d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x %X \" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x %X \" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x %X ( %d )\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x %X \" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x %X ( %d )\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x %X ( %d )\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x %X \" % self . Planes ) self . logger . info ( \" BitPerPixel: %d \" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x %X \" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x %X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d \" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d \" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d \" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d \" % self . ImportantColors ) # print color maps if ( PrintColorMapData ): for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ): self . logger . info ( \" BMP Padding (0x %X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ): self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ) . tolist () for index in range ( len ( ndbl )): if ( index % 16 == 0 ): self . logger . info ( \"0x %04X -\" % index ), self . logger . info ( \" %02X \" % ndbl [ index ]), if ( index % 16 == 15 ): self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Module edk2toollib.uefi.bmp_object"},{"location":"edk2toollib/uefi/bmp_object/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/bmp_object/#bmpcolormap","text":"class BmpColorMap ( filestream = None ) View Source class BmpColorMap ( object ): STATIC_SIZE = 4 # typedef struct { # UINT8 Blue; # UINT8 Green; # UINT8 Red; # UINT8 Reserved; # } BMP_COLOR_MAP; def __init__ ( self , filestream = None ): if filestream is None: self . Blue = 0 self . Green = 0 self . Red = 0 self . Reserved = 0 else: self . PopulateFromFileStream ( filestream ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if fs is None: raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE: # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved ) def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved ))","title":"BmpColorMap"},{"location":"edk2toollib/uefi/bmp_object/#class-variables","text":"STATIC_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/bmp_object/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/bmp_object/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if ( end - offset ) < BmpColorMap . STATIC_SIZE : # size of the bmp color map raise Exception ( \"Invalid file stream size. %d < Color map Size\" % ( end - offset )) # read the Bmp Color Map self . Blue = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Green = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Red = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ] self . Reserved = struct . unpack ( \"=B\" , fs . read ( 1 ))[ 0 ]","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/bmp_object/#print","text":"def Print ( self ) View Source def Print ( self ): logger = logging . get ( __name__ ) logger . info ( \"BMP Color Map\" ) logger . info ( \" Blue: 0x%X\" % self . Blue ) logger . info ( \" Green: 0x%X\" % self . Green ) logger . info ( \" Red: 0x%X\" % self . Red ) logger . info ( \" Reserved: 0x%X\" % self . Reserved )","title":"Print"},{"location":"edk2toollib/uefi/bmp_object/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=B\" , self . Blue )) fs . write ( struct . pack ( \"=B\" , self . Green )) fs . write ( struct . pack ( \"=B\" , self . Red )) fs . write ( struct . pack ( \"=B\" , self . Reserved ))","title":"Write"},{"location":"edk2toollib/uefi/bmp_object/#bmpobject","text":"class BmpObject ( filestream = None ) View Source class BmpObject ( object ) : STATIC_FILE_HEADER_SIZE = 14 STATIC_IMAGE_HEADER_SIZE = 40 # typedef struct { # CHAR8 CharB ; < -- Start of FileHeader # CHAR8 CharM ; # UINT32 Size ; # UINT16 Reserved [ 2 ] ; # UINT32 ImageOffset ; < -- Start of pixel data relative to start of FileHeader # UINT32 HeaderSize ; < -- Start of BmpHeader # UINT32 PixelWidth ; # UINT32 PixelHeight ; # UINT16 Planes ; ///< Must be 1 # UINT16 BitPerPixel ; ///< 1 , 4 , 8 , or 24 # UINT32 CompressionType ; # UINT32 ImageSize ; ///< Compressed image size in bytes # UINT32 XPixelsPerMeter ; # UINT32 YPixelsPerMeter ; # UINT32 NumberOfColors ; # UINT32 ImportantColors ; # } BMP_IMAGE_HEADER ; def __init__ ( self , filestream = None ) : self . logger = logging . getLogger ( __name__ ) if filestream is None : self . CharB = 'B' self . CharM = 'M' self . Size = BmpObject . STATIC_STRUCT_SIZE self . Rsvd16_1 = 0 self . Rsvd16_2 = 0 self . ImageOffset = BmpObject . STATIC_STRUCT_SIZE self . HeaderSize = BmpObject . STATIC_STRUCT_SIZE self . PixelWidth = 0 self . PixelHeight = 0 self . Planes = 1 self . BitPerPixel = 0 self . CompressionType = 0 self . ImageSize = 0 self . XPixelsPerMeter = 0 self . YPixelsPerMeter = 0 self . NumberOfColors = 0 self . ImportantColors = 0 self . ImageData = None self . _Padding = None self . _PaddingLength = 0 self . ColorMapList = [] else : self . ImageData = None self . Padding = None self . _PaddingLength = 0 self . ColorMapList = [] self . PopulateFromFileStream ( filestream ) def ExpectedColorMapEntires ( self ) : if ( self . BitPerPixel == 1 ) : return 2 elif ( self . BitPerPixel == 4 ) : return 16 elif ( self . BitPerPixel == 8 ) : return 256 else : return 0 # # Method to un - serialize from a filestream # def PopulateFromFileStream ( self , fs ) : if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ) : # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 )) [ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ) : raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 )) [ 0 ] if ( self . Size < self . HeaderSize ) : raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )) : raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ) : # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ) : ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ) : self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )) : raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ) : self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ) : raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ())) # # Method to Print Bmp Header to stdout # def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) def Write ( self , fs ) : # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ) : fs . write ( self . Padding ) # Pixel data if ( self . ImageData ) : fs . write ( self . ImageData )","title":"BmpObject"},{"location":"edk2toollib/uefi/bmp_object/#class-variables_1","text":"STATIC_FILE_HEADER_SIZE STATIC_IMAGE_HEADER_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/bmp_object/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/bmp_object/#expectedcolormapentires","text":"def ExpectedColorMapEntires ( self ) View Source def ExpectedColorMapEntires ( self ): if ( self . BitPerPixel == 1 ): return 2 elif ( self . BitPerPixel == 4 ): return 16 elif ( self . BitPerPixel == 8 ): return 256 else : return 0","title":"ExpectedColorMapEntires"},{"location":"edk2toollib/uefi/bmp_object/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if fs is None : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) self . logger . debug ( \"Bmp File size as determined by file is: 0x%X (%d)\" % ( end - offset , end - offset )) if (( end - offset ) < BmpObject . STATIC_FILE_HEADER_SIZE ): # size of the static file header data raise Exception ( \"Invalid file stream size. %d < File Header Size\" % ( end - offset )) # read the BMP File header self . CharB = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . CharM = struct . unpack ( \"=c\" , fs . read ( 1 ))[ 0 ] self . Size = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Rsvd16_1 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Rsvd16_2 = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . ImageOffset = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if (( end - fs . tell ()) < BmpObject . STATIC_IMAGE_HEADER_SIZE ): raise Exception ( \"Invalid file stream size. %d < Img Header Size\" % ( end - fs . tell ())) # read the BMP Image Header self . HeaderSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelWidth = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . PixelHeight = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Planes = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . BitPerPixel = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CompressionType = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImageSize = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . XPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . YPixelsPerMeter = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . NumberOfColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . ImportantColors = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] if ( self . Size < self . HeaderSize ): raise Exception ( \"Size can't be smaller than HeaderSize\" ) if (( end - fs . tell ()) < ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE )): raise Exception ( \"Invalid file stream size (Size) 0x%X Less Than 0x%X\" % ( ( end - fs . tell ()), ( self . Size - self . HeaderSize - BmpObject . STATIC_FILE_HEADER_SIZE ))) StartOfImageData = offset + self . ImageOffset if ( fs . tell () < StartOfImageData ): # Handle any color maps if ( self . ExpectedColorMapEntires () > 0 ): ColorMapCount = self . ExpectedColorMapEntires () if ( self . NumberOfColors > 0 ) and ( self . NumberOfColors != ColorMapCount ): self . logger . info ( \"Current Code has untested support for limited color map, Good Luck. \" ) self . logger . info ( \"Expected Color Map Entries %d\" % ( ColorMapCount )) self . logger . info ( \"Actual Color Map Entries %d\" % ( self . NumberOfColors )) ColorMapCount = self . NumberOfColors if (( StartOfImageData - fs . tell ()) < ( ColorMapCount * BmpColorMap . STATIC_SIZE )): raise Exception ( \"Color Map not as expected\" ) # read all the color maps and append to the list for i in range ( ColorMapCount ): self . ColorMapList . append ( BmpColorMap ( fs )) # handle padding self . _PaddingLength = StartOfImageData - fs . tell () self . _Padding = fs . read ( self . _PaddingLength ) self . ImageData = fs . read ( self . Size - self . ImageOffset ) if (( end - fs . tell ()) > 0 ): raise Exception ( \"Extra Data at the end of BMP file - 0x%X bytes\" % ( end - fs . tell ()))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/bmp_object/#print_1","text":"def Print ( self , PrintImageData = False , PrintColorMapData = False ) View Source def Print ( self , PrintImageData = False , PrintColorMapData = False ) : self . logger . info ( \"BMP\" ) self . logger . info ( \" BMP File Header\" ) self . logger . info ( \" CharB: %s\" % self . CharB ) self . logger . info ( \" CharM: %s\" % self . CharM ) self . logger . info ( \" Size: 0x%X (%d bytes)\" % ( self . Size , self . Size )) self . logger . info ( \" RSVD[1]: 0x%X\" % self . Rsvd16_1 ) self . logger . info ( \" RSVD[2]: 0x%X\" % self . Rsvd16_2 ) self . logger . info ( \" ImageOffset: 0x%X (%d)\" % ( self . ImageOffset , self . ImageOffset )) self . logger . info ( \" BMP Image Header\" ) self . logger . info ( \" HeaderSize: 0x%X\" % self . HeaderSize ) self . logger . info ( \" PixelWidth: 0x%X (%d)\" % ( self . PixelWidth , self . PixelWidth )) self . logger . info ( \" PixelHeight: 0x%X (%d)\" % ( self . PixelHeight , self . PixelHeight )) self . logger . info ( \" Planes: 0x%X\" % self . Planes ) self . logger . info ( \" BitPerPixel: %d\" % self . BitPerPixel ) self . logger . info ( \" CompressionType: 0x%X\" % self . CompressionType ) self . logger . info ( \" ImageSize: 0x%X (used for compressed images only)\" % self . ImageSize ) self . logger . info ( \" XPixelsPerMeter: %d\" % self . XPixelsPerMeter ) self . logger . info ( \" YPixelsPerMeter: %d\" % self . YPixelsPerMeter ) self . logger . info ( \" NumberOfColors: %d\" % self . NumberOfColors ) self . logger . info ( \" ImportantColors: %d\" % self . ImportantColors ) # print color maps if ( PrintColorMapData ) : for cm in self . ColorMapList : cm . Print () if ( self . _PaddingLength > 0 ) : self . logger . info ( \" BMP Padding (0x%X bytes)\" % self . _PaddingLength ) ndbl = memoryview ( self . _Padding ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" ) if self . ImageData is not None and ( PrintImageData ) : self . logger . info ( \" Bmp Image Data: \" ) ndbl = memoryview ( self . ImageData ). tolist () for index in range ( len ( ndbl )) : if ( index % 16 == 0 ) : self . logger . info ( \"0x%04X -\" % index ), self . logger . info ( \" %02X\" % ndbl [ index ] ), if ( index % 16 == 15 ) : self . logger . info ( \"\" ) self . logger . info ( \"\" )","title":"Print"},{"location":"edk2toollib/uefi/bmp_object/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): # Bmp File header fs . write ( struct . pack ( \"=c\" , self . CharB )) fs . write ( struct . pack ( \"=c\" , self . CharM )) fs . write ( struct . pack ( \"=I\" , self . Size )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_1 )) fs . write ( struct . pack ( \"=H\" , self . Rsvd16_2 )) fs . write ( struct . pack ( \"=I\" , self . ImageOffset )) # Bmp Img Header fs . write ( struct . pack ( \"=I\" , self . HeaderSize )) fs . write ( struct . pack ( \"=I\" , self . PixelWidth )) fs . write ( struct . pack ( \"=I\" , self . PixelHeight )) fs . write ( struct . pack ( \"=H\" , self . Planes )) fs . write ( struct . pack ( \"=H\" , self . BitPerPixel )) fs . write ( struct . pack ( \"=I\" , self . CompressionType )) fs . write ( struct . pack ( \"=I\" , self . ImageSize )) fs . write ( struct . pack ( \"=I\" , self . XPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . YPixelsPerMeter )) fs . write ( struct . pack ( \"=I\" , self . NumberOfColors )) fs . write ( struct . pack ( \"=I\" , self . ImportantColors )) # Bmp Color Map for cm in self . ColorMapList : cm . Write ( fs ) # padding if ( self . _PaddingLength > 0 ): fs . write ( self . Padding ) # Pixel data if ( self . ImageData ): fs . write ( self . ImageData )","title":"Write"},{"location":"edk2toollib/uefi/pi_firmware_file/","text":"Module edk2toollib.uefi.pi_firmware_file View Source # @file # Module contains helper classes and functions to work with UEFI FFs. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # EFI_FFS_FILE_HEADER # # typedef struct { # EFI_GUID Name; # EFI_FFS_INTEGRITY_CHECK IntegrityCheck; # EFI_FV_FILETYPE Type; # EFI_FFS_FILE_ATTRIBUTES Attributes; # UINT8 Size[3]; # EFI_FFS_FILE_STATE State; # } EFI_FFS_FILE_HEADER; class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) Classes EfiFirmwareFileSystemHeader class EfiFirmwareFileSystemHeader ( ) View Source class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) Methods get_size def get_size ( self ) View Source def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self serialize def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"Pi firmware file"},{"location":"edk2toollib/uefi/pi_firmware_file/#module-edk2toollibuefipi_firmware_file","text":"View Source # @file # Module contains helper classes and functions to work with UEFI FFs. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # EFI_FFS_FILE_HEADER # # typedef struct { # EFI_GUID Name; # EFI_FFS_INTEGRITY_CHECK IntegrityCheck; # EFI_FV_FILETYPE Type; # EFI_FFS_FILE_ATTRIBUTES Attributes; # UINT8 Size[3]; # EFI_FFS_FILE_STATE State; # } EFI_FFS_FILE_HEADER; class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"Module edk2toollib.uefi.pi_firmware_file"},{"location":"edk2toollib/uefi/pi_firmware_file/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/pi_firmware_file/#efifirmwarefilesystemheader","text":"class EfiFirmwareFileSystemHeader ( ) View Source class EfiFirmwareFileSystemHeader ( object ): def __init__ ( self ): self . StructString = \"=16sHBBBBBB\" self . FileSystemGuid = None self . Size0 = None self . Size1 = None self . Size2 = None self . Attributes = None self . Type = None self . State = None def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 ) def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"EfiFirmwareFileSystemHeader"},{"location":"edk2toollib/uefi/pi_firmware_file/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_file/#get_size","text":"def get_size ( self ) View Source def get_size ( self ): return self . Size0 + ( self . Size1 << 8 ) + ( self . Size2 << 16 )","title":"get_size"},{"location":"edk2toollib/uefi/pi_firmware_file/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = self . FileSystemGuid ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = self . FileSystemGuid ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_file/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , file_system_guid_bin , self . Checksum , self . Type , self . Attributes , self . Size0 , self . Size1 , self . Size2 , self . State )","title":"serialize"},{"location":"edk2toollib/uefi/pi_firmware_volume/","text":"Module edk2toollib.uefi.pi_firmware_volume View Source # @file # Module contains helper classes and functions to work with UEFI FVs. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # UEFI GUIDs # EfiSystemNvDataFvGuid = uuid . UUID ( fields = ( 0xFFF12B8D , 0x7696 , 0x4C8B , 0xA9 , 0x85 , 0x2747075B4F50 )) # # UEFI #Defines # EFI_FVH_SIGNATURE = b \"_FVH\" # # EFI_FIRMWARE_VOLUME_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_HEADER structure/byte buffer. # # typedef struct { # UINT8 ZeroVector[16]; # EFI_GUID FileSystemGuid; # UINT64 FvLength; # UINT32 Signature; # EFI_FVB_ATTRIBUTES_2 Attributes; # UINT16 HeaderLength; # UINT16 Checksum; # UINT16 ExtHeaderOffset; # UINT8 Reserved[1]; # UINT8 Revision; # EFI_FV_BLOCK_MAP_ENTRY BlockMap[1]; # } EFI_FIRMWARE_VOLUME_HEADER; class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) # # EFI_FIRMWARE_VOLUME_EXT_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_EXT_HEADER structure/byte buffer. # # typedef struct { # EFI_GUID FileSystemGuid; # UINT32 ExtHeaderSize; # } EFI_FIRMWARE_VOLUME_EXT_HEADER; class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self Variables EFI_FVH_SIGNATURE EfiSystemNvDataFvGuid Classes EfiFirmwareVolumeExtHeader class EfiFirmwareVolumeExtHeader ( ) View Source class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self EfiFirmwareVolumeHeader class EfiFirmwareVolumeHeader ( ) View Source class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE: raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is . if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self serialize def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"Pi firmware volume"},{"location":"edk2toollib/uefi/pi_firmware_volume/#module-edk2toollibuefipi_firmware_volume","text":"View Source # @file # Module contains helper classes and functions to work with UEFI FVs. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import uuid import struct import sys # # UEFI GUIDs # EfiSystemNvDataFvGuid = uuid . UUID ( fields = ( 0xFFF12B8D , 0x7696 , 0x4C8B , 0xA9 , 0x85 , 0x2747075B4F50 )) # # UEFI #Defines # EFI_FVH_SIGNATURE = b \"_FVH\" # # EFI_FIRMWARE_VOLUME_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_HEADER structure/byte buffer. # # typedef struct { # UINT8 ZeroVector[16]; # EFI_GUID FileSystemGuid; # UINT64 FvLength; # UINT32 Signature; # EFI_FVB_ATTRIBUTES_2 Attributes; # UINT16 HeaderLength; # UINT16 Checksum; # UINT16 ExtHeaderOffset; # UINT8 Reserved[1]; # UINT8 Revision; # EFI_FV_BLOCK_MAP_ENTRY BlockMap[1]; # } EFI_FIRMWARE_VOLUME_HEADER; class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) # # EFI_FIRMWARE_VOLUME_EXT_HEADER # Can parse or produce an EFI_FIRMWARE_VOLUME_EXT_HEADER structure/byte buffer. # # typedef struct { # EFI_GUID FileSystemGuid; # UINT32 ExtHeaderSize; # } EFI_FIRMWARE_VOLUME_EXT_HEADER; class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"Module edk2toollib.uefi.pi_firmware_volume"},{"location":"edk2toollib/uefi/pi_firmware_volume/#variables","text":"EFI_FVH_SIGNATURE EfiSystemNvDataFvGuid","title":"Variables"},{"location":"edk2toollib/uefi/pi_firmware_volume/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/pi_firmware_volume/#efifirmwarevolumeextheader","text":"class EfiFirmwareVolumeExtHeader ( ) View Source class EfiFirmwareVolumeExtHeader ( object ): def __init__ ( self ): self . StructString = \"=16sL\" self . FileSystemGuid = None self . ExtHeaderSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"EfiFirmwareVolumeExtHeader"},{"location":"edk2toollib/uefi/pi_firmware_volume/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_volume/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . FileSystemGuid , self . ExtHeaderSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_volume/#efifirmwarevolumeheader","text":"class EfiFirmwareVolumeHeader ( ) View Source class EfiFirmwareVolumeHeader ( object ): def __init__ ( self ): self . StructString = \"=16s16sQ4sLHHHBBQQ\" self . ZeroVector = None self . FileSystemGuid = None self . FvLength = None self . Attributes = None self . HeaderLength = None self . Checksum = None self . ExtHeaderOffset = None self . Reserved = None self . Revision = None self . Blockmap0 = None self . Blockmap1 = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is. if self . Signature != EFI_FVH_SIGNATURE: raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else: self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"EfiFirmwareVolumeHeader"},{"location":"edk2toollib/uefi/pi_firmware_volume/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/pi_firmware_volume/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 ) = struct . unpack ( self . StructString , struct_bytes ) # Make sure that this structure is what we think it is . if self . Signature != EFI_FVH_SIGNATURE : raise Exception ( \"File does not appear to point to a valid EfiFirmwareVolumeHeader!\" ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . FileSystemGuid = uuid . UUID ( bytes = file_system_guid_bin ) else : self . FileSystemGuid = uuid . UUID ( bytes_le = file_system_guid_bin ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/pi_firmware_volume/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): file_system_guid_bin = self . FileSystemGuid . bytes if sys . byteorder == 'big' else self . FileSystemGuid . bytes_le return struct . pack ( self . StructString , self . ZeroVector , file_system_guid_bin , self . FvLength , self . Signature , self . Attributes , self . HeaderLength , self . Checksum , self . ExtHeaderOffset , self . Reserved , self . Revision , self . Blockmap0 , self . Blockmap1 )","title":"serialize"},{"location":"edk2toollib/uefi/status_codes/","text":"Module edk2toollib.uefi.status_codes View Source # @file # Code to help convert an Int to StatusCode string # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## class UefiStatusCode ( object ) : # string Array StatusCodeStrings = [ \"Success\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\" ] def Convert32BitToString ( self , i ) : # convert a 32 bit value to string return UefiStatusCode . StatusCodeStrings [ (i & 0xFFF) ] def Convert64BitToString ( self , l ) : if ( l > len ( UefiStatusCode . StatusCodeStrings )) : return \"\" return UefiStatusCode . StatusCodeStrings [ (l & 0xFFF) ] def ConvertHexString64ToString ( self , hexstring ) : value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) Classes UefiStatusCode class UefiStatusCode ( / , * args , ** kwargs ) View Source class UefiStatusCode ( object ): # string Array StatusCodeStrings = [ \"Success\" , \"Load Error\" , \"Invalid Parameter\" , \"Unsupported\" , \"Bad BufferSize\" , \"Buffer Too Small\" , \"Not Ready\" , \"Device Error\" , \"Write Protected\" , \"Out of Resources\" , \"Volume Corrupt\" , \"Volume Full\" , \"No Media\" , \"Media Changed\" , \"Not Found\" , \"Access Denied\" , \"No Response\" , \"No Mapping\" , \"Time Out\" , \"Not Started\" , \"Already Started\" , \"Aborted\" , \"ICMP Error\" , \"TFTP Error\" , \"Protocol Error\" , \"Incompatible Error\" , \"Security Violation\" , \"CRC Error\" , \"End of Media\" , \"Reserved(29)\" , \"Reserved(30)\" , \"End of File\" , \"Invalid Language\" , \"Compromised Data\" ] def Convert32BitToString ( self , i ): # convert a 32bit value to string return UefiStatusCode . StatusCodeStrings [( i & 0xFFF )] def Convert64BitToString ( self , l ): if ( l > len ( UefiStatusCode . StatusCodeStrings )): return \"\" return UefiStatusCode . StatusCodeStrings [( l & 0xFFF )] def ConvertHexString64ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) Class variables StatusCodeStrings Methods Convert32BitToString def Convert32BitToString ( self , i ) View Source def Convert32BitToString ( self , i ): # convert a 32 bit value to string return UefiStatusCode . StatusCodeStrings [( i & 0 xFFF )] Convert64BitToString def Convert64BitToString ( self , l ) View Source def Convert64BitToString ( self , l ): if ( l > len ( UefiStatusCode . StatusCodeStrings )): return \"\" return UefiStatusCode . StatusCodeStrings [( l & 0 xFFF )] ConvertHexString32ToString def ConvertHexString32ToString ( self , hexstring ) View Source def ConvertHexString32ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert32BitToString ( value ) ConvertHexString64ToString def ConvertHexString64ToString ( self , hexstring ) View Source def ConvertHexString64ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert64BitToString ( value )","title":"Status codes"},{"location":"edk2toollib/uefi/status_codes/#module-edk2toollibuefistatus_codes","text":"View Source # @file # Code to help convert an Int to StatusCode string # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## class UefiStatusCode ( object ) : # string Array StatusCodeStrings = [ \"Success\", \"Load Error\", \"Invalid Parameter\", \"Unsupported\", \"Bad BufferSize\", \"Buffer Too Small\", \"Not Ready\", \"Device Error\", \"Write Protected\", \"Out of Resources\", \"Volume Corrupt\", \"Volume Full\", \"No Media\", \"Media Changed\", \"Not Found\", \"Access Denied\", \"No Response\", \"No Mapping\", \"Time Out\", \"Not Started\", \"Already Started\", \"Aborted\", \"ICMP Error\", \"TFTP Error\", \"Protocol Error\", \"Incompatible Error\", \"Security Violation\", \"CRC Error\", \"End of Media\", \"Reserved(29)\", \"Reserved(30)\", \"End of File\", \"Invalid Language\", \"Compromised Data\" ] def Convert32BitToString ( self , i ) : # convert a 32 bit value to string return UefiStatusCode . StatusCodeStrings [ (i & 0xFFF) ] def Convert64BitToString ( self , l ) : if ( l > len ( UefiStatusCode . StatusCodeStrings )) : return \"\" return UefiStatusCode . StatusCodeStrings [ (l & 0xFFF) ] def ConvertHexString64ToString ( self , hexstring ) : value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ) : value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"Module edk2toollib.uefi.status_codes"},{"location":"edk2toollib/uefi/status_codes/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/status_codes/#uefistatuscode","text":"class UefiStatusCode ( / , * args , ** kwargs ) View Source class UefiStatusCode ( object ): # string Array StatusCodeStrings = [ \"Success\" , \"Load Error\" , \"Invalid Parameter\" , \"Unsupported\" , \"Bad BufferSize\" , \"Buffer Too Small\" , \"Not Ready\" , \"Device Error\" , \"Write Protected\" , \"Out of Resources\" , \"Volume Corrupt\" , \"Volume Full\" , \"No Media\" , \"Media Changed\" , \"Not Found\" , \"Access Denied\" , \"No Response\" , \"No Mapping\" , \"Time Out\" , \"Not Started\" , \"Already Started\" , \"Aborted\" , \"ICMP Error\" , \"TFTP Error\" , \"Protocol Error\" , \"Incompatible Error\" , \"Security Violation\" , \"CRC Error\" , \"End of Media\" , \"Reserved(29)\" , \"Reserved(30)\" , \"End of File\" , \"Invalid Language\" , \"Compromised Data\" ] def Convert32BitToString ( self , i ): # convert a 32bit value to string return UefiStatusCode . StatusCodeStrings [( i & 0xFFF )] def Convert64BitToString ( self , l ): if ( l > len ( UefiStatusCode . StatusCodeStrings )): return \"\" return UefiStatusCode . StatusCodeStrings [( l & 0xFFF )] def ConvertHexString64ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert64BitToString ( value ) def ConvertHexString32ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"UefiStatusCode"},{"location":"edk2toollib/uefi/status_codes/#class-variables","text":"StatusCodeStrings","title":"Class variables"},{"location":"edk2toollib/uefi/status_codes/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/status_codes/#convert32bittostring","text":"def Convert32BitToString ( self , i ) View Source def Convert32BitToString ( self , i ): # convert a 32 bit value to string return UefiStatusCode . StatusCodeStrings [( i & 0 xFFF )]","title":"Convert32BitToString"},{"location":"edk2toollib/uefi/status_codes/#convert64bittostring","text":"def Convert64BitToString ( self , l ) View Source def Convert64BitToString ( self , l ): if ( l > len ( UefiStatusCode . StatusCodeStrings )): return \"\" return UefiStatusCode . StatusCodeStrings [( l & 0 xFFF )]","title":"Convert64BitToString"},{"location":"edk2toollib/uefi/status_codes/#converthexstring32tostring","text":"def ConvertHexString32ToString ( self , hexstring ) View Source def ConvertHexString32ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert32BitToString ( value )","title":"ConvertHexString32ToString"},{"location":"edk2toollib/uefi/status_codes/#converthexstring64tostring","text":"def ConvertHexString64ToString ( self , hexstring ) View Source def ConvertHexString64ToString ( self , hexstring ): value = int ( hexstring , 16 ) return self . Convert64BitToString ( value )","title":"ConvertHexString64ToString"},{"location":"edk2toollib/uefi/uefi_multi_phase/","text":"Module edk2toollib.uefi.uefi_multi_phase View Source # @file # Module contains defintions and structures from the UefiMultiPhase header file . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## EFI_VARIABLE_NON_VOLATILE = 0x00000001 EFI_VARIABLE_BOOTSERVICE_ACCESS = 0x00000002 EFI_VARIABLE_RUNTIME_ACCESS = 0x00000004 EFI_VARIABLE_HARDWARE_ERROR_RECORD = 0x00000008 EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS = 0x00000010 EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS = 0x00000020 EFI_VARIABLE_APPEND_WRITE = 0x00000040 Variables EFI_VARIABLE_APPEND_WRITE EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS EFI_VARIABLE_BOOTSERVICE_ACCESS EFI_VARIABLE_HARDWARE_ERROR_RECORD EFI_VARIABLE_NON_VOLATILE EFI_VARIABLE_RUNTIME_ACCESS EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS","title":"Uefi multi phase"},{"location":"edk2toollib/uefi/uefi_multi_phase/#module-edk2toollibuefiuefi_multi_phase","text":"View Source # @file # Module contains defintions and structures from the UefiMultiPhase header file . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## EFI_VARIABLE_NON_VOLATILE = 0x00000001 EFI_VARIABLE_BOOTSERVICE_ACCESS = 0x00000002 EFI_VARIABLE_RUNTIME_ACCESS = 0x00000004 EFI_VARIABLE_HARDWARE_ERROR_RECORD = 0x00000008 EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS = 0x00000010 EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS = 0x00000020 EFI_VARIABLE_APPEND_WRITE = 0x00000040","title":"Module edk2toollib.uefi.uefi_multi_phase"},{"location":"edk2toollib/uefi/uefi_multi_phase/#variables","text":"EFI_VARIABLE_APPEND_WRITE EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS EFI_VARIABLE_BOOTSERVICE_ACCESS EFI_VARIABLE_HARDWARE_ERROR_RECORD EFI_VARIABLE_NON_VOLATILE EFI_VARIABLE_RUNTIME_ACCESS EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS","title":"Variables"},{"location":"edk2toollib/uefi/wincert/","text":"Module edk2toollib.uefi.wincert View Source # @file wincert.py # Code to work with UEFI WinCert data # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid from edk2toollib.utility_functions import PrintByteList class WinCertPkcs1 ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s \" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) ## # WIN_CERT_UEFI_GUID ## class WinCertUefiGuid ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) PKCS7Guid = uuid . UUID ( \"{4aafd29d-68df-49ee-8aa9-347d375665a7}\" ) # PKCS7 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertUefiGuid . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = WinCertUefiGuid . PKCS7Guid self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" CertType: %s \" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData ) class WinCert ( object ): STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE.wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ): return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ): return WinCertPkcs1 ( fs ) else : return None Classes WinCert class WinCert ( / , * args , ** kwargs ) View Source class WinCert ( object ) : STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE . wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None Class variables REVISION STATIC_STRUCT_SIZE WIN_CERT_TYPE_EFI_GUID WIN_CERT_TYPE_EFI_PKCS115 WIN_CERT_TYPE_NONE WIN_CERT_TYPE_PKCS_SIGNED_DATA Static methods Factory def Factory ( fs ) View Source @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None WinCertPkcs1 class WinCertPkcs1 ( filestream = None ) View Source class WinCertPkcs1 ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else: self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) Class variables EFI_HASH_SHA256 STATIC_STRUCT_SIZE Methods AddCertData def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) Print def Print ( self ) View Source def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) WinCertUefiGuid class WinCertUefiGuid ( filestream = None ) View Source class WinCertUefiGuid ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) PKCS7Guid = uuid . UUID ( \"{4aafd29d-68df-49ee-8aa9-347d375665a7}\" ) # PKCS7 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertUefiGuid . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = WinCertUefiGuid . PKCS7Guid self . CertData = None else: self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" CertType: %s\" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData ) Class variables PKCS7Guid STATIC_STRUCT_SIZE Methods AddCertData def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) PopulateFromFileStream def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )) Print def Print ( self ) View Source def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" CertType: %s\" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) Write def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData )","title":"Wincert"},{"location":"edk2toollib/uefi/wincert/#module-edk2toollibuefiwincert","text":"View Source # @file wincert.py # Code to work with UEFI WinCert data # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid from edk2toollib.utility_functions import PrintByteList class WinCertPkcs1 ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s \" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData ) ## # WIN_CERT_UEFI_GUID ## class WinCertUefiGuid ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) PKCS7Guid = uuid . UUID ( \"{4aafd29d-68df-49ee-8aa9-347d375665a7}\" ) # PKCS7 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertUefiGuid . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = WinCertUefiGuid . PKCS7Guid self . CertData = None else : self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x %X \" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x %X \" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x %X \" % self . Hdr_wCertificateType ) print ( \" CertType: %s \" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData ) class WinCert ( object ): STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE.wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ): return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ): return WinCertPkcs1 ( fs ) else : return None","title":"Module edk2toollib.uefi.wincert"},{"location":"edk2toollib/uefi/wincert/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/wincert/#wincert","text":"class WinCert ( / , * args , ** kwargs ) View Source class WinCert ( object ) : STATIC_STRUCT_SIZE = 8 # WIN_CERTIFICATE . wCertificateTypes UEFI Spec defined WIN_CERT_TYPE_NONE = 0x0000 WIN_CERT_TYPE_PKCS_SIGNED_DATA = 0x0002 WIN_CERT_TYPE_EFI_PKCS115 = 0x0EF0 WIN_CERT_TYPE_EFI_GUID = 0x0EF1 # Revision REVISION = 0x200 # # this method is a factory # @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None","title":"WinCert"},{"location":"edk2toollib/uefi/wincert/#class-variables","text":"REVISION STATIC_STRUCT_SIZE WIN_CERT_TYPE_EFI_GUID WIN_CERT_TYPE_EFI_PKCS115 WIN_CERT_TYPE_NONE WIN_CERT_TYPE_PKCS_SIGNED_DATA","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/wincert/#factory","text":"def Factory ( fs ) View Source @staticmethod def Factory ( fs ) : if ( fs is None ) : raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCert . STATIC_STRUCT_SIZE ) : # size of the static header data raise Exception ( \"Invalid file stream size\" ) # 1 read len # 2 read revision # 3 read cert type fs . seek ( 4 , 1 ) # seeking past Hdr_dwLength fs . seek ( 2 , 1 ) # seeking past Hdr_wRevision Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 )) [ 0 ] fs . seek ( offset ) if ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_GUID ) : return WinCertUefiGuid ( fs ) elif ( Hdr_wCertificateType == WinCert . WIN_CERT_TYPE_EFI_PKCS115 ) : return WinCertPkcs1 ( fs ) else : return None","title":"Factory"},{"location":"edk2toollib/uefi/wincert/#wincertpkcs1","text":"class WinCertPkcs1 ( filestream = None ) View Source class WinCertPkcs1 ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) EFI_HASH_SHA256 = uuid . UUID ( \"{51AA59DE-FDF2-4EA3-BC63-875FB7842EE9}\" ) # EFI_HASH_SHA256 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertPkcs1 . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_PKCS115 self . HashAlgorithm = None self . CertData = None else: self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData )","title":"WinCertPkcs1"},{"location":"edk2toollib/uefi/wincert/#class-variables_1","text":"EFI_HASH_SHA256 STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/wincert/#addcertdata","text":"def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) if ( self . HashAlgorithm is None ): raise Exception ( \"You must set the Hash Algorithm first\" ) self . CertData = fs . read () self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData )","title":"AddCertData"},{"location":"edk2toollib/uefi/wincert/#populatefromfilestream","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertPkcs1 . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . HashAlgorithm = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size\" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertPkcs1 . STATIC_STRUCT_SIZE ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/wincert/#print","text":"def Print ( self ) View Source def Print ( self ): print ( \"WinCertPKCS115\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" Hash Guid: %s\" % str ( self . HashAlgorithm )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl )","title":"Print"},{"location":"edk2toollib/uefi/wincert/#write","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . HashAlgorithm . bytes_le ) fs . write ( self . CertData )","title":"Write"},{"location":"edk2toollib/uefi/wincert/#wincertuefiguid","text":"class WinCertUefiGuid ( filestream = None ) View Source class WinCertUefiGuid ( object ): STATIC_STRUCT_SIZE = ( 4 + 2 + 2 + 16 ) PKCS7Guid = uuid . UUID ( \"{4aafd29d-68df-49ee-8aa9-347d375665a7}\" ) # PKCS7 guid defined by UEFI spec def __init__ ( self , filestream = None ): if ( filestream is None ): self . Hdr_dwLength = WinCertUefiGuid . STATIC_STRUCT_SIZE self . Hdr_wRevision = WinCert . REVISION self . Hdr_wCertificateType = WinCert . WIN_CERT_TYPE_EFI_GUID self . CertType = WinCertUefiGuid . PKCS7Guid self . CertData = None else: self . PopulateFromFileStream ( filestream ) def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData ) # # Method to un-serialize from a filestream # def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )) def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" CertType: %s\" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl ) def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData )","title":"WinCertUefiGuid"},{"location":"edk2toollib/uefi/wincert/#class-variables_2","text":"PKCS7Guid STATIC_STRUCT_SIZE","title":"Class variables"},{"location":"edk2toollib/uefi/wincert/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/wincert/#addcertdata_1","text":"def AddCertData ( self , fs ) View Source def AddCertData ( self , fs ): if ( self . CertData is not None ): raise Exception ( \"Cert Data not 0\" ) self . CertData = memoryview ( fs . read ()) self . Hdr_dwLength = self . Hdr_dwLength + len ( self . CertData )","title":"AddCertData"},{"location":"edk2toollib/uefi/wincert/#populatefromfilestream_1","text":"def PopulateFromFileStream ( self , fs ) View Source def PopulateFromFileStream ( self , fs ): if ( fs is None ): raise Exception ( \"Invalid File stream\" ) # only populate from file stream those parts that are complete in the file stream offset = fs . tell () fs . seek ( 0 , 2 ) end = fs . tell () fs . seek ( offset ) if (( end - offset ) < WinCertUefiGuid . STATIC_STRUCT_SIZE ): # size of the static header data raise Exception ( \"Invalid file stream size\" ) self . Hdr_dwLength = struct . unpack ( \"=I\" , fs . read ( 4 ))[ 0 ] self . Hdr_wRevision = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . Hdr_wCertificateType = struct . unpack ( \"=H\" , fs . read ( 2 ))[ 0 ] self . CertType = uuid . UUID ( bytes_le = fs . read ( 16 )) self . CertData = None if (( end - fs . tell ()) < 1 ): raise Exception ( \"Invalid File stream. No data for signature cert data\" ) if (( end - fs . tell ()) < ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE )): raise Exception ( \"Invalid file stream size \" ) self . CertData = memoryview ( fs . read ( self . Hdr_dwLength - WinCertUefiGuid . STATIC_STRUCT_SIZE ))","title":"PopulateFromFileStream"},{"location":"edk2toollib/uefi/wincert/#print_1","text":"def Print ( self ) View Source def Print ( self ): print ( \"WinCertUefiGuid\" ) print ( \" Hdr_dwLength: 0x%X\" % self . Hdr_dwLength ) print ( \" Hdr_wRevision: 0x%X\" % self . Hdr_wRevision ) print ( \" Hdr_wCertificateType: 0x%X\" % self . Hdr_wCertificateType ) print ( \" CertType: %s\" % str ( self . CertType )) print ( \" CertData: \" ) cdl = self . CertData . tolist () PrintByteList ( cdl )","title":"Print"},{"location":"edk2toollib/uefi/wincert/#write_1","text":"def Write ( self , fs ) View Source def Write ( self , fs ): fs . write ( struct . pack ( \"=I\" , self . Hdr_dwLength )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wRevision )) fs . write ( struct . pack ( \"=H\" , self . Hdr_wCertificateType )) fs . write ( self . CertType . bytes_le ) fs . write ( self . CertData )","title":"Write"},{"location":"edk2toollib/uefi/edk2/","text":"Module edk2toollib.uefi.edk2 View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.edk2.ftw_working_block_format edk2toollib.uefi.edk2.parsers edk2toollib.uefi.edk2.path_utilities edk2toollib.uefi.edk2.variable_format edk2toollib.uefi.edk2.variable_format_test edk2toollib.uefi.edk2.variablestore_manulipulations","title":"Index"},{"location":"edk2toollib/uefi/edk2/#module-edk2toollibuefiedk2","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi.edk2"},{"location":"edk2toollib/uefi/edk2/#sub-modules","text":"edk2toollib.uefi.edk2.ftw_working_block_format edk2toollib.uefi.edk2.parsers edk2toollib.uefi.edk2.path_utilities edk2toollib.uefi.edk2.variable_format edk2toollib.uefi.edk2.variable_format_test edk2toollib.uefi.edk2.variablestore_manulipulations","title":"Sub-modules"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/","text":"Module edk2toollib.uefi.edk2.ftw_working_block_format View Source # @file # Module contains helper classes for working with Fault Tolerant Working block content # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid import sys # # UEFI GUIDs # EdkiiWorkingBlockSignatureGuid = uuid . UUID ( fields = ( 0x9E58292B , 0x7C68 , 0x497D , 0xA0 , 0xCE , 0x6500FD9F1B95 )) # # The EDKII Fault tolerant working block header. # The header is immediately followed by the write queue data. # # typedef struct { # EFI_GUID Signature; # UINT32 Crc; # UINT8 WorkingBlockValid : 1; # UINT8 WorkingBlockInvalid : 1; # UINT8 Reserved : 6; # UINT8 Reserved3[3]; # UINT64 WriteQueueSize; # } EFI_FAULT_TOLERANT_WORKING_BLOCK_HEADER; class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s \" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) # # EFI Fault tolerant block update write queue entry. # # typedef struct { # UINT8 HeaderAllocated : 1; # UINT8 WritesAllocated : 1; # UINT8 Complete : 1; # UINT8 Reserved : 5; # EFI_GUID CallerId; # UINT64 NumberOfWrites; # UINT64 PrivateDataSize; # } EFI_FAULT_TOLERANT_WRITE_HEADER; class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) # # EFI Fault tolerant block update write queue record. # # typedef struct { # UINT8 BootBlockUpdate : 1; # UINT8 SpareComplete : 1; # UINT8 DestinationComplete : 1; # UINT8 Reserved : 5; # EFI_LBA Lba; # UINT64 Offset; # UINT64 Length; # INT64 RelativeOffset; # } EFI_FAULT_TOLERANT_WRITE_RECORD; class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) Variables EdkiiWorkingBlockSignatureGuid Classes EfiFtwWorkingBlockHeader class EfiFtwWorkingBlockHeader ( ) View Source class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid: raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self serialize def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) EfiFtwWriteHeader class EfiFtwWriteHeader ( ) View Source class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self serialize def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) EfiFtwWriteRecord class EfiFtwWriteRecord ( ) View Source class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self serialize def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"Ftw working block format"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#module-edk2toollibuefiedk2ftw_working_block_format","text":"View Source # @file # Module contains helper classes for working with Fault Tolerant Working block content # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import struct import uuid import sys # # UEFI GUIDs # EdkiiWorkingBlockSignatureGuid = uuid . UUID ( fields = ( 0x9E58292B , 0x7C68 , 0x497D , 0xA0 , 0xCE , 0x6500FD9F1B95 )) # # The EDKII Fault tolerant working block header. # The header is immediately followed by the write queue data. # # typedef struct { # EFI_GUID Signature; # UINT32 Crc; # UINT8 WorkingBlockValid : 1; # UINT8 WorkingBlockInvalid : 1; # UINT8 Reserved : 6; # UINT8 Reserved3[3]; # UINT64 WriteQueueSize; # } EFI_FAULT_TOLERANT_WORKING_BLOCK_HEADER; class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s \" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) # # EFI Fault tolerant block update write queue entry. # # typedef struct { # UINT8 HeaderAllocated : 1; # UINT8 WritesAllocated : 1; # UINT8 Complete : 1; # UINT8 Reserved : 5; # EFI_GUID CallerId; # UINT64 NumberOfWrites; # UINT64 PrivateDataSize; # } EFI_FAULT_TOLERANT_WRITE_HEADER; class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) # # EFI Fault tolerant block update write queue record. # # typedef struct { # UINT8 BootBlockUpdate : 1; # UINT8 SpareComplete : 1; # UINT8 DestinationComplete : 1; # UINT8 Reserved : 5; # EFI_LBA Lba; # UINT64 Offset; # UINT64 Length; # INT64 RelativeOffset; # } EFI_FAULT_TOLERANT_WRITE_RECORD; class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"Module edk2toollib.uefi.edk2.ftw_working_block_format"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#variables","text":"EdkiiWorkingBlockSignatureGuid","title":"Variables"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwworkingblockheader","text":"class EfiFtwWorkingBlockHeader ( ) View Source class EfiFtwWorkingBlockHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBBBQ\" self . Signature = None self . Crc = None self . WorkingBlockValidFields = None self . Reserved1 = None self . Reserved2 = None self . Reserved3 = None self . WriteQueueSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid: raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize )","title":"EfiFtwWorkingBlockHeader"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check that signature is valid if self . Signature != EdkiiWorkingBlockSignatureGuid : raise Exception ( \"FTW Working Block Header has unknown signature: %s\" % self . Signature ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize","text":"def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Crc , self . WorkingBlockValidFields , self . Reserved1 , self . Reserved2 , self . Reserved3 , self . WriteQueueSize )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwwriteheader","text":"class EfiFtwWriteHeader ( ) View Source class EfiFtwWriteHeader ( object ): def __init__ ( self ): self . StructString = \"=BBBB16sLQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . CallerId = None self . ReservedUint32 = None self . NumberOfWrites = None self . PrivateDataSize = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize )","title":"EfiFtwWriteHeader"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize_1","text":"def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . CallerId , self . ReservedUint32 , self . NumberOfWrites , self . PrivateDataSize )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#efiftwwriterecord","text":"class EfiFtwWriteRecord ( ) View Source class EfiFtwWriteRecord ( object ): def __init__ ( self ): self . StructString = \"=BBBBLQQQQ\" self . StatusBits = None self . ReservedByte1 = None self . ReservedByte2 = None self . ReservedByte3 = None self . ReservedUint32 = None self . Lba = None self . Offset = None self . Length = None self . RelativeOffset = None def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"EfiFtwWriteRecord"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#load_from_file_2","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset ) = struct . unpack ( self . StructString , struct_bytes ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/ftw_working_block_format/#serialize_2","text":"def serialize ( self ) View Source def serialize ( self ): return struct . pack ( self . StructString , self . StatusBits , self . ReservedByte1 , self . ReservedByte2 , self . ReservedByte3 , self . ReservedUint32 , self . Lba , self . Offset , self . Length , self . RelativeOffset )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/path_utilities/","text":"Module edk2toollib.uefi.edk2.path_utilities View Source # @file path_utilities.py # Code to help convert Edk2, absolute, and relative file paths # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import fnmatch # # Class to help convert from absolute path to EDK2 build path # using workspace and packagepath variables # class Edk2Path ( object ): # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path. Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ): self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )): self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )): self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )): self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )): self . PackagePathList . append ( wsr ) else : # assume current working dir relative. Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )): self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ): raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower () . partition ( a . lower ())[ 2 ] if stripped : # found our path...now lets correct for case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s \" % ( abspath , a )) break if ( not found ): # try to strip the workspace stripped = abspath . lower () . partition ( self . WorkspacePath . lower ())[ 2 ] if stripped : # found our path...now lets correct for case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s \" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn't find the path for conversion. self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s \" % abspath ) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s \" % relpath ) return None # Find the package this path belongs to using # some Heuristic. This isn't perfect but at least # identifies the directory consistently # # @param InputPath: absolute path to module # # @ret Name of Package that the module is in. def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s \" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ): # # if at the root of a packagepath return the previous dir. # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s \" % a ) return a # # if at the root of the workspace return the previous dir. # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s \" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f , '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s . Pkg is: %s \" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s \" % InputPath ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None Classes Edk2Path class Edk2Path ( ws , packagepathlist ) View Source class Edk2Path ( object ) : # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path . Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ) : self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )) : self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )) : self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )) : self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )) : self . PackagePathList . append ( wsr ) else : # assume current working dir relative . Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )) : self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ) : raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) : relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower (). partition ( a . lower ()) [ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len(a): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ) : # try to strip the workspace stripped = abspath . lower (). partition ( self . WorkspacePath . lower ()) [ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len(self.WorkspacePath): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ) : relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn 't find the path for conversion. self.logger.error(\"Failed to convert AbsPath to Edk2Relative Path\") self.logger.error(\"AbsolutePath: %s\" % abspath) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath(self, relpath): if relpath is None: return None relpath = relpath.replace(\"/\", os.sep) abspath = os.path.join(self.WorkspacePath, relpath) if os.path.exists(abspath): return abspath for a in self.PackagePathList: abspath = os.path.join(a, relpath) if(os.path.exists(abspath)): return abspath self.logger.error(\"Failed to convert Edk2Relative Path to an Absolute Path on this system.\") self.logger.error(\"Relative Path: %s\" % relpath) return None # Find the package this path belongs to using # some Heuristic. This isn' t perfect but at least # identifies the directory consistently # # @param InputPath : absolute path to module # # @ret Name of Package that the module is in . def GetContainingPackage ( self , InputPath ) : self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ) : # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f , '*.dec' ) : a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None Methods GetAbsolutePathOnThisSytemFromEdk2RelativePath def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ) View Source def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s\" % relpath ) return None GetContainingPackage def GetContainingPackage ( self , InputPath ) View Source def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ): # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f , '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None GetEdk2RelativePathFromAbsolutePath def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) View Source def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower (). partition ( a . lower ())[ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ): # try to strip the workspace stripped = abspath . lower (). partition ( self . WorkspacePath . lower ())[ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn ' t find the path for conversion . self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s\" % abspath ) return None","title":"Path utilities"},{"location":"edk2toollib/uefi/edk2/path_utilities/#module-edk2toollibuefiedk2path_utilities","text":"View Source # @file path_utilities.py # Code to help convert Edk2, absolute, and relative file paths # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import fnmatch # # Class to help convert from absolute path to EDK2 build path # using workspace and packagepath variables # class Edk2Path ( object ): # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path. Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ): self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )): self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )): self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )): self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )): self . PackagePathList . append ( wsr ) else : # assume current working dir relative. Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )): self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ): raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower () . partition ( a . lower ())[ 2 ] if stripped : # found our path...now lets correct for case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s \" % ( abspath , a )) break if ( not found ): # try to strip the workspace stripped = abspath . lower () . partition ( self . WorkspacePath . lower ())[ 2 ] if stripped : # found our path...now lets correct for case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s \" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn't find the path for conversion. self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s \" % abspath ) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s \" % relpath ) return None # Find the package this path belongs to using # some Heuristic. This isn't perfect but at least # identifies the directory consistently # # @param InputPath: absolute path to module # # @ret Name of Package that the module is in. def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s \" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ): # # if at the root of a packagepath return the previous dir. # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s \" % a ) return a # # if at the root of the workspace return the previous dir. # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s \" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f , '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s . Pkg is: %s \" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s \" % InputPath ) self . logger . info ( \"PackagePath is: %s \" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s \" % self . WorkspacePath ) return None","title":"Module edk2toollib.uefi.edk2.path_utilities"},{"location":"edk2toollib/uefi/edk2/path_utilities/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/path_utilities/#edk2path","text":"class Edk2Path ( ws , packagepathlist ) View Source class Edk2Path ( object ) : # # ws - absolute path or cwd relative to workspace # packagepathlist - list of packages path . Absolute path list or workspace relative path # def __init__ ( self , ws , packagepathlist ) : self . WorkspacePath = ws self . logger = logging . getLogger ( \"Edk2Path\" ) if ( not os . path . isabs ( ws )) : self . WorkspacePath = os . path . abspath ( os . path . join ( os . getcwd (), ws )) if ( not os . path . isdir ( self . WorkspacePath )) : self . logger . error ( \"Workspace path invalid. {0}\" . format ( ws )) raise Exception ( \"Workspace path invalid. {0}\" . format ( ws )) # Set PackagePath self . PackagePathList = list () for a in packagepathlist : if ( os . path . isabs ( a )) : self . PackagePathList . append ( a ) else : # see if workspace relative wsr = os . path . join ( ws , a ) if ( os . path . isdir ( wsr )) : self . PackagePathList . append ( wsr ) else : # assume current working dir relative . Will catch invalid dir when checking whole list self . PackagePathList . append ( os . path . abspath ( os . path . join ( os . getcwd (), a ))) error = False for a in self . PackagePathList : if ( not os . path . isdir ( a )) : self . logger . error ( \"Invalid package path entry {0}\" . format ( a )) error = True # report error if ( error ) : raise Exception ( \"Invalid package path directory(s)\" ) def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) : relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower (). partition ( a . lower ()) [ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len(a): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ) : # try to strip the workspace stripped = abspath . lower (). partition ( self . WorkspacePath . lower ()) [ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len(self.WorkspacePath): ] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ) : relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn 't find the path for conversion. self.logger.error(\"Failed to convert AbsPath to Edk2Relative Path\") self.logger.error(\"AbsolutePath: %s\" % abspath) return None def GetAbsolutePathOnThisSytemFromEdk2RelativePath(self, relpath): if relpath is None: return None relpath = relpath.replace(\"/\", os.sep) abspath = os.path.join(self.WorkspacePath, relpath) if os.path.exists(abspath): return abspath for a in self.PackagePathList: abspath = os.path.join(a, relpath) if(os.path.exists(abspath)): return abspath self.logger.error(\"Failed to convert Edk2Relative Path to an Absolute Path on this system.\") self.logger.error(\"Relative Path: %s\" % relpath) return None # Find the package this path belongs to using # some Heuristic. This isn' t perfect but at least # identifies the directory consistently # # @param InputPath : absolute path to module # # @ret Name of Package that the module is in . def GetContainingPackage ( self , InputPath ) : self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ) : # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ) : a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ) : if fnmatch . fnmatch ( f , '*.dec' ) : a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None","title":"Edk2Path"},{"location":"edk2toollib/uefi/edk2/path_utilities/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getabsolutepathonthissytemfromedk2relativepath","text":"def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ) View Source def GetAbsolutePathOnThisSytemFromEdk2RelativePath ( self , relpath ): if relpath is None : return None relpath = relpath . replace ( \"/\" , os . sep ) abspath = os . path . join ( self . WorkspacePath , relpath ) if os . path . exists ( abspath ): return abspath for a in self . PackagePathList : abspath = os . path . join ( a , relpath ) if ( os . path . exists ( abspath )): return abspath self . logger . error ( \"Failed to convert Edk2Relative Path to an Absolute Path on this system.\" ) self . logger . error ( \"Relative Path: %s\" % relpath ) return None","title":"GetAbsolutePathOnThisSytemFromEdk2RelativePath"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getcontainingpackage","text":"def GetContainingPackage ( self , InputPath ) View Source def GetContainingPackage ( self , InputPath ): self . logger . debug ( \"GetContainingPackage: %s\" % InputPath ) dirpathprevious = os . path . dirname ( InputPath ) dirpath = os . path . dirname ( InputPath ) while ( dirpath is not None ): # # if at the root of a packagepath return the previous dir . # this catches cases where a package has no DEC # if ( dirpath in self . PackagePathList ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Package Path. Using previous directory: %s\" % a ) return a # # if at the root of the workspace return the previous dir . # this catches cases where a package has no DEC # if ( dirpath == self . WorkspacePath ): a = os . path . basename ( dirpathprevious ) self . logger . debug ( \"Reached Workspace Path. Using previous directory: %s\" % a ) return a # # Check for a DEC file in this folder # if here then return the directory name as the \"package\" # for f in os . listdir ( dirpath ): if fnmatch . fnmatch ( f , '*.dec' ): a = os . path . basename ( dirpath ) self . logger . debug ( \"Found DEC file at %s. Pkg is: %s\" , dirpath , a ) return a dirpathprevious = dirpath dirpath = os . path . dirname ( dirpath ) self . logger . error ( \"Failed to find containing package for %s\" % InputPath ) self . logger . info ( \"PackagePath is: %s\" % os . pathsep . join ( self . PackagePathList )) self . logger . info ( \"Workspace path is : %s\" % self . WorkspacePath ) return None","title":"GetContainingPackage"},{"location":"edk2toollib/uefi/edk2/path_utilities/#getedk2relativepathfromabsolutepath","text":"def GetEdk2RelativePathFromAbsolutePath ( self , abspath ) View Source def GetEdk2RelativePathFromAbsolutePath ( self , abspath ): relpath = None found = False if abspath is None : return None for a in self . PackagePathList : stripped = abspath . lower (). partition ( a . lower ())[ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len ( a ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using PackagePath\" ) self . logger . debug ( \"AbsolutePath: %s found in PackagePath: %s\" % ( abspath , a )) break if ( not found ): # try to strip the workspace stripped = abspath . lower (). partition ( self . WorkspacePath . lower ())[ 2 ] if stripped : # found our path ... now lets correct for case relpath = abspath [ len ( self . WorkspacePath ):] found = True self . logger . debug ( \"Successfully converted AbsPath to Edk2Relative Path using WorkspacePath\" ) self . logger . debug ( \"AbsolutePath: %s found in Workspace: %s\" % ( abspath , self . WorkspacePath )) if ( found ): relpath = relpath . replace ( os . sep , \"/\" ) return relpath . lstrip ( \"/\" ) # didn ' t find the path for conversion . self . logger . error ( \"Failed to convert AbsPath to Edk2Relative Path\" ) self . logger . error ( \"AbsolutePath: %s\" % abspath ) return None","title":"GetEdk2RelativePathFromAbsolutePath"},{"location":"edk2toollib/uefi/edk2/variable_format/","text":"Module edk2toollib.uefi.edk2.variable_format View Source # @file variable_format . py # Module contains helper classes and functions to work with UEFI Variables . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import uuid import struct import sys import edk2toollib . uefi . uefi_multi_phase as ump # # UEFI GUIDs # EfiVariableGuid = uuid . UUID ( fields= ( 0xDDCF3616 , 0x3275 , 0x4164 , 0x98 , 0xB6 , 0xFE85707FFE7D )) EfiAuthenticatedVariableGuid = uuid . UUID ( fields= ( 0xAAF32C78 , 0x947B , 0x439A , 0xA1 , 0x80 , 0x2E144EC37792 )) # # UEFI # Defines # HEADER_ALIGNMENT = 4 VARIABLE_STORE_FORMATTED = 0x5A VARIABLE_STORE_HEALTHY = 0xFE VARIABLE_DATA = 0x55AA VAR_IN_DELETED_TRANSITION = 0xFE # Variable is in obsolete transition . VAR_DELETED = 0xFD # Variable is obsolete . VAR_HEADER_VALID_ONLY = 0x7F # Variable header has been valid . VAR_ADDED = 0x3F # Variable has been completely added . # # VARIABLE_STORE_HEADER # Can parse or produce an VARIABLE_STORE_HEADER structure / byte buffer . # # typedef struct { # EFI_GUID Signature ; # UINT32 Size ; # UINT8 Format ; # UINT8 State ; # UINT16 Reserved ; # UINT32 Reserved1 ; # } VARIABLE_STORE_HEADER ; class VariableStoreHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=16sLBBHL\" self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature ! = EfiVariableGuid and self . Signature ! = EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self.Signature) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self def serialize ( self ) : signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) # # TODO : VariableHeader and AuthenticatedVariableHeader are not truly # header structures . They 're entire variables. This code should be # cleaned up. # # # VARIABLE_HEADER # Can parse or produce an VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } VARIABLE_HEADER; class VariableHeader(object): def __init__(self): self.StructString = \"=HBBLLL16s\" self.StructSize = struct.calcsize(self.StructString) self.StartId = VARIABLE_DATA self.State = VAR_ADDED self.Attributes = (ump.EFI_VARIABLE_NON_VOLATILE | ump.EFI_VARIABLE_BOOTSERVICE_ACCESS) self.NameSize = 0 self.DataSize = 0 self.VendorGuid = uuid.uuid4() self.Name = None self.Data = None def populate_structure_fields(self, in_bytes): (self.StartId, self.State, reserved, self.Attributes, self.NameSize, self.DataSize, self.VendorGuid) = struct.unpack(self.StructString, in_bytes) def load_from_bytes(self, in_bytes): # Load this object with the contents of the data. self.populate_structure_fields(in_bytes[0:self.StructSize]) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: raise EOFError(\"No variable data!\") # Finally, load the data. data_offset = self.StructSize self.Name = in_bytes[data_offset:(data_offset + self.NameSize)].decode('utf - 16 ') self.Name = self.Name[:-1] # Strip the terminating char. data_offset += self.NameSize self.Data = in_bytes[data_offset:(data_offset + self.DataSize)] return self def load_from_file(self, file): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file.tell() struct_bytes = file.read(struct.calcsize(self.StructString)) # Load this object with the contents of the data. self.populate_structure_fields(struct_bytes) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: file.seek(orig_seek) raise EOFError(\"No variable data!\") # Finally, load the data. self.Name = file.read(self.NameSize).decode('utf - 16 ')[:-1] # Strip the terminating char. self.Data = file.read(self.DataSize) file.seek(orig_seek) return self def get_buffer_data_size(self): return self.StructSize + self.NameSize + self.DataSize def get_buffer_padding_size(self): buffer_data_size = self.get_buffer_data_size() padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - (buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size(self): return self.get_buffer_data_size() + self.get_buffer_padding_size() def get_packed_name(self): # Make sure to replace the terminating char. # name_bytes = b\"\\x00\".join([char for char in (self.Name + b'\\x00')]) name_bytes = self.Name.encode('utf - 16 ') # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type. UEFI does not use this. name_bytes = name_bytes[2:] # Python encode skips the terminating character, so let's add that . name_bytes += b \"\\x00\\x00\" return name_bytes def set_name ( self , new_name ) : self . Name = new_name self . NameSize = len ( self . get_packed_name ()) def set_data ( self , new_data ) : self . Data = new_data self . DataSize = len ( new_data ) def pack_struct ( self ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self.get_buffer_padding_size() return bytes # # AUTHENTICATED_VARIABLE_HEADER # Can parse or produce an AUTHENTICATED_VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT64 MonotonicCount; # EFI_TIME TimeStamp; # UINT32 PubKeyIndex; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } AUTHENTICATED_VARIABLE_HEADER; class AuthenticatedVariableHeader(VariableHeader): def __init__(self): super(AuthenticatedVariableHeader, self).__init__() self.StructString = \" = HBBLQ16sLLL16s \" self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) if __ name__ == '__main__': pass Variables EfiAuthenticatedVariableGuid EfiVariableGuid HEADER_ALIGNMENT VARIABLE_DATA VARIABLE_STORE_FORMATTED VARIABLE_STORE_HEALTHY VAR_ADDED VAR_DELETED VAR_HEADER_VALID_ONLY VAR_IN_DELETED_TRANSITION Classes AuthenticatedVariableHeader class AuthenticatedVariableHeader ( ) View Source class AuthenticatedVariableHeader ( VariableHeader ): def __init__ ( self ): super ( AuthenticatedVariableHeader , self ). __init__ () self . StructString = \"=HBBLQ16sLLL16s\" self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) Ancestors (in MRO) edk2toollib.uefi.edk2.variable_format.VariableHeader Methods get_buffer_data_size def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize get_buffer_padding_size def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size get_buffer_size def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size () get_packed_name def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes load_from_bytes def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self pack_struct def pack_struct ( self , with_padding = False ) View Source def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) populate_structure_fields def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) serialize def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes set_data def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data ) set_name def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ()) VariableHeader class VariableHeader ( ) View Source class VariableHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=HBBLLL16s\" self . StructSize = struct . calcsize ( self . StructString ) self . StartId = VARIABLE_DATA self . State = VAR_ADDED self . Attributes = ( ump . EFI_VARIABLE_NON_VOLATILE | ump . EFI_VARIABLE_BOOTSERVICE_ACCESS ) self . NameSize = 0 self . DataSize = 0 self . VendorGuid = uuid . uuid4 () self . Name = None self . Data = None def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self def get_buffer_data_size ( self ) : return self . StructSize + self . NameSize + self . DataSize def get_buffer_padding_size ( self ) : buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size ( self ) : return self . get_buffer_data_size () + self . get_buffer_padding_size () def get_packed_name ( self ) : # Make sure to replace the terminating char . # name_bytes = b \" \\x00 \" . join ([ char for char in ( self . Name + b'\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 : ] # Python encode skips the terminating character , so let's add that. name_bytes += b\"\\x00\\x00\" return name_bytes def set_name(self, new_name): self.Name = new_name self.NameSize = len(self.get_packed_name()) def set_data(self, new_data): self.Data = new_data self.DataSize = len(new_data) def pack_struct(self): vendor_guid = self.VendorGuid.bytes if sys.byteorder == 'big ' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self . get_buffer_padding_size () return bytes Descendants edk2toollib.uefi.edk2.variable_format.AuthenticatedVariableHeader Methods get_buffer_data_size def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize get_buffer_padding_size def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size get_buffer_size def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size () get_packed_name def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes load_from_bytes def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self pack_struct def pack_struct ( self ) View Source def pack_struct ( self ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) populate_structure_fields def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) serialize def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes set_data def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data ) set_name def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ()) VariableStoreHeader class VariableStoreHeader ( ) View Source class VariableStoreHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBHL\" self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing. if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid: raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid: self . Type = 'AuthVar' return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) Methods load_from_file def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self serialize def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"Variable format"},{"location":"edk2toollib/uefi/edk2/variable_format/#module-edk2toollibuefiedk2variable_format","text":"View Source # @file variable_format . py # Module contains helper classes and functions to work with UEFI Variables . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import uuid import struct import sys import edk2toollib . uefi . uefi_multi_phase as ump # # UEFI GUIDs # EfiVariableGuid = uuid . UUID ( fields= ( 0xDDCF3616 , 0x3275 , 0x4164 , 0x98 , 0xB6 , 0xFE85707FFE7D )) EfiAuthenticatedVariableGuid = uuid . UUID ( fields= ( 0xAAF32C78 , 0x947B , 0x439A , 0xA1 , 0x80 , 0x2E144EC37792 )) # # UEFI # Defines # HEADER_ALIGNMENT = 4 VARIABLE_STORE_FORMATTED = 0x5A VARIABLE_STORE_HEALTHY = 0xFE VARIABLE_DATA = 0x55AA VAR_IN_DELETED_TRANSITION = 0xFE # Variable is in obsolete transition . VAR_DELETED = 0xFD # Variable is obsolete . VAR_HEADER_VALID_ONLY = 0x7F # Variable header has been valid . VAR_ADDED = 0x3F # Variable has been completely added . # # VARIABLE_STORE_HEADER # Can parse or produce an VARIABLE_STORE_HEADER structure / byte buffer . # # typedef struct { # EFI_GUID Signature ; # UINT32 Size ; # UINT8 Format ; # UINT8 State ; # UINT16 Reserved ; # UINT32 Reserved1 ; # } VARIABLE_STORE_HEADER ; class VariableStoreHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=16sLBBHL\" self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature ! = EfiVariableGuid and self . Signature ! = EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self.Signature) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self def serialize ( self ) : signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) # # TODO : VariableHeader and AuthenticatedVariableHeader are not truly # header structures . They 're entire variables. This code should be # cleaned up. # # # VARIABLE_HEADER # Can parse or produce an VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } VARIABLE_HEADER; class VariableHeader(object): def __init__(self): self.StructString = \"=HBBLLL16s\" self.StructSize = struct.calcsize(self.StructString) self.StartId = VARIABLE_DATA self.State = VAR_ADDED self.Attributes = (ump.EFI_VARIABLE_NON_VOLATILE | ump.EFI_VARIABLE_BOOTSERVICE_ACCESS) self.NameSize = 0 self.DataSize = 0 self.VendorGuid = uuid.uuid4() self.Name = None self.Data = None def populate_structure_fields(self, in_bytes): (self.StartId, self.State, reserved, self.Attributes, self.NameSize, self.DataSize, self.VendorGuid) = struct.unpack(self.StructString, in_bytes) def load_from_bytes(self, in_bytes): # Load this object with the contents of the data. self.populate_structure_fields(in_bytes[0:self.StructSize]) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: raise EOFError(\"No variable data!\") # Finally, load the data. data_offset = self.StructSize self.Name = in_bytes[data_offset:(data_offset + self.NameSize)].decode('utf - 16 ') self.Name = self.Name[:-1] # Strip the terminating char. data_offset += self.NameSize self.Data = in_bytes[data_offset:(data_offset + self.DataSize)] return self def load_from_file(self, file): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file.tell() struct_bytes = file.read(struct.calcsize(self.StructString)) # Load this object with the contents of the data. self.populate_structure_fields(struct_bytes) # Update the GUID to be a UUID object. if sys.byteorder == 'big': self.VendorGuid = uuid.UUID(bytes=self.VendorGuid) else: self.VendorGuid = uuid.UUID(bytes_le=self.VendorGuid) # Before loading data, make sure that this is a valid variable. if self.StartId != VARIABLE_DATA: file.seek(orig_seek) raise EOFError(\"No variable data!\") # Finally, load the data. self.Name = file.read(self.NameSize).decode('utf - 16 ')[:-1] # Strip the terminating char. self.Data = file.read(self.DataSize) file.seek(orig_seek) return self def get_buffer_data_size(self): return self.StructSize + self.NameSize + self.DataSize def get_buffer_padding_size(self): buffer_data_size = self.get_buffer_data_size() padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - (buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size(self): return self.get_buffer_data_size() + self.get_buffer_padding_size() def get_packed_name(self): # Make sure to replace the terminating char. # name_bytes = b\"\\x00\".join([char for char in (self.Name + b'\\x00')]) name_bytes = self.Name.encode('utf - 16 ') # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type. UEFI does not use this. name_bytes = name_bytes[2:] # Python encode skips the terminating character, so let's add that . name_bytes += b \"\\x00\\x00\" return name_bytes def set_name ( self , new_name ) : self . Name = new_name self . NameSize = len ( self . get_packed_name ()) def set_data ( self , new_data ) : self . Data = new_data self . DataSize = len ( new_data ) def pack_struct ( self ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self.get_buffer_padding_size() return bytes # # AUTHENTICATED_VARIABLE_HEADER # Can parse or produce an AUTHENTICATED_VARIABLE_HEADER structure/byte buffer. # # typedef struct { # UINT16 StartId; # UINT8 State; # UINT8 Reserved; # UINT32 Attributes; # UINT64 MonotonicCount; # EFI_TIME TimeStamp; # UINT32 PubKeyIndex; # UINT32 NameSize; # UINT32 DataSize; # EFI_GUID VendorGuid; # } AUTHENTICATED_VARIABLE_HEADER; class AuthenticatedVariableHeader(VariableHeader): def __init__(self): super(AuthenticatedVariableHeader, self).__init__() self.StructString = \" = HBBLQ16sLLL16s \" self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ) : vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid ) if __ name__ == '__main__': pass","title":"Module edk2toollib.uefi.edk2.variable_format"},{"location":"edk2toollib/uefi/edk2/variable_format/#variables","text":"EfiAuthenticatedVariableGuid EfiVariableGuid HEADER_ALIGNMENT VARIABLE_DATA VARIABLE_STORE_FORMATTED VARIABLE_STORE_HEALTHY VAR_ADDED VAR_DELETED VAR_HEADER_VALID_ONLY VAR_IN_DELETED_TRANSITION","title":"Variables"},{"location":"edk2toollib/uefi/edk2/variable_format/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/variable_format/#authenticatedvariableheader","text":"class AuthenticatedVariableHeader ( ) View Source class AuthenticatedVariableHeader ( VariableHeader ): def __init__ ( self ): super ( AuthenticatedVariableHeader , self ). __init__ () self . StructString = \"=HBBLQ16sLLL16s\" self . StructSize = struct . calcsize ( self . StructString ) self . MonotonicCount = 0 self . TimeStamp = b'' self . PubKeyIndex = 0 def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid )","title":"AuthenticatedVariableHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.variable_format.VariableHeader","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_data_size","text":"def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize","title":"get_buffer_data_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_padding_size","text":"def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size","title":"get_buffer_padding_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_size","text":"def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size ()","title":"get_buffer_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_packed_name","text":"def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes","title":"get_packed_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_bytes","text":"def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self","title":"load_from_bytes"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#pack_struct","text":"def pack_struct ( self , with_padding = False ) View Source def pack_struct ( self , with_padding = False ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , vendor_guid )","title":"pack_struct"},{"location":"edk2toollib/uefi/edk2/variable_format/#populate_structure_fields","text":"def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . MonotonicCount , self . TimeStamp , self . PubKeyIndex , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes )","title":"populate_structure_fields"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize","text":"def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_data","text":"def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data )","title":"set_data"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_name","text":"def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ())","title":"set_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#variableheader","text":"class VariableHeader ( ) View Source class VariableHeader ( object ) : def __ init__ ( self ) : self . StructString = \"=HBBLLL16s\" self . StructSize = struct . calcsize ( self . StructString ) self . StartId = VARIABLE_DATA self . State = VAR_ADDED self . Attributes = ( ump . EFI_VARIABLE_NON_VOLATILE | ump . EFI_VARIABLE_BOOTSERVICE_ACCESS ) self . NameSize = 0 self . DataSize = 0 self . VendorGuid = uuid . uuid4 () self . Name = None self . Data = None def populate_structure_fields ( self , in_bytes ) : ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes ) def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self def get_buffer_data_size ( self ) : return self . StructSize + self . NameSize + self . DataSize def get_buffer_padding_size ( self ) : buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0: padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT) return padding_size def get_buffer_size ( self ) : return self . get_buffer_data_size () + self . get_buffer_padding_size () def get_packed_name ( self ) : # Make sure to replace the terminating char . # name_bytes = b \" \\x00 \" . join ([ char for char in ( self . Name + b'\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 : ] # Python encode skips the terminating character , so let's add that. name_bytes += b\"\\x00\\x00\" return name_bytes def set_name(self, new_name): self.Name = new_name self.NameSize = len(self.get_packed_name()) def set_data(self, new_data): self.Data = new_data self.DataSize = len(new_data) def pack_struct(self): vendor_guid = self.VendorGuid.bytes if sys.byteorder == 'big ' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid ) def serialize ( self , with_padding = False ) : bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding: bytes += b \" \\xFF \" * self . get_buffer_padding_size () return bytes","title":"VariableHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#descendants","text":"edk2toollib.uefi.edk2.variable_format.AuthenticatedVariableHeader","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_data_size_1","text":"def get_buffer_data_size ( self ) View Source def get_buffer_data_size ( self ): return self . StructSize + self . NameSize + self . DataSize","title":"get_buffer_data_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_padding_size_1","text":"def get_buffer_padding_size ( self ) View Source def get_buffer_padding_size ( self ): buffer_data_size = self . get_buffer_data_size () padding_size = 0 if buffer_data_size % HEADER_ALIGNMENT != 0 : padding_size += HEADER_ALIGNMENT - ( buffer_data_size % HEADER_ALIGNMENT ) return padding_size","title":"get_buffer_padding_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_buffer_size_1","text":"def get_buffer_size ( self ) View Source def get_buffer_size ( self ): return self . get_buffer_data_size () + self . get_buffer_padding_size ()","title":"get_buffer_size"},{"location":"edk2toollib/uefi/edk2/variable_format/#get_packed_name_1","text":"def get_packed_name ( self ) View Source def get_packed_name ( self ): # Make sure to replace the terminating char . # name_bytes = b \"\\x00\" . join ([ char for char in ( self . Name + b '\\x00' )]) name_bytes = self . Name . encode ( 'utf-16' ) # Python encode will leave an \"0xFFFE\" on the front # to declare the encoding type . UEFI does not use this . name_bytes = name_bytes [ 2 :] # Python encode skips the terminating character , so let ' s add that . name_bytes += b \"\\x00\\x00\" return name_bytes","title":"get_packed_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_bytes_1","text":"def load_from_bytes ( self , in_bytes ) View Source def load_from_bytes ( self , in_bytes ) : # Load this object with the contents of the data . self . populate_structure_fields ( in_bytes [ 0 :self . StructSize ]) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : raise EOFError ( \"No variable data!\" ) # Finally , load the data . data_offset = self . StructSize self . Name = in_bytes [ data_offset: ( data_offset + self . NameSize )]. decode ( 'utf-16' ) self . Name = self . Name [:- 1 ] # Strip the terminating char . data_offset += self . NameSize self . Data = in_bytes [ data_offset: ( data_offset + self . DataSize )] return self","title":"load_from_bytes"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file_1","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ) : # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) # Load this object with the contents of the data . self . populate_structure_fields ( struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big': self . VendorGuid = uuid . UUID ( bytes = self . VendorGuid ) else : self . VendorGuid = uuid . UUID ( bytes_le = self . VendorGuid ) # Before loading data , make sure that this is a valid variable . if self . StartId ! = VARIABLE_DATA : file . seek ( orig_seek ) raise EOFError ( \"No variable data!\" ) # Finally , load the data . self . Name = file . read ( self . NameSize ). decode ( 'utf-16' )[:- 1 ] # Strip the terminating char . self . Data = file . read ( self . DataSize ) file . seek ( orig_seek ) return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#pack_struct_1","text":"def pack_struct ( self ) View Source def pack_struct ( self ): vendor_guid = self . VendorGuid . bytes if sys . byteorder == 'big' else self . VendorGuid . bytes_le return struct . pack ( self . StructString , self . StartId , self . State , 0 , self . Attributes , self . NameSize , self . DataSize , vendor_guid )","title":"pack_struct"},{"location":"edk2toollib/uefi/edk2/variable_format/#populate_structure_fields_1","text":"def populate_structure_fields ( self , in_bytes ) View Source def populate_structure_fields ( self , in_bytes ): ( self . StartId , self . State , reserved , self . Attributes , self . NameSize , self . DataSize , self . VendorGuid ) = struct . unpack ( self . StructString , in_bytes )","title":"populate_structure_fields"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize_1","text":"def serialize ( self , with_padding = False ) View Source def serialize ( self , with_padding = False ): bytes = self . pack_struct () # Now add the name and data . bytes += self . get_packed_name () bytes += self . Data # Add padding if necessary . if with_padding : bytes += b \"\\xFF\" * self . get_buffer_padding_size () return bytes","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_data_1","text":"def set_data ( self , new_data ) View Source def set_data ( self , new_data ): self . Data = new_data self . DataSize = len ( new_data )","title":"set_data"},{"location":"edk2toollib/uefi/edk2/variable_format/#set_name_1","text":"def set_name ( self , new_name ) View Source def set_name ( self , new_name ): self . Name = new_name self . NameSize = len ( self . get_packed_name ())","title":"set_name"},{"location":"edk2toollib/uefi/edk2/variable_format/#variablestoreheader","text":"class VariableStoreHeader ( ) View Source class VariableStoreHeader ( object ): def __init__ ( self ): self . StructString = \"=16sLBBHL\" self . StructSize = struct . calcsize ( self . StructString ) self . Signature = None self . Size = None self . Format = None self . State = None self . Reserved0 = None self . Reserved1 = None self . Type = 'Var' def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location. orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data. ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object. if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else: self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing. if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid: raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid: self . Type = 'AuthVar' return self def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"VariableStoreHeader"},{"location":"edk2toollib/uefi/edk2/variable_format/#methods_2","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variable_format/#load_from_file_2","text":"def load_from_file ( self , file ) View Source def load_from_file ( self , file ): # This function assumes that the file has been seeked # to the correct starting location . orig_seek = file . tell () struct_bytes = file . read ( struct . calcsize ( self . StructString )) file . seek ( orig_seek ) # Load this object with the contents of the data . ( signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 ) = struct . unpack ( self . StructString , struct_bytes ) # Update the GUID to be a UUID object . if sys . byteorder == 'big' : self . Signature = uuid . UUID ( bytes = signature_bin ) else : self . Signature = uuid . UUID ( bytes_le = signature_bin ) # Check one last thing . if self . Signature != EfiVariableGuid and self . Signature != EfiAuthenticatedVariableGuid : raise Exception ( \"VarStore is of unknown type! %s\" % self . Signature ) if self . Signature == EfiAuthenticatedVariableGuid : self . Type = 'AuthVar' return self","title":"load_from_file"},{"location":"edk2toollib/uefi/edk2/variable_format/#serialize_2","text":"def serialize ( self ) View Source def serialize ( self ): signature_bin = self . Signature . bytes if sys . byteorder == 'big' else self . Signature . bytes_le return struct . pack ( self . StructString , signature_bin , self . Size , self . Format , self . State , self . Reserved0 , self . Reserved1 )","title":"serialize"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/","text":"Module edk2toollib.uefi.edk2.variablestore_manulipulations View Source # @file # Contains classes and helper functions to modify variables in a UEFI ROM image. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.uefi.pi_firmware_volume as PiFV import edk2toollib.uefi.edk2.variable_format as VF import os import mmap class VariableStore ( object ): def __init__ ( self , romfile , store_base = None , store_size = None ): self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ): raise Exception ( \"' %s ' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things. file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ): raise Exception ( \"ROM file is %d bytes. Cannot seek to %d + %d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header. self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader () . load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d !\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header. self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader () . load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we're finally ready to read some variables. self . variables = [] self . rom_file . seek ( self . var_store_header . StructSize , os . SEEK_CUR ) try : while True : new_var = self . get_new_var_class () . load_from_file ( self . rom_file ) # Seek past the current variable in the store. self . rom_file . seek ( new_var . get_buffer_size (), os . SEEK_CUR ) # Add the variable to the array. self . variables . append ( new_var ) except EOFError : pass except : raise # Finally, reset the file cursor to the beginning of the VarStore FV. self . rom_file . seek ( self . store_base ) def __del__ ( self ): if self . rom_file_map is not None : self . rom_file_map . flush () self . rom_file_map . close () if self . rom_file is not None : self . rom_file . close () def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var def add_variable ( self , new_var ): self . variables . append ( new_var ) def flush_to_file ( self ): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header. dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d !\" % ( var_size , self . var_store_header . Size )) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header. self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b ' \\xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file. self . rom_file_map . flush () Classes VariableStore class VariableStore ( romfile , store_base = None , store_size = None ) View Source class VariableStore ( object ) : def __init__ ( self , romfile , store_base = None , store_size = None ) : self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ) : raise Exception ( \"'%s' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things . file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ) : raise Exception ( \"ROM file is %d bytes. Cannot seek to %d+%d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header . self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader (). load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d!\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header . self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader (). load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we 're finally ready to read some variables. self.variables = [] self.rom_file.seek(self.var_store_header.StructSize, os.SEEK_CUR) try: while True: new_var = self.get_new_var_class().load_from_file(self.rom_file) # Seek past the current variable in the store. self.rom_file.seek(new_var.get_buffer_size(), os.SEEK_CUR) # Add the variable to the array. self.variables.append(new_var) except EOFError: pass except: raise # Finally, reset the file cursor to the beginning of the VarStore FV. self.rom_file.seek(self.store_base) def __del__(self): if self.rom_file_map is not None: self.rom_file_map.flush() self.rom_file_map.close() if self.rom_file is not None: self.rom_file.close() def get_new_var_class(self): if self.var_store_header.Type == ' Var ': new_var = VF.VariableHeader() else: new_var = VF.AuthenticatedVariableHeader() return new_var def add_variable(self, new_var): self.variables.append(new_var) def flush_to_file(self): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum([var.get_buffer_size() for var in self.variables]) # Add the terminating var header. dummy_var = self.get_new_var_class() var_size += dummy_var.StructSize if var_size > self.var_store_header.Size: raise Exception(\"Total variable size %d is too large to fit in VarStore %d!\" % (var_size, self.var_store_header.Size)) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self.store_base + self.fv_header.HeaderLength + self.var_store_header.StructSize for var in self.variables: var_buffer_size = var.get_buffer_size() self.rom_file_map[var_offset:(var_offset + var_buffer_size)] = var.serialize(True) var_offset += var_buffer_size # Add a terminating Variable Header. self.rom_file_map[var_offset:(var_offset + dummy_var.StructSize)] = b' \\ xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush () Methods add_variable def add_variable ( self , new_var ) View Source def add_variable ( self , new_var ): self . variables . append ( new_var ) flush_to_file def flush_to_file ( self ) View Source def flush_to_file ( self ): # First , we need to make sure that our variables will fit in the VarStore . var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header . dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d!\" % ( var_size , self . var_store_header . Size )) # Now , we just have to serialize each variable in turn and write them to the mmap buffer . var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header . self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b '\\xFF' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush () get_new_var_class def get_new_var_class ( self ) View Source def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var","title":"Variablestore manulipulations"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#module-edk2toollibuefiedk2variablestore_manulipulations","text":"View Source # @file # Contains classes and helper functions to modify variables in a UEFI ROM image. # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import edk2toollib.uefi.pi_firmware_volume as PiFV import edk2toollib.uefi.edk2.variable_format as VF import os import mmap class VariableStore ( object ): def __init__ ( self , romfile , store_base = None , store_size = None ): self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ): raise Exception ( \"' %s ' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things. file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ): raise Exception ( \"ROM file is %d bytes. Cannot seek to %d + %d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header. self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader () . load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d !\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header. self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader () . load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we're finally ready to read some variables. self . variables = [] self . rom_file . seek ( self . var_store_header . StructSize , os . SEEK_CUR ) try : while True : new_var = self . get_new_var_class () . load_from_file ( self . rom_file ) # Seek past the current variable in the store. self . rom_file . seek ( new_var . get_buffer_size (), os . SEEK_CUR ) # Add the variable to the array. self . variables . append ( new_var ) except EOFError : pass except : raise # Finally, reset the file cursor to the beginning of the VarStore FV. self . rom_file . seek ( self . store_base ) def __del__ ( self ): if self . rom_file_map is not None : self . rom_file_map . flush () self . rom_file_map . close () if self . rom_file is not None : self . rom_file . close () def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var def add_variable ( self , new_var ): self . variables . append ( new_var ) def flush_to_file ( self ): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header. dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d !\" % ( var_size , self . var_store_header . Size )) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header. self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b ' \\xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file. self . rom_file_map . flush ()","title":"Module edk2toollib.uefi.edk2.variablestore_manulipulations"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#variablestore","text":"class VariableStore ( romfile , store_base = None , store_size = None ) View Source class VariableStore ( object ) : def __init__ ( self , romfile , store_base = None , store_size = None ) : self . rom_file_path = romfile self . store_base = store_base self . store_size = store_size self . rom_file = None self . rom_file_map = None if not os . path . isfile ( self . rom_file_path ) : raise Exception ( \"'%s' is not the path to a file!\" % self . rom_file_path ) self . rom_file = open ( self . rom_file_path , 'r+b' ) self . rom_file_map = mmap . mmap ( self . rom_file . fileno (), 0 ) # Sanity check some things . file_size = self . rom_file_map . size () if ( store_base is not None and store_size is not None and ( store_base + store_size ) > file_size ) : raise Exception ( \"ROM file is %d bytes. Cannot seek to %d+%d bytes!\" % ( file_size , store_base , store_size )) # Go ahead and advance the file cursor and load the FV header . self . rom_file . seek ( self . store_base ) self . fv_header = PiFV . EfiFirmwareVolumeHeader (). load_from_file ( self . rom_file ) if self . fv_header . FileSystemGuid != PiFV . EfiSystemNvDataFvGuid : raise Exception ( \"Store_base is not pointing at a valid SystemNvData FV!\" ) if self . fv_header . FvLength != self . store_size : raise Exception ( \"Store_size %d does not match FV size %d!\" % ( self . store_size , self . fv_header . FvLength )) # Advance the file cursor and load the VarStore header . self . rom_file . seek ( self . fv_header . HeaderLength , os . SEEK_CUR ) self . var_store_header = VF . VariableStoreHeader (). load_from_file ( self . rom_file ) if self . var_store_header . Format != VF . VARIABLE_STORE_FORMATTED or \\ self . var_store_header . State != VF . VARIABLE_STORE_HEALTHY : raise Exception ( \"VarStore is invalid or cannot be processed with this helper!\" ) # Now we 're finally ready to read some variables. self.variables = [] self.rom_file.seek(self.var_store_header.StructSize, os.SEEK_CUR) try: while True: new_var = self.get_new_var_class().load_from_file(self.rom_file) # Seek past the current variable in the store. self.rom_file.seek(new_var.get_buffer_size(), os.SEEK_CUR) # Add the variable to the array. self.variables.append(new_var) except EOFError: pass except: raise # Finally, reset the file cursor to the beginning of the VarStore FV. self.rom_file.seek(self.store_base) def __del__(self): if self.rom_file_map is not None: self.rom_file_map.flush() self.rom_file_map.close() if self.rom_file is not None: self.rom_file.close() def get_new_var_class(self): if self.var_store_header.Type == ' Var ': new_var = VF.VariableHeader() else: new_var = VF.AuthenticatedVariableHeader() return new_var def add_variable(self, new_var): self.variables.append(new_var) def flush_to_file(self): # First, we need to make sure that our variables will fit in the VarStore. var_size = sum([var.get_buffer_size() for var in self.variables]) # Add the terminating var header. dummy_var = self.get_new_var_class() var_size += dummy_var.StructSize if var_size > self.var_store_header.Size: raise Exception(\"Total variable size %d is too large to fit in VarStore %d!\" % (var_size, self.var_store_header.Size)) # Now, we just have to serialize each variable in turn and write them to the mmap buffer. var_offset = self.store_base + self.fv_header.HeaderLength + self.var_store_header.StructSize for var in self.variables: var_buffer_size = var.get_buffer_size() self.rom_file_map[var_offset:(var_offset + var_buffer_size)] = var.serialize(True) var_offset += var_buffer_size # Add a terminating Variable Header. self.rom_file_map[var_offset:(var_offset + dummy_var.StructSize)] = b' \\ xFF ' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush ()","title":"VariableStore"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#add_variable","text":"def add_variable ( self , new_var ) View Source def add_variable ( self , new_var ): self . variables . append ( new_var )","title":"add_variable"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#flush_to_file","text":"def flush_to_file ( self ) View Source def flush_to_file ( self ): # First , we need to make sure that our variables will fit in the VarStore . var_size = sum ([ var . get_buffer_size () for var in self . variables ]) # Add the terminating var header . dummy_var = self . get_new_var_class () var_size += dummy_var . StructSize if var_size > self . var_store_header . Size : raise Exception ( \"Total variable size %d is too large to fit in VarStore %d!\" % ( var_size , self . var_store_header . Size )) # Now , we just have to serialize each variable in turn and write them to the mmap buffer . var_offset = self . store_base + self . fv_header . HeaderLength + self . var_store_header . StructSize for var in self . variables : var_buffer_size = var . get_buffer_size () self . rom_file_map [ var_offset :( var_offset + var_buffer_size )] = var . serialize ( True ) var_offset += var_buffer_size # Add a terminating Variable Header . self . rom_file_map [ var_offset :( var_offset + dummy_var . StructSize )] = b '\\xFF' * dummy_var . StructSize # Now we have to flush the mmap to the file . self . rom_file_map . flush ()","title":"flush_to_file"},{"location":"edk2toollib/uefi/edk2/variablestore_manulipulations/#get_new_var_class","text":"def get_new_var_class ( self ) View Source def get_new_var_class ( self ): if self . var_store_header . Type == 'Var' : new_var = VF . VariableHeader () else : new_var = VF . AuthenticatedVariableHeader () return new_var","title":"get_new_var_class"},{"location":"edk2toollib/uefi/edk2/parsers/","text":"Module edk2toollib.uefi.edk2.parsers View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.uefi.edk2.parsers.base_parser edk2toollib.uefi.edk2.parsers.buildreport_parser edk2toollib.uefi.edk2.parsers.dec_parser edk2toollib.uefi.edk2.parsers.dsc_parser edk2toollib.uefi.edk2.parsers.fdf_parser edk2toollib.uefi.edk2.parsers.inf_parser edk2toollib.uefi.edk2.parsers.override_parser edk2toollib.uefi.edk2.parsers.override_parser_test edk2toollib.uefi.edk2.parsers.targettxt_parser","title":"Index"},{"location":"edk2toollib/uefi/edk2/parsers/#module-edk2toollibuefiedk2parsers","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.uefi.edk2.parsers"},{"location":"edk2toollib/uefi/edk2/parsers/#sub-modules","text":"edk2toollib.uefi.edk2.parsers.base_parser edk2toollib.uefi.edk2.parsers.buildreport_parser edk2toollib.uefi.edk2.parsers.dec_parser edk2toollib.uefi.edk2.parsers.dsc_parser edk2toollib.uefi.edk2.parsers.fdf_parser edk2toollib.uefi.edk2.parsers.inf_parser edk2toollib.uefi.edk2.parsers.override_parser edk2toollib.uefi.edk2.parsers.override_parser_test edk2toollib.uefi.edk2.parsers.targettxt_parser","title":"Sub-modules"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/","text":"Module edk2toollib.uefi.edk2.parsers.base_parser View Source # @file BaseParser.py # Code to support parsing EDK2 files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging class BaseParser ( object ): def __init__ ( self , log ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None # # For include files set the base root path # def SetBaseAbsPath ( self , path ): self . RootPath = path return self def SetPackagePaths ( self , pps = []): self . PPs = pps return self def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self def FindPath ( self , * p ): # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s \" % Path ) return Path def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s \" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \" \\n \" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) # # convert to int based on prefix # def ConvertToInt ( self , value ): if ( value . upper () . startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d \" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s \" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s \" % retoken ) if ( v is not None ): # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s \" % ( token , line )) # raise Exception(\"Invalid Variable Replacement\", token) # just skip it because we need to support ifdef else : # found in the Env # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ): # need to add support for OR/AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ] . strip (), tokens [ 2 ] . strip (), tokens [ 3 ] . strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ] . count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ] . count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ] . lower () == \"!endif\" ): self . PopConditional () return True return False # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret # # will return true if the the line has # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): # parse a guid in format # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # into F7FDE4A6-294C-493c-B50F-9734553BB757 (NOTE these are not same guid this is just example of format) entries = l . lstrip ( ' {' ) . rstrip ( ' }' ) . split ( ',' ) gu = entries [ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ] . lstrip ( ' { 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ] . split ()[ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . rstrip ( ' } ' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False # # Base Class for Edk2 build files that use # for comments # class HashFileParser ( BaseParser ): def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): return l . split ( '#' )[ 0 ] . strip () def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip () . lstrip ( \"[\" ) . split ( \".\" )[ 0 ] . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () self . CurrentFullSection = l . strip () . lstrip ( \"[\" ) . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () return ( True , section ) return ( False , \"\" ) Classes BaseParser class BaseParser ( log ) View Source class BaseParser ( object ): def __init__ ( self , log ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None # # For include files set the base root path # def SetBaseAbsPath ( self , path ): self . RootPath = path return self def SetPackagePaths ( self , pps =[]): self . PPs = pps return self def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self def FindPath ( self , * p ): # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None: Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs: Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines: f . write ( l + \"\\n\" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) # # convert to int based on prefix # def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else: return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else: self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start:end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else: # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception(\"Invalid Variable Replacement\", token) # just skip it because we need to support ifdef else: # found in the Env # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR/AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): ret = True for a in self . ConditionalStack: if not a: ret = False break return ret # # will return true if the the line has # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): # parse a guid in format # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # into F7FDE4A6-294C-493c-B50F-9734553BB757 (NOTE these are not same guid this is just example of format) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False Descendants edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close () HashFileParser class HashFileParser ( log ) View Source class HashFileParser ( BaseParser ): def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Descendants edk2toollib.uefi.edk2.parsers.dec_parser.DecParser edk2toollib.uefi.edk2.parsers.dsc_parser.DscParser edk2toollib.uefi.edk2.parsers.fdf_parser.FdfParser edk2toollib.uefi.edk2.parsers.inf_parser.InfParser edk2toollib.uefi.edk2.parsers.targettxt_parser.TargetTxtParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Base parser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#module-edk2toollibuefiedk2parsersbase_parser","text":"View Source # @file BaseParser.py # Code to support parsing EDK2 files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging class BaseParser ( object ): def __init__ ( self , log ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None # # For include files set the base root path # def SetBaseAbsPath ( self , path ): self . RootPath = path return self def SetPackagePaths ( self , pps = []): self . PPs = pps return self def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self def FindPath ( self , * p ): # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s \" % Path ) return Path def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s \" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \" \\n \" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) # # convert to int based on prefix # def ConvertToInt ( self , value ): if ( value . upper () . startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d \" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s \" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s \" % retoken ) if ( v is not None ): # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s \" % ( token , line )) # raise Exception(\"Invalid Variable Replacement\", token) # just skip it because we need to support ifdef else : # found in the Env # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ] . lower () == \"!if\" ): # need to add support for OR/AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ] . strip (), tokens [ 2 ] . strip (), tokens [ 3 ] . strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ] . lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ] . count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ] . lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ] . count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ] . lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ] . lower () == \"!endif\" ): self . PopConditional () return True return False # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret # # will return true if the the line has # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): # parse a guid in format # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # into F7FDE4A6-294C-493c-B50F-9734553BB757 (NOTE these are not same guid this is just example of format) entries = l . lstrip ( ' {' ) . rstrip ( ' }' ) . split ( ',' ) gu = entries [ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ] . lstrip ( ' { 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ] . split ()[ 0 ] . lstrip ( ' 0' ) . lstrip ( 'x' ) . rstrip ( ' } ' ) . strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False # # Base Class for Edk2 build files that use # for comments # class HashFileParser ( BaseParser ): def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): return l . split ( '#' )[ 0 ] . strip () def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip () . lstrip ( \"[\" ) . split ( \".\" )[ 0 ] . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () self . CurrentFullSection = l . strip () . lstrip ( \"[\" ) . split ( \",\" )[ 0 ] . rstrip ( \"]\" ) . strip () return ( True , section ) return ( False , \"\" )","title":"Module edk2toollib.uefi.edk2.parsers.base_parser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#baseparser","text":"class BaseParser ( log ) View Source class BaseParser ( object ): def __init__ ( self , log ): self . Logger = logging . getLogger ( log ) self . Lines = [] self . LocalVars = {} self . InputVars = {} self . CurrentSection = \"\" self . CurrentFullSection = \"\" self . Parsed = False self . ConditionalStack = [] self . RootPath = \"\" self . PPs = [] self . TargetFile = None self . TargetFilePath = None # # For include files set the base root path # def SetBaseAbsPath ( self , path ): self . RootPath = path return self def SetPackagePaths ( self , pps =[]): self . PPs = pps return self def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self def FindPath ( self , * p ): # NOTE: Some of this logic should be replaced # with the path resolution from Edk2Module code. # If the absolute path exists, return it. Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails, check a path relative to the target file. if self . TargetFilePath is not None: Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails, check in every possible Pkg path. for Pkg in self . PPs: Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines: f . write ( l + \"\\n\" ) f . close () # # do logical comparisons # def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) # # convert to int based on prefix # def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else: return int ( value , 10 ) # # Push new value on stack # def PushConditional ( self , v ): self . ConditionalStack . append ( v ) # # Pop conditional and return the value # def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else: self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace. # # Method to replace variables # in a line with their value from input dict or local dict # def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start:end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else: # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception(\"Invalid Variable Replacement\", token) # just skip it because we need to support ifdef else: # found in the Env # # fixme: This should just be a workaround!!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result # # Process Conditional # return true if line is a conditional otherwise false # def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR/AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False # # returns true or false depending on what state of conditional you are currently in # def InActiveCode ( self ): ret = True for a in self . ConditionalStack: if not a: ret = False break return ret # # will return true if the the line has # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False def ParseGuid ( self , l ): # parse a guid in format # { 0xD3B36F2C, 0xD551, 0x11D4, { 0x9A, 0x46, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D }} # into F7FDE4A6-294C-493c-B50F-9734553BB757 (NOTE these are not same guid this is just example of format) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"BaseParser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#descendants","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#hashfileparser","text":"class HashFileParser ( log ) View Source class HashFileParser ( BaseParser ): def __init__ ( self , log ): BaseParser . __init__ ( self , log ) def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"HashFileParser"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#descendants_1","text":"edk2toollib.uefi.edk2.parsers.dec_parser.DecParser edk2toollib.uefi.edk2.parsers.dsc_parser.DscParser edk2toollib.uefi.edk2.parsers.fdf_parser.FdfParser edk2toollib.uefi.edk2.parsers.inf_parser.InfParser edk2toollib.uefi.edk2.parsers.targettxt_parser.TargetTxtParser","title":"Descendants"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#computeresult_1","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#converttoint_1","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#findpath_1","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#inactivecode_1","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#isguidstring_1","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parseguid_1","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#popconditional_1","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#processconditional_1","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#pushconditional_1","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#replacevariables_1","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#resetparserstate_1","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setbaseabspath_1","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setinputvars_1","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#setpackagepaths_1","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/base_parser/#writelinestofile_1","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/","text":"Module edk2toollib.uefi.edk2.parsers.buildreport_parser View Source # @file buildreport_parser . py # Code to help parse an EDk2 Build Report # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import os import logging import edk2toollib . utility_functions as uf import edk2toollib . uefi . edk2 . path_utilities as pu # # Class to represent a module within the Build Report # class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise # # Class to parse and objectify the Build report so that # tools can interact with the Build Report . # This should simplify the Build Report based interactions # but should not contain tool specific logic or tests . # class BuildReport ( object ) : RegionTypes = uf . Enum ([ 'PCD' , 'FD' , 'MODULE' , 'UNKNOWN' ]) def __ init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ ReportContents = \"\" self . _ Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ ReportContents = [ x . strip () for x in f . readlines ()] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ ReportContents = [ x . replace ( k , v ) for x in self . _ ReportContents ] logging . debug ( \"Report File is: %s\" % self.ReportFile) logging . debug ( \"Input report had %d lines of content\" % len(self._ReportContents)) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(':') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FVDXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn't find new region return None # # Get the end of region # def _ GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ ReportContents )) : if self . _ ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number) # didn ' t find new region return None def _ GetRegionType ( self , lineNumber ) : line = self . _ ReportContents [ lineNumber ]. strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN Classes BuildReport class BuildReport ( filepath , ws , packagepathcsv , protectedWordsDict ) View Source class BuildReport ( object ) : RegionTypes = uf . Enum ( [ 'PCD', 'FD', 'MODULE', 'UNKNOWN' ] ) def __init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ReportContents = \"\" self . _Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' : ') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FVDXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn' t find new region return None # # Get the end of region # def _GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ReportContents )) : if self . _ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number ) # didn ' t find new region return None def _GetRegionType ( self , lineNumber ) : line = self . _ReportContents [ lineNumber ] . strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN Class variables RegionTypes Methods BasicParse def BasicParse ( self ) View Source def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' :' ) if ( line_partitioned [ 2 ] == \"\" ) : continue key = line_partitioned [ 0 ] . strip (). lower () value = line_partitioned [ 2 ] . strip () if ( key == \"platform name\" ) : self . PlatformName = value elif ( key == \"platform dsc path\" ) : self . DscPath = value elif ( key == \"output path\" ) : self . BuildOutputDir = value # # now for each module summary # parse it for r in self . _Regions : if ( r [ 0 ] == BuildReport . RegionTypes . MODULE ) : mod = ModuleSummary ( self . _ReportContents [ r[1 ] : r [ 2 ] ] , self . Workspace , self . PackagePathList ) mod . Parse () self . Modules [ mod.Guid ] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self . _Regions : # if FD region parse out all INFs in the all of the flash if ( r [ 0 ] == BuildReport . RegionTypes . FD ) : self . _ParseFdRegionForModules ( self . _ReportContents [ r[1 ] : r [ 2 ] ] ) FindComponentByInfPath def FindComponentByInfPath ( self , InfPath ) View Source def FindComponentByInfPath ( self , InfPath ): for ( k , v ) in self . Modules . items (): if ( v . InfPath . lower () == InfPath . lower ()): logging . debug ( \"Found Module by InfPath: %s\" % InfPath ) return v logging . error ( \"Failed to find Module by InfPath %s\" % InfPath ) return None ModuleSummary class ModuleSummary ( content , ws , packagepatahlist ) View Source class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise Methods Parse def Parse ( self ) View Source def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"Buildreport parser"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#module-edk2toollibuefiedk2parsersbuildreport_parser","text":"View Source # @file buildreport_parser . py # Code to help parse an EDk2 Build Report # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import os import logging import edk2toollib . utility_functions as uf import edk2toollib . uefi . edk2 . path_utilities as pu # # Class to represent a module within the Build Report # class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise # # Class to parse and objectify the Build report so that # tools can interact with the Build Report . # This should simplify the Build Report based interactions # but should not contain tool specific logic or tests . # class BuildReport ( object ) : RegionTypes = uf . Enum ([ 'PCD' , 'FD' , 'MODULE' , 'UNKNOWN' ]) def __ init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ ReportContents = \"\" self . _ Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ ReportContents = [ x . strip () for x in f . readlines ()] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ ReportContents = [ x . replace ( k , v ) for x in self . _ ReportContents ] logging . debug ( \"Report File is: %s\" % self.ReportFile) logging . debug ( \"Input report had %d lines of content\" % len(self._ReportContents)) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(':') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FVDXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn't find new region return None # # Get the end of region # def _ GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ ReportContents )) : if self . _ ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number) # didn ' t find new region return None def _ GetRegionType ( self , lineNumber ) : line = self . _ ReportContents [ lineNumber ]. strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN","title":"Module edk2toollib.uefi.edk2.parsers.buildreport_parser"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#buildreport","text":"class BuildReport ( filepath , ws , packagepathcsv , protectedWordsDict ) View Source class BuildReport ( object ) : RegionTypes = uf . Enum ( [ 'PCD', 'FD', 'MODULE', 'UNKNOWN' ] ) def __init__ ( self , filepath , ws , packagepathcsv , protectedWordsDict ) : self . PlatformName = \"\" self . DscPath = \"\" self . FdfPath = \"\" self . BuildOutputDir = \"\" self . ReportFile = filepath self . Modules = {} # fill this in with objects of ModuleSummary type self . _ReportContents = \"\" self . _Regions = [] # fill this in with tuple ( type , start , end ) self . Workspace = ws # needs to contain the trailing slash self . PackagePathList = [] for a in packagepathcsv . split ( \",\" ) : a = a . strip () if ( len ( a ) > 0 ) : self . PackagePathList . append ( a ) self . ProtectedWords = protectedWordsDict self . PathConverter = pu . Edk2Path ( self . Workspace , self . PackagePathList ) # # do region level parsing # to get the layout , lists , and dictionaries setup . # def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' : ') if(line_partitioned[2] == \"\"): continue key = line_partitioned[0].strip().lower() value = line_partitioned[2].strip() if(key == \"platform name\"): self.PlatformName = value elif(key == \"platform dsc path\"): self.DscPath = value elif(key == \"output path\"): self.BuildOutputDir = value # # now for each module summary # parse it for r in self._Regions: if(r[0] == BuildReport.RegionTypes.MODULE): mod = ModuleSummary(self._ReportContents[r[1]:r[2]], self.Workspace, self.PackagePathList) mod.Parse() self.Modules[mod.Guid] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self._Regions: # if FD region parse out all INFs in the all of the flash if(r[0] == BuildReport.RegionTypes.FD): self._ParseFdRegionForModules(self._ReportContents[r[1]:r[2]]) def FindComponentByInfPath(self, InfPath): for (k, v) in self.Modules.items(): if(v.InfPath.lower() == InfPath.lower()): logging.debug(\"Found Module by InfPath: %s\" % InfPath) return v logging.error(\"Failed to find Module by InfPath %s\" % InfPath) return None def _ParseFdRegionForModules(self, rawcontents): FvName = None index = 0 WorkspaceAndPPList = [self.Workspace] WorkspaceAndPPList.extend(self.PackagePathList) while index < len(rawcontents): a = rawcontents[index] tokens = a.split() if a.startswith(\"0x\") and (len(tokens) == 3) and (a.count(' ( ') == 1): if \".inf\" not in a.lower() or (a.count(' ( ') != a.count(\")\")): a = a + rawcontents[index + 1].strip() index += 1 tokens = a.split() i = a.split()[2].strip().strip(' () ') logging.debug(\"Found INF in FV Region: \" + i) # Take absolute path and convert to EDK build path RelativePath = self.PathConverter.GetEdk2RelativePathFromAbsolutePath(i) if(RelativePath is not None): comp = self.FindComponentByInfPath(RelativePath) if comp is not None: comp.FvName = FvName else: logging.error(\"Failed to find component for INF path %a\" % RelativePath) elif a.startswith(\"Fv Name:\"): # Fv Name: FVDXE (99.5% Full) FvName = a.partition(\":\")[2].strip().split()[0] logging.debug(\"Found FvName. RAW: %s Name: %s\" % (a, FvName)) else: logging.debug(\"ignored line in FD parsing: %s\" % a) index += 1 return # # Get the start of region # def _GetNextRegionStart(self, number): lineNumber = number while(lineNumber < len(self._ReportContents)): if self._ReportContents[lineNumber] == \">======================================================================================================================<\": # noqa: E501 return lineNumber + 1 lineNumber += 1 logging.debug(\"Failed to find a Start Next Region after lineNumber: %d\" % number) # didn' t find new region return None # # Get the end of region # def _GetEndOfRegion ( self , number ) : lineNumber = number while ( lineNumber < len ( self . _ReportContents )) : if self . _ReportContents [ lineNumber ] == \"<======================================================================================================================>\" : # noqa : E501 return lineNumber - 1 lineNumber += 1 logging . debug ( \"Failed to find a End Region after lineNumber: %d\" % number ) # didn ' t find new region return None def _GetRegionType ( self , lineNumber ) : line = self . _ReportContents [ lineNumber ] . strip () if ( line == \"Firmware Device (FD)\" ) : return BuildReport . RegionTypes . FD elif ( line == \"Platform Configuration Database Report\" ) : return BuildReport . RegionTypes . PCD elif ( line == \"Module Summary\" ) : return BuildReport . RegionTypes . MODULE else : return BuildReport . RegionTypes . UNKNOWN","title":"BuildReport"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#class-variables","text":"RegionTypes","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#basicparse","text":"def BasicParse ( self ) View Source def BasicParse ( self ) : if ( not os . path . isfile ( self . ReportFile )) : raise Exception ( \"Report File path invalid!\" ) # read report f = open ( self . ReportFile , \"r\" ) self . _ReportContents = [ x.strip() for x in f.readlines() ] f . close () # # replace protected words # for ( k , v ) in self . ProtectedWords . items () : self . _ReportContents = [ x.replace(k, v) for x in self._ReportContents ] logging . debug ( \"Report File is: %s\" % self . ReportFile ) logging . debug ( \"Input report had %d lines of content\" % len ( self . _ReportContents )) # # parse thru and find the regions and basic info at top # this is a little hacky in that internal operations could # fail but it doesn 't seem critical # linenum = self._GetNextRegionStart(0) while(linenum is not None): start = linenum end = self._GetEndOfRegion(start) type = self._GetRegionType(start) self._Regions.append((type, start, end)) linenum = self._GetNextRegionStart(linenum) logging.debug(\"Found a region of type: %s start: %d end: %d\" % (BuildReport.RegionTypes[type], start, end)) # # Parse the basic header of the report. # we do it after parsing region because we # can limit scope to 0 - first start # for n in range(0, self._Regions[0][1]): # loop thru from 0 to start of first region line = self._ReportContents[n].strip() line_partitioned = line.partition(' :' ) if ( line_partitioned [ 2 ] == \"\" ) : continue key = line_partitioned [ 0 ] . strip (). lower () value = line_partitioned [ 2 ] . strip () if ( key == \"platform name\" ) : self . PlatformName = value elif ( key == \"platform dsc path\" ) : self . DscPath = value elif ( key == \"output path\" ) : self . BuildOutputDir = value # # now for each module summary # parse it for r in self . _Regions : if ( r [ 0 ] == BuildReport . RegionTypes . MODULE ) : mod = ModuleSummary ( self . _ReportContents [ r[1 ] : r [ 2 ] ] , self . Workspace , self . PackagePathList ) mod . Parse () self . Modules [ mod.Guid ] = mod # now that all modules are parsed lets parse the FD region so we can get the FV name for each module for r in self . _Regions : # if FD region parse out all INFs in the all of the flash if ( r [ 0 ] == BuildReport . RegionTypes . FD ) : self . _ParseFdRegionForModules ( self . _ReportContents [ r[1 ] : r [ 2 ] ] )","title":"BasicParse"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#findcomponentbyinfpath","text":"def FindComponentByInfPath ( self , InfPath ) View Source def FindComponentByInfPath ( self , InfPath ): for ( k , v ) in self . Modules . items (): if ( v . InfPath . lower () == InfPath . lower ()): logging . debug ( \"Found Module by InfPath: %s\" % InfPath ) return v logging . error ( \"Failed to find Module by InfPath %s\" % InfPath ) return None","title":"FindComponentByInfPath"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#modulesummary","text":"class ModuleSummary ( content , ws , packagepatahlist ) View Source class ModuleSummary ( object ) : def __ init__ ( self , content , ws , packagepatahlist ) : self . _ RawContent = content self . Guid = \"\" self . Name = \"\" self . InfPath = \"\" self . Type = \"\" self . PCDs = {} self . Libraries = {} self . Depex = \"\" self . WorkspacePath = ws self . PackagePathList = packagepatahlist self . FvName = None def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"ModuleSummary"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#methods_1","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/buildreport_parser/#parse","text":"def Parse ( self ) View Source def Parse ( self ) : inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False tokenspace = \"\" pathConverter = pu . Edk2Path ( self . WorkspacePath , self . PackagePathList ) i = 0 try : while i < len ( self . _ RawContent ) : line = self . _ RawContent [ i ]. strip () # parse start and end if line == \">----------------------------------------------------------------------------------------------------------------------<\" : # noqa : E501 nextLineSection = True elif line == \"<---------------------------------------------------------------------------------------------------------------------->\" : # noqa : E501 inPcdSection = False inLibSection = False inDepSection = False nextLineSection = False # parse section header elif ( nextLineSection ) : nextLineSection = False if ( line == \"Library\" ) : inLibSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"PCD\" ) : inPcdSection = True i += 1 # add additional line to skip the dashed line elif ( line == \"Final Dependency Expression (DEPEX) Instructions\" ) : inDepSection = True i += 1 # add additional line to skip the dashed line else : logging . debug ( \"Unsupported Section: \" + line ) inPcdSection = False inLibSection = False inDepSection = False # Normal section parsing else : if ( inLibSection ) : logging . debug ( \"InLibSection: %s\" % line) # get the whole statement library class statement templine = line . strip () while ( '}' not in templine ) : i += 1 templine += self . _ RawContent [ i ]. strip () # have good complete line with no whitespace / newline chars # first is the library instance INF # second is the library class libc = templine . partition ( '{' )[ 2 ]. partition ( '}' )[ 0 ]. partition ( ':' )[ 0 ]. strip () libi = templine . partition ( '{' )[ 0 ]. strip () # Take absolute path and convert to EDK build path RelativePath = pathConverter . GetEdk2RelativePathFromAbsolutePath ( libi ) if ( RelativePath is not None ) : self . Libraries [ libc ] = RelativePath else : self . Libraries [ libc ] = libi i += 1 continue elif ( inPcdSection ) : # this is the namespace token line if ( len ( line . split ()) == 1 ) : tokenspace = line # this is the main line of the PCD value elif ( line . count ( \"=\" ) == 1 and line . count ( \":\" ) == 1 ) : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () while ( line . count ( '{' ) ! = line . count ( '}' )) : i += 1 line += \" \" + self . _ RawContent [ i ]. rstrip () token = line . partition ( '=' )[ 2 ] token2 = line . partition ( ':' )[ 0 ]. split ()[ - 1 ] self . PCDs [ tokenspace + \".\" + token2 ] = token . strip () # this is the secondary lines of PCD values showing Defaults elif line . count ( \":\" ) == 0 and line . count ( \"=\" ) == 1 : while ( line . count ( \"\\\"\" ) % 2) != 0: i += 1 line += self . _ RawContent [ i ]. rstrip () elif ( inDepSection ) : pass # not implemented right now else : # not in section ... Must be header section line_partitioned = line . partition ( ':' ) if ( line_partitioned [ 2 ] == \"\" ) : pass # not a name : value pair else : key = line_partitioned [ 0 ]. strip (). lower () value = line_partitioned [ 2 ]. strip () if ( key == \"module name\" ) : logging . debug ( \"Parsing Mod: %s\" % value) self . Name = value elif ( key == \"module inf path\" ) : self . InfPath = value elif ( key == \"file guid\" ) : self . Guid = value elif ( key == \"driver type\" ) : value = value . strip () self . Type = value [ value . index ( '(' ) + 1 :- 1 ] i += 1 except Exception : logging . debug ( \"Exception in Parsing: %d\" % i) raise","title":"Parse"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/","text":"Module edk2toollib.uefi.edk2.parsers.dec_parser View Source # @file dec_parser.py # Code to help parse DEC file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DecParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibrariesUsed = [] self . PPIsUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PcdsUsed = [] self . IncludesUsed = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ] . strip ()) continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPPISection = True elif sline . strip () . lower () . startswith ( '[pcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[includes' ): InIncludesSection = True self . Parsed = True Classes DecParser class DecParser ( ) View Source class DecParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibrariesUsed = [] self . PPIsUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PcdsUsed = [] self . IncludesUsed = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ]. strip ()) continue elif InIncludesSection: if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else: self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection: if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else: t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ]. strip ()) continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Dec parser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#module-edk2toollibuefiedk2parsersdec_parser","text":"View Source # @file dec_parser.py # Code to help parse DEC file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DecParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibrariesUsed = [] self . PPIsUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PcdsUsed = [] self . IncludesUsed = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ] . strip ()) continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPPISection = True elif sline . strip () . lower () . startswith ( '[pcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[includes' ): InIncludesSection = True self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.dec_parser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#decparser","text":"class DecParser ( ) View Source class DecParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'DecParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibrariesUsed = [] self . PPIsUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PcdsUsed = [] self . IncludesUsed = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ]. strip ()) continue elif InIncludesSection: if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else: self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection: if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else: t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True","title":"DecParser"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPPISection = False InPcdSection = False InIncludesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : t = sline . partition ( \"|\" ) self . LibrariesUsed . append ( t [ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : t = sline . partition ( \"=\" ) self . ProtocolsUsed . append ( t [ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : t = sline . partition ( \"=\" ) self . GuidsUsed . append ( t [ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : t = sline . partition ( \"|\" ) self . PcdsUsed . append ( t [ 0 ]. strip ()) continue elif InIncludesSection : if sline . strip ()[ 0 ] == '[' : InIncludesSection = False else : self . IncludesUsed . append ( sline . strip ()) continue elif InPPISection : if ( sline . strip ()[ 0 ] == '[' ): InPPISection = False else : t = sline . partition ( \"=\" ) self . PPIsUsed . append ( t [ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPPISection = True elif sline . strip (). lower (). startswith ( '[pcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[includes' ): InIncludesSection = True self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/dec_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/","text":"Module edk2toollib.uefi.edk2.parsers.dsc_parser View Source # @file dsc_parser.py # Code to help parse DSC files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DscParser ( HashFileParser ): def __init__ ( self ): super ( DscParser , self ) . __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] def __ParseLine ( self , Line , file_name = None , lineno = None ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , [], None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , [], None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , [], None ) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , toks [ 1 ])) sp = self . FindPath ( toks [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , [], None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 64bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 32bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in library class section (don't use full name) elif ( self . CurrentSection . upper () == \"LIBRARYCLASSES\" ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in Library Class Section: %s \" % p ) return ( line_resolved , [], None ) # process line in PCD section elif ( self . CurrentSection . upper () . startswith ( \"PCDS\" )): if \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s \" % p [ 0 ] . strip ()) return ( line_resolved , [], None ) else : return ( line_resolved , [], None ) def __ParseDefineLine ( self , Line ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , []) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , []) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , toks [ 1 ])) sp = self . FindPath ( toks [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , []) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ): if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ): left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s \" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ]) return ( line_resolved , []) else : return ( line_resolved , []) def ParseInfPathLib ( self , line ): if ( line . count ( \"|\" ) > 0 ): line_parts = [] c = line . split ( \"|\" )[ 0 ] . strip () i = line . split ( \"|\" )[ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ): line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" )[ 1 ] . strip () else : return line . strip () . split ()[ 0 ] def ParseInfPathMod ( self , line ): return line . strip () . split ()[ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ): if ( len ( lines ) > 0 ): for index in range ( 0 , len ( lines )): ( line , add , new_file ) = self . __ParseLine ( lines [ index ], file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ): self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ): if ( len ( lines ) > 0 ): for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ): # # add more DSC parser based state reset here, if necessary # super ( DscParser , self ) . ResetParserState () def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True def GetMods ( self ): return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ): return self . Libs def GetLibsEnhanced ( self ): return self . LibsEnhanced Classes DscParser class DscParser ( ) View Source class DscParser ( HashFileParser ) : def __init__ ( self ) : super ( DscParser , self ). __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] def __ParseLine ( self , Line , file_name = None , lineno = None ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] , None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] , None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] , None ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , toks [ 1 ] )) sp = self . FindPath ( toks [ 1 ] ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] , None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 64bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 32bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in library class section ( don 't use full name) elif(self.CurrentSection.upper() == \"LIBRARYCLASSES\"): if(\".inf\" in line_resolved.lower()): p = self.ParseInfPathLib(line_resolved) self.Libs.append(p) self.Logger.debug(\"Found Library in Library Class Section: %s\" % p) return (line_resolved, [], None) # process line in PCD section elif(self.CurrentSection.upper().startswith(\"PCDS\")): if \"tokenspaceguid\" in line_resolved.lower() and \\ line_resolved.count(' | ') > 0 and line_resolved.count(' . ') > 0: # should be a pcd statement p = line_resolved.partition(' | ' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s\" % p [ 0 ] . strip ()) return ( line_resolved , [] , None ) else : return ( line_resolved , [] , None ) def __ParseDefineLine ( self , Line ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] ) # this line needs to be here to resolve any symbols inside the ! include lines , if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , toks [ 1 ] )) sp = self . FindPath ( toks [ 1 ] ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] ) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ) : if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ) : left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s\" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ] ) return ( line_resolved , [] ) else : return ( line_resolved , [] ) def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ] def ParseInfPathMod ( self , line ) : return line . strip (). split () [ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ) : if ( len ( lines ) > 0 ) : for index in range ( 0 , len ( lines )) : ( line , add , new_file ) = self . __ParseLine ( lines [ index ] , file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ) : self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ) : if ( len ( lines ) > 0 ) : for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ) : # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState () def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True def GetMods ( self ) : return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ) : return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ) : return self . Libs def GetLibsEnhanced ( self ) : return self . LibsEnhanced Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path GetLibs def GetLibs ( self ) View Source def GetLibs ( self ): return self . Libs GetLibsEnhanced def GetLibsEnhanced ( self ) View Source def GetLibsEnhanced ( self ): return self . LibsEnhanced GetMods def GetMods ( self ) View Source def GetMods ( self ): return self . ThreeMods + self . SixMods GetModsEnhanced def GetModsEnhanced ( self ) View Source def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseInfPathLib def ParseInfPathLib ( self , line ) View Source def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ] ParseInfPathMod def ParseInfPathMod ( self , line ) View Source def ParseInfPathMod ( self , line ): return line . strip (). split ()[ 0 ]. rstrip ( \"{\" ) ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState () SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Dsc parser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#module-edk2toollibuefiedk2parsersdsc_parser","text":"View Source # @file dsc_parser.py # Code to help parse DSC files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class DscParser ( HashFileParser ): def __init__ ( self ): super ( DscParser , self ) . __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] def __ParseLine ( self , Line , file_name = None , lineno = None ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , [], None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , [], None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , [], None ) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , toks [ 1 ])) sp = self . FindPath ( toks [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , [], None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 64bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ({ 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p }) self . Logger . debug ( \"Found 32bit Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()): if ( self . ParsingInBuildOption > 0 ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s \" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s \" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s \" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [], None ) # process line in library class section (don't use full name) elif ( self . CurrentSection . upper () == \"LIBRARYCLASSES\" ): if ( \".inf\" in line_resolved . lower ()): p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in Library Class Section: %s \" % p ) return ( line_resolved , [], None ) # process line in PCD section elif ( self . CurrentSection . upper () . startswith ( \"PCDS\" )): if \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s \" % p [ 0 ] . strip ()) return ( line_resolved , [], None ) else : return ( line_resolved , [], None ) def __ParseDefineLine ( self , Line ): line_stripped = self . StripComment ( Line ) . strip () if ( len ( line_stripped ) < 1 ): return ( \"\" , []) # this line needs to be here to resolve any symbols inside the !include lines, if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )): # was a conditional # Other parser returns line_resolved, []. Need to figure out which is right return ( \"\" , []) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()): return ( \"\" , []) # check for include file and import lines from file if ( line_resolved . strip () . lower () . startswith ( \"!include\" )): # include line. toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s \" % os . path . join ( self . RootPath , toks [ 1 ])) sp = self . FindPath ( toks [ 1 ]) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ): self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s \" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s \" % self . CurrentFullSection ) return ( line_resolved , []) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ): if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ): left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s \" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ]) return ( line_resolved , []) else : return ( line_resolved , []) def ParseInfPathLib ( self , line ): if ( line . count ( \"|\" ) > 0 ): line_parts = [] c = line . split ( \"|\" )[ 0 ] . strip () i = line . split ( \"|\" )[ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ): line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" )[ 1 ] . strip () else : return line . strip () . split ()[ 0 ] def ParseInfPathMod ( self , line ): return line . strip () . split ()[ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ): if ( len ( lines ) > 0 ): for index in range ( 0 , len ( lines )): ( line , add , new_file ) = self . __ParseLine ( lines [ index ], file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ): self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ): if ( len ( lines ) > 0 ): for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ): # # add more DSC parser based state reset here, if necessary # super ( DscParser , self ) . ResetParserState () def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True def GetMods ( self ): return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ): return self . Libs def GetLibsEnhanced ( self ): return self . LibsEnhanced","title":"Module edk2toollib.uefi.edk2.parsers.dsc_parser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#dscparser","text":"class DscParser ( ) View Source class DscParser ( HashFileParser ) : def __init__ ( self ) : super ( DscParser , self ). __init__ ( 'DscParser' ) self . SixMods = [] self . SixModsEnhanced = [] self . ThreeMods = [] self . ThreeModsEnhanced = [] self . OtherMods = [] self . Libs = [] self . LibsEnhanced = [] self . ParsingInBuildOption = 0 self . LibraryClassToInstanceDict = {} self . Pcds = [] def __ParseLine ( self , Line , file_name = None , lineno = None ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] , None ) line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] , None ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] , None ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , toks [ 1 ] )) sp = self . FindPath ( toks [ 1 ] ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc , sp ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] , None ) # process line in x64 components if ( self . CurrentFullSection . upper () == \"COMPONENTS.X64\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a 64bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 64bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . SixMods . append ( p ) if file_name is not None and lineno is not None : self . SixModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 64bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in ia32 components elif ( self . CurrentFullSection . upper () == \"COMPONENTS.IA32\" ) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) if file_name is not None and lineno is not None : self . LibsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found Library in a 32bit BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a 32bit Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . ThreeMods . append ( p ) if file_name is not None and lineno is not None : self . ThreeModsEnhanced . append ( { 'file' : os . path . normpath ( file_name ), 'lineno' : lineno , 'data' : p } ) self . Logger . debug ( \"Found 32bit Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in other components elif ( \"COMPONENTS\" in self . CurrentFullSection . upper ()) : if ( self . ParsingInBuildOption > 0 ) : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathLib ( line_resolved ) self . Libs . append ( p ) self . Logger . debug ( \"Found Library in a BuildOptions Section: %s\" % p ) elif \"tokenspaceguid\" in line_resolved . lower () and \\ line_resolved . count ( '|' ) > 0 and line_resolved . count ( '.' ) > 0 : # should be a pcd statement p = line_resolved . partition ( '|' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a Module Override section: %s\" % p [ 0 ] . strip ()) else : if ( \".inf\" in line_resolved . lower ()) : p = self . ParseInfPathMod ( line_resolved ) self . OtherMods . append ( p ) self . Logger . debug ( \"Found Module: %s\" % p ) self . ParsingInBuildOption = self . ParsingInBuildOption + line_resolved . count ( \"{\" ) self . ParsingInBuildOption = self . ParsingInBuildOption - line_resolved . count ( \"}\" ) return ( line_resolved , [] , None ) # process line in library class section ( don 't use full name) elif(self.CurrentSection.upper() == \"LIBRARYCLASSES\"): if(\".inf\" in line_resolved.lower()): p = self.ParseInfPathLib(line_resolved) self.Libs.append(p) self.Logger.debug(\"Found Library in Library Class Section: %s\" % p) return (line_resolved, [], None) # process line in PCD section elif(self.CurrentSection.upper().startswith(\"PCDS\")): if \"tokenspaceguid\" in line_resolved.lower() and \\ line_resolved.count(' | ') > 0 and line_resolved.count(' . ') > 0: # should be a pcd statement p = line_resolved.partition(' | ' ) self . Pcds . append ( p [ 0 ] . strip ()) self . Logger . debug ( \"Found a Pcd in a PCD section: %s\" % p [ 0 ] . strip ()) return ( line_resolved , [] , None ) else : return ( line_resolved , [] , None ) def __ParseDefineLine ( self , Line ) : line_stripped = self . StripComment ( Line ). strip () if ( len ( line_stripped ) < 1 ) : return ( \"\" , [] ) # this line needs to be here to resolve any symbols inside the ! include lines , if any line_resolved = self . ReplaceVariables ( line_stripped ) if ( self . ProcessConditional ( line_resolved )) : # was a conditional # Other parser returns line_resolved , [] . Need to figure out which is right return ( \"\" , [] ) # not conditional keep procesing # check if conditional is active if ( not self . InActiveCode ()) : return ( \"\" , [] ) # check for include file and import lines from file if ( line_resolved . strip (). lower (). startswith ( \"!include\" )) : # include line . toks = line_resolved . split () self . Logger . debug ( \"Opening Include File %s\" % os . path . join ( self . RootPath , toks [ 1 ] )) sp = self . FindPath ( toks [ 1 ] ) lf = open ( sp , \"r\" ) loc = lf . readlines () lf . close () return ( \"\" , loc ) # check for new section ( IsNew , Section ) = self . ParseNewSection ( line_resolved ) if ( IsNew ) : self . CurrentSection = Section . upper () self . Logger . debug ( \"New Section: %s\" % self . CurrentSection ) self . Logger . debug ( \"FullSection: %s\" % self . CurrentFullSection ) return ( line_resolved , [] ) # process line based on section we are in if ( self . CurrentSection == \"DEFINES\" ) or ( self . CurrentSection == \"BUILDOPTIONS\" ) : if line_resolved . count ( \"=\" ) >= 1 : tokens = line_resolved . split ( \"=\" , 1 ) leftside = tokens [ 0 ] . split () if ( len ( leftside ) == 2 ) : left = leftside [ 1 ] else : left = leftside [ 0 ] right = tokens [ 1 ] . strip () self . LocalVars [ left ] = right self . Logger . debug ( \"Key,values found: %s = %s\" % ( left , right )) # iterate through the existed LocalVars and try to resolve the symbols for var in self . LocalVars : self . LocalVars [ var ] = self . ReplaceVariables ( self . LocalVars [ var ] ) return ( line_resolved , [] ) else : return ( line_resolved , [] ) def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ] def ParseInfPathMod ( self , line ) : return line . strip (). split () [ 0 ] . rstrip ( \"{\" ) def __ProcessMore ( self , lines , file_name = None ) : if ( len ( lines ) > 0 ) : for index in range ( 0 , len ( lines )) : ( line , add , new_file ) = self . __ParseLine ( lines [ index ] , file_name = file_name , lineno = index + 1 ) if ( len ( line ) > 0 ) : self . Lines . append ( line ) self . __ProcessMore ( add , file_name = new_file ) def __ProcessDefines ( self , lines ) : if ( len ( lines ) > 0 ) : for l in lines : ( line , add ) = self . __ParseDefineLine ( l ) self . __ProcessDefines ( add ) def ResetParserState ( self ) : # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState () def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True def GetMods ( self ) : return self . ThreeMods + self . SixMods def GetModsEnhanced ( self ) : return self . ThreeModsEnhanced + self . SixModsEnhanced def GetLibs ( self ) : return self . Libs def GetLibsEnhanced ( self ) : return self . LibsEnhanced","title":"DscParser"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getlibs","text":"def GetLibs ( self ) View Source def GetLibs ( self ): return self . Libs","title":"GetLibs"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getlibsenhanced","text":"def GetLibsEnhanced ( self ) View Source def GetLibsEnhanced ( self ): return self . LibsEnhanced","title":"GetLibsEnhanced"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getmods","text":"def GetMods ( self ) View Source def GetMods ( self ): return self . ThreeMods + self . SixMods","title":"GetMods"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#getmodsenhanced","text":"def GetModsEnhanced ( self ) View Source def GetModsEnhanced ( self ): return self . ThreeModsEnhanced + self . SixModsEnhanced","title":"GetModsEnhanced"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) self . TargetFile = os . path . abspath ( filepath ) self . TargetFilePath = os . path . dirname ( self . TargetFile ) f = open ( os . path . join ( filepath ), \"r\" ) # expand all the lines and include other files file_lines = f . readlines () self . __ProcessDefines ( file_lines ) # reset the parser state before processing more self . ResetParserState () self . __ProcessMore ( file_lines , file_name = os . path . join ( filepath )) f . close () self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseinfpathlib","text":"def ParseInfPathLib ( self , line ) View Source def ParseInfPathLib ( self , line ) : if ( line . count ( \"|\" ) > 0 ) : line_parts = [] c = line . split ( \"|\" ) [ 0 ] . strip () i = line . split ( \"|\" ) [ 1 ] . strip () if ( c in self . LibraryClassToInstanceDict ) : line_parts = self . LibraryClassToInstanceDict . get ( c ) sp = self . FindPath ( i ) line_parts . append ( sp ) self . LibraryClassToInstanceDict [ c ] = line_parts return line . split ( \"|\" ) [ 1 ] . strip () else : return line . strip (). split () [ 0 ]","title":"ParseInfPathLib"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parseinfpathmod","text":"def ParseInfPathMod ( self , line ) View Source def ParseInfPathMod ( self , line ): return line . strip (). split ()[ 0 ]. rstrip ( \"{\" )","title":"ParseInfPathMod"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): # # add more DSC parser based state reset here , if necessary # super ( DscParser , self ). ResetParserState ()","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/dsc_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/","text":"Module edk2toollib.uefi.edk2.parsers.fdf_parser View Source # @file fdf_parser.py # Code to help parse EDK2 Fdf files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class FdfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip () . startswith ( \"[\" ) and sline . strip () . endswith ( \"]\" ): # if we're starting a new section # this basically gets what's after the . or if it doesn't have a period # the whole thing for every comma seperated item in sline self . CurrentSection = [ x . split ( \".\" , 1 )[ 1 ] if \".\" in x else x for x in sline . strip ( \"[] \" ) . strip () . split ( \",\" )] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self . LocalVars = {} self . LocalVars . update ( self . Dict ) if InDefinesSection : if sline . count ( \"=\" ) == 1 : tokens = sline . replace ( \"DEFINE\" , \"\" ) . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . info ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InFdSection : for section in self . CurrentSection : if section not in self . FVs : self . FDs [ section ] = { \"Dict\" : {}} # TODO finish the FD section continue elif InFvSection : for section in self . CurrentSection : if section not in self . FVs : self . FVs [ section ] = { \"Dict\" : {}, \"Infs\" : [], \"Files\" : {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline . upper () . startswith ( \"INF \" ): InfValue = sline [ 3 :] . strip () self . FVs [ section ][ \"Infs\" ] . append ( InfValue ) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline . upper () . startswith ( \"FILE\" ): sline = sline . strip ( \"}\" ) . strip ( \"{\" ) . strip () # make sure we take off the { and } file_def = sline [ 4 :] . strip () . split ( \"=\" , 1 ) # split by = if len ( file_def ) != 2 : # check to make sure we can parse this file raise RuntimeError ( \"Unable to properly parse \" + sline ) currentType = file_def [ 0 ] . strip () # get the type FILE currentName = file_def [ 1 ] . strip () # get the name (guid or otherwise) if currentType not in self . FVs [ section ]: self . FVs [ section ][ \"Files\" ][ currentName ] = {} self . FVs [ section ][ \"Files\" ][ currentName ][ \"type\" ] = currentType while self . _BracketCount > 0 : # go until we get our bracket back sline = self . GetNextLine () . strip ( \"}{ \" ) # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline . upper () . startswith ( \"SECTION GUIDED\" ): # get the guided section section_def = sline [ 14 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline . upper () . startswith ( \"SECTION\" ): # get the section section_def = sline [ 7 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = [] self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] . append ( sectionValue ) else : self . Logger . info ( \"Unknown line: {}\" . format ( sline )) continue elif InCapsuleSection : # TODO: finish capsule section continue elif InFmpPayloadSection : # TODO finish FMP payload section continue elif InRuleSection : # TODO finish rule section continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[fd.' ): InFdSection = True elif sline . strip () . lower () . startswith ( '[fv.' ): InFvSection = True elif sline . strip () . lower () . startswith ( '[capsule.' ): InCapsuleSection = True elif sline . strip () . lower () . startswith ( '[fmpPayload.' ): InFmpPayloadSection = True elif sline . strip () . lower () . startswith ( '[rule.' ): InRuleSection = True self . Parsed = True Classes FdfParser class FdfParser ( ) View Source class FdfParser ( HashFileParser ) : def __init__ ( self ) : HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ) : if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ) : return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ) : # was a conditional so skip return self . GetNextLine () if not self . InActiveCode () : return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma seperated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path GetNextLine def GetNextLine ( self ) View Source def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma seperated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Fdf parser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#module-edk2toollibuefiedk2parsersfdf_parser","text":"View Source # @file fdf_parser.py # Code to help parse EDK2 Fdf files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class FdfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip () . startswith ( \"[\" ) and sline . strip () . endswith ( \"]\" ): # if we're starting a new section # this basically gets what's after the . or if it doesn't have a period # the whole thing for every comma seperated item in sline self . CurrentSection = [ x . split ( \".\" , 1 )[ 1 ] if \".\" in x else x for x in sline . strip ( \"[] \" ) . strip () . split ( \",\" )] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self . LocalVars = {} self . LocalVars . update ( self . Dict ) if InDefinesSection : if sline . count ( \"=\" ) == 1 : tokens = sline . replace ( \"DEFINE\" , \"\" ) . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . info ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InFdSection : for section in self . CurrentSection : if section not in self . FVs : self . FDs [ section ] = { \"Dict\" : {}} # TODO finish the FD section continue elif InFvSection : for section in self . CurrentSection : if section not in self . FVs : self . FVs [ section ] = { \"Dict\" : {}, \"Infs\" : [], \"Files\" : {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline . upper () . startswith ( \"INF \" ): InfValue = sline [ 3 :] . strip () self . FVs [ section ][ \"Infs\" ] . append ( InfValue ) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline . upper () . startswith ( \"FILE\" ): sline = sline . strip ( \"}\" ) . strip ( \"{\" ) . strip () # make sure we take off the { and } file_def = sline [ 4 :] . strip () . split ( \"=\" , 1 ) # split by = if len ( file_def ) != 2 : # check to make sure we can parse this file raise RuntimeError ( \"Unable to properly parse \" + sline ) currentType = file_def [ 0 ] . strip () # get the type FILE currentName = file_def [ 1 ] . strip () # get the name (guid or otherwise) if currentType not in self . FVs [ section ]: self . FVs [ section ][ \"Files\" ][ currentName ] = {} self . FVs [ section ][ \"Files\" ][ currentName ][ \"type\" ] = currentType while self . _BracketCount > 0 : # go until we get our bracket back sline = self . GetNextLine () . strip ( \"}{ \" ) # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline . upper () . startswith ( \"SECTION GUIDED\" ): # get the guided section section_def = sline [ 14 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline . upper () . startswith ( \"SECTION\" ): # get the section section_def = sline [ 7 :] . strip () . split ( \"=\" , 1 ) sectionType = section_def [ 0 ] . strip () # UI in this example sectionValue = section_def [ 1 ] . strip () if sectionType not in self . FVs [ section ][ \"Files\" ][ currentName ]: self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] = [] self . FVs [ section ][ \"Files\" ][ currentName ][ sectionType ] . append ( sectionValue ) else : self . Logger . info ( \"Unknown line: {}\" . format ( sline )) continue elif InCapsuleSection : # TODO: finish capsule section continue elif InFmpPayloadSection : # TODO finish FMP payload section continue elif InRuleSection : # TODO finish rule section continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[fd.' ): InFdSection = True elif sline . strip () . lower () . startswith ( '[fv.' ): InFvSection = True elif sline . strip () . lower () . startswith ( '[capsule.' ): InCapsuleSection = True elif sline . strip () . lower () . startswith ( '[fmpPayload.' ): InFmpPayloadSection = True elif sline . strip () . lower () . startswith ( '[rule.' ): InRuleSection = True self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.fdf_parser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#fdfparser","text":"class FdfParser ( ) View Source class FdfParser ( HashFileParser ) : def __init__ ( self ) : HashFileParser . __init__ ( self , 'ModuleFdfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} # defines dictionary self . FVs = {} self . FDs = {} self . CurrentSection = [] self . Path = \"\" def GetNextLine ( self ) : if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ) : return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ) : # was a conditional so skip return self . GetNextLine () if not self . InActiveCode () : return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma seperated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True","title":"FdfParser"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#getnextline","text":"def GetNextLine ( self ) View Source def GetNextLine ( self ): if len ( self . Lines ) == 0 : return None line = self . Lines . pop () self . CurrentLine += 1 sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): return self . GetNextLine () sline = self . ReplaceVariables ( sline ) if self . ProcessConditional ( sline ): # was a conditional so skip return self . GetNextLine () if not self . InActiveCode (): return self . GetNextLine () self . _BracketCount += sline . count ( \"{\" ) self . _BracketCount -= sline . count ( \"}\" ) return sline","title":"GetNextLine"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ) : self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )) : fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp self . CurrentLine = 0 self . _f = open ( fp , \"r\" ) self . Lines = self . _f . readlines () self . Lines . reverse () self . _f . close () self . _BracketCount = 0 InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False sline = \"\" while sline is not None : sline = self . GetNextLine () if sline is None : break if sline . strip (). startswith ( \"[\" ) and sline . strip (). endswith ( \"]\" ) : # if we 're starting a new section # this basically gets what' s after the . or if it doesn 't have a period # the whole thing for every comma seperated item in sline self.CurrentSection = [ x.split(\".\", 1)[1] if \".\" in x else x for x in sline.strip(\"[] \").strip().split(\",\")] InDefinesSection = False InFdSection = False InFvSection = False InCapsuleSection = False InFmpPayloadSection = False InRuleSection = False self.LocalVars = {} self.LocalVars.update(self.Dict) if InDefinesSection: if sline.count(\"=\") == 1: tokens = sline.replace(\"DEFINE\", \"\").split(' = ', 1) self.Dict[tokens[0].strip()] = tokens[1].strip() self.Logger.info(\"Key,values found: %s = %s\" % (tokens[0].strip(), tokens[1].strip())) continue elif InFdSection: for section in self.CurrentSection: if section not in self.FVs: self.FDs[section] = {\"Dict\": {}} # TODO finish the FD section continue elif InFvSection: for section in self.CurrentSection: if section not in self.FVs: self.FVs[section] = {\"Dict\": {}, \"Infs\": [], \"Files\": {}} # ex: INF MdeModulePkg/Core/RuntimeDxe/RuntimeDxe.inf if sline.upper().startswith(\"INF \"): InfValue = sline[3:].strip() self.FVs[section][\"Infs\"].append(InfValue) # ex: FILE FREEFORM = 7E175642-F3AD-490A-9F8A-2E9FC6933DDD { elif sline.upper().startswith(\"FILE\"): sline = sline.strip(\"}\").strip(\"{\").strip() # make sure we take off the { and } file_def = sline[4:].strip().split(\"=\", 1) # split by = if len(file_def) != 2: # check to make sure we can parse this file raise RuntimeError(\"Unable to properly parse \" + sline) currentType = file_def[0].strip() # get the type FILE currentName = file_def[1].strip() # get the name (guid or otherwise) if currentType not in self.FVs[section]: self.FVs[section][\"Files\"][currentName] = {} self.FVs[section][\"Files\"][currentName][\"type\"] = currentType while self._BracketCount > 0: # go until we get our bracket back sline = self.GetNextLine().strip(\"}{ \") # SECTION GUIDED EE4E5898-3914-4259-9D6E-DC7BD79403CF PROCESSING_REQUIRED = TRUE if sline.upper().startswith(\"SECTION GUIDED\"): # get the guided section section_def = sline[14:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = {} # TODO support guided sections # ex: SECTION UI = \"GenericGopDriver\" elif sline.upper().startswith(\"SECTION\"): # get the section section_def = sline[7:].strip().split(\"=\", 1) sectionType = section_def[0].strip() # UI in this example sectionValue = section_def[1].strip() if sectionType not in self.FVs[section][\"Files\"][currentName]: self.FVs[section][\"Files\"][currentName][sectionType] = [] self.FVs[section][\"Files\"][currentName][sectionType].append(sectionValue) else: self.Logger.info(\"Unknown line: {}\".format(sline)) continue elif InCapsuleSection: # TODO: finish capsule section continue elif InFmpPayloadSection: # TODO finish FMP payload section continue elif InRuleSection: # TODO finish rule section continue # check for different sections if sline.strip().lower().startswith(' [ defines '): InDefinesSection = True elif sline.strip().lower().startswith(' [ fd . '): InFdSection = True elif sline.strip().lower().startswith(' [ fv . '): InFvSection = True elif sline.strip().lower().startswith(' [ capsule . '): InCapsuleSection = True elif sline.strip().lower().startswith(' [ fmpPayload . '): InFmpPayloadSection = True elif sline.strip().lower().startswith(' [ rule . ' ) : InRuleSection = True self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/fdf_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/","text":"Module edk2toollib.uefi.edk2.parsers.inf_parser View Source # @file inf_parser.py # Code to help parse EDK2 INF files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os AllPhases = [ \"SEC\" , \"PEIM\" , \"PEI_CORE\" , \"DXE_DRIVER\" , \"DXE_CORE\" , \"DXE_RUNTIME_DRIVER\" , \"UEFI_DRIVER\" , \"SMM_CORE\" , \"DXE_SMM_DRIVER\" , \"UEFI_APPLICATION\" ] class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ] . strip () . lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ] . partition ( \"|\" )[ 0 ] . strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . split () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[packages' ): InPackagesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPpiSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[pcd' ) or \\ sline . strip () . lower () . startswith ( '[patchpcd' ) or \\ sline . strip () . lower () . startswith ( '[fixedpcd' ) or \\ sline . strip () . lower () . startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[sources' ): InSourcesSection = True elif sline . strip () . lower () . startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True Variables AllPhases Classes InfParser class InfParser ( ) View Source class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else: self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection: if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else: self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection: if sline . strip ()[ 0 ] == '[' : InPpiSection = False else: self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection: if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else: self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection: if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else: self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Inf parser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#module-edk2toollibuefiedk2parsersinf_parser","text":"View Source # @file inf_parser.py # Code to help parse EDK2 INF files # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os AllPhases = [ \"SEC\" , \"PEIM\" , \"PEI_CORE\" , \"DXE_DRIVER\" , \"DXE_CORE\" , \"DXE_RUNTIME_DRIVER\" , \"UEFI_DRIVER\" , \"SMM_CORE\" , \"DXE_SMM_DRIVER\" , \"UEFI_APPLICATION\" ] class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ] . strip () . lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ] . partition ( \"|\" )[ 0 ] . strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ] . partition ( \"|\" )[ 2 ] . strip () . split () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ] . strip ()) continue # check for different sections if sline . strip () . lower () . startswith ( '[defines' ): InDefinesSection = True elif sline . strip () . lower () . startswith ( '[packages' ): InPackagesSection = True elif sline . strip () . lower () . startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip () . lower () . startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip () . lower () . startswith ( '[ppis' ): InPpiSection = True elif sline . strip () . lower () . startswith ( '[guids' ): InGuidsSection = True elif sline . strip () . lower () . startswith ( '[pcd' ) or \\ sline . strip () . lower () . startswith ( '[patchpcd' ) or \\ sline . strip () . lower () . startswith ( '[fixedpcd' ) or \\ sline . strip () . lower () . startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip () . lower () . startswith ( '[sources' ): InSourcesSection = True elif sline . strip () . lower () . startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.inf_parser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#variables","text":"AllPhases","title":"Variables"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#infparser","text":"class InfParser ( ) View Source class InfParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'ModuleInfParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . LibraryClass = \"\" self . SupportedPhases = [] self . PackagesUsed = [] self . LibrariesUsed = [] self . ProtocolsUsed = [] self . GuidsUsed = [] self . PpisUsed = [] self . PcdsUsed = [] self . Sources = [] self . Binaries = [] self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection: if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else: if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else: self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection: if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else: self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection: if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else: self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection: if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else: self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection: if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else: self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection: if sline . strip ()[ 0 ] == '[' : InPcdSection = False else: self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection: if sline . strip ()[ 0 ] == '[' : InPpiSection = False else: self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection: if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else: self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection: if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else: self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"InfParser"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () InDefinesSection = False InPackagesSection = False InLibraryClassSection = False InProtocolsSection = False InGuidsSection = False InPpiSection = False InPcdSection = False InSourcesSection = False InBinariesSection = False for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if InDefinesSection : if sline . strip ()[ 0 ] == '[' : InDefinesSection = False else : if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () # # Parse Library class and phases in special manor # if ( tokens [ 0 ]. strip (). lower () == \"library_class\" ): self . LibraryClass = tokens [ 1 ]. partition ( \"|\" )[ 0 ]. strip () self . Logger . debug ( \"Library class found\" ) if ( len ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip ()) < 1 ): self . SupportedPhases = AllPhases elif ( tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). lower () == \"base\" ): self . SupportedPhases = AllPhases else : self . SupportedPhases = tokens [ 1 ]. partition ( \"|\" )[ 2 ]. strip (). split () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue elif InPackagesSection : if sline . strip ()[ 0 ] == '[' : InPackagesSection = False else : self . PackagesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InLibraryClassSection : if sline . strip ()[ 0 ] == '[' : InLibraryClassSection = False else : self . LibrariesUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InProtocolsSection : if sline . strip ()[ 0 ] == '[' : InProtocolsSection = False else : self . ProtocolsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InGuidsSection : if sline . strip ()[ 0 ] == '[' : InGuidsSection = False else : self . GuidsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPcdSection : if sline . strip ()[ 0 ] == '[' : InPcdSection = False else : self . PcdsUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InPpiSection : if sline . strip ()[ 0 ] == '[' : InPpiSection = False else : self . PpisUsed . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InSourcesSection : if sline . strip ()[ 0 ] == '[' : InSourcesSection = False else : self . Sources . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue elif InBinariesSection : if sline . strip ()[ 0 ] == '[' : InBinariesSection = False else : self . Binaries . append ( sline . partition ( \"|\" )[ 0 ]. strip ()) continue # check for different sections if sline . strip (). lower (). startswith ( '[defines' ): InDefinesSection = True elif sline . strip (). lower (). startswith ( '[packages' ): InPackagesSection = True elif sline . strip (). lower (). startswith ( '[libraryclasses' ): InLibraryClassSection = True elif sline . strip (). lower (). startswith ( '[protocols' ): InProtocolsSection = True elif sline . strip (). lower (). startswith ( '[ppis' ): InPpiSection = True elif sline . strip (). lower (). startswith ( '[guids' ): InGuidsSection = True elif sline . strip (). lower (). startswith ( '[pcd' ) or \\ sline . strip (). lower (). startswith ( '[patchpcd' ) or \\ sline . strip (). lower (). startswith ( '[fixedpcd' ) or \\ sline . strip (). lower (). startswith ( '[featurepcd' ): InPcdSection = True elif sline . strip (). lower (). startswith ( '[sources' ): InSourcesSection = True elif sline . strip (). lower (). startswith ( '[binaries' ): InBinariesSection = True self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/inf_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/","text":"Module edk2toollib.uefi.edk2.parsers.override_parser View Source ## @file override_parser.py # Contains classes to help with the parsing of INF files that # may contain OVERRIDE information. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import datetime FORMAT_VERSION_1 = ( 1 , 4 ) # Version 1: #OVERRIDE : VERSION | PATH_TO_MODULE | HASH | YYYY-MM-DDThh-mm-ss class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type ' %s '\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) class OverrideParser ( object ): \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ): super ( OverrideParser , self ) . __init__ () # Make sure that at least some data is provided. if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided. if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. ( %s , %s )\" % ( file_path , inf_contents )) # If a file path was provided, make sure it exists. if file_path is not None : if not os . path . isfile ( file_path ): raise ValueError ( \"File path ' %s ' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing. parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file ' %s '.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found, we're basically done here. if not self . override_lines : raise ValueError ( \"File ' %s ' did not contain any override lines.\" % self . file_path ) self . overrides = [] for override_line in self . override_lines : try : self . overrides . append ( self . parse_override_line ( override_line [ 'line' ])) except OpParseError as pe : raise ValueError ( \"Parse error ' %s ' occurred while processing line %d of ' %s '.\" % ( pe , override_line [ 'lineno' ], override_line [ 'line' ])) @staticmethod def get_override_lines ( parse_contents ): parse_lines = parse_contents . split ( ' \\n ' ) result = [] for i in range ( 0 , len ( parse_lines )): if parse_lines [ i ] . strip () . upper () . startswith ( \"#OVERRIDE\" ): result . append ({ 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip ()}) return result @staticmethod def parse_override_line ( line_contents ): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents . split ( \":\" ) line_parts = [ part . strip () for part in line_parts [ 1 ] . split ( \"|\" )] # Step 1: Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ]) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ]) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ])): raise OpParseError ( OpParseError . PE_VER ) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ]) # Step 3: Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4: Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ], \"%Y-%m- %d T%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result Variables FORMAT_VERSION_1 Classes OpParseError class OpParseError ( my_type ) Common base class for all non-exit exceptions. View Source class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type '%s'\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) Ancestors (in MRO) builtins.Exception builtins.BaseException Class variables PE_DATE PE_HASH PE_PATH PE_VER args Methods with_traceback def with_traceback ( ... ) Exception.with_traceback(tb) \u2013 set self. traceback to tb and return self. OverrideParser class OverrideParser ( file_path = None , inf_contents = None ) OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn\u2019t exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. View Source class OverrideParser ( object ) : \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ) : super ( OverrideParser , self ). __init__ () # Make sure that at least some data is provided . if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided . if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. (%s, %s)\" % ( file_path , inf_contents )) # If a file path was provided , make sure it exists . if file_path is not None : if not os . path . isfile ( file_path ) : raise ValueError ( \"File path '%s' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing . parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file '%s'.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found , we 're basically done here. if not self.override_lines: raise ValueError(\"File ' % s ' did not contain any override lines.\" % self.file_path) self.overrides = [] for override_line in self.override_lines: try: self.overrides.append(self.parse_override_line(override_line[' line '])) except OpParseError as pe: raise ValueError(\"Parse error ' % s ' occurred while processing line %d of ' % s '.\" % (pe, override_line[' lineno '], override_line[' line '])) @staticmethod def get_override_lines(parse_contents): parse_lines = parse_contents.split(' \\ n ') result = [] for i in range(0, len(parse_lines)): if parse_lines[i].strip().upper().startswith(\"#OVERRIDE\"): result.append({' lineno ': i + 1, ' line ': parse_lines[i].strip()}) return result @staticmethod def parse_override_line(line_contents): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents.split(\":\") line_parts = [part.strip() for part in line_parts[1].split(\"|\")] # Step 1: Check version and number of blocks in this entry try: result[' version '] = int(line_parts[0]) except ValueError: raise OpParseError(OpParseError.PE_VER) # Verify this is a known version and has valid number of entries if not ((result[' version '] == FORMAT_VERSION_1[0]) and (len(line_parts) == FORMAT_VERSION_1[1])): raise OpParseError(OpParseError.PE_VER) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result[' original_path '] = os.path.normpath(line_parts[1]) # Step 3: Grep hash entry result[' current_hash '] = line_parts[2] # Step 4: Parse the time of hash generation try: result[' datetime '] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result Static methods get_override_lines def get_override_lines ( parse_contents ) View Source @staticmethod def get_override_lines ( parse_contents ) : parse_lines = parse_contents . split ( '\\n' ) result = [] for i in range ( 0 , len ( parse_lines )) : if parse_lines [ i ] . strip (). upper (). startswith ( \"#OVERRIDE\" ) : result . append ( { 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip () } ) return result parse_override_line def parse_override_line ( line_contents ) View Source @staticmethod def parse_override_line ( line_contents ) : result = {} # Split the override string into pieces . # First the #OVERRIDE , which is separated by a : . # Then everything else by | . line_parts = line_contents . split ( \":\" ) line_parts = [ part.strip() for part in line_parts[1 ] . split ( \"|\" ) ] # Step 1 : Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ] ) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ] ) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ] )) : raise OpParseError ( OpParseError . PE_VER ) # Step 2 : Process the path to overridden module # Normalize the path to support different slashes . result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ] ) # Step 3 : Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4 : Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"Override parser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#module-edk2toollibuefiedk2parsersoverride_parser","text":"View Source ## @file override_parser.py # Contains classes to help with the parsing of INF files that # may contain OVERRIDE information. # # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import datetime FORMAT_VERSION_1 = ( 1 , 4 ) # Version 1: #OVERRIDE : VERSION | PATH_TO_MODULE | HASH | YYYY-MM-DDThh-mm-ss class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type ' %s '\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type ) class OverrideParser ( object ): \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ): super ( OverrideParser , self ) . __init__ () # Make sure that at least some data is provided. if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided. if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. ( %s , %s )\" % ( file_path , inf_contents )) # If a file path was provided, make sure it exists. if file_path is not None : if not os . path . isfile ( file_path ): raise ValueError ( \"File path ' %s ' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing. parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file ' %s '.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found, we're basically done here. if not self . override_lines : raise ValueError ( \"File ' %s ' did not contain any override lines.\" % self . file_path ) self . overrides = [] for override_line in self . override_lines : try : self . overrides . append ( self . parse_override_line ( override_line [ 'line' ])) except OpParseError as pe : raise ValueError ( \"Parse error ' %s ' occurred while processing line %d of ' %s '.\" % ( pe , override_line [ 'lineno' ], override_line [ 'line' ])) @staticmethod def get_override_lines ( parse_contents ): parse_lines = parse_contents . split ( ' \\n ' ) result = [] for i in range ( 0 , len ( parse_lines )): if parse_lines [ i ] . strip () . upper () . startswith ( \"#OVERRIDE\" ): result . append ({ 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip ()}) return result @staticmethod def parse_override_line ( line_contents ): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents . split ( \":\" ) line_parts = [ part . strip () for part in line_parts [ 1 ] . split ( \"|\" )] # Step 1: Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ]) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ]) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ])): raise OpParseError ( OpParseError . PE_VER ) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ]) # Step 3: Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4: Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ], \"%Y-%m- %d T%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"Module edk2toollib.uefi.edk2.parsers.override_parser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#variables","text":"FORMAT_VERSION_1","title":"Variables"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#opparseerror","text":"class OpParseError ( my_type ) Common base class for all non-exit exceptions. View Source class OpParseError ( Exception ): PE_VER = 'VERSION' PE_PATH = 'PATH' PE_HASH = 'HASH' PE_DATE = 'DATE' def __init__ ( self , my_type ): if my_type not in ( OpParseError . PE_VER , OpParseError . PE_PATH , OpParseError . PE_HASH , OpParseError . PE_DATE ): raise ValueError ( \"Unknown type '%s'\" % my_type ) self . type = my_type def __str__ ( self ): return repr ( self . type )","title":"OpParseError"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#ancestors-in-mro","text":"builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#class-variables","text":"PE_DATE PE_HASH PE_PATH PE_VER args","title":"Class variables"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#with_traceback","text":"def with_traceback ( ... ) Exception.with_traceback(tb) \u2013 set self. traceback to tb and return self.","title":"with_traceback"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#overrideparser","text":"class OverrideParser ( file_path = None , inf_contents = None ) OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn\u2019t exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. View Source class OverrideParser ( object ) : \"\"\" OverrideParser is a simple file parser for .inf files that contain OVERRIDE data (i.e. overriding other .infs). Creating the object can be done by passing either a valid file path or a string containing the contents of an .inf file. Will raise an exception if the file doesn't exist or if the contents do not contain any OVERRIDE data. NOTE: There is an argument to be made that this class should actually be a subclass of InfParser, however, the InfParser is looking for far more details and has a much higher overhead. During a parser refactor, this should be considered. ALSO NOTE: There is a pattern used here where the object parses during instantiation. This pattern does not necessarily match the other parsers. The pros and cons of this should also be weighed during any parser refactor. \"\"\" def __init__ ( self , file_path = None , inf_contents = None ) : super ( OverrideParser , self ). __init__ () # Make sure that at least some data is provided . if file_path is None and inf_contents is None : raise ValueError ( \"file_path or inf_contents is required.\" ) # Make sure not too much data is provided . if file_path is not None and inf_contents is not None : raise ValueError ( \"Only provide file_path or inf_contents. (%s, %s)\" % ( file_path , inf_contents )) # If a file path was provided , make sure it exists . if file_path is not None : if not os . path . isfile ( file_path ) : raise ValueError ( \"File path '%s' does not exist.\" % file_path ) self . file_path = os . path . abspath ( file_path ) if file_path is not None else 'String Buffer' # Set up the contents for parsing . parse_contents = inf_contents if file_path is not None : with open ( file_path , 'r' ) as file : parse_contents = file . read () if not parse_contents : raise ValueError ( \"Failed to read contents of file '%s'.\" % self . file_path ) self . override_lines = self . get_override_lines ( parse_contents ) # If no override lines were found , we 're basically done here. if not self.override_lines: raise ValueError(\"File ' % s ' did not contain any override lines.\" % self.file_path) self.overrides = [] for override_line in self.override_lines: try: self.overrides.append(self.parse_override_line(override_line[' line '])) except OpParseError as pe: raise ValueError(\"Parse error ' % s ' occurred while processing line %d of ' % s '.\" % (pe, override_line[' lineno '], override_line[' line '])) @staticmethod def get_override_lines(parse_contents): parse_lines = parse_contents.split(' \\ n ') result = [] for i in range(0, len(parse_lines)): if parse_lines[i].strip().upper().startswith(\"#OVERRIDE\"): result.append({' lineno ': i + 1, ' line ': parse_lines[i].strip()}) return result @staticmethod def parse_override_line(line_contents): result = {} # Split the override string into pieces. # First the #OVERRIDE, which is separated by a :. # Then everything else by |. line_parts = line_contents.split(\":\") line_parts = [part.strip() for part in line_parts[1].split(\"|\")] # Step 1: Check version and number of blocks in this entry try: result[' version '] = int(line_parts[0]) except ValueError: raise OpParseError(OpParseError.PE_VER) # Verify this is a known version and has valid number of entries if not ((result[' version '] == FORMAT_VERSION_1[0]) and (len(line_parts) == FORMAT_VERSION_1[1])): raise OpParseError(OpParseError.PE_VER) # Step 2: Process the path to overridden module # Normalize the path to support different slashes. result[' original_path '] = os.path.normpath(line_parts[1]) # Step 3: Grep hash entry result[' current_hash '] = line_parts[2] # Step 4: Parse the time of hash generation try: result[' datetime '] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"OverrideParser"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#static-methods","text":"","title":"Static methods"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#get_override_lines","text":"def get_override_lines ( parse_contents ) View Source @staticmethod def get_override_lines ( parse_contents ) : parse_lines = parse_contents . split ( '\\n' ) result = [] for i in range ( 0 , len ( parse_lines )) : if parse_lines [ i ] . strip (). upper (). startswith ( \"#OVERRIDE\" ) : result . append ( { 'lineno' : i + 1 , 'line' : parse_lines [ i ] . strip () } ) return result","title":"get_override_lines"},{"location":"edk2toollib/uefi/edk2/parsers/override_parser/#parse_override_line","text":"def parse_override_line ( line_contents ) View Source @staticmethod def parse_override_line ( line_contents ) : result = {} # Split the override string into pieces . # First the #OVERRIDE , which is separated by a : . # Then everything else by | . line_parts = line_contents . split ( \":\" ) line_parts = [ part.strip() for part in line_parts[1 ] . split ( \"|\" ) ] # Step 1 : Check version and number of blocks in this entry try : result [ 'version' ] = int ( line_parts [ 0 ] ) except ValueError : raise OpParseError ( OpParseError . PE_VER ) # Verify this is a known version and has valid number of entries if not (( result [ 'version' ] == FORMAT_VERSION_1 [ 0 ] ) and ( len ( line_parts ) == FORMAT_VERSION_1 [ 1 ] )) : raise OpParseError ( OpParseError . PE_VER ) # Step 2 : Process the path to overridden module # Normalize the path to support different slashes . result [ 'original_path' ] = os . path . normpath ( line_parts [ 1 ] ) # Step 3 : Grep hash entry result [ 'current_hash' ] = line_parts [ 2 ] # Step 4 : Parse the time of hash generation try : result [ 'datetime' ] = datetime . datetime . strptime ( line_parts [ 3 ] , \"%Y-%m-%dT%H-%M-%S\" ) except ValueError : raise OpParseError ( OpParseError . PE_DATE ) return result","title":"parse_override_line"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/","text":"Module edk2toollib.uefi.edk2.parsers.targettxt_parser View Source # @file targettxt_parser.py # Code to help parse Edk2 Conf/Target.txt file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue self . Parsed = True Classes TargetTxtParser class TargetTxtParser ( ) View Source class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True Ancestors (in MRO) edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser Methods ComputeResult def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 ))) ConvertToInt def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 ) FindPath def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path InActiveCode def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret IsGuidString def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False ParseFile def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True ParseGuid def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper () ParseNewSection def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" ) PopConditional def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace . ProcessConditional def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False PushConditional def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v ) ReplaceVariables def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result ResetParserState def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False SetBaseAbsPath def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self SetInputVars def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self SetPackagePaths def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self StripComment def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip () WriteLinesToFile def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"Targettxt parser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#module-edk2toollibuefiedk2parserstargettxt_parser","text":"View Source # @file targettxt_parser.py # Code to help parse Edk2 Conf/Target.txt file # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## from edk2toollib.uefi.edk2.parsers.base_parser import HashFileParser import os class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s \" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ] . strip ()] = tokens [ 1 ] . strip () self . Logger . debug ( \"Key,values found: %s = %s \" % ( tokens [ 0 ] . strip (), tokens [ 1 ] . strip ())) continue self . Parsed = True","title":"Module edk2toollib.uefi.edk2.parsers.targettxt_parser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#classes","text":"","title":"Classes"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#targettxtparser","text":"class TargetTxtParser ( ) View Source class TargetTxtParser ( HashFileParser ): def __init__ ( self ): HashFileParser . __init__ ( self , 'TargetTxtParser' ) self . Lines = [] self . Parsed = False self . Dict = {} self . Path = \"\" def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else: fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines: sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True","title":"TargetTxtParser"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#ancestors-in-mro","text":"edk2toollib.uefi.edk2.parsers.base_parser.HashFileParser edk2toollib.uefi.edk2.parsers.base_parser.BaseParser","title":"Ancestors (in MRO)"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#methods","text":"","title":"Methods"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#computeresult","text":"def ComputeResult ( self , value , cond , value2 ) View Source def ComputeResult ( self , value , cond , value2 ): if ( cond == \"==\" ): # equal return ( value . upper () == value2 . upper ()) elif ( cond == \"!=\" ): # not equal return ( value . upper () != value2 . upper ()) elif ( cond == \"<\" ): return ( self . ConvertToInt ( value ) < ( self . ConvertToInt ( value2 ))) elif ( cond == \"<=\" ): return ( self . ConvertToInt ( value ) <= ( self . ConvertToInt ( value2 ))) elif ( cond == \">\" ): return ( self . ConvertToInt ( value ) > ( self . ConvertToInt ( value2 ))) elif ( cond == \">=\" ): return ( self . ConvertToInt ( value ) >= ( self . ConvertToInt ( value2 )))","title":"ComputeResult"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#converttoint","text":"def ConvertToInt ( self , value ) View Source def ConvertToInt ( self , value ): if ( value . upper (). startswith ( \"0X\" )): return int ( value , 16 ) else : return int ( value , 10 )","title":"ConvertToInt"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#findpath","text":"def FindPath ( self , * p ) View Source def FindPath ( self , * p ): # NOTE : Some of this logic should be replaced # with the path resolution from Edk2Module code . # If the absolute path exists , return it . Path = os . path . join ( self . RootPath , * p ) if os . path . exists ( Path ): return Path # If that fails , check a path relative to the target file . if self . TargetFilePath is not None : Path = os . path . join ( self . TargetFilePath , * p ) if os . path . exists ( Path ): return Path # If that fails , check in every possible Pkg path . for Pkg in self . PPs : Path = os . path . join ( self . RootPath , Pkg , * p ) if os . path . exists ( Path ): return Path # log invalid file path Path = os . path . join ( self . RootPath , * p ) self . Logger . error ( \"Invalid file path %s\" % Path ) return Path","title":"FindPath"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#inactivecode","text":"def InActiveCode ( self ) View Source def InActiveCode ( self ): ret = True for a in self . ConditionalStack : if not a : ret = False break return ret","title":"InActiveCode"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#isguidstring","text":"def IsGuidString ( self , l ) View Source def IsGuidString ( self , l ): if ( l . count ( \"{\" ) == 2 and l . count ( \"}\" ) == 2 and l . count ( \",\" ) == 10 and l . count ( \"=\" ) == 1 ): return True return False","title":"IsGuidString"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parsefile","text":"def ParseFile ( self , filepath ) View Source def ParseFile ( self , filepath ): self . Logger . debug ( \"Parsing file: %s\" % filepath ) if ( not os . path . isabs ( filepath )): fp = self . FindPath ( filepath ) else : fp = filepath self . Path = fp f = open ( fp , \"r\" ) self . Lines = f . readlines () f . close () for line in self . Lines : sline = self . StripComment ( line ) if ( sline is None or len ( sline ) < 1 ): continue if sline . count ( \"=\" ) == 1 : tokens = sline . split ( '=' , 1 ) self . Dict [ tokens [ 0 ]. strip ()] = tokens [ 1 ]. strip () self . Logger . debug ( \"Key,values found: %s = %s\" % ( tokens [ 0 ]. strip (), tokens [ 1 ]. strip ())) continue self . Parsed = True","title":"ParseFile"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parseguid","text":"def ParseGuid ( self , l ) View Source def ParseGuid ( self , l ): # parse a guid in format # { 0 xD3B36F2C , 0 xD551 , 0 x11D4 , { 0 x9A , 0 x46 , 0 x00 , 0 x90 , 0 x27 , 0 x3F , 0 xC1 , 0 x4D }} # into F7FDE4A6 - 294 C - 493 c - B50F - 9734553 BB757 ( NOTE these are not same guid this is just example of format ) entries = l . lstrip ( ' {' ). rstrip ( ' }' ). split ( ',' ) gu = entries [ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () # pad front until 8 chars while ( len ( gu ) < 8 ): gu = \"0\" + gu gut = entries [ 1 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 2 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 4 ): gut = \"0\" + gut gu = gu + \"-\" + gut # strip off extra { gut = entries [ 3 ]. lstrip ( ' { 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 4 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 5 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + \"-\" + gut gut = entries [ 6 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 7 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 8 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 9 ]. lstrip ( ' 0' ). lstrip ( 'x' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut gut = entries [ 10 ]. split ()[ 0 ]. lstrip ( ' 0' ). lstrip ( 'x' ). rstrip ( ' } ' ). strip () while ( len ( gut ) < 2 ): gut = \"0\" + gut gu = gu + gut return gu . upper ()","title":"ParseGuid"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#parsenewsection","text":"def ParseNewSection ( self , l ) View Source def ParseNewSection ( self , l ): if ( l . count ( \"[\" ) == 1 and l . count ( \"]\" ) == 1 ): # new section section = l . strip (). lstrip ( \"[\" ). split ( \".\" )[ 0 ]. split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () self . CurrentFullSection = l . strip (). lstrip ( \"[\" ). split ( \",\" )[ 0 ]. rstrip ( \"]\" ). strip () return ( True , section ) return ( False , \"\" )","title":"ParseNewSection"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#popconditional","text":"def PopConditional ( self ) View Source def PopConditional ( self ): if ( len ( self . ConditionalStack ) > 0 ): return self . ConditionalStack . pop () else : self . Logger . critical ( \"Tried to pop an empty conditional stack. Line Number %d\" % self . CurrentLine ) return self . ConditionalStack . pop () # this should cause a crash but will give trace .","title":"PopConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#processconditional","text":"def ProcessConditional ( self , text ) View Source def ProcessConditional ( self , text ): tokens = text . split () if ( tokens [ 0 ]. lower () == \"!if\" ): # need to add support for OR / AND if ( len ( tokens ) < 4 ): self . Logger . error ( \"!if conditionals need to be formatted correctly (spaces between each token)\" ) raise Exception ( \"Invalid conditional\" , text ) con = self . ComputeResult ( tokens [ 1 ]. strip (), tokens [ 2 ]. strip (), tokens [ 3 ]. strip ()) self . PushConditional ( con ) return True elif ( tokens [ 0 ]. lower () == \"!ifdef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) == 0 )) return True elif ( tokens [ 0 ]. lower () == \"!ifndef\" ): self . PushConditional (( tokens [ 1 ]. count ( \"$\" ) > 0 )) return True elif ( tokens [ 0 ]. lower () == \"!else\" ): v = self . PopConditional () self . PushConditional ( not v ) return True elif ( tokens [ 0 ]. lower () == \"!endif\" ): self . PopConditional () return True return False","title":"ProcessConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#pushconditional","text":"def PushConditional ( self , v ) View Source def PushConditional ( self , v ): self . ConditionalStack . append ( v )","title":"PushConditional"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#replacevariables","text":"def ReplaceVariables ( self , line ) View Source def ReplaceVariables ( self , line ): rep = line . count ( \"$\" ) result = line index = 0 while ( rep > 0 ): start = line . find ( \"$(\" , index ) end = line . find ( \")\" , start ) token = line [ start + 2 : end ] retoken = line [ start : end + 1 ] self . Logger . debug ( \"Token is %s\" % token ) v = self . LocalVars . get ( token ) self . Logger . debug ( \"Trying to replace %s\" % retoken ) if ( v is not None ): # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Local Vars]\" % v ) result = result . replace ( retoken , v , 1 ) else : # use the passed in Env v = self . InputVars . get ( token ) if ( v is None ): self . Logger . error ( \"Unknown variable %s in %s\" % ( token , line )) # raise Exception ( \"Invalid Variable Replacement\" , token ) # just skip it because we need to support ifdef else : # found in the Env # # fixme : This should just be a workaround !!!!! # if ( v . upper () == \"TRUE\" or v . upper () == \"FALSE\" ): v = v . upper () self . Logger . debug ( \"with %s [From Input Vars]\" % v ) result = result . replace ( retoken , v , 1 ) index = end + 1 rep = rep - 1 return result","title":"ReplaceVariables"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#resetparserstate","text":"def ResetParserState ( self ) View Source def ResetParserState ( self ): self . ConditionalStack = [] self . CurrentSection = '' self . CurrentFullSection = '' self . Parsed = False","title":"ResetParserState"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setbaseabspath","text":"def SetBaseAbsPath ( self , path ) View Source def SetBaseAbsPath ( self , path ): self . RootPath = path return self","title":"SetBaseAbsPath"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setinputvars","text":"def SetInputVars ( self , inputdict ) View Source def SetInputVars ( self , inputdict ): self . InputVars = inputdict return self","title":"SetInputVars"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#setpackagepaths","text":"def SetPackagePaths ( self , pps = [] ) View Source def SetPackagePaths ( self , pps = []): self . PPs = pps return self","title":"SetPackagePaths"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#stripcomment","text":"def StripComment ( self , l ) View Source def StripComment ( self , l ): return l . split ( '#' )[ 0 ]. strip ()","title":"StripComment"},{"location":"edk2toollib/uefi/edk2/parsers/targettxt_parser/#writelinestofile","text":"def WriteLinesToFile ( self , filepath ) View Source def WriteLinesToFile ( self , filepath ): self . Logger . debug ( \"Writing all lines to file: %s\" % filepath ) f = open ( filepath , \"w\" ) for l in self . Lines : f . write ( l + \"\\n\" ) f . close ()","title":"WriteLinesToFile"},{"location":"edk2toollib/windows/","text":"Module edk2toollib.windows View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.windows.capsule edk2toollib.windows.locate_tools edk2toollib.windows.locate_tools_test","title":"Index"},{"location":"edk2toollib/windows/#module-edk2toollibwindows","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.windows"},{"location":"edk2toollib/windows/#sub-modules","text":"edk2toollib.windows.capsule edk2toollib.windows.locate_tools edk2toollib.windows.locate_tools_test","title":"Sub-modules"},{"location":"edk2toollib/windows/locate_tools/","text":"Module edk2toollib.windows.locate_tools View Source # @file locate_tools . py # This module provides python services that locate common development tools using vswhere . exe , # vsvars . bat , and other Windows based tools . This works best on systems running Windows # and with dev tools installed but will attempt to use known paths for WinSDK if the dev # tools are not available . This is only a best effort to locate the SDK tools in well # known / default install locations . # # Suggested Dev Tools : # Current Windows SDKs # Visual Studio 2017 Build Tools or newer # # Note : When this module is used in local develop mode it will download vswhere . exe from the github . # It will confirm the hash is a known good value . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import pkg_resources import os import logging import glob import subprocess from edk2toollib . utility_functions import RunCmd from edk2toollib . utility_functions import GetHostInfo import re try : from StringIO import StringIO except ImportError : from io import StringIO import urllib . error import urllib . request # Update this when you want a new version of VsWhere __ VERSION = \"2.6.7\" __ URL = \"https://github.com/microsoft/vswhere/releases/download/{}/vswhere.exe\" . format ( __ VERSION ) __ SHA256 = \"10abd21aeb5003d87c01f033fd7c170360e362be397f23b0b730324abbd92612\" # # Supported Versions that can be queried with vswhere # Use lower case for key as all comparisons will be lower case # supported_vs_versions = { \"vs2017\" : \"15.0,16.0\" , \"vs2019\" : \"16.0,17.0\" } # Downloads VSWhere def _ DownloadVsWhere ( unpack_folder = None ) : if unpack_folder is None : unpack_folder = os . path . dirname ( __ VsWherePath ()) out_file_name = os . path . join ( unpack_folder , \"vswhere.exe\" ) logging . info ( \"Attempting to download vswhere to: {}. This may take a second.\" . format ( unpack_folder )) # check if we have the vswhere file already downloaded if not os . path . isfile ( out_file_name ) : try : # Download the file and save it locally under ` temp_file_name ` with urllib . request . urlopen ( __ URL ) as response , open ( out_file_name , 'wb' ) as out_file: out_file . write ( response . read ()) except urllib . error . HTTPError as e : logging . error ( f \"We ran into an issue when getting VsWhere\" ) raise e # do the hash to make sure the file is good with open ( out_file_name , \"rb\" ) as file : import hashlib temp_file_sha256 = hashlib . sha256 ( file . read ()). hexdigest () if temp_file_sha256 ! = __ SHA256 : # delete the file since it's not what we're expecting os . remove ( out_file_name ) raise RuntimeError ( f \"VsWhere - sha256 does not match\\n\\tdownloaded:\\t{temp_file_sha256}\\n\\t\" ) def __ VsWherePath () : file = \"vswhere.exe\" requirement = pkg_resources . Requirement . parse ( \"edk2-pytool-library\" ) file_path = os . path . join ( \"edk2toollib\" , \"bin\" , file ) vswhere_path = pkg_resources . resource_filename ( requirement , file_path ) return vswhere_path #### # # https : // docs . microsoft . com / en - us / vswhere / install - vswhere - client - tools # # @return string \"/PATH/TO/vswhere.exe\" or None #### def GetVsWherePath ( fail_on_not_found = True ) : vswhere_path = __ VsWherePath () # check if we can't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can't find it , download it if not os . path . isfile ( vswhere_path ) : vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _ DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren't able to find vswhere ! \") return None return vswhere_path #### # Finds a product with VS Where # # product: is defined by vswhere tool # vs_version: helper to find version of supported VS version (example vs2019). #### def FindWithVsWhere(products: str = \" * \", vs_version: str = None): cmd = \" - latest - nologo - all - property installationPath \" vs_where_path = GetVsWherePath() if vs_where_path is None: logging.warning(\" We weren't able to find VSWhere\") return (1, None) if(products is not None): cmd += \" -products \" + products if(vs_version is not None): vs_version = vs_version.lower() if vs_version in supported_vs_versions.keys(): cmd += \" -version \" + supported_vs_versions[vs_version] else: logging.warning(\"Invalid or unsupported vs_version \" + vs_version) return (2, None) a = StringIO() ret = RunCmd(vs_where_path, cmd, outstream=a) if(ret != 0): a.close() return (ret, None) p1 = a.getvalue().strip() a.close() if(len(p1.strip()) > 0): return (0, p1) return (ret, None) # Run visual studio batch file and collect the # interesting environment values # # Inspiration taken from cpython for this method of env collection # # keys: enumerable list with names of env variables to collect after bat run # arch: arch to run. amd64, x86, ?? # product: value defined by vswhere.exe # vs_version: helper to find version of supported VS version (example vs2019). # returns a dictionary of the interesting environment variables def QueryVcVariables(keys: dict, arch: str = None, product: str = None, vs_version: str = None): \"\"\"Launch vcvarsall.bat and read the settings from its environment\"\"\" if product is None: product = \"*\" if arch is None: # TODO: look up host architecture? arch = \"amd64\" interesting = set(keys) result = {} ret, vs_path = FindWithVsWhere(product, vs_version) if ret != 0 or vs_path is None: logging.warning(\"We didn't find VS path or otherwise failed to invoke vsWhere \") raise ValueError(\" Bad VC \") vcvarsall_path = os.path.join(vs_path, \" VC \", \" Auxiliary \", \" Build \", \" vcvarsall . bat \") logging.debug(\" Calling '%s %s' \", vcvarsall_path, arch) popen = subprocess.Popen('\" %s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) raise ValueError ( str ( list ( result . keys ()))) return result # return 1 if a > b # return 0 if b == a # return - 1 if a < b def _ CompareWindowVersions ( a , b ) : a_periods = str ( a ). count ( \".\" ) b_periods = str ( b ). count ( \".\" ) if a_periods == 3 and b_periods ! = 3 : return 1 if b_periods == 3 and a_periods ! = 3 : return - 1 if a_periods ! = 3 and b_periods ! = 3 : return 0 a_parts = str ( a ). split ( \".\" ) b_parts = str ( b ). split ( \".\" ) for i in range ( 3 ) : a_p = int ( a_parts [ i ]) b_p = int ( b_parts [ i ]) if a_p > b_p: return 1 if a_p < b_p: return - 1 return 0 def _ CheckArchOfMatch ( match ) : ''' Returns if this binary matches our host returns true or false if no arch is in the match, then we return true ''' match = str ( match ). lower () isx86 = \"x86\" in match isx64 = \"x64\" in match or \"amd64\" in match isArm64 = \"aarch\" in match or \"aarch64\" in match or \"arm64\" in match isi386 = \"i386\" in match isArm = not isArm64 and ( \"arm\" in match ) count = 0 count += 1 if isx64 else 0 count += 1 if isx86 else 0 count += 1 if isArm else 0 count += 1 if isArm64 else 0 count += 1 if isi386 else 0 if count == 0 : # we don't know what arch this is? return True if count > 1: # there are more than one arch for this binary logging.warning(\"We found more than one architecture for {}. Results maybe inconsistent\".format(match)) return True _, arch, bits = GetHostInfo() bits = int(bits) if isx86 and (bits < 32 or arch != \"x86\"): return False if isx64 and (bits < 64 or arch != \"x86\"): return False if isi386: # TODO add i386 to GetHostInfo return False if isArm64 and (bits < 64 or arch != \"ARM\"): return False if isArm and (bits < 32 or arch != \"ARM\"): return False return True # does a glob in the folder that your sdk is # uses the environmental variable WindowsSdkDir and tries to use WindowsSDKVersion def FindToolInWinSdk(tool, product=None, arch=None): variables = [\"WindowsSdkDir\", \"WindowsSDKVersion\"] # get the value with QueryVcVariables try: results = QueryVcVariables(variables, product, arch) # Get the variables we care about sdk_dir = results[\"WindowsSdkDir\"] sdk_ver = results[\"WindowsSDKVersion\"] except ValueError: sdk_dir = os.path.join(os.getenv(\"ProgramFiles(x86)\"), \"Windows Kits\", \"10\", \"bin\") sdk_ver = \"0.0.0.0\" sdk_dir = os.path.realpath(sdk_dir) search_pattern = os.path.join(sdk_dir, \"**\", tool) match_offset = len(sdk_dir) # look for something like 10.0.12323.0123 windows_ver_regex = re.compile(r'\\d+\\.\\d+\\.\\d+\\.\\d+') top_version_so_far = -1 top_match = None # Look at in match in the tree for match in glob.iglob(search_pattern, recursive=True): match_file = match[match_offset:] # strip off the root match_front, match_end = os.path.split(match_file) # split off the filename versions = windows_ver_regex.findall(match_front) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch(match_front): # make sure it's a good arch for us continue if len ( versions ) == 0 : top_ver_match = \"0.0.0.0\" # if we have a bad version , we should fall to a bad version for version in versions : # find the highest version if there are multiple in this? is_current_sdk_version = _ CompareWindowVersions ( version , sdk_ver ) == 0 if _ CompareWindowVersions ( version , top_ver_match ) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _ CompareWindowVersions ( top_ver_match , sdk_ver ) == 0 if _ CompareWindowVersions ( top_ver_match , top_version_so_far ) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None : logging . critical ( \"We weren't able to find {}\" . format ( tool )) return top_match Variables supported_vs_versions Functions FindToolInWinSdk def FindToolInWinSdk ( tool , product = None , arch = None ) View Source def FindToolInWinSdk ( tool , product = None , arch = None ): variables = [ \"WindowsSdkDir\" , \"WindowsSDKVersion\" ] # get the value with QueryVcVariables try : results = QueryVcVariables ( variables , product , arch ) # Get the variables we care about sdk_dir = results [ \"WindowsSdkDir\" ] sdk_ver = results [ \"WindowsSDKVersion\" ] except ValueError : sdk_dir = os . path . join ( os . getenv ( \"ProgramFiles(x86)\" ), \"Windows Kits\" , \"10\" , \"bin\" ) sdk_ver = \"0.0.0.0\" sdk_dir = os . path . realpath ( sdk_dir ) search_pattern = os . path . join ( sdk_dir , \"**\" , tool ) match_offset = len ( sdk_dir ) # look for something like 10 . 0 . 12323 . 0123 windows_ver_regex = re . compile ( r '\\d+\\.\\d+\\.\\d+\\.\\d+' ) top_version_so_far = - 1 top_match = None # Look at in match in the tree for match in glob . iglob ( search_pattern , recursive = True ): match_file = match [ match_offset :] # strip off the root match_front , match_end = os . path . split ( match_file ) # split off the filename versions = windows_ver_regex . findall ( match_front ) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch ( match_front ): # make sure it 's a good arch for us continue if len(versions) == 0: top_ver_match = \"0.0.0.0\" # if we have a bad version, we should fall to a bad version for version in versions: # find the highest version if there are multiple in this? is_current_sdk_version = _CompareWindowVersions(version, sdk_ver) == 0 if _CompareWindowVersions(version, top_ver_match) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _CompareWindowVersions(top_ver_match, sdk_ver) == 0 if _CompareWindowVersions(top_ver_match, top_version_so_far) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None: logging.critical(\"We weren' t able to find {}\" . format ( tool )) return top_match FindWithVsWhere def FindWithVsWhere ( products : str = '*' , vs_version : str = None ) View Source def FindWithVsWhere ( products : str = \"*\" , vs_version : str = None ) : cmd = \"-latest -nologo -all -property installationPath\" vs_where_path = GetVsWherePath () if vs_where_path is None : logging . warning ( \"We weren't able to find VSWhere\" ) return ( 1 , None ) if ( products is not None ) : cmd += \" -products \" + products if ( vs_version is not None ) : vs_version = vs_version . lower () if vs_version in supported_vs_versions . keys () : cmd += \" -version \" + supported_vs_versions [ vs_version ] else : logging . warning ( \"Invalid or unsupported vs_version \" + vs_version ) return ( 2 , None ) a = StringIO () ret = RunCmd ( vs_where_path , cmd , outstream = a ) if ( ret != 0 ) : a . close () return ( ret , None ) p1 = a . getvalue (). strip () a . close () if ( len ( p1 . strip ()) > 0 ) : return ( 0 , p1 ) return ( ret , None ) GetVsWherePath def GetVsWherePath ( fail_on_not_found = True ) View Source def GetVsWherePath ( fail_on_not_found = True ): vswhere_path = __VsWherePath () # check if we can 't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can' t find it , download it if not os . path . isfile ( vswhere_path ): vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we 're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren' t able to find vswhere ! \" ) return None return vswhere_path QueryVcVariables def QueryVcVariables ( keys : dict , arch : str = None , product : str = None , vs_version : str = None ) Launch vcvarsall.bat and read the settings from its environment View Source def QueryVcVariables ( keys : dict , arch : str = None , product : str = None , vs_version: str = None ) : \"\"\"Launch vcvarsall.bat and read the settings from its environment\"\"\" if product is None : product = \"*\" if arch is None : # TODO : look up host architecture? arch = \"amd64\" interesting = set ( keys ) result = {} ret , vs_path = FindWithVsWhere ( product , vs_version ) if ret ! = 0 or vs_path is None : logging . warning ( \"We didn't find VS path or otherwise failed to invoke vsWhere\" ) raise ValueError ( \"Bad VC\" ) vcvarsall_path = os . path . join ( vs_path , \"VC\" , \"Auxiliary\" , \"Build\" , \"vcvarsall.bat\" ) logging . debug ( \"Calling '%s %s'\" , vcvarsall_path , arch ) popen = subprocess . Popen ( '\"%s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) raise ValueError ( str ( list ( result . keys ()))) return result","title":"Locate tools"},{"location":"edk2toollib/windows/locate_tools/#module-edk2toollibwindowslocate_tools","text":"View Source # @file locate_tools . py # This module provides python services that locate common development tools using vswhere . exe , # vsvars . bat , and other Windows based tools . This works best on systems running Windows # and with dev tools installed but will attempt to use known paths for WinSDK if the dev # tools are not available . This is only a best effort to locate the SDK tools in well # known / default install locations . # # Suggested Dev Tools : # Current Windows SDKs # Visual Studio 2017 Build Tools or newer # # Note : When this module is used in local develop mode it will download vswhere . exe from the github . # It will confirm the hash is a known good value . # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## import pkg_resources import os import logging import glob import subprocess from edk2toollib . utility_functions import RunCmd from edk2toollib . utility_functions import GetHostInfo import re try : from StringIO import StringIO except ImportError : from io import StringIO import urllib . error import urllib . request # Update this when you want a new version of VsWhere __ VERSION = \"2.6.7\" __ URL = \"https://github.com/microsoft/vswhere/releases/download/{}/vswhere.exe\" . format ( __ VERSION ) __ SHA256 = \"10abd21aeb5003d87c01f033fd7c170360e362be397f23b0b730324abbd92612\" # # Supported Versions that can be queried with vswhere # Use lower case for key as all comparisons will be lower case # supported_vs_versions = { \"vs2017\" : \"15.0,16.0\" , \"vs2019\" : \"16.0,17.0\" } # Downloads VSWhere def _ DownloadVsWhere ( unpack_folder = None ) : if unpack_folder is None : unpack_folder = os . path . dirname ( __ VsWherePath ()) out_file_name = os . path . join ( unpack_folder , \"vswhere.exe\" ) logging . info ( \"Attempting to download vswhere to: {}. This may take a second.\" . format ( unpack_folder )) # check if we have the vswhere file already downloaded if not os . path . isfile ( out_file_name ) : try : # Download the file and save it locally under ` temp_file_name ` with urllib . request . urlopen ( __ URL ) as response , open ( out_file_name , 'wb' ) as out_file: out_file . write ( response . read ()) except urllib . error . HTTPError as e : logging . error ( f \"We ran into an issue when getting VsWhere\" ) raise e # do the hash to make sure the file is good with open ( out_file_name , \"rb\" ) as file : import hashlib temp_file_sha256 = hashlib . sha256 ( file . read ()). hexdigest () if temp_file_sha256 ! = __ SHA256 : # delete the file since it's not what we're expecting os . remove ( out_file_name ) raise RuntimeError ( f \"VsWhere - sha256 does not match\\n\\tdownloaded:\\t{temp_file_sha256}\\n\\t\" ) def __ VsWherePath () : file = \"vswhere.exe\" requirement = pkg_resources . Requirement . parse ( \"edk2-pytool-library\" ) file_path = os . path . join ( \"edk2toollib\" , \"bin\" , file ) vswhere_path = pkg_resources . resource_filename ( requirement , file_path ) return vswhere_path #### # # https : // docs . microsoft . com / en - us / vswhere / install - vswhere - client - tools # # @return string \"/PATH/TO/vswhere.exe\" or None #### def GetVsWherePath ( fail_on_not_found = True ) : vswhere_path = __ VsWherePath () # check if we can't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can't find it , download it if not os . path . isfile ( vswhere_path ) : vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _ DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren't able to find vswhere ! \") return None return vswhere_path #### # Finds a product with VS Where # # product: is defined by vswhere tool # vs_version: helper to find version of supported VS version (example vs2019). #### def FindWithVsWhere(products: str = \" * \", vs_version: str = None): cmd = \" - latest - nologo - all - property installationPath \" vs_where_path = GetVsWherePath() if vs_where_path is None: logging.warning(\" We weren't able to find VSWhere\") return (1, None) if(products is not None): cmd += \" -products \" + products if(vs_version is not None): vs_version = vs_version.lower() if vs_version in supported_vs_versions.keys(): cmd += \" -version \" + supported_vs_versions[vs_version] else: logging.warning(\"Invalid or unsupported vs_version \" + vs_version) return (2, None) a = StringIO() ret = RunCmd(vs_where_path, cmd, outstream=a) if(ret != 0): a.close() return (ret, None) p1 = a.getvalue().strip() a.close() if(len(p1.strip()) > 0): return (0, p1) return (ret, None) # Run visual studio batch file and collect the # interesting environment values # # Inspiration taken from cpython for this method of env collection # # keys: enumerable list with names of env variables to collect after bat run # arch: arch to run. amd64, x86, ?? # product: value defined by vswhere.exe # vs_version: helper to find version of supported VS version (example vs2019). # returns a dictionary of the interesting environment variables def QueryVcVariables(keys: dict, arch: str = None, product: str = None, vs_version: str = None): \"\"\"Launch vcvarsall.bat and read the settings from its environment\"\"\" if product is None: product = \"*\" if arch is None: # TODO: look up host architecture? arch = \"amd64\" interesting = set(keys) result = {} ret, vs_path = FindWithVsWhere(product, vs_version) if ret != 0 or vs_path is None: logging.warning(\"We didn't find VS path or otherwise failed to invoke vsWhere \") raise ValueError(\" Bad VC \") vcvarsall_path = os.path.join(vs_path, \" VC \", \" Auxiliary \", \" Build \", \" vcvarsall . bat \") logging.debug(\" Calling '%s %s' \", vcvarsall_path, arch) popen = subprocess.Popen('\" %s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) raise ValueError ( str ( list ( result . keys ()))) return result # return 1 if a > b # return 0 if b == a # return - 1 if a < b def _ CompareWindowVersions ( a , b ) : a_periods = str ( a ). count ( \".\" ) b_periods = str ( b ). count ( \".\" ) if a_periods == 3 and b_periods ! = 3 : return 1 if b_periods == 3 and a_periods ! = 3 : return - 1 if a_periods ! = 3 and b_periods ! = 3 : return 0 a_parts = str ( a ). split ( \".\" ) b_parts = str ( b ). split ( \".\" ) for i in range ( 3 ) : a_p = int ( a_parts [ i ]) b_p = int ( b_parts [ i ]) if a_p > b_p: return 1 if a_p < b_p: return - 1 return 0 def _ CheckArchOfMatch ( match ) : ''' Returns if this binary matches our host returns true or false if no arch is in the match, then we return true ''' match = str ( match ). lower () isx86 = \"x86\" in match isx64 = \"x64\" in match or \"amd64\" in match isArm64 = \"aarch\" in match or \"aarch64\" in match or \"arm64\" in match isi386 = \"i386\" in match isArm = not isArm64 and ( \"arm\" in match ) count = 0 count += 1 if isx64 else 0 count += 1 if isx86 else 0 count += 1 if isArm else 0 count += 1 if isArm64 else 0 count += 1 if isi386 else 0 if count == 0 : # we don't know what arch this is? return True if count > 1: # there are more than one arch for this binary logging.warning(\"We found more than one architecture for {}. Results maybe inconsistent\".format(match)) return True _, arch, bits = GetHostInfo() bits = int(bits) if isx86 and (bits < 32 or arch != \"x86\"): return False if isx64 and (bits < 64 or arch != \"x86\"): return False if isi386: # TODO add i386 to GetHostInfo return False if isArm64 and (bits < 64 or arch != \"ARM\"): return False if isArm and (bits < 32 or arch != \"ARM\"): return False return True # does a glob in the folder that your sdk is # uses the environmental variable WindowsSdkDir and tries to use WindowsSDKVersion def FindToolInWinSdk(tool, product=None, arch=None): variables = [\"WindowsSdkDir\", \"WindowsSDKVersion\"] # get the value with QueryVcVariables try: results = QueryVcVariables(variables, product, arch) # Get the variables we care about sdk_dir = results[\"WindowsSdkDir\"] sdk_ver = results[\"WindowsSDKVersion\"] except ValueError: sdk_dir = os.path.join(os.getenv(\"ProgramFiles(x86)\"), \"Windows Kits\", \"10\", \"bin\") sdk_ver = \"0.0.0.0\" sdk_dir = os.path.realpath(sdk_dir) search_pattern = os.path.join(sdk_dir, \"**\", tool) match_offset = len(sdk_dir) # look for something like 10.0.12323.0123 windows_ver_regex = re.compile(r'\\d+\\.\\d+\\.\\d+\\.\\d+') top_version_so_far = -1 top_match = None # Look at in match in the tree for match in glob.iglob(search_pattern, recursive=True): match_file = match[match_offset:] # strip off the root match_front, match_end = os.path.split(match_file) # split off the filename versions = windows_ver_regex.findall(match_front) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch(match_front): # make sure it's a good arch for us continue if len ( versions ) == 0 : top_ver_match = \"0.0.0.0\" # if we have a bad version , we should fall to a bad version for version in versions : # find the highest version if there are multiple in this? is_current_sdk_version = _ CompareWindowVersions ( version , sdk_ver ) == 0 if _ CompareWindowVersions ( version , top_ver_match ) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _ CompareWindowVersions ( top_ver_match , sdk_ver ) == 0 if _ CompareWindowVersions ( top_ver_match , top_version_so_far ) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None : logging . critical ( \"We weren't able to find {}\" . format ( tool )) return top_match","title":"Module edk2toollib.windows.locate_tools"},{"location":"edk2toollib/windows/locate_tools/#variables","text":"supported_vs_versions","title":"Variables"},{"location":"edk2toollib/windows/locate_tools/#functions","text":"","title":"Functions"},{"location":"edk2toollib/windows/locate_tools/#findtoolinwinsdk","text":"def FindToolInWinSdk ( tool , product = None , arch = None ) View Source def FindToolInWinSdk ( tool , product = None , arch = None ): variables = [ \"WindowsSdkDir\" , \"WindowsSDKVersion\" ] # get the value with QueryVcVariables try : results = QueryVcVariables ( variables , product , arch ) # Get the variables we care about sdk_dir = results [ \"WindowsSdkDir\" ] sdk_ver = results [ \"WindowsSDKVersion\" ] except ValueError : sdk_dir = os . path . join ( os . getenv ( \"ProgramFiles(x86)\" ), \"Windows Kits\" , \"10\" , \"bin\" ) sdk_ver = \"0.0.0.0\" sdk_dir = os . path . realpath ( sdk_dir ) search_pattern = os . path . join ( sdk_dir , \"**\" , tool ) match_offset = len ( sdk_dir ) # look for something like 10 . 0 . 12323 . 0123 windows_ver_regex = re . compile ( r '\\d+\\.\\d+\\.\\d+\\.\\d+' ) top_version_so_far = - 1 top_match = None # Look at in match in the tree for match in glob . iglob ( search_pattern , recursive = True ): match_file = match [ match_offset :] # strip off the root match_front , match_end = os . path . split ( match_file ) # split off the filename versions = windows_ver_regex . findall ( match_front ) # look for windows versions top_ver_match = 0 if not _CheckArchOfMatch ( match_front ): # make sure it 's a good arch for us continue if len(versions) == 0: top_ver_match = \"0.0.0.0\" # if we have a bad version, we should fall to a bad version for version in versions: # find the highest version if there are multiple in this? is_current_sdk_version = _CompareWindowVersions(version, sdk_ver) == 0 if _CompareWindowVersions(version, top_ver_match) > 0 or is_current_sdk_version: top_ver_match = version # if we have a highest version or one that matches our current from environment variables? is_current_sdk_version = _CompareWindowVersions(top_ver_match, sdk_ver) == 0 if _CompareWindowVersions(top_ver_match, top_version_so_far) > 0 or is_current_sdk_version: top_version_so_far = top_ver_match top_match = match if top_match is None: logging.critical(\"We weren' t able to find {}\" . format ( tool )) return top_match","title":"FindToolInWinSdk"},{"location":"edk2toollib/windows/locate_tools/#findwithvswhere","text":"def FindWithVsWhere ( products : str = '*' , vs_version : str = None ) View Source def FindWithVsWhere ( products : str = \"*\" , vs_version : str = None ) : cmd = \"-latest -nologo -all -property installationPath\" vs_where_path = GetVsWherePath () if vs_where_path is None : logging . warning ( \"We weren't able to find VSWhere\" ) return ( 1 , None ) if ( products is not None ) : cmd += \" -products \" + products if ( vs_version is not None ) : vs_version = vs_version . lower () if vs_version in supported_vs_versions . keys () : cmd += \" -version \" + supported_vs_versions [ vs_version ] else : logging . warning ( \"Invalid or unsupported vs_version \" + vs_version ) return ( 2 , None ) a = StringIO () ret = RunCmd ( vs_where_path , cmd , outstream = a ) if ( ret != 0 ) : a . close () return ( ret , None ) p1 = a . getvalue (). strip () a . close () if ( len ( p1 . strip ()) > 0 ) : return ( 0 , p1 ) return ( ret , None )","title":"FindWithVsWhere"},{"location":"edk2toollib/windows/locate_tools/#getvswherepath","text":"def GetVsWherePath ( fail_on_not_found = True ) View Source def GetVsWherePath ( fail_on_not_found = True ): vswhere_path = __VsWherePath () # check if we can 't find it, look for vswhere in the path if not os.path.isfile(vswhere_path): for env_var in os.getenv(\"PATH\").split(os.pathsep): env_var = os.path.join(os.path.normpath(env_var), \"vswhere.exe\") if os.path.isfile(env_var): vswhere_path = env_var break # if we still can' t find it , download it if not os . path . isfile ( vswhere_path ): vswhere_dir = os . path . dirname ( vswhere_path ) try : # try to download _DownloadVsWhere ( vswhere_dir ) except Exception : logging . warning ( \"Tried to download VsWhere and failed\" ) pass # if we 're still hosed if not os.path.isfile(vswhere_path) and fail_on_not_found: logging.error(\"We weren' t able to find vswhere ! \" ) return None return vswhere_path","title":"GetVsWherePath"},{"location":"edk2toollib/windows/locate_tools/#queryvcvariables","text":"def QueryVcVariables ( keys : dict , arch : str = None , product : str = None , vs_version : str = None ) Launch vcvarsall.bat and read the settings from its environment View Source def QueryVcVariables ( keys : dict , arch : str = None , product : str = None , vs_version: str = None ) : \"\"\"Launch vcvarsall.bat and read the settings from its environment\"\"\" if product is None : product = \"*\" if arch is None : # TODO : look up host architecture? arch = \"amd64\" interesting = set ( keys ) result = {} ret , vs_path = FindWithVsWhere ( product , vs_version ) if ret ! = 0 or vs_path is None : logging . warning ( \"We didn't find VS path or otherwise failed to invoke vsWhere\" ) raise ValueError ( \"Bad VC\" ) vcvarsall_path = os . path . join ( vs_path , \"VC\" , \"Auxiliary\" , \"Build\" , \"vcvarsall.bat\" ) logging . debug ( \"Calling '%s %s'\" , vcvarsall_path , arch ) popen = subprocess . Popen ( '\"%s\" %s & set' % (vcvarsall_path, arch), stdout=subprocess.PIPE, stderr=subprocess.PIPE) try : stdout , stderr = popen . communicate () if popen . wait () ! = 0 : raise Exception ( stderr . decode ( \"mbcs\" )) stdout = stdout . decode ( \"mbcs\" ) for line in stdout . split ( \"\\n\" ) : if '=' not in line : continue line = line . strip () key , value = line . split ( '=' , 1 ) if key in interesting : if value . endswith ( os . pathsep ) : value = value [:- 1 ] result [ key ] = value finally : popen . stdout . close () popen . stderr . close () if len ( result ) ! = len ( interesting ) : logging . debug ( \"Input: \" + str ( sorted ( interesting ))) logging . debug ( \"Result: \" + str ( sorted ( list ( result . keys ())))) raise ValueError ( str ( list ( result . keys ()))) return result","title":"QueryVcVariables"},{"location":"edk2toollib/windows/capsule/","text":"Module edk2toollib.windows.capsule View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ## Sub-modules edk2toollib.windows.capsule.cat_generator edk2toollib.windows.capsule.cat_generator_test edk2toollib.windows.capsule.inf_generator edk2toollib.windows.capsule.inf_generator_test","title":"Index"},{"location":"edk2toollib/windows/capsule/#module-edk2toollibwindowscapsule","text":"View Source ## # File to mark this a python package # # Copyright ( c ) Microsoft Corporation # # SPDX - License - Identifier : BSD - 2 - Clause - Patent ##","title":"Module edk2toollib.windows.capsule"},{"location":"edk2toollib/windows/capsule/#sub-modules","text":"edk2toollib.windows.capsule.cat_generator edk2toollib.windows.capsule.cat_generator_test edk2toollib.windows.capsule.inf_generator edk2toollib.windows.capsule.inf_generator_test","title":"Sub-modules"},{"location":"edk2toollib/windows/capsule/cat_generator/","text":"Module edk2toollib.windows.capsule.cat_generator View Source ## @file # Script to generate Cat files for capsule update based on supplied inf file. # This uses the winsdk and the command line tool Inf2Cat.exe # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging from edk2toollib.utility_functions import RunCmd from edk2toollib.windows.locate_tools import FindToolInWinSdk class CatGenerator ( object ): SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ): self . Arch = arch self . OperatingSystem = os @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ): # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ): self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ): # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s \" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ): return self . _operatingsystem @OperatingSystem.setter def OperatingSystem ( self , value ): key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()): logging . critical ( \"Unsupported Operating System: %s \" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d \" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file ( %s ) not created\" % OutputCatFile ) return 0 Classes CatGenerator class CatGenerator ( arch , os ) View Source class CatGenerator ( object ) : SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ) : self . Arch = arch self . OperatingSystem = os @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ) : # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ) : self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ) : # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s\" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ) : return self . _operatingsystem @OperatingSystem . setter def OperatingSystem ( self , value ) : key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()) : logging . critical ( \"Unsupported Operating System: %s\" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) : # Find Inf2Cat tool if ( PathToInf2CatTool is None ) : PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ) : raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ) : raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )) : raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0 Class variables SUPPORTED_OS Instance variables Arch OperatingSystem Methods MakeCat def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) View Source def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"Cat generator"},{"location":"edk2toollib/windows/capsule/cat_generator/#module-edk2toollibwindowscapsulecat_generator","text":"View Source ## @file # Script to generate Cat files for capsule update based on supplied inf file. # This uses the winsdk and the command line tool Inf2Cat.exe # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging from edk2toollib.utility_functions import RunCmd from edk2toollib.windows.locate_tools import FindToolInWinSdk class CatGenerator ( object ): SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ): self . Arch = arch self . OperatingSystem = os @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ): # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ): self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ): # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s \" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ): return self . _operatingsystem @OperatingSystem.setter def OperatingSystem ( self , value ): key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()): logging . critical ( \"Unsupported Operating System: %s \" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d \" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file ( %s ) not created\" % OutputCatFile ) return 0","title":"Module edk2toollib.windows.capsule.cat_generator"},{"location":"edk2toollib/windows/capsule/cat_generator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/windows/capsule/cat_generator/#catgenerator","text":"class CatGenerator ( arch , os ) View Source class CatGenerator ( object ) : SUPPORTED_OS = { 'win10' : '10' , '10' : '10' , '10_au' : '10_AU' , '10_rs2' : '10_RS2' , '10_rs3' : '10_RS3' , '10_rs4' : '10_RS4' , 'server10' : 'Server10' , 'server2016' : 'Server2016' , 'serverrs2' : 'ServerRS2' , 'serverrs3' : 'ServerRS3' , 'serverrs4' : 'ServerRS4' } def __init__ ( self , arch , os ) : self . Arch = arch self . OperatingSystem = os @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : value = value . lower () if ( value == \"x64\" ) or ( value == \"amd64\" ) : # support amd64 value so INF and CAT tools can use same arch value self . _arch = \"X64\" elif ( value == \"arm\" ) : self . _arch = \"ARM\" elif ( value == \"arm64\" ) or ( value == \"aarch64\" ) : # support UEFI defined aarch64 value as well self . _arch = \"ARM64\" else : logging . critical ( \"Unsupported Architecture: %s\" , value ) raise ValueError ( \"Unsupported Architecture\" ) @property def OperatingSystem ( self ) : return self . _operatingsystem @OperatingSystem . setter def OperatingSystem ( self , value ) : key = value . lower () if ( key not in CatGenerator . SUPPORTED_OS . keys ()) : logging . critical ( \"Unsupported Operating System: %s\" , key ) raise ValueError ( \"Unsupported Operating System\" ) self . _operatingsystem = CatGenerator . SUPPORTED_OS [ key ] def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) : # Find Inf2Cat tool if ( PathToInf2CatTool is None ) : PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ) : raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ) : raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )) : raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"CatGenerator"},{"location":"edk2toollib/windows/capsule/cat_generator/#class-variables","text":"SUPPORTED_OS","title":"Class variables"},{"location":"edk2toollib/windows/capsule/cat_generator/#instance-variables","text":"Arch OperatingSystem","title":"Instance variables"},{"location":"edk2toollib/windows/capsule/cat_generator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/windows/capsule/cat_generator/#makecat","text":"def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ) View Source def MakeCat ( self , OutputCatFile , PathToInf2CatTool = None ): # Find Inf2Cat tool if ( PathToInf2CatTool is None ): PathToInf2CatTool = FindToolInWinSdk ( \"Inf2Cat.exe\" ) # check if exists if PathToInf2CatTool is None or not os . path . exists ( PathToInf2CatTool ): raise Exception ( \"Can't find Inf2Cat on this machine. Please install the Windows 10 WDK - \" \"https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\" ) OutputFolder = os . path . dirname ( OutputCatFile ) # Make Cat file cmd = \"/driver:. /os:\" + self . OperatingSystem + \"_\" + self . Arch + \" /verbose\" ret = RunCmd ( PathToInf2CatTool , cmd , workingdir = OutputFolder ) if ( ret != 0 ): raise Exception ( \"Creating Cat file Failed with errorcode %d\" % ret ) if ( not os . path . isfile ( OutputCatFile )): raise Exception ( \"CAT file (%s) not created\" % OutputCatFile ) return 0","title":"MakeCat"},{"location":"edk2toollib/windows/capsule/inf_generator/","text":"Module edk2toollib.windows.capsule.inf_generator View Source ## # Module to generate inf files for capsule update based on INF TEMPLATE and # supplied information (Name, Version, ESRT Guid, Rollback, etc.) # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import datetime import re import uuid class InfGenerator ( object ): ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\"$WINDOWS NT$\" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %F irmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \"{Provider}\" MfgName = \"{MfgName}\" FirmwareDesc = \"{Description}\" DiskName = \"Firmware Update\" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ): self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ): return self . _name @Name.setter def Name ( self , value ): # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )) . match ( value ): logging . critical ( \"Name invalid: ' %s '\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ): return self . _provider @Provider.setter def Provider ( self , value ): self . _provider = value @property def Manufacturer ( self ): if ( self . _manufacturer is None ): return self . Provider return self . _manufacturer @Manufacturer.setter def Manufacturer ( self , value ): self . _manufacturer = value @property def Description ( self ): return self . _description @Description.setter def Description ( self , value ): self . _description = value @property def EsrtGuid ( self ): return self . _esrtguid @EsrtGuid.setter def EsrtGuid ( self , value ): uuid . UUID ( value ) # if this works it is valid...otherwise throws exception # todo - make sure it is formatted exactly right self . _esrtguid = value @property def VersionString ( self ): return self . _versionstring @VersionString.setter def VersionString ( self , value ): c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ): logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ): return \"0x %X \" % self . _versionhex @VersionHex.setter def VersionHex ( self , value ): a = int ( value , 0 ) if ( a > 0xFFFFFFFF ): logging . critical ( \"VersionHex invalid: ' %s '\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()): logging . critical ( \"Arch invalid: ' %s '\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ): return self . _date . strftime ( \"%m/ %d /%Y\" ) @Date.setter def Date ( self , value ): if ( not isinstance ( value , datetime . date )): raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0 Classes InfGenerator class InfGenerator ( name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) View Source class InfGenerator ( object ) : ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\" $ WINDOWS NT $ \" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %FirmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \" { Provider } \" MfgName = \" { MfgName } \" FirmwareDesc = \" { Description } \" DiskName = \" Firmware Update \" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) : self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ) : return self . _name @Name . setter def Name ( self , value ) : # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )). match ( value ) : logging . critical ( \"Name invalid: '%s'\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ) : return self . _provider @Provider . setter def Provider ( self , value ) : self . _provider = value @property def Manufacturer ( self ) : if ( self . _manufacturer is None ) : return self . Provider return self . _manufacturer @Manufacturer . setter def Manufacturer ( self , value ) : self . _manufacturer = value @property def Description ( self ) : return self . _description @Description . setter def Description ( self , value ) : self . _description = value @property def EsrtGuid ( self ) : return self . _esrtguid @EsrtGuid . setter def EsrtGuid ( self , value ) : uuid . UUID ( value ) # if this works it is valid ... otherwise throws exception # todo - make sure it is formatted exactly right self . _esrtguid = value @property def VersionString ( self ) : return self . _versionstring @VersionString . setter def VersionString ( self , value ) : c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ) : logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ) : return \"0x%X\" % self . _versionhex @VersionHex . setter def VersionHex ( self , value ) : a = int ( value , 0 ) if ( a > 0xFFFFFFFF ) : logging . critical ( \"VersionHex invalid: '%s'\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()) : logging . critical ( \"Arch invalid: '%s'\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ) : return self . _date . strftime ( \"%m/%d/%Y\" ) @Date . setter def Date ( self , value ) : if ( not isinstance ( value , datetime . date )) : raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) : RollbackString = \"\" if ( Rollback ) : RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0 Class variables ROLLBACKTEMPLATE SUPPORTED_ARCH TEMPLATE Instance variables Arch Date Description EsrtGuid Manufacturer Name Provider VersionHex VersionString Methods MakeInf def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) View Source def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"Inf generator"},{"location":"edk2toollib/windows/capsule/inf_generator/#module-edk2toollibwindowscapsuleinf_generator","text":"View Source ## # Module to generate inf files for capsule update based on INF TEMPLATE and # supplied information (Name, Version, ESRT Guid, Rollback, etc.) # # Copyright (c) Microsoft Corporation # # SPDX-License-Identifier: BSD-2-Clause-Patent ## import os import logging import datetime import re import uuid class InfGenerator ( object ): ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\"$WINDOWS NT$\" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %F irmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \"{Provider}\" MfgName = \"{MfgName}\" FirmwareDesc = \"{Description}\" DiskName = \"Firmware Update\" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ): self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ): return self . _name @Name.setter def Name ( self , value ): # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )) . match ( value ): logging . critical ( \"Name invalid: ' %s '\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ): return self . _provider @Provider.setter def Provider ( self , value ): self . _provider = value @property def Manufacturer ( self ): if ( self . _manufacturer is None ): return self . Provider return self . _manufacturer @Manufacturer.setter def Manufacturer ( self , value ): self . _manufacturer = value @property def Description ( self ): return self . _description @Description.setter def Description ( self , value ): self . _description = value @property def EsrtGuid ( self ): return self . _esrtguid @EsrtGuid.setter def EsrtGuid ( self , value ): uuid . UUID ( value ) # if this works it is valid...otherwise throws exception # todo - make sure it is formatted exactly right self . _esrtguid = value @property def VersionString ( self ): return self . _versionstring @VersionString.setter def VersionString ( self , value ): c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ): logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ): return \"0x %X \" % self . _versionhex @VersionHex.setter def VersionHex ( self , value ): a = int ( value , 0 ) if ( a > 0xFFFFFFFF ): logging . critical ( \"VersionHex invalid: ' %s '\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ): return self . _arch @Arch.setter def Arch ( self , value ): key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()): logging . critical ( \"Arch invalid: ' %s '\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ): return self . _date . strftime ( \"%m/ %d /%Y\" ) @Date.setter def Date ( self , value ): if ( not isinstance ( value , datetime . date )): raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"Module edk2toollib.windows.capsule.inf_generator"},{"location":"edk2toollib/windows/capsule/inf_generator/#classes","text":"","title":"Classes"},{"location":"edk2toollib/windows/capsule/inf_generator/#infgenerator","text":"class InfGenerator ( name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) View Source class InfGenerator ( object ) : ### INF Template ### TEMPLATE = r \"\"\"; ; {Name}.inf ; {DriverVersion} ; Copyright (C) 2019 Microsoft Corporation. All Rights Reserved. ; [Version] Signature=\" $ WINDOWS NT $ \" Class=Firmware ClassGuid={{f2e7dd72-6468-4e36-b6f1-6488f42c1b52}} Provider=%Provider% DriverVer={Date},{DriverVersion} PnpLockdown=1 CatalogFile={Name}.cat [Manufacturer] %MfgName% = Firmware,NT{Arch} [Firmware.NT{Arch}] %FirmwareDesc% = Firmware_Install,UEFI\\RES_{{{EsrtGuid}}} [Firmware_Install.NT] CopyFiles = Firmware_CopyFiles {Rollback} [Firmware_CopyFiles] {FirmwareBinFile} [Firmware_Install.NT.Hw] AddReg = Firmware_AddReg [Firmware_AddReg] HKR,,FirmwareId,,{{{EsrtGuid}}} HKR,,FirmwareVersion,%REG_DWORD%,{VersionHexString} HKR,,FirmwareFilename,,{FirmwareBinFile} [SourceDisksNames] 1 = %DiskName% [SourceDisksFiles] {FirmwareBinFile} = 1 [DestinationDirs] DefaultDestDir = %DIRID_WINDOWS%,Firmware ; %SystemRoot%\\Firmware [Strings] ; localizable Provider = \" { Provider } \" MfgName = \" { MfgName } \" FirmwareDesc = \" { Description } \" DiskName = \" Firmware Update \" ; non-localizable DIRID_WINDOWS = 10 REG_DWORD = 0x00010001 \"\"\" ROLLBACKTEMPLATE = r \"\"\"AddReg = Firmware_DowngradePolicy_Addreg ;override firmware resource update policy to allow downgrade to lower version [Firmware_DowngradePolicy_Addreg] HKLM,SYSTEM\\CurrentControlSet\\Control\\FirmwareResources\\{{{EsrtGuid}}},Policy,%REG_DWORD%,1 \"\"\" SUPPORTED_ARCH = { 'amd64' : 'amd64' , 'x64' : 'amd64' , 'arm' : 'arm' , 'arm64' : 'ARM64' , 'aarch64' : 'ARM64' } def __init__ ( self , name_string , provider , esrt_guid , arch , description_string , version_string , version_hex ) : self . Name = name_string self . Provider = provider self . EsrtGuid = esrt_guid self . Arch = arch self . Description = description_string self . VersionString = version_string self . VersionHex = version_hex self . _manufacturer = None # default for optional feature self . _date = datetime . date . today () @property def Name ( self ) : return self . _name @Name . setter def Name ( self , value ) : # test here for invalid chars if not ( re . compile ( r '[\\w-]*$' )). match ( value ) : logging . critical ( \"Name invalid: '%s'\" , value ) raise ValueError ( \"Name has invalid chars.\" ) self . _name = value @property def Provider ( self ) : return self . _provider @Provider . setter def Provider ( self , value ) : self . _provider = value @property def Manufacturer ( self ) : if ( self . _manufacturer is None ) : return self . Provider return self . _manufacturer @Manufacturer . setter def Manufacturer ( self , value ) : self . _manufacturer = value @property def Description ( self ) : return self . _description @Description . setter def Description ( self , value ) : self . _description = value @property def EsrtGuid ( self ) : return self . _esrtguid @EsrtGuid . setter def EsrtGuid ( self , value ) : uuid . UUID ( value ) # if this works it is valid ... otherwise throws exception # todo - make sure it is formatted exactly right self . _esrtguid = value @property def VersionString ( self ) : return self . _versionstring @VersionString . setter def VersionString ( self , value ) : c = value . count ( \".\" ) if ( c < 1 ) or ( c > 3 ) : logging . critical ( \"Version string in invalid format.\" ) raise ValueError ( \"VersionString must be in format of xx.xx -> xx.xx.xx.xx\" ) self . _versionstring = value @property def VersionHex ( self ) : return \"0x%X\" % self . _versionhex @VersionHex . setter def VersionHex ( self , value ) : a = int ( value , 0 ) if ( a > 0xFFFFFFFF ) : logging . critical ( \"VersionHex invalid: '%s'\" , value ) raise ValueError ( \"VersionHex must fit within 32bit value range for unsigned integer\" ) self . _versionhex = a @property def Arch ( self ) : return self . _arch @Arch . setter def Arch ( self , value ) : key = value . lower () if ( key not in InfGenerator . SUPPORTED_ARCH . keys ()) : logging . critical ( \"Arch invalid: '%s'\" , value ) raise ValueError ( \"Unsupported Architecture\" ) self . _arch = InfGenerator . SUPPORTED_ARCH [ key ] @property def Date ( self ) : return self . _date . strftime ( \"%m/%d/%Y\" ) @Date . setter def Date ( self , value ) : if ( not isinstance ( value , datetime . date )) : raise ValueError ( \"Date must be a datetime.date object\" ) self . _date = value def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) : RollbackString = \"\" if ( Rollback ) : RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"InfGenerator"},{"location":"edk2toollib/windows/capsule/inf_generator/#class-variables","text":"ROLLBACKTEMPLATE SUPPORTED_ARCH TEMPLATE","title":"Class variables"},{"location":"edk2toollib/windows/capsule/inf_generator/#instance-variables","text":"Arch Date Description EsrtGuid Manufacturer Name Provider VersionHex VersionString","title":"Instance variables"},{"location":"edk2toollib/windows/capsule/inf_generator/#methods","text":"","title":"Methods"},{"location":"edk2toollib/windows/capsule/inf_generator/#makeinf","text":"def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ) View Source def MakeInf ( self , OutputInfFilePath , FirmwareBinFileName , Rollback = False ): RollbackString = \"\" if ( Rollback ): RollbackString = InfGenerator . ROLLBACKTEMPLATE . format ( EsrtGuid = self . EsrtGuid ) binfilename = os . path . basename ( FirmwareBinFileName ) Content = InfGenerator . TEMPLATE . format ( Name = self . Name , Date = self . Date , Arch = self . Arch , DriverVersion = self . VersionString , EsrtGuid = self . EsrtGuid , FirmwareBinFile = binfilename , VersionHexString = self . VersionHex , Provider = self . Provider , MfgName = self . Manufacturer , Description = self . Description , Rollback = RollbackString ) with open ( OutputInfFilePath , \"w\" ) as f : f . write ( Content ) return 0","title":"MakeInf"},{"location":"features/logging.ansi_handler/","text":"Logging ANSI Handler This document details the Ansi Handler How to Use from edk2toollib.logging.ansi_handler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter () Usage info ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formatter from the logging package that will insert ANSI codes according to the logging level into the output stream. ColoredStreamHandler Arguments 1. strip Strip will strip ANSI codes if the terminal does not support them (such as windows). 2. convert Convert will convert ANSI codes on windows platforms into windows platform calls. ColoredFormatter Arguments 1. msg The best documentation for this is from Python itself. It\u2019s the same message that\u2019s passed into the formatted base class. 2. use_azure Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI. Purpose To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don\u2019t support ANSI natively.","title":"Logging.ansi handler"},{"location":"features/logging.ansi_handler/#logging-ansi-handler","text":"This document details the Ansi Handler","title":"Logging ANSI Handler"},{"location":"features/logging.ansi_handler/#how-to-use","text":"from edk2toollib.logging.ansi_handler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter ()","title":"How to Use"},{"location":"features/logging.ansi_handler/#usage-info","text":"ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formatter from the logging package that will insert ANSI codes according to the logging level into the output stream.","title":"Usage info"},{"location":"features/logging.ansi_handler/#coloredstreamhandler-arguments","text":"","title":"ColoredStreamHandler Arguments"},{"location":"features/logging.ansi_handler/#1-strip","text":"Strip will strip ANSI codes if the terminal does not support them (such as windows).","title":"1. strip"},{"location":"features/logging.ansi_handler/#2-convert","text":"Convert will convert ANSI codes on windows platforms into windows platform calls.","title":"2. convert"},{"location":"features/logging.ansi_handler/#coloredformatter-arguments","text":"","title":"ColoredFormatter Arguments"},{"location":"features/logging.ansi_handler/#1-msg","text":"The best documentation for this is from Python itself. It\u2019s the same message that\u2019s passed into the formatted base class.","title":"1. msg"},{"location":"features/logging.ansi_handler/#2-use_azure","text":"Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI.","title":"2. use_azure"},{"location":"features/logging.ansi_handler/#purpose","text":"To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don\u2019t support ANSI natively.","title":"Purpose"},{"location":"features/utility_functions.GetHostInfo/","text":"Utility Functions GetHostInfo() This document details the utility function called GetHostInfo. This function was written because tools needed a consistent way to determine attributes about the host system. Purpose Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform. How to Use from edk2toollib.utility_functions import GetHostInfo host_info = GetHostInfo () Usage info GetHostInfo() will return a named tuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein. 1. os - OS Name Windows, Linux, or Java 2. arch - Processor architecture ARM or x86 3. bit - Highest order bit 32 or 64","title":"Utility functions.get host info"},{"location":"features/utility_functions.GetHostInfo/#utility-functions-gethostinfo","text":"This document details the utility function called GetHostInfo. This function was written because tools needed a consistent way to determine attributes about the host system.","title":"Utility Functions GetHostInfo()"},{"location":"features/utility_functions.GetHostInfo/#purpose","text":"Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform.","title":"Purpose"},{"location":"features/utility_functions.GetHostInfo/#how-to-use","text":"from edk2toollib.utility_functions import GetHostInfo host_info = GetHostInfo ()","title":"How to Use"},{"location":"features/utility_functions.GetHostInfo/#usage-info","text":"GetHostInfo() will return a named tuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein.","title":"Usage info"},{"location":"features/utility_functions.GetHostInfo/#1-os-os-name","text":"Windows, Linux, or Java","title":"1. os - OS Name"},{"location":"features/utility_functions.GetHostInfo/#2-arch-processor-architecture","text":"ARM or x86","title":"2. arch - Processor architecture"},{"location":"features/utility_functions.GetHostInfo/#3-bit-highest-order-bit","text":"32 or 64","title":"3. bit - Highest order bit"}]}